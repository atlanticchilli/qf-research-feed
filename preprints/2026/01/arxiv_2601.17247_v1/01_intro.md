---
authors:
- Julius Graf
- Thibaut Mastrolia
doc_id: arxiv:2601.17247v1
family_id: arxiv:2601.17247
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Learning Market Making with Closing Auctions
url_abs: http://arxiv.org/abs/2601.17247v1
url_html: https://arxiv.org/html/2601.17247v1
venue: arXiv q-fin
version: 1
year: 2026
---


Julius Graf111julius.graf@berkeley.edu ‚Äâ and‚Äâ Thibaut Mastrolia222mastrolia@berkeley.edu
  
Department of Industrial Engineering and Operations Research
  
University of California, Berkeley, USA.

###### Abstract

In this work, we investigate the market-making problem on a trading session in which a continuous phase on a limit order book is followed by a closing auction. Whereas standard optimal market-making models typically rely on terminal inventory penalties to manage end-of-day risk, ignoring the significant liquidity events available in closing auctions, we propose a Deep Q-Learning framework that explicitly incorporates this mechanism. We introduce a market-making framework designed to explicitly anticipate the closing auction, continuously refining the projected clearing price as the trading session evolves. We develop a generative stochastic market model to simulate the trading session and to emulate the market. Our theoretical model and Deep Q-Learning method is applied on the generator in two settings: (1) when the mid price follows a rough Heston model with generative data from this stochastic model; and (2) when the mid price corresponds to historical data of assets from the S&P 500 index and the performance of our algorithm is compared with classical benchmarks from optimal market making.

Key words: optimal market making, auction trading, reinforcement learning, Markov Decision Process, Deep Q-Learning, regret analysis.

## 1 Introduction

### 1.1 Reinforcement learning and market making

Market making is a cornerstone of modern electronic financial markets, providing liquidity by continuously posting buy and sell quotes while managing inventory and adverse selection risk with different participants having diverse objectives. Since the seminal work of Avellaneda and Stoikov [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book")] and its extension to explicit solutions in [[28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")], optimal market making has been studied extensively through stochastic control frameworks, leading to tractable strategies that balance expected profit against inventory risk under stylized assumptions on order flow dynamics and price evolution. We refer to [[15](https://arxiv.org/html/2601.17247v1#bib.bib31 "Algorithmic and high-frequency trading")] for a review of the literature on market making and high-frequency trading and to [[5](https://arxiv.org/html/2601.17247v1#bib.bib30 "Algorithmic market making for options"), [6](https://arxiv.org/html/2601.17247v1#bib.bib15 "Market liquidity and competition among designated market makers")] for recent advances in the topic. These models, however, typically rely on parametric assumptions that are difficult to validate empirically and may fail to adapt to the non-stationarity and strategic complexity of real-world markets.

The rapid growth of electronic trading and data availability combined with AI raising influence in financial industry has motivated the use of reinforcement learning as a flexible, data-driven alternative to classical control methods. Reinforcement learning allows a market maker to learn optimal quoting policies directly from interaction with the market, without requiring full knowledge of the underlying dynamics. Recent studies have demonstrated the promise of RL in market making and related problems, showing improved adaptability to complex market conditions, latent regimes, and evolving order flow patterns. The seminal article [[49](https://arxiv.org/html/2601.17247v1#bib.bib56 "Reinforcement learning for optimized trade execution")] introduces a Q-learning algorithm for market making problem on limit order book with many state variables. It has been later extended in for example [[7](https://arxiv.org/html/2601.17247v1#bib.bib6 "Market making via reinforcement learning"), [50](https://arxiv.org/html/2601.17247v1#bib.bib18 "Double deep Q-learning for optimal execution"), [57](https://arxiv.org/html/2601.17247v1#bib.bib54 "Deep learning for limit order books"), [25](https://arxiv.org/html/2601.17247v1#bib.bib57 "Market making with signals through deep reinforcement learning"), [29](https://arxiv.org/html/2601.17247v1#bib.bib29 "Deep reinforcement learning for market making in corporate bonds: beating the curse of dimensionality"), [33](https://arxiv.org/html/2601.17247v1#bib.bib45 "Mbt-gym: reinforcement learning for model-based limit order book trading"), [37](https://arxiv.org/html/2601.17247v1#bib.bib65 "Learning a functional control for high-frequency finance")] and adding regret analysis [[16](https://arxiv.org/html/2601.17247v1#bib.bib53 "Market making without regret"), [12](https://arxiv.org/html/2601.17247v1#bib.bib52 "Logarithmic regret in the ergodic Avellaneda-Stoikov market making model")]. We also refer to [[30](https://arxiv.org/html/2601.17247v1#bib.bib55 "Recent advances in reinforcement learning in finance"), [17](https://arxiv.org/html/2601.17247v1#bib.bib13 "Special issue on machine learning in finance"), [13](https://arxiv.org/html/2601.17247v1#bib.bib14 "Machine learning and data sciences for financial markets: a guide to contemporary practices")] for comprehensive summaries of recent advances in RL techniques in finance.

While the notion of market making is an active topic of research including new developments with reinforcement learning technics, one aspect remains insufficiently explored in the RL-based market making literature. At the end of the day, most of exchanges are closing the market by triggering a closing auction, which plays a fundamental role in price discovery and liquidity provision in modern equity markets. Closing auctions concentrate a significant fraction of daily trading volume and often exhibit dynamics that differ markedly from those observed during continuous trading. Inventory held into the closing auction can be liquidated at a single clearing price, but doing so exposes the market maker to auction-specific price impact, imbalance risk, and strategic interactions. Traditional market making models typically ignore the auction or treat the end-of-day liquidation in an ad-hoc manner, while most reinforcement learning approaches focus exclusively on continuous limit order book trading.

This paper aims to bridge this gap by proposing a reinforcement learning framework for optimal market making that explicitly incorporates regret minimization and a closing auction mechanism. We consider a market maker who operates over a finite horizon, posting bid and ask quotes during continuous trading and facing a terminal liquidation opportunity through a closing auction. The agent does not assume knowledge of the true order arrival intensities, price impact, or auction clearing rules, and instead learns an optimal policy through interaction with the market.

### 1.2 On the importance of (closing) auctions

Early works in financial auctions has been developed in [[36](https://arxiv.org/html/2601.17247v1#bib.bib36 "Continuous auctions and insider trading")]. In this article, Kyle provides the first tractable equilibrium model of a continuous auction with asymmetric information.
It explains how prices aggregate private information through order flow, introducing measure of market depth and price impact. This paper became the benchmark for analyzing liquidity, price discovery, and strategic trading in modern auction-based financial markets. While auction markets have been well-investigated in the economical community for discrete-time model, see for example [[44](https://arxiv.org/html/2601.17247v1#bib.bib28 "Auctions and bidding: a primer"), [59](https://arxiv.org/html/2601.17247v1#bib.bib27 "Optimal dynamic auctions for revenue management"), [43](https://arxiv.org/html/2601.17247v1#bib.bib16 "Putting auction theory to work")] and have known a growing interest, especially since the work of the Nobel laureate Paul Milgrom, it stays challenging at the high frequency-level and for continuous time framework and has been pointed as one of the most challenging question in financial engineering in [[14](https://arxiv.org/html/2601.17247v1#bib.bib40 "The influence of economic research on financial mathematics: evidence from the last 25 years"), Section 5.1].

The big picture of the trading session considered in this paper is the following: along the session a market maker quotes on a limit order book to liquidate her position until the end of the continuous trading time session. Then, the exchange triggers a closing auction for the next minutes of the day. During this auction, order are accumulated by the exchange along time, where participants proposes limit orders at which there are willing to buy or sell the asset with a specific volume, and limit order of the previous continuous trading phase are added as trading block for the auction clearing. At the end of the auction phase, known as the clearing time, a clearing price is set by the exchange to ensure as much transaction as possible to clear the market and trade the asset. This closing auction plays a fundamental role in market liquidation and empowers efficiency of price discovery as explained in [[34](https://arxiv.org/html/2601.17247v1#bib.bib35 "The effect of a closing call auction on market quality and trading strategies"), [53](https://arxiv.org/html/2601.17247v1#bib.bib51 "The growing importance of the closing auction in share trading volumes")]. We also refer to [[45](https://arxiv.org/html/2601.17247v1#bib.bib37 "Auction market design: recent innovations")] for an overview of auction mechanism.

On the one hand, auctions successfully fix mechanical flaws of limit order book like correlation breakdown as explained in [[11](https://arxiv.org/html/2601.17247v1#bib.bib50 "Implementation details for frequent batch auctions: slowing down markets to the blink of an eye")]. On the other hand, unlike a LOB trading, the key challenge of the auction phase is to set an efficient (clearing) price to trade the asset, given the different operations of market participants, known as the price discovery mechanism [[38](https://arxiv.org/html/2601.17247v1#bib.bib34 "Price discovery in auction markets: a look inside the black box"), [8](https://arxiv.org/html/2601.17247v1#bib.bib33 "IPO auctions: english, dutch,‚Ä¶ french, and internet"), [9](https://arxiv.org/html/2601.17247v1#bib.bib32 "Price discovery and learning during the preopening period in the paris bourse")].

The benefit of auctions for market quality, as reducing the spread between the clearing price and the efficient price of a risk asset has been investigated in the recent literature, for example [[20](https://arxiv.org/html/2601.17247v1#bib.bib39 "Welfare and optimal trading frequency in dynamic double auctions"), [51](https://arxiv.org/html/2601.17247v1#bib.bib60 "Optimal auction duration: a price formation viewpoint"), [18](https://arxiv.org/html/2601.17247v1#bib.bib38 "AHEAD: ad hoc electronic auction design"), [56](https://arxiv.org/html/2601.17247v1#bib.bib26 "Equity auction dynamics: latent liquidity models with activity acceleration"), [31](https://arxiv.org/html/2601.17247v1#bib.bib25 "Transaction cost (in) transparency: coasian dynamics in frequent batch auctions")] by proposing incentives and optimal fees scheme to mitigate auctions‚Äô flaws [[40](https://arxiv.org/html/2601.17247v1#bib.bib48 "Clearing time randomization and transaction fees for auction market design"), [41](https://arxiv.org/html/2601.17247v1#bib.bib49 "Optimal rebate design: incentives, competition and efficiency in auction markets")].

### 1.3 Methodology, contributions and financial insights

This work proposes a new market-making model based on a reinforcement learning approach, designed to operate over a typical trading session while explicitly anticipating the closing auction at the end of the session. As far as we know, this paper is the first considering a reinforcement learning method for CLOB optimal market making followed by anticipated closing auciton. The proposed reinforcement learning framework relies on Q-learning, originally introduced in [[61](https://arxiv.org/html/2601.17247v1#bib.bib24 "Q-learning")], and on its extension to Deep Q-Learning using neural networks for strategy exploration and selection [[47](https://arxiv.org/html/2601.17247v1#bib.bib17 "Playing atari with deep reinforcement learning"), [22](https://arxiv.org/html/2601.17247v1#bib.bib20 "A theoretical analysis of deep Q-learning")]. These approaches have been successfully applied to a wide range of financial problems, including optimal asset allocation, optimal execution in dark pools, and market making; see, for instance, [[48](https://arxiv.org/html/2601.17247v1#bib.bib23 "Enhancing Q-learning for optimal asset allocation"), [24](https://arxiv.org/html/2601.17247v1#bib.bib22 "Reinforcement learning for market making in a multi-agent dealer market"), [35](https://arxiv.org/html/2601.17247v1#bib.bib21 "Machine learning for market microstructure and high frequency trading"), [50](https://arxiv.org/html/2601.17247v1#bib.bib18 "Double deep Q-learning for optimal execution"), [5](https://arxiv.org/html/2601.17247v1#bib.bib30 "Algorithmic market making for options")].

More specifically, we compare a standard Q-learning approach for market making with closing auction trading to a neural-fitted Q-learning method. The goal of Q-learning is to find the optimal action-value function QQ which yields the optimal policy. Neural-fitted Q-learning consists in parameterizing the action-value function with a neural network QŒ∏Q\_{\theta} such that optimization over QQ becomes optimization over the weights Œ∏‚àà‚Ñùq\theta\in\mathbb{R}^{q}, for some q‚àà‚Ñï‚àóq\in\mathbb{N}^{\*}. In the Neural Fitted Q-Iteration (NFQ) algorithm, the neural network is trained by minimizing a squared temporal-difference error over a batch of sampled transitions using gradient descent [[55](https://arxiv.org/html/2601.17247v1#bib.bib2 "Neural fitted Q iteration‚Äìfirst experiences with a data efficient neural reinforcement learning method")]. Using a deep neural network for QŒ∏Q\_{\theta} then leads to the Deep Q-Network (DQN) approach. We refer to [[47](https://arxiv.org/html/2601.17247v1#bib.bib17 "Playing atari with deep reinforcement learning")] where QŒ∏Q\_{\theta} was a convolutional neural network (operating on pixels) used to play Atari games and outperform baseline methods. The primary strength of neural-fitted Q-learning is to handle high-dimensional state spaces, as it is the case in our study. The key contribution of DQN is to stabilize Deep Q-Learning through a replay memory ùíü\mathcal{D} with fixed capacity NN: gradient steps are computed using mini-batches from the replay memory, which avoids the issue of correlated samples in trajectory. Training is furthermore stabilized by fixing the training target. One maintains a target Q-network whose parameters are held fixed for several updates and refreshed periodically [[58](https://arxiv.org/html/2601.17247v1#bib.bib5 "Reinforcement learning: an introduction"), [47](https://arxiv.org/html/2601.17247v1#bib.bib17 "Playing atari with deep reinforcement learning"), [46](https://arxiv.org/html/2601.17247v1#bib.bib4 "Human-level control through deep reinforcement learning")].

As a benchmark, we use the optimal market-making model introduced by [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book")] and derived in [[28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")], which allows us to quantitatively assess the efficiency and performance of the Q-learning-based methods considered in this study. We furthermore compare the performance to the time-weighted average price strategy.

The structure of this work is the following. Section [2](https://arxiv.org/html/2601.17247v1#S2 "2 Market model ‚Ä£ Learning Market Making with Closing Auctions") describes the general trading session structure investigated. We first introduce the mathematical framework in Section [2.1](https://arxiv.org/html/2601.17247v1#S2.SS1 "2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"), providing rigorous definitions of all stochastic processes, agents, and market participants involved in the model. The continuous trading phase and the auction phase are respectively described in Sections [2.1.1](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS1 "2.1.1 Trading during the continuous phase [0,ùúè·µí·µñ) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") and [2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").
We then introduce the auction clearing mechanism in Section [2.1.3](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS3 "2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"), where we also state the main theoretical result of this study: the existence of a clearing price under very general supply-demand functions given by Theorem [2.1](https://arxiv.org/html/2601.17247v1#S2.Thmtheorem1 "Theorem 2.1 (Existence of a unique (estimated) clearing price). ‚Ä£ 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"). Section [2.1.4](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS4 "2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") proposes an algorithm to predict a hypothetical clearing price during the limit order book trading session and to anticipate the conversion of unmatched limit orders into trade blocks for the future closing auction. This algorithm lies at the core of our contribution, as it directly links market-making decisions in the continuous phase to the projected outcome of the closing auction.
In Section [3](https://arxiv.org/html/2601.17247v1#S3 "3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions"), we formulate a Markov Decision Process modeling the market dynamics, the actions of the market maker, and the rewards generated by her activity across both the continuous trading phase and the auction phase. Section [4](https://arxiv.org/html/2601.17247v1#S4 "4 Learning market making with closing auction in an unknown environment ‚Ä£ Learning Market Making with Closing Auctions") establishes the regret analysis and introduces the (neural-fitted) Q-learning algorithm employed in our framework. Section [5](https://arxiv.org/html/2601.17247v1#S5 "5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions") recalls the main results of [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book"), [28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")], which we use as a benchmark to compare the profit-and-loss (PnL for short) performance of a market maker who anticipates the closing auction with one who does not. Section [6](https://arxiv.org/html/2601.17247v1#S6 "6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") explains the numerical methods we considered in this work. Section [6.1](https://arxiv.org/html/2601.17247v1#S6.SS1 "6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") introduces the generative stochastic model of the market we use to simulate the Markov Decision Process for the numerical simulations. Section [6.2](https://arxiv.org/html/2601.17247v1#S6.SS2 "6.2 Benchmark simulations ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") presents the simulation for the two benchmark models use for our comparative study. In Section [6.3](https://arxiv.org/html/2601.17247v1#S6.SS3 "6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"), we generate synthetic data using a stylized Heston model for the asset price, combined with limit order book parameters calibrated to reflect the projected future closing auction. Section [6.4](https://arxiv.org/html/2601.17247v1#S6.SS4 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") presents the numerical results obtained when using historical data of S&P 500 assets for the mid price process.

These numerical results highlight the benefits of anticipating the closing auction, as well as the effectiveness of the proposed Q-learning approach in maximizing the market maker‚Äôs PnL over a trading session for both stochastic rough models and historical data from the S&P 500.

## 2 Market model

### 2.1 Mathematical framework and trading phases

Along this work, we fix a probability space (Œ©,‚Ñ±,‚Ñô)(\Omega,\mathcal{F},\mathbb{P}), named the market, where Œ©\Omega represents all the possible market configurations, ‚Ñ±\mathcal{F} is a œÉ\sigma-algebra denoting the available information and ‚Ñô\mathbb{P} is the market probability. We consider a financial asset traded on the financial market along a trading session with price evolving randomly. We divide the trading period into two phases: a continuous phase on a limit order book with market makers and takers and an auction phase, seen as a usual closing auction. We fix
two deterministic times 0<œÑop<œÑcl0<\tau^{\mathrm{op}}<\tau^{\mathrm{cl}} representing respectively the opening and the closing of the auction phase and denote by h=œÑcl‚àíœÑoph=\tau^{\mathrm{cl}}-\tau^{\mathrm{op}} the auction duration. We assume that both (œÑop,œÑcl)‚àà‚Ñï2(\tau^{\mathrm{op}},\tau^{\mathrm{cl}})\in\mathbb{N}^{2} and hh is a positive integer. Therefore, the trading horizon is divided into a continuous phase [0,œÑop)[0,\tau^{\mathrm{op}}), in which the trader interacts with the central limit-order book (CLOB) and a fixed length hh closing auction [œÑop,œÑcl][\tau^{\mathrm{op}},\tau^{\mathrm{cl}}]. In what follows, we consider a fixed time grid 0=t0<‚ãØ<tn<œÑop=tn+1<‚ãØ<tm<œÑcl=tm+10=t\_{0}<\cdots<t\_{n}<\tau^{\mathrm{op}}=t\_{n+1}<\cdots<t\_{m}<\tau^{\mathrm{cl}}=t\_{m+1} for n‚àà‚Ñï‚àón\in\mathbb{N}^{\*} and m‚àà‚Ñï‚àóm\in\mathbb{N}^{\*}.

We denote by ItI\_{t} the trader‚Äôs inventory at time tt. This inventory is positive (resp. negative) for long position (resp. short positions) with respect to the traded risky asset.

We denote by Œ±>0\alpha>0 the tick size of the asset, fixed by the exchange. We will consider three types of market participants in this study:

* ‚Ä¢

  a strategic market maker, named the agent, setting limit orders along the day,
* ‚Ä¢

  exogenous market makers, fixing limit orders and providing liquidity during the continuous trading session on both side of the LOB and proposing limit prices during the auction session,
* ‚Ä¢

  exogenous market takers. These participants submit aggressive market orders during both the CLOB and the auction phases to buy or sell the asset.

While we will focus on the optimization of the agent along the day, we use the term exogenous to emphasize the fact that other market makers and takers‚Äô optimizations are not considered here. We now turn to the details of the trading period [0,œÑop)‚à™[œÑop,œÑcl][0,\tau^{\mathrm{op}})\cup[\tau^{\mathrm{op}},\tau^{\mathrm{cl}}] composed by continuous trading activities on the CLOB followed by a closing auction.

#### 2.1.1 Trading during the continuous phase [0,œÑop)[0,\tau^{\mathrm{op}})

During the continuous phase on the LOB, we assume that each market participant observes the mid price Stmid=Œ±‚ÄãktmidS\_{t}^{\mathrm{mid}}=\alpha k\_{t}^{\mathrm{mid}} at any time t<œÑopt<\tau^{\mathrm{op}}, where ktmid‚àà‚Ñïk^{\mathrm{mid}}\_{t}\in\mathbb{N} represents the number of tick at which the mid price is priced. Exogenous market takers take submit market orders on both side of the market and consume liquidity. The number of market taker arriving on the side Œ∂‚àà{+,‚àí}\zeta\in\{+,-\} follows a counting process denoted by NŒ∂N^{\zeta}, where Œ∂=+\zeta=+ denotes the ask side, and Œ∂=‚àí\zeta=- the bid side. In other words, NtŒ∂N\_{t}^{\zeta} market takers have arrived on the side Œ∂\zeta. We assume that each market taker i‚â§NtŒ∂i\leq N\_{t}^{\zeta} submits a market order with volume ŒΩtŒ∂,i\nu\_{t}^{\zeta,i} on the Œ∂\zeta side of the CLOB at time tt.

The agent is a market maker and submit limit orders characterized by a limit price denoted by St‚àô=Œ±‚ÄãktS\_{t}^{\bullet}=\alpha k\_{t} at time tt where ktk\_{t} denoted the number of tick chosen at time tt to price the asset, and a proposed volume vtv\_{t}. The agent therefore submits an order characterized by the pair (kt,vt)(k\_{t},v\_{t}) at time tt on the limit order book. We assume that the agent is selling her inventory II on the LOB during the continuous phase. This order is thus a limit order on vt‚â§Itv\_{t}\leq I\_{t} shares at price St‚àô=Œ±‚ÄãktS\_{t}^{\bullet}=\alpha k\_{t}.

###### Remark 2.1.

Note that Œ¥t:=kt‚àíktmid\delta\_{t}:=k\_{t}-k\_{t}^{\mathrm{mid}} represents the number of tick between the sell limit order proposed by the agent and the mid price, seen as the ask-spread of the agent.

The liquidity provided by exogenous market makers at price level StŒ∂,j=Œ±‚ÄãktŒ∂,jS\_{t}^{\zeta,j}=\alpha k\_{t}^{\zeta,j}, where ktŒ∂,j=ktmid+Œ∂‚Äãjk\_{t}^{\zeta,j}=k\_{t}^{\mathrm{mid}}+\zeta j for j‚àà‚Ñ§j\in\mathbb{Z} and Œ∂‚àà{+,‚àí}\zeta\in\{+,-\} is given by the volume VtŒ∂,jV\_{t}^{\zeta,j} at any time tt. The depth of the order book on side Œ∂\zeta is given by

|  |  |  |
| --- | --- | --- |
|  | LtŒ∂=inf{j‚â•1:VtŒ∂,j=0}.L\_{t}^{\zeta}=\inf\{j\geq 1:V\_{t}^{\zeta,j}=0\}. |  |

###### Assumption 1.

We assume that all market orders are always executed at any time tt during the LOB session.

Note that this assumption is justified by empirical evidence: market takers are in general small investors. It is consistent with [[51](https://arxiv.org/html/2601.17247v1#bib.bib60 "Optimal auction duration: a price formation viewpoint")] assuming that the LOB is never empty. Regarding now the execution of the limit orders sent by the agent, we will enforce the following assumption.

###### Assumption 2.

The agent is always executed with priority at a fixed depth of the CLOB, i.e., she systematically posts her orders at a predetermined price level and is assumed to be the fastest participant at that level.

In view of this assumption, we can see our agent as a high-frequency trader having a time advantage with respect to other participants.

###### Remark 2.2.

Based on the random arrivals of market takers, there is (at least partial) execution on the order of the agent if given that a market taker arrives at time tt the following condition is satisfied

|  |  |  |
| --- | --- | --- |
|  | ‚àëi=Nt‚àí+Nt+ŒΩt+,i>‚àëj<ktVt+,j.\sum\_{i=N\_{t-}^{+}}^{N\_{t}^{+}}\nu\_{t}^{+,i}>\sum\_{j<k\_{t}}V\_{t}^{+,j}. |  |

Note that as soon as the buying volume of market takers reaches selling index ktk\_{t} of the agent, her order gets (at least partially) executed.

The number of executed shares at time tt of the agent is then given by

|  |  |  |
| --- | --- | --- |
|  | Et=max‚Å°(0,min‚Å°(vt,‚àëi=Nt‚àí+Nt+ŒΩt+,i‚àí‚àëj<Œ¥tVt+,j)).E\_{t}=\max\left(0,\min\left(v\_{t},\sum\_{i=N\_{t-}^{+}}^{N\_{t}^{+}}\nu\_{t}^{+,i}-\sum\_{j<{\delta\_{t}}}V\_{t}^{+,j}\right)\right). |  |

We recall that EtE\_{t} is a random variable since vtv\_{t} and Vt+,jV\_{t}^{+,j} are random. The inventory of the agent between tt and t+Œî‚Äãtt+\Delta t is It+Œî‚Äãt=It‚àíEtI\_{t+\Delta t}=I\_{t}-E\_{t} for t‚àà[0,œÑop)t\in[0,\tau^{\mathrm{op}}) and some Œî‚Äãt>0\Delta t>0.

Motivated by the reinforcement learning approach, we assume that the agent will trade during this session until a fixed deterministic time tn<œÑopt\_{n}<\tau^{\mathrm{op}} before the market switch to the closing auction phase, where nn denotes the number of operations made by the agent along the CLOB session.

#### 2.1.2 Trading during the auction phase [œÑop,œÑcl)[\tau^{\mathrm{op}},\tau^{\mathrm{cl}})

At time œÑop\tau^{\mathrm{op}}, the system transitions to an auction, opened by the exchange. Similarly to [[18](https://arxiv.org/html/2601.17247v1#bib.bib38 "AHEAD: ad hoc electronic auction design"), [40](https://arxiv.org/html/2601.17247v1#bib.bib48 "Clearing time randomization and transaction fees for auction market design")] and motivated by the reinforcement learning approach with the Markov Decision Process modeling the agent interacting with the market, we assume that the agent is setting bids at deterministic fixed time along the auction duration.

###### Assumption 3.

The agent bids along the auction at discrete times œÑop=tn+1<‚ãØ<tm<œÑcl\tau^{\mathrm{op}}=t\_{n+1}<\dots<t\_{m}<\tau^{\mathrm{cl}}.

The inventory IœÑopI\_{\tau^{\mathrm{op}}} of the agent remaining from the continuous phase, i.e. that has not been liquidated, is then traded on this auction. More precisely, for all t‚àà{tn+1,‚Ä¶,tm}t\in\{t\_{n+1},\dots,t\_{m}\}, the agent observes exogenous market and limit orders arriving on the auction. Market orders are composed by a certain volume to be bought/sold no matter the price is set at the clearing time by the exchange, while limit orders are set along the auction through a supply function (functional volume to sell/buy below/above a certain price). Every market participant can cancel prior orders, unlike in the continuous trading phase. The agent chooses an action, which will be a limit order to submit, and/or the cancellation of a previous order. In this sense, the agent reacts to the environment (since he posts his order after seeing the orders of other market participants). After his final action at the terminal trading time tm<œÑclt\_{m}<\tau^{\mathrm{cl}}, the system transitions to a final state that will allow to compute the clearing price and the exchanged volume, thus allows to compute the terminal reward of the agent. Exogenous market participants do not modify their offers from tmt\_{m} to œÑcl\tau^{\mathrm{cl}}. Solely the agent can cancel his older orders and submit a final limit order. Similarly to [[20](https://arxiv.org/html/2601.17247v1#bib.bib39 "Welfare and optimal trading frequency in dynamic double auctions"), [51](https://arxiv.org/html/2601.17247v1#bib.bib60 "Optimal auction duration: a price formation viewpoint"), [41](https://arxiv.org/html/2601.17247v1#bib.bib49 "Optimal rebate design: incentives, competition and efficiency in auction markets")] we assume that the agent submit a linear supply curve to the auction stated in the following assumption.

###### Assumption 4.

The agent has a linear supply curve Œ£t:p‚ààŒ±‚Äã‚Ñï‚üºKta‚Äã(p‚àíSta)\Sigma\_{t}:p\in\alpha\mathbb{N}\longmapsto K\_{t}^{a}(p-S\_{t}^{a}) for all t‚â•œÑopt\geq\tau^{\mathrm{op}}, where Kta‚â•0K\_{t}^{a}\geq 0 and Sta‚ààŒ±‚Äã‚ÑïS\_{t}^{a}\in\alpha\mathbb{N}.

At each tj‚àà{tn+1,‚Ä¶,tm}t\_{j}\in\{t\_{n+1},\dots,t\_{m}\} the agent controls Ktja‚â•0K\_{t\_{j}}^{a}\geq 0 and Stja‚ààŒ±‚Äã‚ÑïS\_{t\_{j}}^{a}\in\alpha\mathbb{N} so that Œ£tj‚Äã(p)\Sigma\_{t\_{j}}(p) represents the number of shares the agent is willing to sell at price pp. If Œ£tj‚Äã(p)‚â§0\Sigma\_{t\_{j}}(p)\leq 0 the agent is willing to buy at price pp or below and conversely if Œ£tj‚Äã(p)‚â•0\Sigma\_{t\_{j}}(p)\geq 0 the agent is willing to sell at price pp or above. We let the supply function unsigned, but the agent will be penalized for dealing on the wrong side i.e., as a buyer while he is supposed to be a seller, similarly to [[40](https://arxiv.org/html/2601.17247v1#bib.bib48 "Clearing time randomization and transaction fees for auction market design")].

We allow the agent to cancel her past bids at unit cost d>0d>0. Let ctj‚àà{0,1}m‚àínc\_{t\_{j}}\in\{0,1\}^{m-n} where ctj(s)=1c\_{t\_{j}}^{(s)}=1 if and only if the order at time tn+st\_{n+s} for s‚àà{1,‚Ä¶,j‚àí1‚àín}s\in\{1,\ldots,j-1-n\} is canceled exactly at time tjt\_{j} for j‚àà{n+1,‚Ä¶,m}j\in\{n+1,\ldots,m\}. In particular, ctn+1=ùüéc\_{t\_{n+1}}=\mathbf{0} where ùüé\mathbf{0} is the m‚àínm-n-vector with 0 components. We further set Œ∏tn=ùüé\theta\_{t\_{n}}=\mathbf{0} and define Œ∏tn+1=ùüé\theta\_{t\_{n+1}}=\mathbf{0} and Œ∏tj=Œ∏tj‚àí1+ctj\theta\_{t\_{j}}=\theta\_{t\_{j-1}}+c\_{t\_{j}}. We write ‚Äñct‚Äñ1\|c\_{t}\|\_{1} the number of cancellations performed at an auction trading time time t‚àà{tn+1,‚Ä¶,tm}t\in\{t\_{n+1},\dots,t\_{m}\}. Note that t‚Ü¶‚ÄñŒ∏t‚Äñ1t\mapsto\|\theta\_{t}\|\_{1} is increasing. The agent cancels only once a past order, so that we impose the constraint ctj‚â§ùüè‚àíŒ∏tj‚àí1c\_{t\_{j}}\leq\mathbf{1}-\theta\_{t\_{j-1}} (for ùüè\mathbf{1} the m‚àínm-n-vector with 1 components) to ensure that if ctj(s)=1c\_{t\_{j}}^{(s)}=1 for some tn+s<tjt\_{n+s}<t\_{j}, then ctj+1(s)=0c\_{t\_{j+1}}^{(s)}=0, for s‚àà{1,‚Ä¶,m‚àín}s\in\{1,\ldots,m-n\}.

At each trading time t‚àà{tn+1,‚Ä¶,tm}t\in\{t\_{n+1},\dots,t\_{m}\}, the agent submits an order (Kta,Sta,ct)(K\_{t}^{a},S\_{t}^{a},c\_{t}) to the market. Note that with the definition above, ctc\_{t} has no impact on the order (Kta,Sta)(K\_{t}^{a},S\_{t}^{a}), only on orders sent at time strictly before tt. The inventory of the agent remains frozen during the auction, i.e. It=IœÑopI\_{t}=I\_{\tau^{\mathrm{op}}} for t<œÑclt<\tau^{\mathrm{cl}}.

During the auction, we suppose in addition that both exogenous market makers and market takers are present in the auction and that the agent has access to full information on their activities. At each trading time tt, the number of bids sent by exogenous market makers is denoted by MtM\_{t}. Each bid sent by these actors is a limit orders, each with volume gi,t‚Äã(p)g\_{i,t}(p), which is the supply schedule of the ii-th bid offer present at time tt for i‚â§Mti\leq M\_{t}. As for the agent, we assume that the other market makers are not "signed", meaning that they are willing to be either seller or buyer depending on the clearing price set by the exchange at œÑcl\tau^{\mathrm{cl}}.

Market takers submit market orders in the auction. Let Nt+N\_{t}^{+} (resp. Nt‚àíN\_{t}^{-}) be the number of selling (resp. buying) market orders arrived up to time t‚àà{tn+1,‚Ä¶,tm}t\in\{t\_{n+1},\dots,t\_{m}\}. For Œ∂‚àà{+,‚àí}\zeta\in\{+,-\}, market taker i‚â§NtŒ∂i\leq N\_{t}^{\zeta} submits a volume ŒΩtŒ∂,i\nu\_{t}^{\zeta,i}. Market takers can cancel their order along the auction, for instance, volume ŒΩtn+sŒ∂,i\nu\_{t\_{n+s}}^{\zeta,i} can be set to zero at a time tjt\_{j} should the market maker of the ii-th bid on side Œ∂\zeta decide to cancel his order from time tj‚àí1t\_{j-1} to tjt\_{j}, with i‚â§Ntj‚àí1Œ∂i\leq N\_{t\_{j-1}}^{\zeta}, for all j‚àà{n+1,‚Ä¶,m}j\in\{n+1,\dots,m\} and s‚àà{1,‚Ä¶,j‚àí1‚àín}s\in\{1,\dots,j-1-n\}. If no cancellation occurs, we keep ŒΩtj‚àí1Œ∂,i=ŒΩtjŒ∂,i\nu\_{t\_{j-1}}^{\zeta,i}=\nu\_{t\_{j}}^{\zeta,i} for i‚â§Ntj‚àí1Œ∂i\leq N\_{t\_{j-1}}^{\zeta}. New market orders having arrived at time tt are thus indexed by Ntj‚àí1Œ∂<i‚â§NtjŒ∂N\_{t\_{j-1}}^{\zeta}<i\leq N\_{t\_{j}}^{\zeta}.

#### 2.1.3 Clearing price rule and estimation along the auction

After time tmt\_{m}, the system moves into a final stage to set the clearing price of the auction. The market makers and takers can first send a last order in the auction, then the agent can still send a final limit order and/or cancel past ones. At time t=œÑclt=\tau^{\mathrm{cl}}, the auction matches total demand and supply to maximize the exchanged volume at a uniform clearing price SœÑclclS\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}. The clearing price SœÑclclS\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}} solves the equation

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚àëi=1Mtmgi,tm‚Äã(p)+‚àës=n+1m(1‚àíŒ∏œÑcl(s))‚ÄãKtsa‚Äã(p‚àíStsa)+‚àëŒ∂‚àà{+,‚àí}‚àëi=1NtmŒ∂Œ∂‚ÄãŒΩtmŒ∂,i=0,¬†for¬†‚Äãp‚àà‚Ñù+.\sum\_{i=1}^{M\_{t\_{m}}}g\_{i,t\_{m}}(p)+\sum\_{s=n+1}^{m}\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)K\_{t\_{s}}^{a}(p-S\_{t\_{s}}^{a})+\sum\_{\zeta\in\{+,-\}}\sum\_{i=1}^{N\_{t\_{m}}^{\zeta}}\zeta\nu\_{t\_{m}}^{\zeta,i}=0,\text{ for }p\in\mathbb{R}^{+}. |  | (1) |

Along the auction, we assume that the agent computes the projected clearing price by solving the equation

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚àëi=1Mtj‚àí1gi,tj‚àí1‚Äã(p)+‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa‚Äã(p‚àíStsa)+‚àëŒ∂‚àà{+,‚àí}‚àëi=1Ntj‚àí1Œ∂Œ∂‚ÄãŒΩtj‚àí1Œ∂,i=0,¬†for¬†‚Äãp‚àà‚Ñù+\sum\_{i=1}^{M\_{t\_{j-1}}}g\_{i,t\_{j-1}}(p)+\sum\_{s=n+1}^{j-1}\left(1-\theta\_{t\_{j}}^{(s)}\right)K\_{t\_{s}}^{a}(p-S\_{t\_{s}}^{a})+\sum\_{\zeta\in\{+,-\}}\sum\_{i=1}^{N\_{t\_{j-1}}^{\zeta}}\zeta\nu\_{t\_{j-1}}^{\zeta,i}=0,\text{ for }p\in\mathbb{R}^{+} |  | (2) |

which is the clearing price equation were the auction to close at time tj‚àà{tn+2,‚Ä¶,tm}‚à™{œÑcl}t\_{j}\in\{t\_{n+2},\ldots,t\_{m}\}\cup\{\tau^{\mathrm{cl}}\}. The estimation at time tj=œÑclt\_{j}=\tau^{\mathrm{cl}} corresponds to solve ([1](https://arxiv.org/html/2601.17247v1#S2.E1 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) fitting with the exchange clearing rule. We now provide sufficient conditions on ensuring existence of a solution to equation ([2](https://arxiv.org/html/2601.17247v1#S2.E2 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")). Note that this condition is not necessary since for linear supply and demand curve for the agent there always exists a solution, see Proposition [2.1](https://arxiv.org/html/2601.17247v1#S2.Thmproposition1 "Proposition 2.1 (Linear supply curve). ‚Ä£ 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") below. This theorem is however the first one as far as we know building a quantitative clearing rule for general supply and demand curve function for an active agent in an auction.

###### Theorem 2.1 (Existence of a unique (estimated) clearing price).

Let tj‚àà{tn+2,‚Ä¶,tm}‚à™{œÑcl}t\_{j}\in\{t\_{n+2},\ldots,t\_{m}\}\cup\{\tau^{\mathrm{cl}}\}. Assume that limp‚Üí¬±‚àûgi,tj‚àí1‚Äã(p)=¬±‚àû\lim\limits\_{p\to\pm\infty}g\_{i,t\_{j-1}}(p)=\pm\infty and p‚üºgi,tj‚Äã(p)p\longmapsto g\_{i,t\_{j}}(p) is continuous and increasing for any i‚â§Mtj‚àí1i\leq M\_{t\_{j-1}}. Assume moreover that one of the following condition is satisfied

* (a)

  ‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa=0\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}=0,
* (b)

  ‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa>0\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}>0 and gi,tj‚àí1g\_{i,t\_{j-1}} are Lipschitz uniformly in ii, that is there exists a constant Ltj>0L\_{t\_{j}}>0 such that for any exogenous market maker i‚â§Mtj‚àí1i\leq M\_{t\_{j-1}} we have

  |  |  |  |
  | --- | --- | --- |
  |  | |gi,tj‚àí1‚Äã(p)‚àígi,tj‚àí1‚Äã(p~)|‚â§Ltj‚Äã|p‚àíp~|.|g\_{i,t\_{j-1}}(p)-g\_{i,t\_{j-1}}(\tilde{p})|\leq L\_{t\_{j}}|p-\tilde{p}|. |  |

  Let

  |  |  |  |
  | --- | --- | --- |
  |  | Œªtj:=Mtj‚àí1‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa,\lambda\_{t\_{j}}:=\frac{M\_{t\_{j-1}}}{\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}}, |  |

  with Ltj<1ŒªtjL\_{t\_{j}}<\frac{1}{\lambda\_{t\_{j}}}.

Then, the estimated clearing price equation ([2](https://arxiv.org/html/2601.17247v1#S2.E2 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) admits a unique solution.

Condition (a) reflects the absence of the agent in the auction. The estimated clearing price can still be set by the agent by observing the activities of other participants. In this case, the clearing price is estimated as the equilibrium between limit orders of exogenous market makers and takers only. Condition (b) corresponds to a situation in which the agent has provided active liquidity in the auction at time tjt\_{j}.

###### Proof of Theorem [2.1](https://arxiv.org/html/2601.17247v1#S2.Thmtheorem1 "Theorem 2.1 (Existence of a unique (estimated) clearing price). ‚Ä£ 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").

Regarding Case (a), the existence of a solution to ([2](https://arxiv.org/html/2601.17247v1#S2.E2 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) follows directly from the properties of gi,tj‚àí1g\_{i,t\_{j-1}} (increasing, continuous with its limit conditions). Now, consider Case (b) and suppose that the agent has sent at least one order, that is, ‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa>0\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}>0. Define

|  |  |  |
| --- | --- | --- |
|  | œï‚Äã(p)=‚àí‚àëi=1Mtj‚àí1gi,tj‚àí1‚Äã(p)+‚àëŒ∂‚àà{+,‚àí}‚àëi=1Ntj‚àí1Œ∂Œ∂‚ÄãŒΩtj‚àí1Œ∂,i‚àí‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa‚ÄãStsa‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa.\phi(p)=-\frac{\sum\_{i=1}^{M\_{t\_{j-1}}}g\_{i,t\_{j-1}}(p)+\sum\_{\zeta\in\{+,-\}}\sum\_{i=1}^{N\_{t\_{j-1}}^{\zeta}}\zeta\nu\_{t\_{j-1}}^{\zeta,i}-\sum\_{s=n+1}^{j-1}\left(1-\theta\_{t\_{j}}^{(s)}\right)K\_{t\_{s}}^{a}S\_{t\_{s}}^{a}}{\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}}. |  |

We want to ensure the existence of a fixed point of œï\phi. for any price p,p~‚àà‚Ñùp,\tilde{p}\in\mathbb{R} we have

|  |  |  |
| --- | --- | --- |
|  | |œï‚Äã(p)‚àíœï‚Äã(p~)|‚â§‚àëi=1Mtj‚àí1|gi,tj‚àí1‚Äã(p)‚àígi,tj‚àí1‚Äã(p~)|‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa‚â§Œªtj‚ÄãLtj‚Äã|p‚àíp~|.|\phi(p)-\phi(\tilde{p})|\leq\frac{\sum\_{i=1}^{M\_{t\_{j-1}}}|g\_{i,t\_{j-1}}(p)-g\_{i,t\_{j-1}}(\tilde{p})|}{\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}}\leq\lambda\_{t\_{j}}L\_{t\_{j}}|p-\tilde{p}|. |  |

As soon as Ltj‚ÄãŒªtj<1L\_{t\_{j}}\lambda\_{t\_{j}}<1, the function œï\phi is a contraction map on ‚Ñù\mathbb{R}.
‚àé

###### Corollary 2.1.

Assume that the assumptions of Theorem [2.1](https://arxiv.org/html/2601.17247v1#S2.Thmtheorem1 "Theorem 2.1 (Existence of a unique (estimated) clearing price). ‚Ä£ 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") in the case (b) are satisfied with ‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa‚â•K¬Ø>0\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}\geq\underline{K}>0, and moreover Mtj‚àí1M\_{t\_{j-1}} is bounded by M¬Ø>0\overline{M}>0. Then by choosing Ltj=(1‚àíŒµ)‚ÄãK¬Ø/M¬ØL\_{t\_{j}}=(1-\varepsilon)\underline{K}/\overline{M}-Lipschitz with Œµ>0\varepsilon>0, there exists a unique clearing price solving the clearing rule ([1](https://arxiv.org/html/2601.17247v1#S2.E1 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")).

###### Proof.

The proof is a direct consequence of the definition of Œªt‚àíj\lambda\_{t-j} checking that Ltj:=(1‚àíŒµ)‚ÄãK¬Ø/M¬Ø<1ŒªtjL\_{t\_{j}}:=(1-\varepsilon)\underline{K}/\overline{M}<\frac{1}{\lambda\_{t\_{j}}}.
‚àé

###### Remark 2.3.

The additional condition in Corollary [2.1](https://arxiv.org/html/2601.17247v1#S2.Thmcorollary1 "Corollary 2.1. ‚Ä£ 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") is equivalent to assume that at time tjt\_{j} the agent has submitted at least one active order in the auction without canceling it before time tjt\_{j}.

Finally and as we have mentioned earlier, our clearing rule recover the one stated in [[51](https://arxiv.org/html/2601.17247v1#bib.bib60 "Optimal auction duration: a price formation viewpoint")] or [[41](https://arxiv.org/html/2601.17247v1#bib.bib49 "Optimal rebate design: incentives, competition and efficiency in auction markets")] for linear supply and demand curve as stated in the following proposition.

###### Proposition 2.1 (Linear supply curve).

Assume that gi,t‚Äã(p)=Kti‚Äã(p‚àíSti)g\_{i,t}(p)=K\_{t}^{i}(p-S\_{t}^{i}). Then there exists a unique clearing price solving ([1](https://arxiv.org/html/2601.17247v1#S2.E1 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) and given by

|  |  |  |
| --- | --- | --- |
|  | p=‚àëi=1Mtj‚àí1Ktj‚àí1i‚ÄãStj‚àí1i+‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa‚ÄãStsa‚àí‚àëŒ∂‚àà{+,‚àí}‚àëi=1Ntj‚àí1Œ∂Œ∂‚ÄãŒΩtj‚àí1Œ∂,i‚àëi=1Mtj‚àí1Ktj‚àí1i+‚àës=n+1j‚àí1(1‚àíŒ∏tj(s))‚ÄãKtsa.p=\frac{\sum\_{i=1}^{M\_{t\_{j-1}}}K\_{t\_{j-1}}^{i}S\_{t\_{j-1}}^{i}+\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}S\_{t\_{s}}^{a}-\sum\_{\zeta\in\{+,-\}}\sum\_{i=1}^{N\_{t\_{j-1}}^{\zeta}}\zeta\nu\_{t\_{j-1}}^{\zeta,i}}{\sum\_{i=1}^{M\_{t\_{j-1}}}K\_{t\_{j-1}}^{i}+\sum\_{s=n+1}^{j-1}(1-\theta\_{t\_{j}}^{(s)})K\_{t\_{s}}^{a}}. |  |

From now on, we assume that such an estimated clearing price exists and given as the solution to ([1](https://arxiv.org/html/2601.17247v1#S2.E1 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) at any time tjt\_{j} during the auction.

Note that the executed volume of the agent at the clearing time is given by

|  |  |  |
| --- | --- | --- |
|  | ZœÑcl=‚àës=n+1m(1‚àíŒ∏œÑcl(s))‚ÄãKtsa‚Äã(SœÑclcl‚àíStsa)Z\_{\tau^{\mathrm{cl}}}=\sum\_{s=n+1}^{m}\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)K\_{t\_{s}}^{a}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right) |  |

so that IœÑcl=IœÑop‚àíZœÑclI\_{\tau^{\mathrm{cl}}}=I\_{\tau^{\mathrm{op}}}-Z\_{\tau^{\mathrm{cl}}}. Notice that also volume that has been dealed as a buyer will get executed, although the agent is supposed to act as a seller. To account for dealing on the wrong side, the agent will be penalized by receiving a reward penalization on the volumes dealt on the wrong side to compute the objective function in the next section with the Markov Decision Process modeling.

#### 2.1.4 Projected hypothetical clearing price during the continuous session

During the continuous phase [0,œÑop)[0,\tau^{\mathrm{op}}), we assume that the agent is estimating the clearing price of the auction. For that purpose, the agent observes all outstanding (unexecuted) limit orders and treats them as if they were submitted to a fictitious auction, where they would be jointly matched to infer the implied clearing price. The agent is then creating a projected hypothetical clearing price HtclH\_{t}^{\mathrm{cl}} along the duration of the LOB trading before the closing auction starts. The computation is detailed in algorithm [1](https://arxiv.org/html/2601.17247v1#alg1 "Algorithm 1 ‚Ä£ 2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"), the calibration of the different characteristics of the auction prices and parameters comes from [[51](https://arxiv.org/html/2601.17247v1#bib.bib60 "Optimal auction duration: a price formation viewpoint")].

Algorithm 1  Computation of HticlH\_{t\_{i}}^{\mathrm{cl}} for ti‚àà‚ü¶0,tn‚üßt\_{i}\in\llbracket 0,t\_{n}\rrbracket

0:‚ÄÇTick size Œ±>0\alpha>0, smoothing parameter œÑ‚àà(0,1]\tau\in(0,1], initial value H0H\_{0}

1:‚ÄÇInitialize H0cl‚ÜêH0H\_{0}^{\mathrm{cl}}\leftarrow H\_{0}

2:‚ÄÇfor i=1,‚Ä¶,ni=1,\dots,n do

3:‚ÄÉ‚ÄÇRecord standing orders before time tit\_{i} by set Oi‚äÜ(Œ±‚Äã‚Ñ§)√ó‚ÑïO\_{i}\subseteq(\alpha\mathbb{Z})\times\mathbb{N}

4:‚ÄÉ‚ÄÇùí≥i‚Üêproj1‚Å°(Oi)/Œ±\mathcal{X}\_{i}\leftarrow\operatorname{proj}\_{1}(O\_{i})/\alpha {Standing price levels}

5:‚ÄÉ‚ÄÇùí±i‚Üêproj2‚Å°(Oi)\mathcal{V}\_{i}\leftarrow\operatorname{proj}\_{2}(O\_{i}) {Standing volumes}

6:‚ÄÉ‚ÄÇfor k‚ààùí≥ik\in\mathcal{X}\_{i} do

7:‚ÄÉ‚ÄÉ‚ÄÇe^ik‚Üê1i‚Äã‚àës=1i‚àëv‚ààùí±sv‚ÄãùüèOs‚Äã((Œ±‚Äãk,v))\hat{e}\_{i}^{k}\leftarrow\frac{1}{i}\sum\_{s=1}^{i}\sum\_{v\in\mathcal{V}\_{s}}v\mathbf{1}\_{O\_{s}}((\alpha k,v)) {Average volume available at level kk}

8:‚ÄÉ‚ÄÉ‚ÄÇœÇ^ik‚Üê1i‚Äã‚àës=1i(‚àëv‚ààùí±sv‚ÄãùüèOs‚Äã((Œ±‚Äãk,v)))2\hat{\varsigma}\_{i}^{k}\leftarrow\frac{1}{i}\sum\_{s=1}^{i}\left(\sum\_{v\in\mathcal{V}\_{s}}v\mathbf{1}\_{O\_{s}}((\alpha k,v))\right)^{2} {Average squared volume available at level kk}

9:‚ÄÉ‚ÄÉ‚ÄÇK^ik‚Üê(2‚Äãe^ik‚àíœÇ^ik/e^ik)‚ÄãŒ±‚àí1\hat{K}\_{i}^{k}\leftarrow(2\hat{e}\_{i}^{k}-\hat{\varsigma}\_{i}^{k}/\hat{e}\_{i}^{k})\alpha^{-1} {Calibrated slope at level kk}

10:‚ÄÉ‚ÄÇend for

11:‚ÄÉ‚ÄÇSolve ‚àëk‚ààùí≥iK^ik‚Äã(Œ±‚Äãk‚àíp)=0\sum\_{k\in\mathcal{X}\_{i}}\hat{K}\_{i}^{k}(\alpha k-p)=0 for pp and denote the solution S~ti\tilde{S}\_{t\_{i}} {Clearing price rule}

12:‚ÄÉ‚ÄÇHticl‚ÜêHti‚àí1cl+œÑ‚Äã(S~ti‚àíHti‚àí1cl)H\_{t\_{i}}^{\mathrm{cl}}\leftarrow H\_{t\_{i-1}}^{\mathrm{cl}}+\tau(\tilde{S}\_{t\_{i}}-H\_{t\_{i-1}}^{\mathrm{cl}}) {Smoothed update rule}

13:‚ÄÇend for

###### Remark 2.4.

In Algorithm [1](https://arxiv.org/html/2601.17247v1#alg1 "Algorithm 1 ‚Ä£ 2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"), we implicitly assume OiO\_{i} to be non-empty for all i‚àà‚ü¶1,œÑop‚àí1‚üßi\in\llbracket 1,\tau^{\mathrm{op}}-1\rrbracket which follows from Assumption [1](https://arxiv.org/html/2601.17247v1#Thmassumption1 "Assumption 1. ‚Ä£ 2.1.1 Trading during the continuous phase [0,ùúè·µí·µñ) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"), all market orders get executed. Thus, we implicitly assume that the edge case, in which there are as many limit orders as market orders on both sides, does not occur in practice.

Finally, the agent is penalized for submitting orders below the clearing price estimate HticlH\_{t\_{i}}^{\mathrm{cl}}. This is because an order with a price below the hypothetical clearing price would tell the agent to rather wait for the auction to liquidate her shares. This penalty will be detailed in the next section as a penalization for the reward function.

## 3 Markov Decision Process and dynamic programming for optimal market making with closing auction

We now turn to the discretization of the problem. In order to well defined the Markov Decision Process associated to the market modeling, we need to enforce the following assumption for the time grid (tj)j‚àà‚ü¶0,n‚üß(t\_{j})\_{j\in\llbracket 0,n\rrbracket} before the closing auction‚Äôs opening.

###### Assumption 5.

For all j‚àà‚ü¶1,n‚üßj\in\llbracket 1,n\rrbracket and Œ∂‚àà{+,‚àí}\zeta\in\{+,-\}, the discretization (tj)1‚â§j‚â§n(t\_{j})\_{1\leq j\leq n} satisfies NtjŒ∂>Ntj‚àí1Œ∂N\_{t\_{j}}^{\zeta}>N\_{t\_{j-1}}^{\zeta} ‚Ñô\mathbb{P}-almost surely.

Let ùíØ={ti;i‚àà‚ü¶0,œÑcl‚üß}\mathcal{T}=\{t\_{i};\,i\in\llbracket 0,\tau^{\mathrm{cl}}\rrbracket\}. In the following, we simplify the notations by replacing tit\_{i} with the index ii for any i‚àà‚ü¶0,m+1‚üßi\in\llbracket 0,m+1\rrbracket so that n=œÑop‚àí1n=\tau^{\mathrm{op}}-1 and m=œÑcl‚àí1m=\tau^{\mathrm{cl}}-1. Note that this is an abuse of notation since the discretization has to be fixed a posteriori of the realization of NŒ∂N^{\zeta} as stated in Assumption [5](https://arxiv.org/html/2601.17247v1#Thmassumption5 "Assumption 5. ‚Ä£ 3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions"). This simplifies ùíØ\mathcal{T} to be ‚ü¶0,m+1‚üß\llbracket 0,m+1\rrbracket. During the continuous phase, the agent does not observe the market takers when he submits his orders. For t‚ààùíØt\in\mathcal{T}, after taking action AtA\_{t} in state StS\_{t}, a random number of market orders arrive and imply the execution (or not) of the trader‚Äôs orders (and potentially exogenous orders). Note that by Assumption [5](https://arxiv.org/html/2601.17247v1#Thmassumption5 "Assumption 5. ‚Ä£ 3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions"), new market takers have arrived at any time tt of the continuous phase. It this ensures that any actions taken by the agent will have an impact on the market in the next state.

The market is modeled by a Markov Decision Process denoted by XX and defined for any time t‚ààùíØt\in\mathcal{T} as a tuple

|  |  |  |
| --- | --- | --- |
|  | Xt=(Xt1,Xt2,Xt3,Xt4,Xt5,Xt6,Xt7,Xt8,Xt9,Xt10,Xt11,Xt12,Xt13,Xt14,Xt15,Xt16,Xt17),X\_{t}=(X\_{t}^{1},X\_{t}^{2},X\_{t}^{3},X\_{t}^{4},X\_{t}^{5},X\_{t}^{6},X\_{t}^{7},X\_{t}^{8},X\_{t}^{9},X\_{t}^{10},X\_{t}^{11},X\_{t}^{12},X\_{t}^{13},X\_{t}^{14},X\_{t}^{15},X\_{t}^{16},X\_{t}^{17}), |  |

where each attribute encodes one of the market characteristics before the choice of an actions form the market marker as detailed below.

##### State space

* ‚Ä¢

  Inventory: Xt1=ItX\_{t}^{1}=I\_{t} represents the inventory of the market maker at time tt;
* ‚Ä¢

  Volume executed at the clearing: Xt2=0X\_{t}^{2}=0 for t<œÑclt<\tau^{\mathrm{cl}} and XœÑcl=ZœÑclX\_{\tau^{\mathrm{cl}}}=Z\_{\tau^{\mathrm{cl}}};
* ‚Ä¢

  Hypothetical/estimated auction‚Äôs clearing price: Xt3=HtclX\_{t}^{3}=H\_{t}^{\mathrm{cl}} represents the hypothetical clearing price as defined in Section [2.1.4](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS4 "2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") during the continuous trading phase for t<œÑopt<\tau^{\mathrm{op}} or the estimated clearing price as defined in Section [2.1.3](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS3 "2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") as the solution to Equation ([2](https://arxiv.org/html/2601.17247v1#S2.E2 "In 2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")) during the auction trading phase for œÑop‚â§t<œÑcl\tau^{\mathrm{op}}\leq t<\tau^{\mathrm{cl}};
* ‚Ä¢

  Limit order book depth: Xt4=Lt+‚Äãùüè{0‚â§t‚â§œÑop‚àí1}X\_{t}^{4}=L\_{t}^{+}\mathbf{1}\_{\{0\leq t\leq\tau^{\mathrm{op}}-1\}} and Xt5=Lt‚àí‚Äãùüè{0‚â§t‚â§œÑop‚àí1}X\_{t}^{5}=L\_{t}^{-}\mathbf{1}\_{\{0\leq t\leq\tau^{\mathrm{op}}-1\}} represent respectively the depth in the limit order book on the ask (resp. bid) side;
* ‚Ä¢

  Number of limit order in the auction: Xt6=Mt‚Äãùüè{t‚â•œÑop}X\_{t}^{6}=M\_{t}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}};
* ‚Ä¢

  Number of investors in the auction: Xt7=Nt‚àí+‚Äãùüè{t‚â•œÑop}X\_{t}^{7}=N\_{t-}^{+}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}} and Xt8=Nt‚àí‚àí‚Äãùüè{t‚â•œÑop}X\_{t}^{8}=N\_{t-}^{-}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}} represents respectively the number of aggressive order sent in the auction to buy (resp. sell) the asset;
* ‚Ä¢

  Cancellation history: Xt9=Œ∏t‚Äãùüè{t‚â•œÑop}X\_{t}^{9}=\theta\_{t}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}} represent the vector of canceled orders in the auction up to time tt;
* ‚Ä¢

  mid price: Xt10=StmidX\_{t}^{10}=S\_{t}^{\mathrm{mid}}
* ‚Ä¢

  Volume sent by investors in the auction: Xt11=(ŒΩt+,i‚Äãùüè{i‚â§Nt+}‚Äãùüè{t‚â•œÑop})1‚â§i‚â§ùí©X\_{t}^{11}=(\nu\_{t}^{+,i}\mathbf{1}\_{\{i\leq N\_{t}^{+}\}}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}})\_{1\leq i\leq\mathcal{N}} and Xt12=(ŒΩt‚àí,i‚Äãùüè{i‚â§Nt‚àí}‚Äãùüè{t‚â•œÑop})1‚â§i‚â§ùí©X\_{t}^{12}=(\nu\_{t}^{-,i}\mathbf{1}\_{\{i\leq N\_{t}^{-}\}}\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}})\_{1\leq i\leq\mathcal{N}} represent the number of aggressive orders sent in the auction to buy (resp. sell) the asset
* ‚Ä¢

  Volume in the limit order book (ask/bid side): Xt13=(Vt+,j‚Äãùüè{j‚â§Lt+}‚Äãùüè{t‚â§œÑop‚àí1})1‚â§j‚â§ùí©X\_{t}^{13}=(V\_{t}^{+,j}\mathbf{1}\_{\{j\leq L\_{t}^{+}\}}\mathbf{1}\_{\{t\leq\tau^{\mathrm{op}}-1\}})\_{1\leq j\leq\mathcal{N}} and Xt14=(Vt‚àí,j‚Äãùüè{j‚â§Lt‚àí}‚Äãùüè{t‚â§œÑop‚àí1})1‚â§j‚â§ùí©X\_{t}^{14}=(V\_{t}^{-,j}\mathbf{1}\_{\{j\leq L\_{t}^{-}\}}\mathbf{1}\_{\{t\leq\tau^{\mathrm{op}}-1\}})\_{1\leq j\leq\mathcal{N}} are the volume existing in the limit order book on the ask and bid side at any depth
* ‚Ä¢

  Limit order in the auction: Xt15=((Kti,Sti))1‚â§i‚â§ùí©X\_{t}^{15}=((K\_{t}^{i},S\_{t}^{i}))\_{1\leq i\leq\mathcal{N}}, with Kti=Sti=0K\_{t}^{i}=S\_{t}^{i}=0 if t‚â§œÑop‚àí1t\leq\tau^{\mathrm{op}}-1 or i>Mti>M\_{t};
* ‚Ä¢

  Price history in the auction: Xt16=Sa‚Äã(t)X\_{t}^{16}=S^{a}(t) where Sa‚Äã(t):=(SœÑopa,‚Ä¶,Sta,0,‚Ä¶,0)S^{a}(t):=(S\_{\tau^{\mathrm{op}}}^{a},\ldots,S^{a}\_{t},0,\ldots,0) represents the vector of limit order prices submitted in the auction up to time tt;
* ‚Ä¢

  Supply/Demand slope history: Xt17=Ka‚Äã(t)X\_{t}^{17}=K^{a}(t) where Ka‚Äã(t):=(KœÑopa,‚Ä¶,Kta,0,‚Ä¶,0)K^{a}(t):=(K\_{\tau^{\mathrm{op}}}^{a},\ldots,K\_{t}^{a},0,\ldots,0) represents the slope of the limit order submitted up to time tt.

###### Remark 3.1.

We assume that all numbers of market participants are bounded by ùí©>0\mathcal{N}>0, the limit order book depth is bounded by ‚Ñí>0\mathcal{L}>0, all volumes are bounded by ùí±>0\mathcal{V}>0, all prices are bounded by Œ±‚Äã‚Ñ¨\alpha\mathcal{B} for ‚Ñ¨>0\mathcal{B}>0. Furthermore, all slopes (i.e., the Ka‚Äã(t)K^{a}(t)) lie on a grid with step Œ≤\beta by Œ≤‚Äãùí¶\beta\mathcal{K} for some ùí¶>0\mathcal{K}>0.
We chose the same bound ùí©>0\mathcal{N}>0 (resp. ùí±>0\mathcal{V}>0) on the number of (resp. volumes submitted by) market participants for both market makers and investors during the continuous phase and the auction. While one could choose different constants for each type of market participant (for example, because investors are assumed small as per Assumption [1](https://arxiv.org/html/2601.17247v1#Thmassumption1 "Assumption 1. ‚Ä£ 2.1.1 Trading during the continuous phase [0,ùúè·µí·µñ) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions")), we chose the bounds to be large enough to bound all quantities.

###### Remark 3.2.

Recall that the strategic market maker is assumed to submit a linear supply/demand market order of the form
Kta‚Äã(p‚àíSta),K\_{t}^{a}(p-S\_{t}^{a}),
into the auction, as a function of the clearing price pp at time tt. The other limit orders are characterized by general supply/demand functions
gi,t‚Äã(p)=Kti‚Äã(p‚àíSti),g\_{i,t}(p)=K\_{t}^{i}(p-S\_{t}^{i}),
where KtiK\_{t}^{i} and StiS\_{t}^{i} denote, respectively, the slope and the reference price of other agent ii‚Äôs order. In the case of linear supply/demand functions for the other limit orders, the state variable
Xt15:=((Kti,Sti))1‚â§i‚â§ùí©X\_{t}^{15}:=\big((K\_{t}^{i},S\_{t}^{i})\big)\_{1\leq i\leq\mathcal{N}}
collectively represents the slopes and reference prices submitted by the other market participants.

###### Remark 3.3.

Note that X16,X17X^{16},X^{17} are vectors of size m‚àín+1m-n+1 with 0 components after time tt. This is due to the fact that we require a fixed length on the state attribute independent of the time tt studied.

This defines the non-empty and finite state space

|  |  |  |  |
| --- | --- | --- | --- |
|  | ùí≥\displaystyle\mathcal{X} | =‚ü¶0,ùí±‚üß2√ó(Œ±‚Äã‚ü¶0,‚Ñ¨‚üß)√ó‚ü¶0,‚Ñí‚üß2√ó‚ü¶0,ùí©‚üß3√ó{0,1}m+2√ó(Œ±‚Äã‚ü¶0,‚Ñ¨‚üß)√ó‚ü¶0,ùí±‚üß2‚Äãùí©\displaystyle=\llbracket 0,\mathcal{V}\rrbracket^{2}\times(\alpha\,\llbracket 0,\mathcal{B}\rrbracket)\times\llbracket 0,\mathcal{L}\rrbracket^{2}\times\llbracket 0,\mathcal{N}\rrbracket^{3}\times\{0,1\}^{m+2}\times(\alpha\,\llbracket 0,\mathcal{B}\rrbracket)\times\llbracket 0,\mathcal{V}\rrbracket^{2\mathcal{N}} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | √ó‚ü¶0,ùí±‚üß2‚Äã‚Ñí√ó[(Œ≤‚Äã‚ü¶0,ùí¶‚üß)√ó(Œ±‚Äã‚ü¶0,‚Ñ¨‚üß)]ùí©√ó(Œ±‚Äã‚ü¶0,‚Ñ¨‚üß)m+2√ó(Œ≤‚Äã‚ü¶0,ùí¶‚üß)m‚àín\displaystyle\quad\times\llbracket 0,\mathcal{V}\rrbracket^{2\mathcal{L}}\times[(\beta\llbracket 0,\mathcal{K}\rrbracket)\times(\alpha\llbracket 0,\mathcal{B}\rrbracket)]^{\mathcal{N}}\times(\alpha\,\llbracket 0,\mathcal{B}\rrbracket)^{m+2}\times(\beta\,\llbracket 0,\mathcal{K}\rrbracket)^{m-n} |  |

##### Action space.

We now turn to the actions of the strategic market maker. Given a state vector Xt‚ààùí≥X\_{t}\in\mathcal{X}, we define the action vector AtA\_{t} as

|  |  |  |
| --- | --- | --- |
|  | At=(At1,At2,At3,At4,At5)A\_{t}=(A\_{t}^{1},A\_{t}^{2},A\_{t}^{3},A\_{t}^{4},A\_{t}^{5}) |  |

where each component represents a particular action.

* ‚Ä¢

  Volume set in the limit order: At1=vt‚Äãùüè{0‚â§t‚â§œÑop‚àí1}A\_{t}^{1}=v\_{t}\mathbf{1}\_{\{0\leq t\leq\tau^{\mathrm{op}}-1\}};
* ‚Ä¢

  Depth in the limit order book: At2=kt‚Äãùüè{0‚â§t‚â§œÑop‚àí1}A\_{t}^{2}=k\_{t}\mathbf{1}\_{\{0\leq t\leq\tau^{\mathrm{op}}-1\}};
* ‚Ä¢

  Supply/demand slope and reference price: At3=Kta‚Äãùüè{œÑop‚â§t‚â§œÑcl‚àí1}A\_{t}^{3}=K\_{t}^{a}\mathbf{1}\_{\{\tau^{\mathrm{op}}\leq t\leq\tau^{\mathrm{cl}}-1\}};
  and At4=Sta‚Äãùüè{œÑop‚â§t‚â§œÑcl‚àí1}A\_{t}^{4}=S\_{t}^{a}\mathbf{1}\_{\{\tau^{\mathrm{op}}\leq t\leq\tau^{\mathrm{cl}}-1\}}
* ‚Ä¢

  Order cancellation in the auction: At5=ct‚Äãùüè{œÑop‚â§t‚â§œÑcl‚àí1}A\_{t}^{5}=c\_{t}\mathbf{1}\_{\{\tau^{\mathrm{op}}\leq t\leq\tau^{\mathrm{cl}}-1\}}.

This defines the action space ùíú\mathcal{A} as

|  |  |  |
| --- | --- | --- |
|  | ùíú=‚ü¶0,ùí±‚üß√ó‚ü¶0,‚Ñí‚üß√ó(Œ≤‚Äã‚ü¶0,ùí¶‚üß)√ó(Œ±‚Äã‚ü¶0,‚Ñ¨‚üß)√ó{0,1}œÑcl\mathcal{A}=\llbracket 0,\mathcal{V}\rrbracket\times\llbracket 0,\mathcal{L}\rrbracket\times(\beta\,\llbracket 0,\mathcal{K}\rrbracket)\times(\alpha\,\llbracket 0,\mathcal{B}\rrbracket)\times\{0,1\}^{\tau^{\mathrm{cl}}} |  |

Recalling that on the limit order book the market maker is liquidating his inventory, hence submits a volume At1‚â§It=Xt1A\_{t}^{1}\leq I\_{t}=X\_{t}^{1}, at a price Œ±‚ÄãAt2‚â•Stmid\alpha A\_{t}^{2}\geq S\_{t}^{\mathrm{mid}}. During the auction phase, the market makers can cancel previous orders exactly once, thus At5‚â§ùüè‚àíŒ∏t=1‚àíXt9A\_{t}^{5}\leq\mathbf{1}-\theta\_{t}=1-X\_{t}^{9}.

###### Definition 3.1 (Admissible actions).

Given a state xx, the set Adm‚Å°(x)\operatorname{Adm}(x) of admissible actions is defined as

|  |  |  |
| --- | --- | --- |
|  | Adm‚Å°(x)={a‚ààùíú:a1‚â§x1,a2‚â•x10‚ÄãŒ±‚àí1,a5‚â§ùüè‚àíx9}\operatorname{Adm}(x)=\{a\in\mathcal{A}:a^{1}\leq x^{1},a^{2}\geq x^{10}\alpha^{-1},a^{5}\leq\mathbf{1}-x^{9}\} |  |

###### Definition 3.2 (Admissible policies).

An admissible policy is a map œÄ:x‚ààùí≥‚Ü¶œÄ(‚ãÖ|x)‚ààùí´(Adm(x))\pi\colon x\in\mathcal{X}\mapsto\pi(\cdot|x)\in\mathcal{P}(\operatorname{Adm}(x)), where ùí´‚Äã(Adm‚Å°(x))\mathcal{P}(\operatorname{Adm}(x)) is the set of probability measures over Adm‚Å°(x)\operatorname{Adm}(x). We denote Œ†\Pi the set of these admissible policies. We define the set of greedy policy by the set of map œÄ:ùí≥‚ü∂ùíú\pi:\mathcal{X}\longrightarrow\mathcal{A} denoted by Œ†g\Pi^{g}.

##### Reward.

We define the reward on three separated region as explained below.

1. 1.

   During the continuous trading session for t<œÑopt<\tau^{\mathrm{op}}. The market maker submit a price St‚àô=Œ±‚ÄãAt2S\_{t}^{\bullet}=\alpha A\_{t}^{2}. The volume executed is given by EtE\_{t}. The profit is thus given by Œ±‚ÄãAt2√óEt\alpha A\_{t}^{2}\times E\_{t}. We moreover assume that the market maker penalizes the execution by comparing the price executed with the hypothetical clearing price Htcl=Xt3H\_{t}^{\mathrm{cl}}=X\_{t}^{3}. If St‚àô>HtclS\_{t}^{\bullet}>H\_{t}^{\mathrm{cl}}, the market maker receives the full profit otherwise if St‚àô<HtclS\_{t}^{\bullet}<H\_{t}^{\mathrm{cl}} the market maker may regret the execution. We assume that the difference between X3X^{3} and S‚àôS^{\bullet} tolerated is given by k‚ãÜ‚ÄãŒ±k^{\star}\alpha for some k‚ãÜk^{\star} fixed. It means that as soon as

   |  |  |  |
   | --- | --- | --- |
   |  | |Htcl‚àíSt‚àô|‚â§k‚ãÜ‚ÄãŒ±,|H\_{t}^{\mathrm{cl}}-S\_{t}^{\bullet}|\leq k^{\star}\alpha, |  |

   the market maker still get a profit from the execution on the limit order. We thus introduce a penalty function fc:‚Ñù‚ü∂‚Ñùf^{c}:\mathbb{R}\longrightarrow\mathbb{R} convex, continuous and increasing such that fcf^{c} is zero on ‚Ñù‚àí\mathbb{R}\_{-}, such that the reward of the market maker is given by

   |  |  |  |
   | --- | --- | --- |
   |  | rt‚Äã(Xt,At)=St‚àô‚ÄãEt‚Äãfc‚Äã(k‚ãÜ‚ÄãŒ±‚àí(Htcl‚àíSt‚àô)).r\_{t}(X\_{t},A\_{t})=S\_{t}^{\bullet}E\_{t}f^{c}(k^{\star}\alpha-(H\_{t}^{\mathrm{cl}}-S\_{t}^{\bullet})). |  |
2. 2.

   During the auction trading session for œÑop‚â§t<œÑcl\tau^{\mathrm{op}}\leq t<\tau^{\mathrm{cl}}. The market maker submits a slope Kta=At3K\_{t}^{a}=A\_{t}^{3} and a price Sta=At4S\_{t}^{a}=A\_{t}^{4}. The agent receives a fictive reward Kta‚ÄãHtcl‚Äã(Htcl‚àíSta)K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a}), where HtclH\_{t}^{\mathrm{cl}} is the anticipated clearing price (were the auction to close at time tt. The agent is penalized for canceling previous orders at cost dd per cancellation, yielding a penalty ‚àíd‚Äã‚Äñct‚Äñ1-d\|c\_{t}\|\_{1}. Finally, the agent is penalized for dealing as a buyer while he is supposed to be a seller. This happens when Htcl‚â§StaH\_{t}^{\mathrm{cl}}\leq S\_{t}^{a}: the market maker is willing to buy Kta‚Äã(Sta‚àíHtcl)K\_{t}^{a}(S\_{t}^{a}-H\_{t}^{\mathrm{cl}}) shares at price HtclH\_{t}^{\mathrm{cl}} or below. We introduce a penalty function fa:‚Ñù‚ü∂‚Ñùf^{a}:\mathbb{R}\longrightarrow\mathbb{R} concave, continuous and increasing such that faf^{a} is zero on ‚Ñù+\mathbb{R}\_{+}, such that the penalty writes fa‚Äã(Kta‚ÄãHtcl‚Äã(Htcl‚àíSta))f^{a}(K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a})). The reward of the market maker is given by

   |  |  |  |
   | --- | --- | --- |
   |  | rt‚Äã(Xt,At)=Kta‚ÄãHtcl‚Äã(Htcl‚àíSta)+fa‚Äã(Kta‚ÄãHtcl‚Äã(Htcl‚àíSta))‚àíd‚Äã‚Äñct‚Äñ1.r\_{t}(X\_{t},A\_{t})=K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a})+f^{a}(K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a}))-d\|c\_{t}\|\_{1}. |  |
3. 3.

   Final reward at the clearing for t=œÑclt=\tau^{\mathrm{cl}}. At the clearing time, the clearing price SœÑclclS\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}} is determined and order get matched. The market maker makes the profit or loss

   |  |  |  |
   | --- | --- | --- |
   |  | ‚àës=n+1m[Ktsa‚ÄãSœÑclcl‚Äã(SœÑclcl‚àíStsa)‚Äã(1‚àíŒ∏œÑcl(s))]\sum\_{s=n+1}^{m}\left[K\_{t\_{s}}^{a}S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right)\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)\right] |  |

   based on the orders he sent to the market and did not cancel by the clearing time. The agent is furthermore penalized for holding inventory. We introduce Œª>0\lambda>0 as a penalization parameter. Furthermore, the agent is again penalized for wrong-side dealing. The final reward of the market maker is given by

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | rt‚Äã(Xt,At)\displaystyle r\_{t}(X\_{t},A\_{t}) | =‚àës=n+1m[Ktsa‚ÄãSœÑclcl‚Äã(SœÑclcl‚àíStsa)‚Äã(1‚àíŒ∏œÑcl(s))]‚àíŒª‚Äã|IœÑcl|2\displaystyle=\sum\_{s=n+1}^{m}\left[K\_{t\_{s}}^{a}S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right)\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)\right]-\lambda|I\_{\tau^{\mathrm{cl}}}|^{2} |  |
   |  |  |  |  |
   | --- | --- | --- | --- |
   |  |  | +‚àës=n+1mfa‚Äã(Ktsa‚ÄãSœÑclcl‚Äã(SœÑclcl‚àíStsa)‚Äã(1‚àíŒ∏œÑcl(s))).\displaystyle\quad+\sum\_{s=n+1}^{m}f^{a}\left(K\_{t\_{s}}^{a}S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right)\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)\right). |  |

###### Remark 3.4.

In the numerical part we will choose fc‚Äã(t)=1k‚ãÜ‚ÄãŒ±‚Äã(t)+f^{c}(t)=\frac{1}{k^{\star}\alpha}(t)\_{+} and fa‚Äã(t)=‚àíq‚Äã(‚àít)+f^{a}(t)=-q(-t)\_{+} for some q>0q>0. One can interpret the penalty as removing a fraction qq of the reward. With q=1q=1, one obtains no reward for dealing on the wrong side

To summarize, at time t‚ààùíØt\in\mathcal{T} the random one-step reward is

|  |  |  |
| --- | --- | --- |
|  | rt‚Äã(Xt,At)={St‚àô‚ÄãEt‚Äãfc‚Äã(k‚ãÜ‚ÄãŒ±‚àí(Htcl‚àíSt‚àô)),if¬†‚Äãt<œÑop,Kta‚ÄãHtcl‚Äã(Htcl‚àíSta)+fa‚Äã(Kta‚ÄãHtcl‚Äã(Htcl‚àíSta))‚àíd‚Äã‚Äñct‚Äñ1,if¬†‚ÄãœÑop‚â§t<œÑcl,‚àës=n+1m[Ktsa‚ÄãSœÑclcl‚Äã(SœÑclcl‚àíStsa)‚Äã(1‚àíŒ∏œÑcl(s))]‚àíŒª‚Äã|IœÑcl|2,if¬†‚Äãt=œÑcl.+‚àës=n+1mfa‚Äã(Ktsa‚ÄãSœÑclcl‚Äã(SœÑclcl‚àíStsa)‚Äã(1‚àíŒ∏œÑcl(s)))r\_{t}(X\_{t},A\_{t})=\begin{cases}\displaystyle S\_{t}^{\bullet}E\_{t}f^{c}(k^{\star}\alpha-(H\_{t}^{\mathrm{cl}}-S\_{t}^{\bullet})),&\text{if }t<\tau^{\mathrm{op}},\\ K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a})+f^{a}(K\_{t}^{a}H\_{t}^{\mathrm{cl}}(H\_{t}^{\mathrm{cl}}-S\_{t}^{a}))-d\|c\_{t}\|\_{1},&\text{if }\tau^{\mathrm{op}}\leq t<\tau^{\mathrm{cl}},\\ \sum\_{s=n+1}^{m}\left[K\_{t\_{s}}^{a}S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right)\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)\right]-\lambda|I\_{\tau^{\mathrm{cl}}}|^{2},&\text{if }t=\tau^{\mathrm{cl}}.\\ +\sum\_{s=n+1}^{m}f^{a}\left(K\_{t\_{s}}^{a}S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}\left(S\_{\tau^{\mathrm{cl}}}^{\mathrm{cl}}-S\_{t\_{s}}^{a}\right)\left(1-\theta\_{\tau^{\mathrm{cl}}}^{(s)}\right)\right)\end{cases} |  |

In our setting, the agent chooses action AtA\_{t} in state XtX\_{t}. Then, the executed volume EtE\_{t} is randomly observed. Finally, the agent transitions into state Xt+1X\_{t+1}.

The objective function of the strategic market maker is to maximize, over all œÄ‚ààŒ†\pi\in\Pi, the total expected reward, i.e. to solve

|  |  |  |  |
| --- | --- | --- | --- |
|  | (ùêè)maximize\displaystyle(\mathbf{P})\quad\operatorname{maximize}\quad | J‚Äã(œÄ)=ùîº‚Äã[‚àët‚ààùíØœát‚Äãrt‚Äã(Xt,At)]\displaystyle J(\pi)=\mathbb{E}\left[\sum\_{t\in\mathcal{T}}\chi^{t}r\_{t}(X\_{t},A\_{t})\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | s.t. | {œÄ‚ààŒ†X0‚àºŒº0At‚àºœÄ(‚ãÖ‚à£Xt),\displaystyle\left\{\begin{array}[]{ll}\pi\in\Pi\\ X\_{0}\sim\mu\_{0}\\ A\_{t}\sim\pi(\cdot\mid X\_{t})\end{array}\right., |  |

where œá‚àà(0,1]\chi\in(0,1] denotes a discount factor.
We also define the problem reduced to greedy policies:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (ùêèùê†)maximize\displaystyle\mathbf{(P^{g})}\quad\operatorname{maximize}\quad | J‚Äã(œÄ)=ùîº‚Äã[‚àët‚ààùíØœát‚Äãrt‚Äã(Xt,At)]\displaystyle J(\pi)=\mathbb{E}\left[\sum\_{t\in\mathcal{T}}\chi^{t}r\_{t}(X\_{t},A\_{t})\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | s.t. | {œÄ‚ààŒ†gX0‚àºŒº0At=œÄ‚Äã(Xt)\displaystyle\left\{\begin{array}[]{ll}\pi\in\Pi^{g}\\ X\_{0}\sim\mu\_{0}\\ A\_{t}=\pi(X\_{t})\end{array}\right. |  |

We recall that our system is finite in the sense that the number of state, actions, rewards are finite, so that we can reduce our study to greedy policy œÄg‚ààŒ†g\pi^{g}\in\Pi^{g}.

###### Proposition 3.1 (Theorem 6.2.10 in [[52](https://arxiv.org/html/2601.17247v1#bib.bib11 "Markov decision processes: discrete stochastic dynamic programming")]).

(ùêè)\mathbf{(P)} is equivalent to solve (ùêèùê†)\mathbf{(P^{g})}, that is there exists a greedy policies which is optimal in the set Œ†\Pi.

## 4 Learning market making with closing auction in an unknown environment

In this section, we explain the numerical method used to solve (ùêèùê†)(\mathbf{P^{g}}).

### 4.1 Problem formulation

We consider the online episodic RL setting. In this setting, the agent executes the MDP sequentially for EE episodes, each episode being of length m+2m+2 and independent each others. This leads to a total number of episode samples T=(m+2)‚ÄãET=(m+2)E. For each episode e‚àà‚ü¶1,E‚üße\in\llbracket 1,E\rrbracket, an initial state x0,ex\_{0,e} is sampled. The learning process is evaluated by the cumulative regret with respect to a benchmark policy, defined as follows.

###### Definition 4.1.

Given initial states (x0,e)1‚â§e‚â§E(x\_{0,e})\_{1\leq e\leq E} that are chosen by the environment, we define the cumulative pseudo regret with respect to a benchmark policy œÄ‚àò‚ààŒ†g\pi^{\circ}\in\Pi^{g} as

|  |  |  |
| --- | --- | --- |
|  | PRegret‚Å°(T)=‚àëe=1E(V0œÄ‚àò‚Äã(x0,e)‚àíV0œÄe‚Äã(x0,e))\operatorname{PRegret}(T)=\sum\_{e=1}^{E}(V\_{0}^{\pi^{\circ}}(x\_{0,e})-V\_{0}^{\pi^{e}}(x\_{0,e})) |  |

where T=(m+2)‚ÄãET=(m+2)E is the total number of time steps i.e. the sample size, and œÄe\pi^{e} is the policy at the beginning of episode ee.

###### Remark 4.1.

Note that ‚àíPRegret‚Å°(T)-\operatorname{PRegret}(T) corresponds to the gain the learning policy œÄe\pi^{e} generates compared with the benchmark policy œÄ^\hat{\pi}.

The environment being unknown, we do not deterministically know the rewards, the initial distribution, and the transition probabilities. We will therefore use a model-free method to find the optimal policy œÄ^\hat{\pi} maximizing JJ. The idea is to approximate the optimal Q-function Qt‚Äã(x,a)Q\_{t}(x,a), see [[61](https://arxiv.org/html/2601.17247v1#bib.bib24 "Q-learning")] defined as

|  |  |  |
| --- | --- | --- |
|  | ‚àÄ(x,a)‚ààùí≥√óùíú,Qt‚Äã(x,a)=ùîºœÄ‚Äã[‚àës‚â•tœás‚Äãrs‚Äã(Xs,As)‚à£Xt=x,At=a].\forall(x,a)\in\mathcal{X}\times\mathcal{A},\quad Q\_{t}(x,a)=\mathbb{E}\_{\pi}\left[\sum\_{s\geq t}\chi^{s}r\_{s}(X\_{s},A\_{s})\mid X\_{t}=x,A\_{t}=a\right]. |  |

The classical Q-learning algorithm writes as follows. Whenever a transition (xt,at,rt,xt+1)(x\_{t},a\_{t},r\_{t},x\_{t+1}) is observed, Q-learning forms a one-step target rt+Vt+1‚Äã(xt+1)r\_{t}+V\_{t+1}(x\_{t+1}) for the long-run return. The update moves the current entry Qt‚Äã(xt,at)Q\_{t}(x\_{t},a\_{t}) a fraction Œ∑k\eta\_{k} toward this target, by reducing the temporal-difference error rt+Vt+1‚Äã(xt+1)‚àíQt‚Äã(xt,at)r\_{t}+V\_{t+1}(x\_{t+1})-Q\_{t}(x\_{t},a\_{t}). At time step tt in state xtx\_{t}, if action ata\_{t} is taken and yields return rtr\_{t} before moving to state xt+1x\_{t+1}, then

|  |  |  |
| --- | --- | --- |
|  | Qt‚Äã(xt,at)‚Üê(1‚àíŒ∑k)‚ÄãQt‚Äã(xt,at)+Œ∑k‚Äã(rt+Vt+1‚Äã(xt+1))Q\_{t}(x\_{t},a\_{t})\leftarrow(1-\eta\_{k})Q\_{t}(x\_{t},a\_{t})+\eta\_{k}(r\_{t}+V\_{t+1}(x\_{t+1})) |  |

where kk is the number of time action ata\_{t} has been taken in state xtx\_{t} at time tt so far (one should write kt‚Äã(xt,at)k\_{t}(x\_{t},a\_{t}) for rigor). As shown in [[61](https://arxiv.org/html/2601.17247v1#bib.bib24 "Q-learning")], as soon as all the rewards rtr\_{t} are bounded, the learning rates Œ∑k‚àà[0,1)\eta\_{k}\in[0,1) satisfy

|  |  |  |
| --- | --- | --- |
|  | ‚àëk=1+‚àû|Œ∑k|=+‚àûand‚àëk=1+‚àûŒ∑k2<+‚àû,\sum\_{k=1}^{+\infty}|\eta\_{k}|=+\infty\quad\text{and}\quad\sum\_{k=1}^{+\infty}\eta\_{k}^{2}<+\infty, |  |

then the Q-learning algorithm is converging towards the optimal Q-function Qt‚àó‚Äã(x,a)Q\_{t}^{\*}(x,a).

### 4.2 Neural-fitted Q-learning

The classical Q-learning algorithm would fill a table with (œÑcl+1)√ó|ùí≥|√ó|ùíú|(\tau^{\mathrm{cl}}+1)\times|\mathcal{X}|\times|\mathcal{A}| values to approximate the optimal Q-values Qt‚Äã(x,a)Q\_{t}(x,a) for all (x,a)‚ààùí≥√óùíú(x,a)\in\mathcal{X}\times\mathcal{A} and t‚ààùíØ.t\in\mathcal{T}. Given the size of our state space, this is extremely expensive. We therefore have recourse to neural networks and Deep Q-Learning. First, we render the problem stationary by enriching the state space as ùí≥~=ùí≥√óùíØ‚àñ{œÑcl}\tilde{\mathcal{X}}=\mathcal{X}\times\mathcal{T}\setminus\{\tau^{\mathrm{cl}}\} and by writing x~=(x,t)\tilde{x}=(x,t) for x‚ààùí≥x\in\mathcal{X} and t‚ààùíØ‚àñ{œÑcl}t\in\mathcal{T}\setminus\{\tau^{\mathrm{cl}}\}. Let Q~‚Äã(x~,a)=Qt‚Äã(x,a)\tilde{Q}(\tilde{x},a)=Q\_{t}(x,a).

Deep Q-Learning consists in approximating Q~‚Äã(x~,a)\tilde{Q}(\tilde{x},a) with a neural network Q~Œ∏‚Äã(x,a)\tilde{Q}\_{\theta}(x,a), for some weight Œ∏‚àà‚Ñùq\theta\in\mathbb{R}^{q}, where q‚â•1q\geq 1. Our setting is organized in two phases. While states and actions have been defined in a unified way in Section [3](https://arxiv.org/html/2601.17247v1#S3 "3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions") to formulate the MDP, they are inherently different for each phase. We therefore define a separate neural network for each phase:

|  |  |  |
| --- | --- | --- |
|  | ‚àÄ(x,a,t)‚ààùí≥√óùíú√óùíØ‚àñ{œÑcl},Q~Œ∏‚Äã(x,t)=Q~œï‚Äã((x,t),a)‚Äãùüè{t<œÑop}+Q~œà‚Äã((x,t),a)‚Äãùüè{t‚â•œÑop}\forall(x,a,t)\in\mathcal{X}\times\mathcal{A}\times\mathcal{T}\setminus\{\tau^{\mathrm{cl}}\},\quad\tilde{Q}\_{\theta}(x,t)=\tilde{Q}\_{\phi}((x,t),a)\mathbf{1}\_{\{t<\tau^{\mathrm{op}}\}}+\tilde{Q}\_{\psi}((x,t),a)\mathbf{1}\_{\{t\geq\tau^{\mathrm{op}}\}} |  |

where Œ∏=(œï,œà)\theta=(\phi,\psi) and œï‚àà‚Ñùq1,œà‚àà‚Ñùq2\phi\in\mathbb{R}^{q\_{1}},\psi\in\mathbb{R}^{q\_{2}} and q1+q2=qq\_{1}+q\_{2}=q. The goal is to train the neural network such that Q~Œ∏\tilde{Q}\_{\theta} approximates as good as possible the Q-function Q~\tilde{Q}. For the terminal state œÑcl\tau^{\mathrm{cl}}, the Q-function is given by the reward rœÑclr\_{\tau^{\mathrm{cl}}}, which is why we do not need to define a neural network. We then apply the classical NFQ iteration algorithm from [[55](https://arxiv.org/html/2601.17247v1#bib.bib2 "Neural fitted Q iteration‚Äìfirst experiences with a data efficient neural reinforcement learning method")] with ensuring junction at t=œÑopt=\tau^{\mathrm{op}} when the phase switch occurs.

Let us now detail how the NFQ algorithm is implemented. We denote the weights for the two neural networks as œï\phi and œà\psi, corresponding to the continuous phase and the auction phase, respectively. At each timestep, in state x~\tilde{x}, the agent selects an action aa, and then receives reward rr before moving to the next state x~‚Ä≤\tilde{x}^{\prime}. One stores the transition (x~,a,r,x~‚Ä≤)(\tilde{x},a,r,\tilde{x}^{\prime}). The action aa is selected according to an exponential Œµ\varepsilon-greedy schedule, to balance exploration and exploitation. During episode ee, one chooses a=arg‚Å°maxa‚ààùíú‚Å°Q~‚Äã(x~,a)a=\arg\max\_{a\in\mathcal{A}}\tilde{Q}(\tilde{x},a) with probability 1‚àíŒµ1-\varepsilon and chooses randomly and uniformly an action of ùíú\mathcal{A} with probability Œµ\varepsilon. The subsequent state x~‚Ä≤\tilde{x}^{\prime} is samples from the environment.

Depending on which phase the state x~\tilde{x} is in, the transition is memorized in two separate replay buffers for the CLOB phase and for the auction phase. To stabilize the learning, the NFQ algorithm holds target networks parameterized by œï‚àí\phi^{-} and œà‚àí\psi^{-}, which are frozen copies of the weights from the previous iteration. These weights are used to compute the QQ-targets (which correspond to the values rt+Vt+1‚Äã(xt+1)r\_{t}+V\_{t+1}(x\_{t+1})). Given the transition (x~j=(xj,tj),aj,rj,x~j‚Ä≤)(\tilde{x}\_{j}=(x\_{j},t\_{j}),a\_{j},r\_{j},\tilde{x}\_{j}^{\prime}), the target values is computed as

|  |  |  |
| --- | --- | --- |
|  | yj=rj+œá‚Äã{0¬†if¬†x~j¬†is a terminal statemaxa‚Ä≤‚ààùíú‚Å°Q~œï‚àí‚Äã(x~j‚Ä≤,a‚Ä≤)¬†if¬†x~j‚Ä≤¬†is in the continuous phasemaxa‚Ä≤‚ààùíú‚Å°Q~œà‚àí‚Äã(x~j‚Ä≤,a‚Ä≤)¬†if¬†x~j‚Ä≤¬†is in the auction phasey\_{j}=r\_{j}+\chi\left\{\begin{array}[]{ll}0&\text{ if $\tilde{x}\_{j}$ is a terminal state}\\ \max\_{a^{\prime}\in\mathcal{A}}\tilde{Q}\_{\phi^{-}}(\tilde{x}\_{j}^{\prime},a^{\prime})&\text{ if $\tilde{x}\_{j}^{\prime}$ is in the continuous phase}\\ \max\_{a^{\prime}\in\mathcal{A}}\tilde{Q}\_{\psi^{-}}(\tilde{x}\_{j}^{\prime},a^{\prime})&\text{ if $\tilde{x}\_{j}^{\prime}$ is in the auction phase}\end{array}\right. |  |

The targets are used to fit Q~œï‚Äã(x~j,aj)\tilde{Q}\_{\phi}(\tilde{x}\_{j},a\_{j}) and Q~œà‚Äã(x~j,aj)\tilde{Q}\_{\psi}(\tilde{x}\_{j},a\_{j}) against yjy\_{j}. More precisely, at the end of each episode, the weights of the neural networks are updated using mini-batch stochastic gradient descent over MM epochs and batch size BB, with constant learning rate Œ∑\eta. We require that B‚â•N¬ØB\geq\underline{N} before training starts, to avoid overfitting on the first episodes, and bound B‚â§N¬ØB\leq\overline{N} for numerical simplicity. We use the Huber loss, defined as ‚Ñì‚Äã(u)=12‚Äãu2‚Äãùüè[‚àí1,1]‚Äã(u)+(|u|‚àí12)‚Äã(1‚àíùüè[‚àí1,1]‚Äã(u))\ell(u)=\frac{1}{2}u^{2}\mathbf{1}\_{[-1,1]}(u)+(|u|-\frac{1}{2})(1-\mathbf{1}\_{[-1,1]}(u)) and a constant learning rate. Once all epochs for episode ee are complete, the target network is hard updated as œï‚àí‚Üêœï\phi^{-}\leftarrow\phi.

| Symbol | Value | Comment |
| --- | --- | --- |
| Œ∑\eta | 3√ó10‚àí43\times 10^{-4} | Learning rate (both nets) |
| MM | 3 | Epochs per episode |
| N¬Ø\overline{N} | 50,000 | Maximum buffer size |
| N¬Ø\underline{N} | 5,000 | Minimum buffer size to launch training |
| œá\chi | 0.990.99 | Discount factor |
| EE | 2,000 | Number of episodes |
| BB | 128 | Batch size |
| œÑ\tau | 0.95 | Smoothing parameter in Algorithm [1](https://arxiv.org/html/2601.17247v1#alg1 "Algorithm 1 ‚Ä£ 2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") |
| H0H\_{0} | 100 | Initial estimated clearing price in Algorithm [1](https://arxiv.org/html/2601.17247v1#alg1 "Algorithm 1 ‚Ä£ 2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions") |

Table 1: Neural-fitted Q-iteration parameters

###### Remark 4.2.

The replay buffers are growing with each episode. In our implementation, each episode sees a pass over the whole replay buffer for training. Hence, computations get heavier with each passing episode. There certainly is room for improvement on that point.

###### Remark 4.3.

The exponential Œµ\varepsilon-greedy schedule reduces the exploration parameter from 1 to 0.01 with a warm-up period of 100100 episodes.

## 5 Theoretical benchmarks

We compare the performance of our NFQ-learned policy against two different theoretical benchmarks for optimal market making. The first benchmark is adapted from the optimal market making models of Avellaneda and Stoikov [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book")] later solved explicitly by Gu√©ant, Lehalle and Fernandez-Tapia [[28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")]. We adapt the market making model to liquidation only and without risk aversion for the continuous phase. We then suggest an approximation allowing a straightforward application to our discrete-time setup. The second theoretical benchmark is the time weighted average price policy for the continuous phase. We adopt the same heuristic liquidation rule for the auction phase. For both benchmark, we adopt in the auction phase a heuristic liquidation rule.

### 5.1 Avellaneda-Stoikov optimal market making

In this section, we will recall the main results of [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book")] and [[28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")], in the case where the market maker acts as a seller only. We consider the continuous phase, that is t<œÑopt<\tau^{\mathrm{op}} in what follows. Suppose we consider a continuous time setup, that is we work on [0,tn][0,t\_{n}], where tnt\_{n} is the last time of the continuous phase in our initial framework. The market mid price is assumed to follow an arithmetic Brownian motion d‚ÄãStmid=œÉ‚Äãd‚ÄãBt\mathrm{d}S\_{t}^{\mathrm{mid}}=\sigma\mathrm{d}B\_{t} with œÉ>0\sigma>0. We assume
that transactions have constant size Œî\Delta. For simplicity, assume Œî=1\Delta=1. The inventory process writes qt=I0‚àíNtaq\_{t}=I\_{0}-N\_{t}^{a}, where NaN^{a} is the point process, independent of BB, giving the cumulative number of shares sold by the market maker. Formulated initially by Avellaneda and Stoikov, we assume that the intensity of NaN^{a} depends on the spread Œ¥ta=kt‚àô‚àíktmid\delta\_{t}^{a}=k\_{t}^{\bullet}-k\_{t}^{\mathrm{mid}} via the following relationship:

|  |  |  |
| --- | --- | --- |
|  | Œªa‚Äã(Œ¥a)=A‚Äãe‚àíŒ±‚Äãk‚ÄãŒ¥a,\lambda^{a}(\delta^{a})=Ae^{-\alpha k\delta^{a}}, |  |

for A,k>0A,k>0. The cash process XtX\_{t} of the market maker evolves according to d‚ÄãXt=(Stmid+Œ±‚ÄãŒ¥ta)‚Äãd‚ÄãNta\mathrm{d}X\_{t}=(S\_{t}^{\mathrm{mid}}+\alpha\delta\_{t}^{a})\mathrm{d}N\_{t}^{a}. Let T=tnT=t\_{n} and ùíú~\tilde{\mathcal{A}} be the set of bounded predictable processes. The market maker optimizes

|  |  |  |
| --- | --- | --- |
|  | (ùêå)supŒ¥a‚ààùíú~ùîº‚Äã[XT+qT‚ÄãSTmid](\mathbf{M})\quad\sup\_{\delta^{a}\in\tilde{\mathcal{A}}}\mathbb{E}\left[X\_{T}+q\_{T}S\_{T}^{\mathrm{mid}}\right] |  |

###### Proposition 5.1.

The optimal quotes solving (ùêå)(\mathbf{M}) are given by

|  |  |  |
| --- | --- | --- |
|  | Œ¥a,‚àó‚Äã(t,q)=1Œ±‚Äãk‚Äã[1+ln‚Å°(vq‚Äã(t)vq‚àí1‚Äã(t))],\delta^{a,\*}(t,q)=\frac{1}{\alpha k}\left[1+\ln\left(\frac{v\_{q}(t)}{v\_{q-1}(t)}\right)\right], |  |

where

|  |  |  |
| --- | --- | --- |
|  | ‚àÄq‚àà‚ü¶0,Q‚üß,vq‚Äã(t)=‚àëj=0q(A‚Äãe‚àí1‚Äã(T‚àít))jj!.\forall q\in\llbracket 0,Q\rrbracket,\quad v\_{q}(t)=\sum\_{j=0}^{q}\frac{(Ae^{-1}(T-t))^{j}}{j!}. |  |

###### Proof.

Note that (ùêå)(\mathbf{M}) corresponds to the risk-neutral market maker Œ≥‚Üí0\gamma\to 0 in the standard optimal market making problem investigated in [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book"), [28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")]. In this case, one proves that the problem is reduced to find the solution to the ODE system

|  |  |  |
| --- | --- | --- |
|  | vq‚Ä≤‚Äã(t)=‚àíA‚Äãe‚àí1‚Äãvq‚àí1‚Äã(t),‚àÄq‚àà‚ü¶1,Q‚üß,v\_{q}^{\prime}(t)=-Ae^{-1}v\_{q-1}(t),\quad\forall q\in\llbracket 1,Q\rrbracket, |  |

and we directly get optimal quotes from [[28](https://arxiv.org/html/2601.17247v1#bib.bib59 "Dealing with the inventory risk: a solution to the market making problem")] when Œ≥‚Üí0\gamma\to 0 by

|  |  |  |
| --- | --- | --- |
|  | Œ¥a,‚àó‚Äã(t,q)=1Œ±‚Äãk‚Äã[1+ln‚Å°(vq‚Äã(t)vq‚àí1‚Äã(t))].\delta^{a,\*}(t,q)=\frac{1}{\alpha k}\left[1+\ln\left(\frac{v\_{q}(t)}{v\_{q-1}(t)}\right)\right]. |  |

We prove the result by induction. Note that v0=1v\_{0}=1. Assume now that

|  |  |  |
| --- | --- | --- |
|  | vq‚àí1‚Äã(t)=‚àëj=0q‚àí1(A‚Äãe‚àí1‚Äã(T‚àít))jj!,q‚â•1.v\_{q-1}(t)=\sum\_{j=0}^{q-1}\frac{(Ae^{-1}(T-t))^{j}}{j!},\;q\geq 1. |  |

We compute

|  |  |  |  |
| --- | --- | --- | --- |
|  | vq‚Äã(t)\displaystyle v\_{q}(t) | =vq‚Äã(T)‚àí‚à´tTvq‚Ä≤‚Äã(s)‚Äãds\displaystyle=v\_{q}(T)-\int\_{t}^{T}v\_{q}^{\prime}(s)\mathrm{d}s |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =1+A‚Äãe‚àí1‚Äã‚à´tTvq‚àí1‚Äã(s)‚Äãds\displaystyle=1+Ae^{-1}\int\_{t}^{T}v\_{q-1}(s)\mathrm{d}s |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =1+A‚Äãe‚àí1‚Äã‚àëj=0q‚àí1‚à´tT(A‚Äãe‚àí1‚Äã(T‚àís))jj!‚Äãds\displaystyle=1+Ae^{-1}\sum\_{j=0}^{q-1}\int\_{t}^{T}\frac{(Ae^{-1}(T-s))^{j}}{j!}\mathrm{d}s |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =1+‚àëj=0q‚àí1(A‚Äãe‚àí1)j+1j!‚Äã‚à´0T‚àítsj‚Äãds\displaystyle=1+\sum\_{j=0}^{q-1}\frac{(Ae^{-1})^{j+1}}{j!}\int\_{0}^{T-t}s^{j}\mathrm{d}s |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =1+‚àëj=0q‚àí1(Ae‚àí1(T‚àít)j+1(j+1)!\displaystyle=1+\sum\_{j=0}^{q-1}\frac{(Ae^{-1}(T-t)^{j+1}}{(j+1)!} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =‚àëj=0q(A‚Äãe‚àí1‚Äã(T‚àít))jj!.\displaystyle=\sum\_{j=0}^{q}\frac{(Ae^{-1}(T-t))^{j}}{j!}. |  |

This completes the proof by induction.
‚àé

The optimal quotes Œ¥a,‚àó‚Äã(t,q)\delta^{a,\*}(t,q) derived above hold in continuous time. These quotes yield, at time tt and given the current inventory qq, the optimal quote price (that is Stmid+Œ±‚ÄãŒ¥a,‚àó‚Äã(t,q)S\_{t}^{\mathrm{mid}}+\alpha\delta^{a,\*}(t,q)). However, we work in discrete time in our setting. Therefore, if at the end of period tt, when action (vt,Œ¥t)(v\_{t},\delta\_{t}) has been submitted, mtm\_{t} shares have been sold, it can be viewed as if on [t,t+1)[t,t+1), mt/Œîm\_{t}/\Delta fills occurred, all at price Œ¥a,‚àó‚Äã(t,q)\delta^{a,\*}(t,q). The volume to be submitted is vt=qtv\_{t}=q\_{t} in this approximation. This allows to ensure that if enough market takers come to the market, execution is not limited by the volume exposed by the market taker. The approximation is twofold: each of the fills is at price Œ¥a,‚àó‚Äã(t,qt)\delta^{a,\*}(t,q\_{t}) (instead of Œ¥a,‚àó‚Äã(s,qs)\delta^{a,\*}(s,q\_{s}) for t‚â§s<t+1t\leq s<t+1) and we expose the whole current inventory at any time tt. The notion of "exposed volume" does not exist in the continuous time setting because of the fixed transaction size. To conclude, the action of the market maker on the continuous phase writes (qt,Œ¥a,‚àó‚Äã(t,qt))(q\_{t},\delta^{a,\*}(t,q\_{t})).

###### Remark 5.1.

Note that whenever Œ¥a,‚àó‚Äã(t,qt)\delta^{a,\*}(t,q\_{t}) is not integer, we take the closest integer value instead.

###### Remark 5.2.

When qt=0q\_{t}=0, then Œ¥a,‚àó‚Äã(t,0)=(Œ±‚Äãk)‚àí1\delta^{a,\*}(t,0)=(\alpha k)^{-1}: if ‚åä(Œ±‚Äãk)‚àí1‚åã=0\lfloor(\alpha k)^{-1}\rfloor=0, then the price quoted will be the mid price exactly.

Once the auction opens, an inventory qœÑop‚â•0q\_{\tau^{\mathrm{op}}}\geq 0 remains. We implement the following heuristic policy. Let S~\tilde{S} be the average between the mean and the max price of executed orders during the continuous phase. The whole remaining inventory qœÑopq\_{\tau^{\mathrm{op}}} is put on the auction at S~\tilde{S}, with supply function g~z‚Äã(p)=z‚ÄãqœÑop‚Äã(p‚àíS~)+\tilde{g}\_{z}(p)=zq\_{\tau^{\mathrm{op}}}(p-\tilde{S})\_{+}. In Section [6](https://arxiv.org/html/2601.17247v1#S6 "6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"), we consider z=10z=10. This single order is submitted right at the beginning of the auction, and only potentially executed at the clearing time.

### 5.2 Time-weighted average price benchmark

The second benchmark is deliberately simpler. Given the current inventory qtq\_{t}, the trader submits a deterministic volume
vt=‚åàqt/(T‚àít+1)‚åâv\_{t}=\lceil q\_{t}/(T-t+1)\rceil, quoted at the best ask price, i.e. Œ¥t=1\delta\_{t}=1. This strategy corresponds to a uniform liquidation of the remaining inventory over the residual trading horizon. However, such a policy does not guarantee full liquidation during the continuous trading phase, as execution is conditional on order matching.
This benchmark coincides with the minimum-impact strategy introduced in the seminal work of Almgren and Chriss [[3](https://arxiv.org/html/2601.17247v1#bib.bib7 "Optimal execution of portfolio transactions")], which minimizes the expected implementation shortfall under market-impact considerations.
For the auction phase, we adopt exactly the same liquidation policy as in the Avellaneda‚ÄìStoikov benchmark.

## 6 Numerical simulations

This section employs the generative stochastic market model formulated in Section [2](https://arxiv.org/html/2601.17247v1#S2 "2 Market model ‚Ä£ Learning Market Making with Closing Auctions") to simulate continuous trading and closing auctions. We compare an NFQ-learned policy against the two theoretical benchmarks: Avellaneda-Stoikov (AS) strategy, see Section [5.1](https://arxiv.org/html/2601.17247v1#S5.SS1 "5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions") and the TWAP strategy see Section [5.2](https://arxiv.org/html/2601.17247v1#S5.SS2 "5.2 Time-weighted average price benchmark ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"). The goal of this section is to emphasize the performance of our NFQ-learned policy compared with the benchmarks. We start by generating a emulator of the CLOB followed by the closing auction. The algorithm used to generate the market mechanism is defined in Section [6.1](https://arxiv.org/html/2601.17247v1#S6.SS1 "6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") with Algorithm [2](https://arxiv.org/html/2601.17247v1#alg2 "Algorithm 2 ‚Ä£ 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"). In Section [6.3](https://arxiv.org/html/2601.17247v1#S6.SS3 "6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") we generate mid price process values by using the rough-Heston to describe the evolution of the price of a risky asset, see [[26](https://arxiv.org/html/2601.17247v1#bib.bib8 "Volatility is rough")]. Finally, in Section [6.4](https://arxiv.org/html/2601.17247v1#S6.SS4 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions")
we train and test our NFQ-learned policy to find the optimal trading strategy along a trading day with historical data on December 31, 2025 for CAT, PG, GOOGL, JPM and MSFT. In both cases (generated or historical data for the stock price) we note that our learning algorithm outperform the benchmarks on the mean returns.

### 6.1 Generative stochastic market model

We now explain in details our market emulator to generate the financial market in our setting.
The algorithm is describe in Algorithm [2](https://arxiv.org/html/2601.17247v1#alg2 "Algorithm 2 ‚Ä£ 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
Not that our emulator is based on empirical studies to model some key components of our model.

Algorithm 2  Generative stochastic model

0:‚ÄÇParameter vector (Œª0,vm,Œ≥m,V,Œ≤a,Œ≤b,V‚àû,œÅ,U1,U2,M1,M2,p1,p2,p3,p4)(\lambda\_{0},v\_{m},\gamma\_{m},V,\beta\_{a},\beta\_{b},V\_{\infty},\rho,U\_{1},U\_{2},M\_{1},M\_{2},p\_{1},p\_{2},p\_{3},p\_{4})

1:‚ÄÇSample N+,N‚àí‚àºPP‚Äã(Œª0)N^{+},N^{-}\sim\mathrm{PP}(\lambda\_{0}) on [0,œÑop][0,\tau^{\mathrm{op}}]

2:‚ÄÇDefine {t^i;i‚àà‚ü¶0,m‚üß}\{\hat{t}\_{i};\,i\in\llbracket 0,m\rrbracket\} as t^0=0\hat{t}\_{0}=0 and

|  |  |  |
| --- | --- | --- |
|  | t^i=min‚Å°(max‚Å°(t^i‚àí1+1,œÑi),œÑop‚àí1)‚Äãùüè{t^i‚àí1<œÑop‚àí1}+(œÑop‚àí1)‚Äãùüè{t^i‚àí1‚â•œÑop‚àí1}\hat{t}\_{i}=\min(\max(\hat{t}\_{i-1}+1,\tau\_{i}),\tau^{\mathrm{op}}-1)\mathbf{1}\_{\{\hat{t}\_{i-1}<\tau^{\mathrm{op}}-1\}}+(\tau^{\mathrm{op}}-1)\mathbf{1}\_{\{\hat{t}\_{i-1}\geq\tau^{\mathrm{op}}-1\}} |  |

with œÑi=max‚Å°(œÑi+,œÑi‚àí)\tau\_{i}=\max(\tau\_{i}^{+},\tau\_{i}^{-}) and œÑiŒ∂=inf(s‚â•t^i‚àí1,NsŒ∂>Nt^i‚àí1Œ∂)\tau\_{i}^{\zeta}=\inf\left(s\geq\hat{t}\_{i-1},\,N\_{s}^{\zeta}>N\_{\hat{t}\_{i-1}}^{\zeta}\right) for i‚â•1i\geq 1 and Œ∂‚àà{‚àí,+}\zeta\in\{-,+\}.

3:‚ÄÇfor k=0,‚Ä¶,mk=0,\ldots,m do

4:‚ÄÉ‚ÄÇSample Zt^k,Œ∂,i‚àºPareto‚Äã(vm,Œ≥m)Z\_{\hat{t}\_{k},\zeta,i}\sim\mathrm{Pareto}(v\_{m},\gamma\_{m}) for Œ∂‚àà{+,‚àí}\zeta\in\{+,-\} and i‚â§Nt^k+i\leq N\_{\hat{t}\_{k}}^{+} and let ŒΩt^kŒ∂,i=min‚Å°(Zt^k,Œ∂,i,V)\nu\_{\hat{t}\_{k}}^{\zeta,i}=\min(Z\_{\hat{t}\_{k},\zeta,i},V)

5:‚ÄÉ‚ÄÇSample Vt^kŒ∂,1‚àºV‚àû‚ÄãBeta‚Äã(Œ≤a,Œ≤b)V\_{\hat{t}\_{k}}^{\zeta,1}\sim V\_{\infty}\mathrm{Beta}(\beta\_{a},\beta\_{b}) and let Vt^kŒ∂,j=œÅ‚àí1‚ÄãVt^kŒ∂,j+1V\_{\hat{t}\_{k}}^{\zeta,j}=\rho^{-1}V\_{\hat{t}\_{k}}^{\zeta,j+1} for j‚àà‚ü¶1,L‚üßj\in\llbracket 1,L\rrbracket

6:‚ÄÇend for

7:‚ÄÇfor k=m+1,‚Ä¶,nk=m+1,\ldots,n do

8:‚ÄÉ‚ÄÇSample Bt^k‚àº‚Ñ¨‚Äã(p1)B\_{\hat{t}\_{k}}\sim\mathcal{B}(p\_{1}), Dt^k‚àº‚Ñ¨‚Äã(p2)D\_{\hat{t}\_{k}}\sim\mathcal{B}(p\_{2}), Jt^k+‚àº‚Ñ¨‚Äã(p3)J\_{\hat{t}\_{k}}^{+}\sim\mathcal{B}(p\_{3}), Jt^k‚àí‚àº‚Ñ¨‚Äã(p3)J\_{\hat{t}\_{k}}^{-}\sim\mathcal{B}(p\_{3}) and Gt^k‚àº‚Ñ¨‚Äã(p4)G\_{\hat{t}\_{k}}\sim\mathcal{B}(p\_{4})

9:‚ÄÉ‚ÄÇif Bt^k=1B\_{\hat{t}\_{k}}=1 then

10:‚ÄÉ‚ÄÉ‚ÄÇSample Kt^ki‚àºùí∞‚Äã([U1,U2])K\_{\hat{t}\_{k}}^{i}\sim\mathcal{U}([U\_{1},U\_{2}]) and St^ki‚àºSœÑopmid+Œ±‚Äãùí∞‚Äã(‚ü¶M1,M2‚üß)S\_{\hat{t}\_{k}}^{i}\sim S\_{\tau^{\mathrm{op}}}^{\mathrm{mid}}+\alpha\mathcal{U}(\llbracket M\_{1},M\_{2}\rrbracket) {Last belief on the mid price}

11:‚ÄÉ‚ÄÉ‚ÄÇNew market maker (Kt^ki,St^ki)(K\_{\hat{t}\_{k}}^{i},S\_{\hat{t}\_{k}}^{i}) arrives

12:‚ÄÉ‚ÄÇend if

13:‚ÄÉ‚ÄÇif Dt^k=1D\_{\hat{t}\_{k}}=1 and at least one market maker is present then

14:‚ÄÉ‚ÄÉ‚ÄÇCancel a random exogenous supply order

15:‚ÄÉ‚ÄÇend if

16:‚ÄÉ‚ÄÇfor Œ∂‚àà{+,‚àí}\zeta\in\{+,-\} do

17:‚ÄÉ‚ÄÉ‚ÄÇif Jt^kŒ∂=1J\_{\hat{t}\_{k}}^{\zeta}=1 and at least one market taker is present on side Œ∂\zeta then

18:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇSample Zt^k,Œ∂‚àºPareto‚Äã(vm,Œ≥m)Z\_{\hat{t}\_{k},\zeta}\sim\mathrm{Pareto}(v\_{m},\gamma\_{m}) and let ŒΩtŒ∂=min‚Å°(Zt^k,Œ∂,V)\nu^{\zeta}\_{t}=\min(Z\_{\hat{t}\_{k},\zeta},V)

19:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇNew market taker arrives with volume ŒΩtŒ∂\nu^{\zeta}\_{t}

20:‚ÄÉ‚ÄÉ‚ÄÇend if

21:‚ÄÉ‚ÄÇend for

22:‚ÄÉ‚ÄÇif Gt^k=1G\_{\hat{t}\_{k}}=1 then

23:‚ÄÉ‚ÄÉ‚ÄÇCancel a random exogenous market order

24:‚ÄÉ‚ÄÇend if

25:‚ÄÇend for

The input of our emulator are given by
(Œª0,vm,Œ≥m,V,Œ≤a,Œ≤b,V‚àû,œÅ,U1,U2,M1,M2,p1,p2,p3,p4)(\lambda\_{0},v\_{m},\gamma\_{m},V,\beta\_{a},\beta\_{b},V\_{\infty},\rho,U\_{1},U\_{2},M\_{1},M\_{2},p\_{1},p\_{2},p\_{3},p\_{4}).

* ‚Ä¢

  Œª0\lambda\_{0} represents the intensity of the counting processes N+N^{+} and N‚àíN^{-} on the continuous phase, modeled as independent Poisson processes. The two processes are not observable for the agent during the continuous phase, but only during the auction phase. They are sampled in the first step of the algorithm.
* ‚Ä¢

  (vm,Œ≥m)(v\_{m},\gamma\_{m}) are the parameters of the Pareto distribution modeling the volumes of the limit orders throughout the whole trading sessions. This reproduces the well-known heavy tail behavior of the density of market order size, see for example [[27](https://arxiv.org/html/2601.17247v1#bib.bib3 "Statistical properties of share volume traded in financial markets"), [23](https://arxiv.org/html/2601.17247v1#bib.bib47 "Power laws in economics and finance"), [10](https://arxiv.org/html/2601.17247v1#bib.bib46 "Power laws in economics and finance: some ideas fromphysics")]. The market model allows orders of maximum size VV: greater liquidity takers will accumulate at volume VV.
* ‚Ä¢

  (Œ≤a,Œ≤b)(\beta\_{a},\beta\_{b}) represent the parameters of the Beta distribution modeling the first volume of the limit order book. It is similar to the Beta scaling effect described in for example [[32](https://arxiv.org/html/2601.17247v1#bib.bib43 "Market making with scaled beta policies"), [60](https://arxiv.org/html/2601.17247v1#bib.bib44 "Market making with learned beta policies")]. Note that V‚àûV\_{\infty} is a rescaling parameter as the Beta distribution has support [0,1][0,1]. Further volumes in the limit order book decay geometrically with parameter œÅ‚àà(0,1]\rho\in(0,1].
* ‚Ä¢

  (U1,U2)(U\_{1},U\_{2}) represent the bounds between which exogenous market maker sample their supply slopes from during the auction phase.
* ‚Ä¢

  (M1,M2)(M\_{1},M\_{2}) represent the integer bounds of the price at which exogenous market makers quote during the auction phase. Exogenous market makers during the volume are assumed to be sampled as Sti‚àºSœÑopmid+Œ±‚Äãùí∞‚Äã(‚ü¶M1,M2‚üß)S\_{t}^{i}\sim S\_{\tau^{\mathrm{op}}}^{\mathrm{mid}}+\alpha\mathcal{U}(\llbracket M\_{1},M\_{2}\rrbracket) because the auction opening time is the last time market participants see the mid price. Note that this shape of auction price have been introduced in [[19](https://arxiv.org/html/2601.17247v1#bib.bib42 "Equilibria and incentives for illiquid auction markets")].
* ‚Ä¢

  (p1,p2,p3,p4)(p\_{1},p\_{2},p\_{3},p\_{4}) represent the probabilities that drive the market structure during the auction phase. A new market maker arrives per step with probability p1p\_{1}, one market maker cancels his order with probability p2p\_{2}, a market taker arrives on either side with probability p3p\_{3}, and a market taker cancels his order with probability p4p\_{4}. These events are sampled using a Bernoulli distribution.

Note that all samples are done independently from each other. We do assume that the limit order book is refreshed from one time step to the next one.

Line 2 of Algorithm [2](https://arxiv.org/html/2601.17247v1#alg2 "Algorithm 2 ‚Ä£ 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") defines the time grid {t^i;i‚àà‚ü¶0,m‚üß}\{\hat{t}\_{i};\,i\in\llbracket 0,m\rrbracket\}. The time grid is chosen such that there is at least one market taker on either side of the market at any time t^i\hat{t}\_{i} for i‚àà‚ü¶0,m‚üßi\in\llbracket 0,m\rrbracket. This allows to satisfy Assumption [5](https://arxiv.org/html/2601.17247v1#Thmassumption5 "Assumption 5. ‚Ä£ 3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions"). Lines 3 to 6 describe the mechanics of the continuous phase. Lines 7 to 24 describe the mechanics of the auction phase.

For the learning process, both Q-networks (Q~œï\tilde{Q}\_{\phi} and Q~œà\tilde{Q}\_{\psi}) are multi-layer perceptrons with three width-16 fully connected hidden layers and ReLU activations. To simplify computations, we pruned the state vector to Xt=(It,Htcl,Lt+,Lt‚àí,Stmid,Vt+,1,Vt‚àí,1)X\_{t}=(I\_{t},H\_{t}^{\mathrm{cl}},L\_{t}^{+},L\_{t}^{-},S\_{t}^{\mathrm{mid}},V\_{t}^{+,1},V\_{t}^{-,1}) for the continuous phase, and Xt=(It,Zt‚Äãùüè{t=œÑcl},Htcl,Mt,Nt+,Nt‚àí,Œ∏t,Stmid)X\_{t}=(I\_{t},Z\_{t}\mathbf{1}\_{\{t=\tau^{\mathrm{cl}}\}},H\_{t}^{\mathrm{cl}},M\_{t},N\_{t}^{+},N\_{t}^{-},\theta\_{t},S\_{t}^{\mathrm{mid}}) for the auction.

###### Remark 6.1.

The neural network structure is intentionally simple to limit computational cost, serving a primarily illustrative purpose. We still expect the model to outperform benchmarks on average but with higher variance, given the low penalty parameters and the agent‚Äôs ability to obtain fictive rewards in the closing auction.

| Symbol | Value | Comment |
| --- | --- | --- |
| œÑop\tau^{\mathrm{op}} | 120 | Auction opening time |
| œÑcl\tau^{\mathrm{cl}} | 150 | Clearing time |
| I0I\_{0} | 100 | Initial inventory |
| Œª0\lambda\_{0} | 11 | Continuous phase Poisson intensity |
| vmv\_{m} | 2 | Pareto distribution scale parameter |
| Œ≥m\gamma\_{m} | 2.5 | Pareto distribution shape parameter |
| V‚àûV\_{\infty} | 15 | Beta distribution scaling parameter |
| Œ≤a\beta\_{a} | 2 | First Beta distribution shape parameter |
| Œ≤b\beta\_{b} | 5 | Second Beta distribution shape parameter |
| œÅ\rho | 12\frac{1}{2} | Limit order book volume decay parameter |
| VV | 30 | Maximum volume admitted by the market |
| U1U\_{1} | 0.1 | Exogenous supply slope lower bound |
| U2U\_{2} | 2.0 | Exogenous supply slope upper bound |
| M1M\_{1} | 10 | Exogenous supply spread upper bound |
| M2M\_{2} | ‚àí10-10 | Exogenous supply spread lower bound |
| p1p\_{1} | 0.3 | New market maker arrival probability |
| p2p\_{2} | 0.2 | Market maker cancellation probability |
| p3p\_{3} | 0.3 | New market taker arrival probability |
| p4p\_{4} | 0.1 | Market taker cancellation probability |
| Œª\lambda | 0.5 | Inventory penalty |
| qq | 1 | Wrong-side dealing penalty |
| k‚ãÜk^{\star} | 1,000 | Tolerance |
| dd | 0.1 | Cancellation cost per unit |
| Œ±\alpha | 0.01 | Tick size |
| Œ≤\beta | 3.33 | Tick size of grid on KaK^{a} |
| ùí¶\mathcal{K} | 10 | Upper bound on Ka/Œ≤K^{a}/\beta |

Table 2: Generative stochastic market model parameters

The numerical simulations consist in training the model over 2,000 episodes, before evaluating it on 100 independent episodes.

### 6.2 Benchmark simulations

We start by simulating the optimal strategies for the Benchmarks in Figure [1](https://arxiv.org/html/2601.17247v1#S6.F1 "Figure 1 ‚Ä£ 6.2 Benchmark simulations ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"). On the top left, we show the evolution of the inventories for both AS and TWAP, on the top right we simulate the continuous phase limit price, on the bottom left the optimal volume submitted during the continuous phase, and on the bottom right we show the optimal slope KtK\_{t} during the auction. Note that the TWAP fails to liquidate all the inventory before the auction starts unlike the AS strategy explaining the difference of order executed in the auction between these two benchmarks.

![Refer to caption](figures/benchmark_behavior_episode_2000.png)


Figure 1: Episode 2000 for the benchmarks

### 6.3 Rough Heston model for the mid price: generative data approach

In this section, we generate data from the rough-Heston model. We consider a trading session with a 2 minute continuous phase, followed by a 30 second closing auction.

#### 6.3.1 Numerical method and parameter calibration

In the first numerical implementation, we assume that the mid price StS\_{t} follows a rough Heston model. The motivation is based on the so-called rough volatility of financial assets [[26](https://arxiv.org/html/2601.17247v1#bib.bib8 "Volatility is rough"), b√§uerle2020portfolio, [1](https://arxiv.org/html/2601.17247v1#bib.bib9 "Multifactor approximation of rough volatility models")]. Consider œÅ‚àà[‚àí1,1]\rho\in[-1,1] a constant, S0=100S\_{0}=100 (which is the numerical value we work with in this section), V0V\_{0}, HH, Œ∏\theta, Œª\lambda and ŒΩ\nu be positive constants. Recalling [[26](https://arxiv.org/html/2601.17247v1#bib.bib8 "Volatility is rough"), [54](https://arxiv.org/html/2601.17247v1#bib.bib63 "On the discrete-time simulation of the rough heston model")], the rough Heston model writes

|  |  |  |
| --- | --- | --- |
|  | {St=S0+‚à´0tSs‚ÄãVs‚Äãd‚Äã(œÅ‚ÄãBs+1‚àíœÅ2‚ÄãBs‚üÇ),Vt=V0+‚à´0tK‚Äã(t‚àís)‚Äã((Œ∏‚àíŒª‚ÄãVs)‚Äãd‚Äãs+ŒΩ‚ÄãVs‚Äãd‚ÄãBs),\begin{cases}S\_{t}&=S\_{0}+\int\_{0}^{t}S\_{s}\sqrt{V\_{s}}\mathrm{d}\big(\rho B\_{s}+\sqrt{1-\rho^{2}}B\_{s}^{\perp}\big),\\ V\_{t}&=V\_{0}+\int\_{0}^{t}K(t-s)\big((\theta-\lambda V\_{s})\mathrm{d}s+\nu\sqrt{V\_{s}}\mathrm{d}B\_{s}\big),\end{cases} |  |

where (B,B‚üÇ)(B,B^{\perp}) are two independent Brownian motions. We used the Euler-type scheme of [[54](https://arxiv.org/html/2601.17247v1#bib.bib63 "On the discrete-time simulation of the rough heston model")] to approximate this rough Heston model. As a reminder, for the grid œÄn={0=t0n<‚ãØ‚Äãtnn=T}\pi\_{n}=\{0=t\_{0}^{n}<\cdots t\_{n}^{n}=T\} (here T=œÑopT=\tau^{\mathrm{op}} and n=œÑopn=\tau^{\mathrm{op}}), we set Œî‚Äãtk+1n=tk+1n‚àít^kn\Delta t\_{k+1}^{n}=t\_{k+1}^{n}-\hat{t}\_{k}^{n} for k‚àà‚ü¶0,n‚àí1‚üßk\in\llbracket 0,n-1\rrbracket. Then Stk=exp‚Å°(Ytk)S\_{t\_{k}}=\exp(Y\_{t\_{k}}) for k‚àà‚ü¶0,n‚üßk\in\llbracket 0,n\rrbracket where

|  |  |  |
| --- | --- | --- |
|  | {Ytk=Y0+‚àëi=0k‚àí1(‚àí12‚Äã(Vti)+‚ÄãŒî‚Äãti+1n+œÅ‚Äã(Vti)+‚Äã(Bti+1‚àíBti)+1‚àíœÅ2‚Äã(Vti)+‚Äã(Bti+1‚üÇ‚àíBti‚üÇ)),Vtk=V0+‚àëi=0k‚àí1(K‚Äã(tk‚àíti)‚Äã(Œ∏‚àíŒª‚Äã(Vti)+)‚ÄãŒî‚Äãti+1n+K‚Äã(tk‚àíti)‚ÄãŒΩ‚Äã(Vti)+‚Äã(Bti+1‚àíBti)).\begin{cases}Y\_{t\_{k}}&=Y\_{0}+\sum\_{i=0}^{k-1}\big(-\frac{1}{2}(V\_{t\_{i}})\_{+}\Delta t\_{i+1}^{n}+\rho\sqrt{(V\_{t\_{i}})\_{+}}\left(B\_{{t}\_{i+1}}-B\_{{t}\_{i}}\right)+\sqrt{1-\rho^{2}}\sqrt{(V\_{t\_{i}})\_{+}}\left(B\_{{t}\_{i+1}}^{\perp}-B\_{{t}\_{i}}^{\perp}\right)\big),\\ V\_{t\_{k}}&=V\_{0}+\sum\_{i=0}^{k-1}\big(K({t}\_{k}-{t}\_{i})(\theta-\lambda(V\_{t\_{i}})\_{+})\Delta t\_{i+1}^{n}+K({t}\_{k}-{t}\_{i})\nu\sqrt{(V\_{t\_{i}})\_{+}}\left(B\_{{t}\_{i+1}}-B\_{{t}\_{i}}\big)\right).\end{cases} |  |

In numerical applications, we used H=0.1H=0.1, œÅ=‚àí0.7\rho=-0.7, V0=0.02V\_{0}=0.02, Œ∏=0.04\theta=0.04, Œª=0.3\lambda=0.3 and ŒΩ=0.3\nu=0.3 as calibrated in [[2](https://arxiv.org/html/2601.17247v1#bib.bib66 "Lifting the Heston model")]. We scaled these parameters correctly to the trading period.

Now, one may notice that the AS theoretical benchmark assumes that d‚ÄãSt=œÉ‚Äãd‚ÄãBt\mathrm{d}S\_{t}=\sigma\mathrm{d}B\_{t}, instead of the rough Heston model. In this sense, the goal of the numerical simulation is to compare how our NFQ-learned policy performs against a theoretical benchmark, without claiming optimality of this benchmark. We are in fact expecting our model to beat the benchmark (since the benchmark is only optimal for a Bachelier process for the mid price).

We calibrated the value œÉ\sigma by estimating the standard deviation of the mid price on the trading period. From [[4](https://arxiv.org/html/2601.17247v1#bib.bib64 "High-frequency trading in a limit order book")], we have A=Œª0/Œ≥mA=\lambda\_{0}/\gamma\_{m} and k=Œ±‚ÄãKk=\alpha K. Here, KK is the proportionality constant in the empirical relationship K‚ÄãŒî‚Äãp=ln‚Å°(Q)K\Delta p=\ln(Q), where Œî‚Äãp\Delta p is the move in price when a market order of size QQ arrives. We did a least squares regression to determine KK, by simulating 5,000 samples of the limit order book and market orders Q‚àºPareto‚Äã(vm,Œ≥m)Q\sim\mathrm{Pareto}(v\_{m},\gamma\_{m}).

#### 6.3.2 Learning performance

In Figure [2](https://arxiv.org/html/2601.17247v1#S6.F2 "Figure 2 ‚Ä£ 6.3.2 Learning performance ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") we represents on the left the loss associated with the NFQ during the training. We see that the loss during the CLOB session is stable at a low level, while the loss during the auction phase is stable then explodes starting at episode 1,000. This is explained by the fact that after episode 1,000, the loss is not stabilized yet but the NFQ discovers a strategy that outperforms both benchmarks, see Figure [2(b)](https://arxiv.org/html/2601.17247v1#S6.F2.sf2 "In Figure 2 ‚Ä£ 6.3.2 Learning performance ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") leading to a decrease of the regret and better reward.

![Refer to caption](figures/dqn_training_loss.png)


(a) Training loss

![Refer to caption](figures/dqn_vs_glft_regret.png)


(b) Regret analysis

Figure 2: Training analysis

We now represents the behavior of the generative stochastic market model and the performance of the NFQ model over the last training episode. Figure [3](https://arxiv.org/html/2601.17247v1#S6.F3 "Figure 3 ‚Ä£ 6.3.2 Learning performance ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") below shows (from the left to the right and the top to the bottom) the mid price StmidS\_{t}^{\mathrm{mid}}; the inventory ItI\_{t}; the number of executed shares EtE\_{t}; the quantity HtclH\_{t}^{\mathrm{cl}}, which, as a reminder, is the hypothetical clearing price during the continuous phase and the estimated clearing price during the auction phase; the top-of-book volumes Vt+,1V\_{t}^{+,1} and Vt‚àí1V\_{t}^{-1}; the market order arrivals during the auction phase; the one-step reward RtR\_{t}; the cumulative reward, and the actions (vt,Œ¥t)(v\_{t},\delta\_{t}) and (Kta,Sta)(K\_{t}^{a},S\_{t}^{a}).

![Refer to caption](figures/episode_2000.png)


Figure 3: Episode 2000 for the agent

##### Financial insights.

We observe that the inventory of the market maker decays to 0 during the continuous phase, and becomes negative at the clearing time of the auction, as the order of the market taker is executed. This is illustrated by the plot of EtE\_{t}: many orders are executed during the continuous phase, while only one single volume is executed at the end of the auction phase. The estimated clearing price HtclH\_{t}^{\mathrm{cl}} is very stable during the continuous phase. It becomes more variable during the auction phase, as one approaches the clearing time, so more information is available. Finally, the auction allows the agent to obtain important rewards. While these rewards are fictive before the clearing time, even the final reward is very important (the largest reward recorder during the episode) and effectively shows that the closing auction is useful to generate reward.

#### 6.3.3 Returns and performance of the NFQ strategy

In Table [3](https://arxiv.org/html/2601.17247v1#S6.T3 "Table 3 ‚Ä£ 6.3.3 Returns and performance of the NFQ strategy ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") we illustrate the mean return, standard deviation of the return, the median return, the mean final inventory, the mean CLOB return and mean auction return for the initial NFQ (before training), AS, TWAP and final NFQ (after training). The second bottom part of the table shows a comparative performance between initial NFQ, AS, TWAP and final NFQ. The final NFQ strategy benefits from the auction trading phase to generate more profit. Note that the variance is however high, as expected and explained in Remark [6.1](https://arxiv.org/html/2601.17247v1#S6.Thmremark1 "Remark 6.1. ‚Ä£ 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"). The final NFQ model does however outperform the two benchmarks on mean returns.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Metric | Initial NFQ | AS | TWAP | Final NFQ |
| Mean Return | 3,536.5 | 9,411.1 | 4,592.5 | 12,169.2 |
| Std Return | 18,612.0 | 1,606.9 | 3,110.4 | 16,552.4 |
| Median Return | 6,493.2 | 9,847.3 | 4,877.7 | 9,752.9 |
| Mean Final Inventory | 10.93 |  |  | 10.98 |
| Mean CLOB Reward | 8,935.7 |  |  | 8,879.1 |
| Mean Auction Reward | -5,399.2 |  |  | 3,290.1 |
| Relative Improvements (Mean Return) | | | | |
| vs Initial NFQ |  | +166.1% | +29.9% | +244.1% |
| vs AS |  |  | -51.2% | +29.3% |
| vs TWAP |  |  |  | +165.0% |

Table 3: Evaluation results on 100 episodes

### 6.4 Historical data

We now consider a trading session of a 2 hour continuous phase, followed by a 30 minute closing auction. Instead of simulating a fictive mid price, we consider realized mid price paths of stocks of the S&P500 index, from December 31, 2025 between 2:30pm and 5pm EST. We train on 1,000 episodes. All other parameters remain identical. For precision, we use the same realized price path of each asset for each episode for the training. The symbol œÉ^\hat{\sigma} in table [4](https://arxiv.org/html/2601.17247v1#S6.T4 "Table 4 ‚Ä£ 6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions") corresponds to the estimated volatility of each stock on the continuous session.

| Symbol | œÉ^\hat{\sigma} | Initial NFQ | AS | TWAP | Final NFQ | Imp. vs | Imp. vs |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  |  | Return | Return | Return | Return | AS (%) | TWAP (%) |
| CAT | 5.77√ó10‚àí45.77\times 10^{-4} | 8,469.42 | 9,691.33 | 9,774.44 | 15,823.51 | +63.27% | +61.89% |
| PG | 4.10√ó10‚àí44.10\times 10^{-4} | 8,225.24 | 9,537.41 | 9,713.63 | 14,743.17 | +54.58% | +51.78% |
| GOOGL | 5.90√ó10‚àí45.90\times 10^{-4} | 8,473.45 | 9,808.40 | 9,933.75 | 13,905.10 | +41.77% | +39.98% |
| JPM | 5.49√ó10‚àí45.49\times 10^{-4} | 8,293.70 | 9,497.72 | 9,416.98 | 12,655.13 | +33.24% | +34.39% |
| MSFT | 4.12√ó10‚àí44.12\times 10^{-4} | 8,454.15 | 9,630.56 | 9,465.55 | 10,687.35 | +10.97% | +12.91% |
| Mean |  | 8,383.19 | 9,633.09 | 9,660.87 | 13,562.85 | +40.77% | +40.19% |

Table 4: Comparison of mean returns on 100 episodes

We see that the final NFQ outperforms both benchmarks on average returns. These results advocate for NFQ strategy over the classical AS or TWAP benchmark to maximize the return. We demonstrate that neural-fitted Q-learning can learn policies that outperform theoretical benchmarks on average. These findings suggest that reinforcement learning has the potential to be effective for market making in complex structures beyond simple limit order books with closing auction, as for example workup session or AHEAD mechanism [[21](https://arxiv.org/html/2601.17247v1#bib.bib41 "Size discovery"), [18](https://arxiv.org/html/2601.17247v1#bib.bib38 "AHEAD: ad hoc electronic auction design")] or sequence of periodic auctions [[42](https://arxiv.org/html/2601.17247v1#bib.bib61 "The economics of competitive bidding: a selective survey"), [39](https://arxiv.org/html/2601.17247v1#bib.bib62 "Trading mechanisms in securities markets"), [11](https://arxiv.org/html/2601.17247v1#bib.bib50 "Implementation details for frequent batch auctions: slowing down markets to the blink of an eye")].

## References

* [1]
  E. Abi Jaber and O. El Euch (2019)
  Multifactor approximation of rough volatility models.
  SIAM journal on financial mathematics 10 (2),  pp.¬†309‚Äì349.
  Cited by: [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p1.8 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [2]
  E. Abi Jaber (2019)
  Lifting the Heston model.
  Quantitative finance 19 (12),  pp.¬†1995‚Äì2013.
  Cited by: [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p1.22 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [3]
  R. Almgren and N. Chriss (2001)
  Optimal execution of portfolio transactions.
  Journal of Risk 3,  pp.¬†5‚Äì40.
  Cited by: [¬ß5.2](https://arxiv.org/html/2601.17247v1#S5.SS2.p1.3 "5.2 Time-weighted average price benchmark ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions").
* [4]
  M. Avellaneda and S. Stoikov (2008)
  High-frequency trading in a limit order book.
  Quantitative Finance 8 (3),  pp.¬†217‚Äì224.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p1.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p3.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p4.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5.1](https://arxiv.org/html/2601.17247v1#S5.SS1.1.p1.2 "Proof. ‚Ä£ 5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5.1](https://arxiv.org/html/2601.17247v1#S5.SS1.p1.12 "5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5](https://arxiv.org/html/2601.17247v1#S5.p1.1 "5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p3.9 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [5]
  B. Baldacci, P. Bergault, and O. Gu√©ant (2021)
  Algorithmic market making for options.
  Quantitative Finance 21 (1),  pp.¬†85‚Äì97.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p1.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [6]
  M. Bellia, L. Pelizzon, M. G. Subrahmanyam, and D. Yuferova (2025)
  Market liquidity and competition among designated market makers.
  Management Science 71 (1),  pp.¬†184‚Äì201.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p1.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [7]
  T. Beysolow II (2019)
  Market making via reinforcement learning.
  In Applied Reinforcement Learning with Python: With OpenAI Gym, Tensorflow, and Keras,
   pp.¬†77‚Äì94.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [8]
  B. Biais and A. M. Faugeron-Crouzet (2002)
  IPO auctions: english, dutch,‚Ä¶ french, and internet.
  Journal of Financial Intermediation 11 (1),  pp.¬†9‚Äì36.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p3.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [9]
  B. Biais, P. Hillion, and C. Spatt (1999)
  Price discovery and learning during the preopening period in the paris bourse.
  Journal of Political Economy 107 (6),  pp.¬†1218‚Äì1248.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p3.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [10]
  J. Bouchaud (2001)
  Power laws in economics and finance: some ideas fromphysics.
  Quantitative finance 1 (1),  pp.¬†105.
  Cited by: [2nd item](https://arxiv.org/html/2601.17247v1#S6.I1.i2.p1.3 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [11]
  E. Budish, P. Cramton, and J. Shim (2014)
  Implementation details for frequent batch auctions: slowing down markets to the blink of an eye.
  American Economic Review 104 (5),  pp.¬†418‚Äì424.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p3.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß6.4](https://arxiv.org/html/2601.17247v1#S6.SS4.p2.1 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [12]
  J. Cao, D. ≈†i≈°ka, L. Szpruch, and T. Treetanthiploet (2024)
  Logarithmic regret in the ergodic Avellaneda-Stoikov market making model.
  arXiv preprint arXiv:2409.02025.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [13]
  A. Capponi and C. Lehalle (2023)
  Machine learning and data sciences for financial markets: a guide to contemporary practices.
   Cambridge University Press.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [14]
  R. Carmona (2022)
  The influence of economic research on financial mathematics: evidence from the last 25 years.
  Finance and Stochastics 26 (1),  pp.¬†85‚Äì101.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p1.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [15]
  √Å. Cartea, S. Jaimungal, and J. Penalva (2015)
  Algorithmic and high-frequency trading.
   Cambridge University Press.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p1.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [16]
  N. Cesa-Bianchi, T. Cesari, R. Colomboni, L. Foscari, and V. Pathak (2024)
  Market making without regret.
  arXiv preprint arXiv:2411.13993.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [17]
  C. Cuchiero, H. Ruimeng, S. Svaluto-Ferro, X. Renyuan, et al. (2024)
  Special issue on machine learning in finance.
  Mathematical Finance 34 (2),  pp.¬†259‚Äì261.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [18]
  J. Derchu, P. Guillot, T. Mastrolia, and M. Rosenbaum (2024)
  AHEAD: ad hoc electronic auction design.
  Frontiers of Mathematical Finance 3 (2),  pp.¬†163‚Äì213.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p1.1 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß6.4](https://arxiv.org/html/2601.17247v1#S6.SS4.p2.1 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [19]
  J. Derchu, D. Kavvathas, T. Mastrolia, and M. Rosenbaum (2023)
  Equilibria and incentives for illiquid auction markets.
  arXiv preprint arXiv:2307.15805, to appear in
  Market Microstructure and Liquidity.
  Cited by: [5th item](https://arxiv.org/html/2601.17247v1#S6.I1.i5.p1.2 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [20]
  S. Du and H. Zhu (2014)
  Welfare and optimal trading frequency in dynamic double auctions.
  Technical report
   National Bureau of Economic Research.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p2.5 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").
* [21]
  D. Duffie and H. Zhu (2017)
  Size discovery.
  The Review of Financial Studies 30 (4),  pp.¬†1095‚Äì1150.
  Cited by: [¬ß6.4](https://arxiv.org/html/2601.17247v1#S6.SS4.p2.1 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [22]
  J. Fan, Z. Wang, Y. Xie, and Z. Yang (2020)
  A theoretical analysis of deep Q-learning.
  In Learning for dynamics and control,
   pp.¬†486‚Äì489.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [23]
  X. Gabaix (2009)
  Power laws in economics and finance.
  Annu. Rev. Econ. 1 (1),  pp.¬†255‚Äì294.
  Cited by: [2nd item](https://arxiv.org/html/2601.17247v1#S6.I1.i2.p1.3 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [24]
  S. Ganesh, N. Vadori, M. Xu, H. Zheng, P. Reddy, and M. Veloso (2019)
  Reinforcement learning for market making in a multi-agent dealer market.
  arXiv preprint arXiv:1911.05892.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [25]
  B. Ga≈°perov and Z. Kostanjƒçar (2021)
  Market making with signals through deep reinforcement learning.
  IEEE access 9,  pp.¬†61611‚Äì61622.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [26]
  J. Gatheral, T. Jaisson, and M. Rosenbaum (2022)
  Volatility is rough.
  In Commodities,
   pp.¬†659‚Äì690.
  Cited by: [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p1.8 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß6](https://arxiv.org/html/2601.17247v1#S6.p1.1 "6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [27]
  P. Gopikrishnan, V. Plerou, X. Gabaix, and H. E. Stanley (2000)
  Statistical properties of share volume traded in financial markets.
  Physical review e 62 (4),  pp.¬†R4493.
  Cited by: [2nd item](https://arxiv.org/html/2601.17247v1#S6.I1.i2.p1.3 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [28]
  O. Gu√©ant, C. Lehalle, and J. Fernandez-Tapia (2013)
  Dealing with the inventory risk: a solution to the market making problem.
  Mathematics and financial economics 7 (4),  pp.¬†477‚Äì507.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p1.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p3.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p4.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5.1](https://arxiv.org/html/2601.17247v1#S5.SS1.1.p1.2 "Proof. ‚Ä£ 5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5.1](https://arxiv.org/html/2601.17247v1#S5.SS1.1.p1.3 "Proof. ‚Ä£ 5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5.1](https://arxiv.org/html/2601.17247v1#S5.SS1.p1.12 "5.1 Avellaneda-Stoikov optimal market making ‚Ä£ 5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß5](https://arxiv.org/html/2601.17247v1#S5.p1.1 "5 Theoretical benchmarks ‚Ä£ Learning Market Making with Closing Auctions").
* [29]
  O. Gu√©ant and I. Manziuk (2019)
  Deep reinforcement learning for market making in corporate bonds: beating the curse of dimensionality.
  Applied Mathematical Finance 26 (5),  pp.¬†387‚Äì452.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [30]
  B. Hambly, R. Xu, and H. Yang (2023)
  Recent advances in reinforcement learning in finance.
  Mathematical Finance 33 (3),  pp.¬†437‚Äì503.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [31]
  S. Jantschgi (2024)
  Transaction cost (in) transparency: coasian dynamics in frequent batch auctions.
  Available at SSRN 4861066.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [32]
  J. Jerome, G. Palmer, and R. Savani (2022)
  Market making with scaled beta policies.
  In Proceedings of the Third ACM International Conference on AI in Finance,
   pp.¬†214‚Äì222.
  Cited by: [3rd item](https://arxiv.org/html/2601.17247v1#S6.I1.i3.p1.4 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [33]
  J. Jerome, L. S√°nchez-Betancourt, R. Savani, and M. Herdegen (2023)
  Mbt-gym: reinforcement learning for model-based limit order book trading.
  In Proceedings of the Fourth ACM International Conference on AI in Finance,
   pp.¬†619‚Äì627.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [34]
  E. Kandel, B. Rindi, and L. Bosetti (2012)
  The effect of a closing call auction on market quality and trading strategies.
  Journal of Financial Intermediation 21 (1),  pp.¬†23‚Äì49.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p2.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [35]
  M. Kearns and Y. Nevmyvaka (2013)
  Machine learning for market microstructure and high frequency trading.
  High frequency trading: New realities for traders, markets, and regulators 72,  pp.¬†1877‚Äì1901.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [36]
  A. S. Kyle (1985)
  Continuous auctions and insider trading.
  Econometrica: Journal of the Econometric Society,  pp.¬†1315‚Äì1335.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p1.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [37]
  L. Leal, M. Lauri√®re, and C. Lehalle (2022)
  Learning a functional control for high-frequency finance.
  Quantitative Finance 22 (11),  pp.¬†1973‚Äì1987.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [38]
  A. Madhavan and V. Panchapagesan (2000)
  Price discovery in auction markets: a look inside the black box.
  The Review of Financial Studies 13 (3),  pp.¬†627‚Äì658.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p3.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [39]
  A. Madhavan (1992)
  Trading mechanisms in securities markets.
  the Journal of Finance 47 (2),  pp.¬†607‚Äì641.
  Cited by: [¬ß6.4](https://arxiv.org/html/2601.17247v1#S6.SS4.p2.1 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [40]
  T. Mastrolia and T. Xu (2024)
  Clearing time randomization and transaction fees for auction market design.
  arXiv preprint arXiv:2405.09764.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p1.1 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p3.9 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").
* [41]
  T. Mastrolia and T. Xu (2025)
  Optimal rebate design: incentives, competition and efficiency in auction markets.
  arXiv preprint arXiv:2501.12591.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p2.5 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.3](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS3.p4.1 "2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").
* [42]
  P. R. Milgrom (1985)
  The economics of competitive bidding: a selective survey.
  Social goals and social organization: Essays in memory of Elisha Pazner,  pp.¬†261‚Äì292.
  Cited by: [¬ß6.4](https://arxiv.org/html/2601.17247v1#S6.SS4.p2.1 "6.4 Historical data ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [43]
  P. R. Milgrom (2004)
  Putting auction theory to work.
   Cambridge University Press.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p1.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [44]
  P. Milgrom (1989)
  Auctions and bidding: a primer.
  Journal of economic perspectives 3 (3),  pp.¬†3‚Äì22.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p1.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [45]
  P. Milgrom (2019)
  Auction market design: recent innovations.
  Annual Review of Economics 11 (1),  pp.¬†383‚Äì405.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p2.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [46]
  V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al. (2015)
  Human-level control through deep reinforcement learning.
  nature 518 (7540),  pp.¬†529‚Äì533.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p2.9 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [47]
  V. Mnih (2013)
  Playing atari with deep reinforcement learning.
  arXiv preprint arXiv:1312.5602.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p2.9 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [48]
  R. Neuneier (1997)
  Enhancing Q-learning for optimal asset allocation.
  Advances in neural information processing systems 10.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [49]
  Y. Nevmyvaka, Y. Feng, and M. Kearns (2006)
  Reinforcement learning for optimized trade execution.
  In Proceedings of the 23rd international conference on Machine learning,
   pp.¬†673‚Äì680.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [50]
  B. Ning, F. H. T. Lin, and S. Jaimungal (2021)
  Double deep Q-learning for optimal execution.
  Applied Mathematical Finance 28 (4),  pp.¬†361‚Äì380.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [51]
  J. Paul, M. Thibaut, and R. Mathieu (2021)
  Optimal auction duration: a price formation viewpoint.
  Operations Research 69 (6),  pp.¬†1734‚Äì1745.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.1](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS1.p4.1 "2.1.1 Trading during the continuous phase [0,ùúè·µí·µñ) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.2](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS2.p2.5 "2.1.2 Trading during the auction phase [ùúè·µí·µñ,ùúè^cl) ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.3](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS3.p4.1 "2.1.3 Clearing price rule and estimation along the auction ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß2.1.4](https://arxiv.org/html/2601.17247v1#S2.SS1.SSS4.p1.2 "2.1.4 Projected hypothetical clearing price during the continuous session ‚Ä£ 2.1 Mathematical framework and trading phases ‚Ä£ 2 Market model ‚Ä£ Learning Market Making with Closing Auctions").
* [52]
  M. L. Puterman (2014)
  Markov decision processes: discrete stochastic dynamic programming.
   John Wiley & Sons.
  Cited by: [Proposition 3.1](https://arxiv.org/html/2601.17247v1#S3.Thmproposition1 "Proposition 3.1 (Theorem 6.2.10 in [52]). ‚Ä£ Reward. ‚Ä£ 3 Markov Decision Process and dynamic programming for optimal market making with closing auction ‚Ä£ Learning Market Making with Closing Auctions").
* [53]
  F. Raillon (2020)
  The growing importance of the closing auction in share trading volumes.
  Journal of Securities Operations & Custody 12 (2),  pp.¬†135‚Äì152.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p2.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [54]
  A. Richard, X. Tan, and F. Yang (2023)
  On the discrete-time simulation of the rough heston model.
  SIAM Journal on Financial Mathematics 14 (1),  pp.¬†223‚Äì249.
  Cited by: [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p1.16 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß6.3.1](https://arxiv.org/html/2601.17247v1#S6.SS3.SSS1.p1.8 "6.3.1 Numerical method and parameter calibration ‚Ä£ 6.3 Rough Heston model for the mid price: generative data approach ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [55]
  M. Riedmiller (2005)
  Neural fitted Q iteration‚Äìfirst experiences with a data efficient neural reinforcement learning method.
  In European conference on machine learning,
   pp.¬†317‚Äì328.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p2.9 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß4.2](https://arxiv.org/html/2601.17247v1#S4.SS2.p2.12 "4.2 Neural-fitted Q-learning ‚Ä£ 4 Learning market making with closing auction in an unknown environment ‚Ä£ Learning Market Making with Closing Auctions").
* [56]
  M. Salek, D. Challet, and I. Muni Toke (2024)
  Equity auction dynamics: latent liquidity models with activity acceleration.
  Quantitative Finance 24 (10),  pp.¬†1381‚Äì1398.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p4.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [57]
  J. A. Sirignano (2019)
  Deep learning for limit order books.
  Quantitative Finance 19 (4),  pp.¬†549‚Äì570.
  Cited by: [¬ß1.1](https://arxiv.org/html/2601.17247v1#S1.SS1.p2.1 "1.1 Reinforcement learning and market making ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [58]
  R. S. Sutton, A. G. Barto, et al.
  Reinforcement learning: an introduction.
  Vol. 1.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p2.9 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [59]
  G. Vulcano, G. Van Ryzin, and C. Maglaras (2002)
  Optimal dynamic auctions for revenue management.
  Management Science 48 (11),  pp.¬†1388‚Äì1407.
  Cited by: [¬ß1.2](https://arxiv.org/html/2601.17247v1#S1.SS2.p1.1 "1.2 On the importance of (closing) auctions ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions").
* [60]
  Y. Wang, R. Savani, A. Gu, C. Mascioli, T. Turocy, and M. Wellman (2024)
  Market making with learned beta policies.
  In Proceedings of the 5th ACM International Conference on AI in Finance,
   pp.¬†643‚Äì651.
  Cited by: [3rd item](https://arxiv.org/html/2601.17247v1#S6.I1.i3.p1.4 "In 6.1 Generative stochastic market model ‚Ä£ 6 Numerical simulations ‚Ä£ Learning Market Making with Closing Auctions").
* [61]
  C. J. Watkins and P. Dayan (1992)
  Q-learning.
  Machine learning 8 (3),  pp.¬†279‚Äì292.
  Cited by: [¬ß1.3](https://arxiv.org/html/2601.17247v1#S1.SS3.p1.1 "1.3 Methodology, contributions and financial insights ‚Ä£ 1 Introduction ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß4.1](https://arxiv.org/html/2601.17247v1#S4.SS1.p2.3 "4.1 Problem formulation ‚Ä£ 4 Learning market making with closing auction in an unknown environment ‚Ä£ Learning Market Making with Closing Auctions"),
  [¬ß4.1](https://arxiv.org/html/2601.17247v1#S4.SS1.p3.17 "4.1 Problem formulation ‚Ä£ 4 Learning market making with closing auction in an unknown environment ‚Ä£ Learning Market Making with Closing Auctions").