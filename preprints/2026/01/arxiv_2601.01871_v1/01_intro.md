---
authors:
- Takaaki Shiotani
- Takaki Hayashi
- Yuta Koike
doc_id: arxiv:2601.01871v1
family_id: arxiv:2601.01871
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: On lead-lag estimation of non-synchronously observed point processes
url_abs: http://arxiv.org/abs/2601.01871v1
url_html: https://arxiv.org/html/2601.01871v1
venue: arXiv q-fin
version: 1
year: 2026
---


Takaaki Shiotani
Graduate School of Mathematical Sciences, The University of Tokyo, 3-8-1 Komaba, Meguro-ku, Tokyo 153-8914 Japan
â€ƒâ€ƒ
Takaki Hayashi
Graduate School of Business Administration, Keio University, 4-1-1 Hiyoshi, Yokohama 223-8526, Japan
â€ƒâ€ƒ
Yuta Koike11footnotemark: 1

###### Abstract

This paper introduces a new theoretical framework for analyzing lead-lag relationships between point processes, with a special focus on applications to high-frequency financial data.
In particular, we are interested in lead-lag relationships between two sequences of order arrival timestamps.
The seminal work of Dobrev and Schaumburg proposed model-free measures of cross-market trading activity based on cross-counts of timestamps.
While their method is known to yield reliable results, it faces limitations because its original formulation inherently relies on discrete-time observations, an issue we address in this study.
Specifically, we formulate the problem of estimating lead-lag relationships in two point processes as that of estimating the shape of the cross-pair correlation function (CPCF) of a bivariate stationary point process, a quantity well-studied in the neuroscience and spatial statistics literature.
Within this framework, the prevailing lead-lag time is defined as the location of the CPCFâ€™s sharpest peak.
Under this interpretation, the peak location in Dobrev and Schaumburgâ€™s cross-market activity measure can be viewed as an estimator of the lead-lag time in the aforementioned sense.
We further propose an alternative lead-lag time estimator based on kernel density estimation and show that it possesses desirable theoretical properties and delivers superior numerical performance.
Empirical evidence from high-frequency financial data demonstrates the effectiveness of our proposed method.

Keywords: Bandwidth selection; cross-correlation histogram; cross-pair correlation function; high-frequency data; non-synchronicity; lead-lag effect.

## 1 Introduction

Empirical research on lead-lag relationships between two financial time series has long been an active area of study in finance.
Their identification is fundamental to understanding price discovery and may provide practitioners with opportunities for excess profits.
In modern financial markets, such relationships can persist only over very short horizons, even on the order of one millisecond or less.
Therefore, lower-frequency or coarsely aggregated data inevitably fail to find the fine structure of these relationships.
This motivates the use of *tick data*, i.e., raw high-frequency data that records all transactions as they arrive randomly and *non-synchronously*. In particular, handling non-synchronicity is a central issue when estimating leadâ€“lag relationships from such data.

Most existing studies have examined high-frequency lead-lag dynamics using price series.
Prominent approaches include methods based on estimating the cross-covariance function [hoffmann2013estimation, de1997high, huth2014high], wavelet analysis [hayashi2017multi, hayashi2018wavelet], local spectral estimation [koike2021inference], Hawkes process-based multi-asset models [bacry2013some, da2017correlation] and the multi-asset lagged adjustment model of [buccheri2021high].
Among these, hoffmann2013estimation introduced a simple cross-covariance estimator that can be computed directly from non-synchronously observed returns and proposed estimating the prevailing lead-lag time by locating its maximizer.
Although their method yields sensible empirical implications due to its intuitive interpretation [huth2014high, bollen2017tail, bangsgaard2024lead, dao2018ultra, alsayed2014ultra, poutre2024profitability], the resulting lead-lag time estimates are often unstable and unreliable [huth2014high, hayashi2017jpn, bangsgaard2024lead], presumably because high-frequency price series are affected by market microstructure noise.
As an alternative method, dobrev2017high proposed model-free measurements of the lead-lag relationship between two assets based on cross-counts of their order arrivals.
Their estimator of leadâ€“lag time has been shown to produce highly stable and reliable estimates in practice; see [dobrev2017high, hayashi2017jpn].

However, the Dobrevâ€“Schaumburg method is essentially descriptive, and it is not immediately clear what underlying quantity the method actually estimates.111Although [dobrev2023high] discuss some asymptotic properties of their measurements when the two timestamp series are independent, they do not clearly specify the underlying estimands.
Indeed, as we show in [SectionÂ 2](https://arxiv.org/html/2601.01871v1#S2 "2 The Dobrevâ€“Schaumburg method â€£ On lead-lag estimation of non-synchronously observed point processes"), there exist situations in which their method performs poorly in practice, particularly when the data contain relatively few observations.
Moreover, implementing their method requires partitioning the observation period into equi-spaced buckets, and the choice of bucket size has a substantial impact on the results.
Yet, because the method is â€œmodel-free,â€ it does not offer a statistical explanation for why such sensitivity arises.

To address these issues, we reformulate the Dobrevâ€“Schaumburg method from a point process perspective.
This viewpoint reveals that their measurements essentially estimate shape characteristics of the *cross-pair correlation function* (CPCF) of a bivariate point process generated by order arrivals; see [SectionÂ 3](https://arxiv.org/html/2601.01871v1#S3 "3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") for definitions.
Accordingly, the Dobrevâ€“Schaumburg estimator of lead-lag time can be interpreted as an estimator of the CPCFâ€™s sharpest peak location.
This interpretation also clarifies that the instability observed in their method arises when the bucket size is chosen too small relative to a range that is permissible given the properties of the underlying data.
At the same time, because their estimator can only take values that are integer multiples of the bucket size, using a larger bucket size results in excessively coarse estimates.
To overcome these limitations, we propose a nonparametric, kernel-based estimator of the leadâ€“lag time, together with a data-driven bandwidth selection procedure. We show both theoretically and empirically that this new estimator produces stable and accurate results even in settings where the Dobrevâ€“Schaumburg method fails.

The remainder of the paper is organized as follows.
[SectionÂ 2](https://arxiv.org/html/2601.01871v1#S2 "2 The Dobrevâ€“Schaumburg method â€£ On lead-lag estimation of non-synchronously observed point processes") provides a detailed explanation of the Dobrevâ€“Schaumburg method.
[SectionÂ 3](https://arxiv.org/html/2601.01871v1#S3 "3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") introduces a point process framework that clarifies the theoretical meaning of the Dobrevâ€“Schaumburg method.
[SectionÂ 4](https://arxiv.org/html/2601.01871v1#S4 "4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") proposes an alternative estimator of the lead-lag time within this framework and develops its theoretical properties.
[SectionÂ 5](https://arxiv.org/html/2601.01871v1#S5 "5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes") demonstrates its superior numerical performance through a comprehensive Monte Carlo study.
[SectionÂ 6](https://arxiv.org/html/2601.01871v1#S6 "6 Empirical illustration â€£ On lead-lag estimation of non-synchronously observed point processes") presents an empirical application that illustrates the effectiveness of our proposed estimator using real data.
[SectionÂ 7](https://arxiv.org/html/2601.01871v1#S7 "7 Concluding remarks â€£ On lead-lag estimation of non-synchronously observed point processes") concludes by summarizing our main contributions and discussing directions for future research.
The appendix contains mathematical proofs and additional implementation details.

##### Notation

The cardinality of a finite set SS is denoted by |S||S|.
Leb\operatorname{Leb} denotes the Lebesgue measure.
The Borel Ïƒ\sigma-algebra of a topological space SS is denoted by â„¬â€‹(S)\mathcal{B}(S).
For a real-valued function ff defined on a set SS, we set â€–fâ€–âˆ=supxâˆˆS|fâ€‹(x)|\|f\|\_{\infty}=\sup\_{x\in S}|f(x)|.
Also, we denote by argâ€‹maxxâˆˆSâ¡fâ€‹(x)\operatorname\*{arg\,max}\_{x\in S}f(x) the set of maximizers of ff on SS.
For a random variable XX and pâ‰¥1p\geq 1, we set â€–Xâ€–p:=(Eâ¡[|X|p])1/p\|X\|\_{p}:=(\operatorname{E}[|X|^{p}])^{1/p}.
The underlying probability space is denoted by (Î©,â„±,P)(\Omega,\mathcal{F},\operatorname{P}).
We interpret 1/0=âˆ1/0=\infty by convention.

## 2 The Dobrevâ€“Schaumburg method

Suppose that we have tick data for two financial assets, with timestamps given by 0â‰¤t11<â‹¯<tn11â‰¤T0\leq t^{1}\_{1}<\cdots<t^{1}\_{n\_{1}}\leq T and 0â‰¤t12<â‹¯<tn22â‰¤T0\leq t^{2}\_{1}<\cdots<t^{2}\_{n\_{2}}\leq T.
Throughout the paper, we assume that Tâ‰¥1T\geq 1 is an integer and timestamps are expressed in seconds when working with real data.; hence we may regard TT as a large integer. dobrev2017high proposed measuring the lead-lag relationship between two assets using the following procedure.

First, divide the observation interval [0,T][0,T] into equi-spaced time buckets Ikh:=(kâ€‹h,(k+1)â€‹h]I^{h}\_{k}:=(kh,(k+1)h], k=0,1,â€¦,T/hâˆ’1k=0,1,\dots,T/h-1, where h>0h>0 is chosen so that hâˆ’1âˆˆâ„•h^{-1}\in\mathbb{N}.
We interpret a situation where an event for asset 2 occurs with a lag â„“âˆˆâ„¤\ell\in\mathbb{Z} after an event for asset 1 as the existence of timestamps ti1,tj2t^{1}\_{i},t^{2}\_{j} and a bucket index kâˆˆ{|â„“|,|â„“|+1,â€¦,T/hâˆ’1âˆ’|â„“|}k\in\{|\ell|,|\ell|+1,\dots,T/h-1-|\ell|\} such that ti1âˆˆIkht^{1}\_{i}\in I^{h}\_{k} and tj2âˆˆIk+â„“ht^{2}\_{j}\in I^{h}\_{k+\ell}.
By calculating the number of such bucket indices, we obtain a measure of the lead-lag effect of asset 1 on asset 2 with lag â„“\ell.
Based on this idea, dobrev2017high introduced the *raw cross-market activity* at offset â„“\ell as

|  |  |  |
| --- | --- | --- |
|  | ğ’³hrawâ€‹(â„“):=âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{âˆƒti1âˆˆIkh,âˆƒtj2âˆˆIk+â„“h}.\mathcal{X}^{\mathrm{raw}}\_{h}(\ell):=\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{\exists t^{1}\_{i}\in I^{h}\_{k},\,\exists t^{2}\_{j}\in I^{h}\_{k+\ell}\}}. |  |

To adjust the degree of freedom, they also defined the *relative cross-market activity* as

|  |  |  |
| --- | --- | --- |
|  | ğ’³hrelâ€‹(â„“):=ğ’³hrawâ€‹(â„“)minâ¡{âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{âˆƒti1âˆˆIkh},âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{âˆƒti+â„“2âˆˆIkh}}.\mathcal{X}^{\mathrm{rel}}\_{h}(\ell):=\frac{\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)}{\min\left\{\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{\exists t^{1}\_{i}\in I^{h}\_{k}\}},\ \sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{\exists t^{2}\_{i+\ell}\in I^{h}\_{k}\}}\right\}}. |  |

Computing ğ’³hrawâ€‹(â„“)\mathcal{X}^{\mathrm{raw}}\_{h}(\ell) and ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) requires choosing a value of hh.
In [dobrev2017high], hh is set to 1 millisecond, which is chosen in an ad-hoc manner by considering the time granularity of the data.
Here, 1 millisecond is the minimum time unit available in their dataset for the S&P 500 cash market.

By definition, the larger value of ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) indicates a stronger lead-lag effect in which asset 2 follows asset 1 after a delay of â„“â€‹h\ell h.
Motivated by this, dobrev2017high proposed identifying the prevailing lead-lag time by locating the peak of the map â„“â†¦ğ’³hrelâ€‹(â„“)\ell\mapsto\mathcal{X}^{\mathrm{rel}}\_{h}(\ell).
Specifically, given a search grid
ğ’¢h\mathcal{G}\_{h}, the lead-lag time is estimated by

|  |  |  |
| --- | --- | --- |
|  | Î¸^hDâ€‹S=â„“^â€‹h,whereÂ â€‹â„“^âˆˆargâ€‹maxâ„“âˆˆğ’¢hâ¡ğ’³hrelâ€‹(â„“).\hat{\theta}\_{h}^{DS}=\hat{\ell}h,\quad\text{where }\hat{\ell}\in\operatorname\*{arg\,max}\_{\ell\in\mathcal{G}\_{h}}\mathcal{X}^{\mathrm{rel}}\_{h}(\ell). |  |

We refer to Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} as the *DS estimator*.
In what follows, we assume the true lead-lag time lies within the interval (âˆ’r,r)(-r,r) for some known positive constant rr, and define ğ’¢h:={â„“âˆˆâ„¤:|â„“â€‹h|â‰¤r}\mathcal{G}\_{h}:=\{\ell\in\mathbb{Z}:|\ell h|\leq r\}.

As mentioned in the introduction, several empirical studies have reported that the DS estimator yields stable and interpretable estimates of lead-lag time.
However, there are cases where the estimator performs poorly, particularly when the dataset contains relatively few observations.
[Fig.Â 1](https://arxiv.org/html/2601.01871v1#S2.F1 "In 2 The Dobrevâ€“Schaumburg method â€£ On lead-lag estimation of non-synchronously observed point processes") illustrates this issue, showing the relative cross-market activity measure computed from best-quote updates on two U.S.Â stock exchanges, NASDAQ and BATS, for the MNST stock on August 12, 2015.
In this example, the values of the cross-market activity measure fluctuate heavily, making it difficult to identify the peak reliability.
Yet, due to the â€œmodel-freeâ€ nature of the Dobrevâ€“Schaumburg method, no statistical interpretation is provided for the origin of such instability.
One goal of this study is to establish a theoretical foundation for their approach and fill this gap.

![Refer to caption](pics/MNST_with_CPCF.png)


Figure 1: Contrast functions: DS vs ours. MNST, NASDAQ vs BATS (quote, Aug. 12, 2015). The cross-market activity measure ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) is indicated by the red line, while the kernel density estimator gh^â€‹(u)g\_{\hat{h}}(u) with the Lepski-selected bandwith (see [SectionÂ 4](https://arxiv.org/html/2601.01871v1#S4 "4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")) is indicated by the blue line. The unit of the horizontal axis is seconds.

## 3 Proposed framework

To clarify the statistical meaning of the Dobrevâ€“Schaumburg method, we model the observed timestamps (ti1)i=1n1(t^{1}\_{i})\_{i=1}^{n\_{1}} and (tj2)j=1n2(t^{2}\_{j})\_{j=1}^{n\_{2}} as realizations of a bivariate point process on the real line.
Specifically, for each a=1,2a=1,2, we consider the timestamps (tia)(t^{a}\_{i}) to be a result of observing a point process NaN\_{a} on â„\mathbb{R} over the interval [0,T][0,T].
That is, Naâ€‹(A)=|{i:tiaâˆˆA}|N\_{a}(A)=|\{i:t^{a}\_{i}\in A\}| for a Borel set AâŠ‚[0,T]A\subset[0,T].
Here and below, we mainly follow the mathematical formulation of point processes described in [daley2006introduction, daley2007introduction] and refer to these monographs for unexplained concepts and notation (see also [shiotani2024statistical, Section 2.2] for a summary).
With this formulation, we can rewrite ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) as

|  |  |  |
| --- | --- | --- |
|  | ğ’³hrelâ€‹(â„“)=âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N1â€‹(Ikh)>0,N2â€‹(Ik+â„“h)>0}minâ¡{âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N1â€‹(Ikh)>0},âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N2â€‹(Ik+â„“h)>0}}.\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)=\frac{\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{1}(I\_{k}^{h})>0,\ N\_{2}(I\_{k+\ell}^{h})>0\}}}{\min\left\{\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{1}(I\_{k}^{h})>0\}},\ \sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{2}(I\_{k+\ell}^{h})>0\}}\right\}}. |  |

Using this expression, we can relate ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) to the *cross-pair correlation function (CPCF)* of NN.

To state the theoretical result formally, we introduce several assumptions and notation.
We assume that N=(N1,N2)N=(N\_{1},N\_{2}) is a simple stationary bivariate point process on â„\mathbb{R} with intensities Î»1,Î»2âˆˆ(0,âˆ)\lambda\_{1},\lambda\_{2}\in(0,\infty).
Note that we use the term â€œintensityâ€ in the same sense as in [daley2006introduction] (see page 47 ibidem).
By [daley2006introduction, Proposition 3.3.IV], we have Î»a=Eâ¡[Naâ€‹((0,1])]\lambda\_{a}=\operatorname{E}[N\_{a}((0,1])] for a=1,2a=1,2.
We also assume that there exists a locally integrable function Î»12:â„â†’[0,âˆ]\lambda\_{12}:\mathbb{R}\to[0,\infty] such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[N1â€‹(A1)â€‹N2â€‹(A2)]=âˆ«A1Ã—A2Î»12â€‹(yâˆ’x)â€‹ğ‘‘xâ€‹ğ‘‘y\operatorname{E}[N\_{1}(A\_{1})N\_{2}(A\_{2})]=\int\_{A\_{1}\times A\_{2}}\lambda\_{12}(y-x)dxdy |  | (3.1) |

for any bounded A1,A2âˆˆâ„¬â€‹(â„)A\_{1},A\_{2}\in\mathcal{B}(\mathbb{R}).
We refer to Î»12\lambda\_{12} as the *cross-intensity function*222In neuroscience, the term â€œcross-intensity functionâ€ usually refers to the functions Î»12â€‹(u)/Î»1\lambda\_{12}(u)/\lambda\_{1} or Î»12â€‹(u)/Î»2\lambda\_{12}(u)/\lambda\_{2} (see e.g.Â [bryant1973correlations]).
We follow the terminology used in spatial statistics [hessellund2022semiparametric, hessellund2022second].
In the terminology of point process theory, Î»12\lambda\_{12} is a density of the reduced cross-moment measure of NN (cf.Â [daley2006introduction, Section 8.3]). of NN.
The CPCF of NN is the function g:â„â†’[0,âˆ]g:\mathbb{R}\to[0,\infty] defined as

|  |  |  |
| --- | --- | --- |
|  | gâ€‹(u)=Î»12â€‹(u)Î»1â€‹Î»2(uâˆˆâ„).g(u)=\frac{\lambda\_{12}(u)}{\lambda\_{1}\lambda\_{2}}\qquad(u\in\mathbb{R}). |  |

The cross-intensity function can be related to the cross-covariance function between the infinitesimal increments of N1N\_{1} and N2N\_{2} in the following sense (cf.Â ([A.11](https://arxiv.org/html/2601.01871v1#A1.E11 "Equation A.11 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"))):

|  |  |  |
| --- | --- | --- |
|  | Î½12â€‹(u):=limhâ†“0Covâ¡(N1â€‹(0,h],N2â€‹(u,u+h])h2=Î»12â€‹(u)âˆ’Î»1â€‹Î»2a.e.Â â€‹u.\nu\_{12}(u):=\lim\_{h\downarrow 0}\frac{\operatorname{Cov}(N\_{1}(0,h],N\_{2}(u,u+h])}{h^{2}}=\lambda\_{12}(u)-\lambda\_{1}\lambda\_{2}\quad\text{a.e. }u. |  |

The function Î½12\nu\_{12} is called the *covariance density* of NN.
In this sense, gâ€‹(u)g(u) measures the cross-covariation between N1â€‹(â‹…)N\_{1}(\cdot) and N2(â‹…+u)N\_{2}(\cdot+u).

We also need the notion of Î±\alpha-mixing (or strong mixing) for point processes.
Recall that the Î±\alpha-mixing coefficient of two sub-Ïƒ\sigma-algebras ğ’¢\mathcal{G} and â„‹\mathcal{H} of â„±\mathcal{F} is defined as

|  |  |  |
| --- | --- | --- |
|  | Î±(ğ’¢,â„‹):=sup{|P(Câˆ©D)âˆ’P(C)P(D)|:Câˆˆğ’¢,Dâˆˆâ„‹}.\alpha(\mathcal{G},\mathcal{H}):=\sup\{|\operatorname{P}(C\cap D)-\operatorname{P}(C)\operatorname{P}(D)|:C\in\mathcal{G},D\in\mathcal{H}\}. |  |

For Eâˆˆâ„¬â€‹(â„)E\in\mathcal{B}(\mathbb{R}), we denote by Nâˆ©E=(Niâˆ©E)i=12N\cap E=(N\_{i}\cap E)\_{i=1}^{2} the restriction of NN to EE, i.e.Â (Niâˆ©E)â€‹(A)=Niâ€‹(Aâˆ©E)(N\_{i}\cap E)(A)=N\_{i}(A\cap E) for i=1,2i=1,2 and Aâˆˆâ„¬â€‹(â„)A\in\mathcal{B}(\mathbb{R}).
Also, EâŠ•r:={xâˆˆâ„:|yâˆ’x|<râ€‹Â for someÂ â€‹yâˆˆE}E\oplus r:=\{x\in\mathbb{R}:|y-x|<r\text{ for some }y\in E\} denotes the rr-enlargement of EE.
Moreover, given a bivariate point process M=(M1,M2)M=(M\_{1},M\_{2}) on â„\mathbb{R}, Ïƒâ€‹(M)\sigma(M) denotes the Ïƒ\sigma-algebra generated by â‹ƒi=12{Miâ€‹(A):Aâˆˆâ„¬â€‹(â„)}\bigcup\_{i=1}^{2}\{M\_{i}(A):A\in\mathcal{B}(\mathbb{R})\}.
As Î±\alpha-mixing coefficients of NN, we adopt the following definition:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î±c1,c2N(m;r)=sup{Î±â€‹(Ïƒâ€‹(Nâˆ©E1),Ïƒâ€‹(Nâˆ©E2)):E1=â‹ƒjâˆˆJ1IjâŠ•r,E2=â‹ƒjâˆˆJ2IjâŠ•r,|J1|â‰¤c1,|J2|â‰¤c2,d(J1,J2)â‰¥m,J1,J2âŠ‚â„¤},m,c1,c2,râ‰¥0,\begin{split}\alpha\_{c\_{1},c\_{2}}^{N}(m;r)=\sup\Bigl\{&\alpha(\sigma(N\cap E\_{1}),\sigma(N\cap E\_{2})):E\_{1}=\bigcup\_{j\in J\_{1}}I\_{j}\oplus r,\,E\_{2}=\bigcup\_{j\in J\_{2}}I\_{j}\oplus r,\\ &|J\_{1}|\leq c\_{1},\,|J\_{2}|\leq c\_{2},\,d(J\_{1},J\_{2})\geq m,\,J\_{1},J\_{2}\subset\mathbb{Z}\Bigr\},\quad m,c\_{1},c\_{2},r\geq 0,\end{split} |  | (3.2) |

where Ij:=Ij1=(j,j+1]I\_{j}:=I\_{j}^{1}=(j,j+1] and d(J1,J2):=inf{|j1âˆ’j2|:j1âˆˆJ1,j2âˆˆJ2}d(J\_{1},J\_{2}):=\inf\{|j\_{1}-j\_{2}|:j\_{1}\in J\_{1},\,j\_{2}\in J\_{2}\}.
This definition is a minor variant of the one used in [shiotani2024statistical], where they use (jâˆ’12,j+12](j-\frac{1}{2},j+\frac{1}{2}] instead of IjI\_{j}.
This difference is inessential, and we just adopt the present definition to (slightly) simplify our technical arguments.

###### Remark 3.1 (Mixing coefficients as a continuous-time process).

Since NN can be regarded as a stochastic process indexed by â„\mathbb{R}, we can also define the Î±\alpha-mixing coefficients in this sense [brillinger1976estimation]:

|  |  |  |
| --- | --- | --- |
|  | Î±procNâ€‹(Ï„):=suptâˆˆâ„Î±â€‹(Ïƒâ€‹(Nâˆ©(âˆ’âˆ,t)),Ïƒâ€‹(Nâˆ©(t+Ï„,âˆ))),Ï„â‰¥0.\alpha^{N}\_{\text{proc}}(\tau):=\sup\_{t\in\mathbb{R}}\alpha\left(\sigma(N\cap(-\infty,t)),\,\sigma(N\cap(t+\tau,\infty))\right),\qquad\tau\geq 0. |  |

Our definition is weaker than this version in the sense that we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î±c1,c2Nâ€‹(m;r)â‰¤Î±procNâ€‹(mâˆ’2â€‹r)\alpha^{N}\_{c\_{1},c\_{2}}(m;r)\leq\alpha^{N}\_{\text{proc}}(m-2r) |  | (3.3) |

for all c1,c2,râ‰¥0c\_{1},c\_{2},r\geq 0 and mâ‰¥2â€‹rm\geq 2r.
For the case of point processes, it is important to work with the weaker version because it is sometimes difficult to bound the left hand side of ([3.3](https://arxiv.org/html/2601.01871v1#S3.E3 "Equation 3.3 â€£ Remark 3.1 (Mixing coefficients as a continuous-time process). â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) uniformly in c1,c2â‰¥0c\_{1},c\_{2}\geq 0; see [poinas2019mixing, Proposition 2.8] and [shiotani2024statistical, Lemma 10.13] for example.

We impose the following regularity conditions on NN.

1. [A1]

   (i) For every pâ‰¥1p\geq 1, there exists a constant Bp>0B\_{p}>0 such that maxi=1,2â¡Î»iâˆ’1â€‹â€–Niâ€‹((0,1])â€–pâ‰¤Bp\max\_{i=1,2}\lambda\_{i}^{-1}\|N\_{i}((0,1])\|\_{p}\leq B\_{p}.

   (ii) For any p,qâ‰¥1p,q\geq 1, there exists a constant Bp,q>0B\_{p,q}>0 such that
   Î±p,pNâ€‹(m;r1)â‰¤Bp,qâ€‹mâˆ’q\alpha\_{p,p}^{N}(m;r\_{1})\leq B\_{p,q}m^{-q}
   for all mâˆˆâ„•m\in\mathbb{N}, where r1:=r+1r\_{1}:=r+1.

This assumption is fairly reasonable in the literature and is satisfied by many standard point process models such as the Hawkes process and Neyman-Scott process as long as their kernels satisfy some regularity conditions; see [SectionÂ 5.1](https://arxiv.org/html/2601.01871v1#S5.SS1 "5.1 Models â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes") for details.

Under [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and additional technical assumptions, we have the following asymptotic representation of Dobrevâ€“Schaumburgâ€™s cross-market activity measure:

###### Proposition 3.1.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Assume also that gg is bounded and

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡Eâ¡[N1â€‹(I0h)â€‹{N1â€‹(I0h)âˆ’1}â€‹N2â€‹(Iâ„“h)]=oâ€‹(h1+Ï–),maxâ„“âˆˆğ’¢hâ¡Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)â€‹{N2â€‹(Iâ„“h)âˆ’1}]=oâ€‹(h1+Ï–)\begin{split}\max\_{\ell\in\mathcal{G}\_{h}}\operatorname{E}[N\_{1}(I\_{0}^{h})\{N\_{1}(I\_{0}^{h})-1\}N\_{2}(I\_{\ell}^{h})]&=o(h^{1+\varpi}),\\ \max\_{\ell\in\mathcal{G}\_{h}}\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})\{N\_{2}(I\_{\ell}^{h})-1\}]&=o(h^{1+\varpi})\end{split} |  | (3.4) |

as hâ†’0h\to 0 for Ï–=1\varpi=1.
Moreover, assume h=hTâ‰Tâˆ’Î³h=h\_{T}\asymp T^{-\gamma} as Tâ†’âˆT\to\infty for some 0<Î³<10<\gamma<1.
Then

|  |  |  |
| --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|ğ’³hrelâ€‹(â„“)hâˆ’(Î»1âˆ¨Î»2)â€‹âˆ«â„1hâ€‹Ktriâ€‹(uâˆ’â„“â€‹hh)â€‹gâ€‹(u)â€‹ğ‘‘u|â†’p0,\displaystyle\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)}{h}-(\lambda\_{1}\vee\lambda\_{2})\int\_{\mathbb{R}}\frac{1}{h}K^{\mathrm{tri}}\left(\frac{u-\ell h}{h}\right)g(u)du\right|\to^{p}0, |  |

where Ktriâ€‹(x)=(1âˆ’|x|)â€‹1[âˆ’1,1]â€‹(x)K^{\mathrm{tri}}(x)=(1-|x|)1\_{[-1,1]}(x).

###### Remark 3.2 (On condition ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"))).

The quantities on the left hand sides of ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) can be related to the factorial moment measures of orders (2,1) and (1,2) of NN (see Section 2.3 of [shiotani2024statistical] for the definition).
In particular, ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) holds for Ï–=1\varpi=1 if these measures have bounded densities with respect to the Lebesgue measure.
Since each factorial moment measure can be expressed as a sum of factorial cumulant measures through [shiotani2024statistical, Eq.(2.5)] (see also [brillinger1972spectral, Eq.(3.21)]), its density can be computed for the Hawkes process via [jovanovic2015cumulants, Eq.(39)] and the Neyman-Scott process via [shiotani2024statistical, Eq.(5.2)], respectively; hence, one can in principle verify ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) under appropriate assumptions on their kernels.
We do not pursue this point further because this condition is unnecessary for the theoretical development of our new estimator proposed in the next section.

Under the assumptions of [PropositionÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmproposition1 "Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), we have maxâ„“âˆˆğ’¢hâ¡|ğ’³hrelâ€‹(â„“)/hâˆ’(Î»1âˆ¨Î»2)â€‹gâ€‹(â„“â€‹h)|â†’p0\max\_{\ell\in\mathcal{G}\_{h}}|\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)/h-(\lambda\_{1}\vee\lambda\_{2})g(\ell h)|\to^{p}0 if gg is continuous.
Hence, the cross-market activity measure can be interpreted as an estimator for the CPCF up to a multiplicative constant.
Moreover, if gg has a unique maximizer Î¸âˆ—\theta^{\*} in (âˆ’r,r)(-r,r), the above result implies that Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} is a consistent estimator of Î¸âˆ—\theta^{\*} as Tâ†’âˆT\to\infty.
For further understanding of theoretical properties of Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS}, we study its rate of convergence.
For this purpose, we introduce the following assumption on gg:

1. [A2]

   There exist constants Î¸âˆ—âˆˆ(âˆ’r,r)\theta^{\*}\in(-r,r), Î±âˆˆ(0,1)âˆª(1,âˆ)\alpha\in(0,1)\cup(1,\infty), b>1b>1 and Î´>0\delta>0 such that the following conditions hold:

   1. (i)

      If Î±>1\alpha>1, supuâˆˆâ„gâ€‹(u)â‰¤b\sup\_{u\in\mathbb{R}}g(u)\leq b and

      |  |  |  |
      | --- | --- | --- |
      |  | minâ¡{sup0<uâˆ’Î¸âˆ—<Î´gâ€‹(Î¸âˆ—)âˆ’gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1,sup0<Î¸âˆ—âˆ’u<Î´gâ€‹(Î¸âˆ—)âˆ’gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1}â‰¤b\min\left\{\sup\_{0<u-\theta^{\*}<\delta}\frac{g(\theta^{\*})-g(u)}{|u-\theta^{\*}|^{\alpha-1}},\sup\_{0<\theta^{\*}-u<\delta}\frac{g(\theta^{\*})-g(u)}{|u-\theta^{\*}|^{\alpha-1}}\right\}\leq b |  |

      and

      |  |  |  |
      | --- | --- | --- |
      |  | inf0<|uâˆ’Î¸âˆ—|<Î´gâ€‹(Î¸âˆ—)âˆ’gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1â‰¥1b\inf\_{0<|u-\theta^{\*}|<\delta}\frac{g(\theta^{\*})-g(u)}{|u-\theta^{\*}|^{\alpha-1}}\geq\frac{1}{b} |  |

      and

      |  |  |  |
      | --- | --- | --- |
      |  | sup|uâˆ’Î¸âˆ—|â‰¥Î´gâ€‹(u)â‰¤gâ€‹(Î¸âˆ—)âˆ’1b.\sup\_{|u-\theta^{\*}|\geq\delta}g(u)\leq g(\theta^{\*})-\frac{1}{b}. |  |
   2. (ii)

      If Î±<1\alpha<1,

      |  |  |  |
      | --- | --- | --- |
      |  | maxâ¡{inf0<uâˆ’Î¸âˆ—<Î´gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1,infâˆ’Î´<uâˆ’Î¸âˆ—<0gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1}â‰¥1b.\max\left\{\inf\_{0<u-\theta^{\*}<\delta}\frac{g(u)}{|u-\theta^{\*}|^{\alpha-1}},\inf\_{-\delta<u-\theta^{\*}<0}\frac{g(u)}{|u-\theta^{\*}|^{\alpha-1}}\right\}\geq\frac{1}{b}. |  |

      Moreover, there exist a constant Î±<Î±0â‰¤1\alpha<\alpha\_{0}\leq 1 and a measurable function g0:â„â†’[0,âˆ]g\_{0}:\mathbb{R}\to[0,\infty] such that â€–g0â€–L1/(1âˆ’Î±0)â€‹([âˆ’r1,r1])â‰¤b\|g\_{0}\|\_{L^{1/(1-\alpha\_{0})}([-r\_{1},r\_{1}])}\leq b and

      |  |  |  |
      | --- | --- | --- |
      |  | gâ€‹(u)â‰¤bâ€‹(g0â€‹(u)+|uâˆ’Î¸âˆ—|Î±âˆ’1)for allÂ â€‹uâˆˆ[âˆ’r1,r1].g(u)\leq b\left(g\_{0}(u)+|u-\theta^{\*}|^{\alpha-1}\right)\quad\text{for all }u\in[-r\_{1},r\_{1}]. |  |

Under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](i)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i1 "Item [A2](i) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), gg is bounded and Î¸âˆ—\theta^{\*} is the unique maximizer of gg.
By contrast, under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](ii)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i2 "Item [A2](ii) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), gg diverges at Î¸âˆ—\theta^{\*} and is therefore unbounded.
We allow gg to have poles other than Î¸âˆ—\theta^{\*} through an auxiliary function g0g\_{0}; however, the condition â€–g0â€–L1/(1âˆ’Î±0)â€‹([âˆ’r1,r1])<âˆ\|g\_{0}\|\_{L^{1/(1-\alpha\_{0})}([-r\_{1},r\_{1}])}<\infty ensures that Î¸âˆ—\theta^{\*} remains the â€œsharpestâ€ peak location of gg.
We call Î¸âˆ—\theta^{\*} the *lead-lag (time) parameter*.
We allow gg to be unbounded motivated by several empirical observations: (i) Dobrevâ€“Schaumburgâ€™s cross-market activity measure often exhibits extremely sharp peaks (see e.g.Â [dobrev2017high, Fig.Â 7]); (ii) shiotani2024statistical found that their semiparametric model fits Japanese stock market data better when the CPCF is unbounded; (iii) rambaldi2018detection report that intensity burst occurrences across different foreign exchange rates exhibit lead-lag relationships.

###### Remark 3.3 (Relation to mode estimation).

Our formulation of the lead-lag parameter estimation problem is naturally connected to mode estimation for a probability density function, once the CPCF is replaced by the density.
[[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") is motivated by this observation.
In fact, wegman1971note classifies the problem of mode estimation for unimodal distributions into three types, labeling cases with bounded density as Type I, cases with unbounded density as Type II, and cases without density as Type III.
In this classification, [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](i)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i1 "Item [A2](i) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") corresponds to Type I, and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](ii)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i2 "Item [A2](ii) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") corresponds to Type II.
For the purpose of analyzing the convergence rate, we assume that the CPCF behaves like a power function |uâˆ’Î¸âˆ—|Î±âˆ’1|u-\theta^{\*}|^{\alpha-1} in a neighborhood of Î¸âˆ—\theta^{\*}.
When Î±>1\alpha>1, this assumptions is analogous to the conditions studied in [arias2022estimation] (see Section 1.1 ibidem).
When Î±<1\alpha<1, it corresponds to the analogue of condition [H-III] in [bercu2002estimation].
Note that the case Î±=1\alpha=1 is excluded simply because the power function |uâˆ’Î¸âˆ—|Î±âˆ’1|u-\theta^{\*}|^{\alpha-1} becomes constant in that case.

Under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), we set

|  |  |  |
| --- | --- | --- |
|  | Î²Î±:=Î±âˆ¨(2â€‹Î±âˆ’1)={Î±ifÂ â€‹Î±<1,2â€‹Î±âˆ’1ifÂ â€‹Î±>1.\beta\_{\alpha}:=\alpha\vee(2\alpha-1)=\begin{cases}\alpha&\text{if }\alpha<1,\\ 2\alpha-1&\text{if }\alpha>1.\end{cases} |  |

###### Theorem 3.1.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and h=hTâ‰Tâˆ’Î³h=h\_{T}\asymp T^{-\gamma} as Tâ†’âˆT\to\infty for some 0<Î³<1/Î²Î±0<\gamma<1/\beta\_{\alpha}.
Moreover, assume ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) for Ï–=Î±\varpi=\alpha.
Then, Î¸^hDâ€‹S=Î¸âˆ—+Opâ€‹(h)\hat{\theta}\_{h}^{DS}=\theta^{\*}+O\_{p}(h) as Tâ†’âˆT\to\infty.

Since Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} is, by construction, an integer multiple of hh, [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") implies that its convergence rate is exactly of order Oâ€‹(h)O(h).
In particular, the accuracy of Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} improves as hh becomes smaller.
Given the definition of ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell), however, it is meaningless to choose hh smaller than the minimum time unit in the data.
In this sense, it is reasonable that dobrev2017high set hh equal to the minimum time resolution.

Nevertheless, [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") also imposes a constraint on the order of hh, requiring that hh converge to 0 more slowly than Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}}.
Moreover, this constraint is not a technical artifact of the proof; it is essential, because we show that Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} gives a minimax lower bound on the convergence rate of any estimator of Î¸âˆ—\theta^{\*} under the assumptions of [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), at least when Î±<2\alpha<2 (see [4.2](https://arxiv.org/html/2601.01871v1#S4.Thmrmk2 "Remark 4.2. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")).
Therefore, it is theoretically impossible for the conclusion of [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") to hold when hâ‰ªTâˆ’1/Î²Î±h\ll T^{-1/\beta\_{\alpha}}.

Note that na/Tâ†’Î»a>0n\_{a}/T\to\lambda\_{a}>0 as Tâ†’âˆT\to\infty a.s.Â for each a=1,2a=1,2 under [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Hence, for Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} to perform properly, hh must be chosen based on n1,n2n\_{1},n\_{2} (the sample sizes) and Î±\alpha (the sharpness of the CPCF peak).
Specifically, hh should be taken larger when n1n\_{1} and n2n\_{2} are smaller and/or when Î±\alpha is larger.
This provides one explanation for the poor performance of the Dobrevâ€“Schaumburg method in the example shown in [Fig.Â 1](https://arxiv.org/html/2601.01871v1#S2.F1 "In 2 The Dobrevâ€“Schaumburg method â€£ On lead-lag estimation of non-synchronously observed point processes").
That is, in that dataset, setting h=1â€‹Î¼â€‹sh=1~\mu\text{s} was likely far too small, given the relatively small numbers of observations (n1,n2)=(28048,11287)(n\_{1},n\_{2})=(28048,11287).

These observations indicate that the choice of hh plays a crucial role in the implementation of the DS estimator.
However, the DS estimator should be interpreted as an estimator of an interval containing the lead-lag parameter, rather than the parameter itself, which makes data-driven selection of hh difficult.
For these reasons, in the next section, we propose a new lead-lag time estimator based on kernel density estimation and demonstrate that it can overcome this issue.

## 4 New estimator

[PropositionÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmproposition1 "Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") suggests that ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) would be asymptotically equivalent to a discretized version of a kernel density estimator for gg based on the triangular kernel.
This naturally motivates us to consider kernel density estimators for gg directly.

Formally, let K:â„â†’â„K:\mathbb{R}\to\mathbb{R} be a kernel function and h=hT>0h=h\_{T}>0 a bandwidth parameter such that hâ†’0h\to 0 as Tâ†’âˆT\to\infty.
We then consider the following statistic:

|  |  |  |
| --- | --- | --- |
|  | g^hâ€‹(u)=Tn1â€‹n2â€‹âˆ«(0,T]2Khâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y),uâˆˆâ„,\hat{g}\_{h}(u)=\frac{T}{n\_{1}n\_{2}}\int\_{(0,T]^{2}}K\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy),\qquad u\in\mathbb{R}, |  |

where Khâ€‹(t)=hâˆ’1â€‹Kâ€‹(t/h)K\_{h}(t)=h^{-1}K(t/h) for tâˆˆâ„t\in\mathbb{R}.
We estimate Î¸âˆ—\theta^{\*} by taking a maximizer of g^h\hat{g}\_{h}.
That is, we define a random variable Î¸^h\hat{\theta}\_{h} satisfying

|  |  |  |
| --- | --- | --- |
|  | Î¸^hâˆˆargâ€‹maxuâˆˆ[âˆ’r,r]â¡g^hâ€‹(u).\hat{\theta}\_{h}\in\operatorname\*{arg\,max}\_{u\in[-r,r]}\hat{g}\_{h}(u). |  |

The practical procedure for computing Î¸^h\hat{\theta}\_{h} and its computational complexity are described in Appendix [B](https://arxiv.org/html/2601.01871v1#A2 "Appendix B Implementation and computational complexity â€£ On lead-lag estimation of non-synchronously observed point processes").

When the uniform kernel is used as the kernel function, g^h\hat{g}\_{h} is essentially equivalent to the so-called cross-correlation histogram in neuroscience and has long been applied to investigate relationships between neuronal spikes (see e.g.Â [bryant1973correlations]).
This line of work has motivated statisticians to investigate the theoretical properties of g^h\hat{g}\_{h} [cox1972multivariate, brillinger1975statistical, brillinger1976estimation, ellis1991density].
Nevertheless, to the best of our knowledge, no prior research has addressed the case where gg is unbounded, nor the asymptotic behavior of the maximizer of g^h\hat{g}\_{h}.

We impose the following assumption on the kernel.

1. [K]

   KK is non-negative, continuous at 0, of bounded variation and supported on [âˆ’1,1][-1,1] such that Kâ€‹(0)>0K(0)>0, âˆ«âˆ’âˆâˆKâ€‹(t)â€‹ğ‘‘t=1\int\_{-\infty}^{\infty}K(t)dt=1 and argâ€‹maxuâˆˆ[âˆ’r,r]â¡g^hâ€‹(u)â‰ âˆ…\operatorname\*{arg\,max}\_{u\in[-r,r]}\hat{g}\_{h}(u)\neq\emptyset a.s.

Assumption [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") holds for the uniform kernel K=12â€‹1[âˆ’1,1]K=\frac{1}{2}1\_{[-1,1]} and the triangular kernel K=KtriK=K^{\mathrm{tri}}, for example.

###### Theorem 4.1.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").
Let Î·>0\eta>0 be a constant.
Then, there exist constants A>1A>1 and 0<h0<10<h\_{0}<1 depending only on Î±,Î±0,Î´,b\alpha,\alpha\_{0},\delta,b and KK such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(|Î¸^hâˆ’Î¸âˆ—|>Aâ€‹h)â‰¤CTâ€‹hÎ²Î±+Îµ\operatorname{P}(|\hat{\theta}\_{h}-\theta^{\*}|>Ah)\leq\frac{C}{\sqrt{Th^{\beta\_{\alpha}+\varepsilon}}} |  | (4.1) |

for all hâ‰¤h0âˆ§Tâˆ’Î·h\leq h\_{0}\wedge T^{-\eta} and Îµ>0\varepsilon>0, where C>0C>0 is a constant depending only on r,Î±,Î´,br,\alpha,\delta,b, (Bp)pâ‰¥1(B\_{p})\_{p\geq 1}, (Bp,q)p,qâ‰¥1(B\_{p,q})\_{p,q\geq 1}, Îµ,Î·\varepsilon,\eta and â€–Kâ€–âˆ\|K\|\_{\infty}.
In particular, Î¸^h=Î¸âˆ—+Opâ€‹(h)\hat{\theta}\_{h}=\theta^{\*}+O\_{p}(h) as Tâ†’âˆT\to\infty if h=hTâ‰Tâˆ’Î³h=h\_{T}\asymp T^{-\gamma} for some 0<Î³<1/Î²Î±0<\gamma<1/\beta\_{\alpha}.

By [TheoremÂ 4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes"), Î¸^h\hat{\theta}\_{h} estimates Î¸âˆ—\theta^{\*} at the same convergence rate as Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS}.
Moreover, unlike the DS estimator, we do not require assumption ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")).
In particular, by selecting the bandwidth appropriately, our estimator nearly attains the minimax optimal convergence rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} (see [TheoremÂ 4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")).
The next subsection discusses methods for selecting the bandwidth in a data-driven way.

###### Remark 4.1 (Relation to kernel mode estimation).

In light of [3.3](https://arxiv.org/html/2601.01871v1#S3.Thmrmk3 "Remark 3.3 (Relation to mode estimation). â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), our estimator is closely related to a mode estimator obtained by maximizing a kernel density estimator.
Following [chacon2020modal], we refer to this type of estimator as the kernel mode estimator.

For i.i.d.Â data with density ff and unique population mode Î¸âˆ—\theta^{\*},
parzen1962estimation established the asymptotic normality of the kernel mode estimator when ff is of class C2C^{2} and fâ€²â€²â€‹(Î¸âˆ—)<0f^{\prime\prime}(\theta^{\*})<0. This setting is a particular case of [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") with Î±=3\alpha=3.
Notably, with a suitable bandwidth choice, the kernel mode estimator nearly achieves the convergence rate nâˆ’1/5n^{-1/5}, where nn is the sample size. Since Î²3=5\beta\_{3}=5, our estimator enjoys an analogous property.
hasminskii1979lower proved that the rate nâˆ’1/5n^{-1/5} is minimax optimal in this setting, but it can be improved under additional smoothness assumptions on the density and the kernel; see e.g.Â [eddy1980optimum, klemela2005adaptive, vieu1996note].

Without smoothness assumptions on the density, abraham2003simple and herrmann2004rates obtained convergence rates for the kernel mode estimator and its variant under conditions analogous to [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](i)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i1 "Item [A2](i) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
In this scenario, arias2022estimation established the minimax optimal rate and developed an adaptive estimation procedure.
The convergence rate in this setting is nâˆ’1/(2â€‹Î±âˆ’1)n^{-1/(2\alpha-1)}, which again analogous to ours.
To the best of our knowledge, apart from the work of [bercu2002estimation], no results exist for mode estimation under assumptions analogous to [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](ii)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i2 "Item [A2](ii) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
bercu2002estimation investigated a histogram-type estimator, which can be viewed as a discretized kernel mode estimator, and showed that its convergence rate can be made arbitrarily close to nâˆ’1/Î±n^{-1/\alpha} by selecting the bin width appropriately.
This behavior is also analogous to that of our estimator.

Finally, to our knowledge, the asymptotic distribution of the kernel mode estimator remains unknown for non-smooth densities.
We conjecture that it may be non-Gaussian when Î±<3/2\alpha<3/2, drawing a parallel to location parameter estimation in the presence of density singularities (cf.Â [ibragimov2013statistical, Chapter VI]).

### 4.1 Bandwidth selection by Lepskiâ€™s method

In the classical setting of i.i.d. observations and kernel density estimation, bandwidth selection is typically based on minimizing the mean integrated squared error (MISE) of the kernel estimator; see, for example, [tsybakov2008nonparametric, Chapter 1].
In kernel estimation of moment density functions for point processes, analogous MISE-type criteria are also standard [guan2007least, jalilian2018fast].

However, for our purposes, a global loss criterion such as MISE is not entirely satisfactory, because the object of interest is not the function gg itself but the location Î¸âˆ—\theta^{\ast} of its peak.
Intuitively, a global criterion aims to fit the entire curve, including regions where gg is only moderately large or small, whereas the estimation error of Î¸âˆ—\theta^{\ast} may be governed almost exclusively by the local behaviour of gg in a small neighbourhood of the peak, which may even be singular under condition [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii).
A closely related issue has been recognized in the literature on nonparametric modal regression with i.i.d. observation; see, for example, Section 4.2 in chen2018modal.
Motivated by recent works in this context [chen2016nonparametric, zhou2019bandwidth], we investigate loss-minimization approaches based on cross-validation in AppendixÂ [C](https://arxiv.org/html/2601.01871v1#A3 "Appendix C Bandwidth selection by cross-validation â€£ On lead-lag estimation of non-synchronously observed point processes").

Here, we instead adopt an adaptive estimation strategy based on a Lepski-type method, i.e., a pairwise comparison of estimators with different bandwidths.
Our approach was particularly inspired by klemela2005adaptive, who has developed a Lepski-type method for mode estimation from i.i.d.Â data.
For textbook treatments of Lepskiâ€™s method, we refer to [gine2016mathematical, Section 8.2].

Fix constants a>1a>1, Î³max>0\gamma\_{\max}>0 and jminâˆˆâ„•j\_{\min}\in\mathbb{N}.
We consider the following set as candidates for bandwidths:

|  |  |  |
| --- | --- | --- |
|  | â„‹T:={aâˆ’j:jminâ‰¤jâ‰¤âŒˆlogaâ¡(TÎ³max)âŒ‰,jâˆˆâ„¤}.\mathcal{H}\_{T}:=\{a^{-j}:j\_{\min}\leq j\leq\lceil\log\_{a}(T^{\gamma\_{\max}})\rceil,\,j\in\mathbb{Z}\}. |  |

For every hâˆˆâ„‹Th\in\mathcal{H}\_{T}, set

|  |  |  |
| --- | --- | --- |
|  | â„³h:=argâ€‹maxuâˆˆ[âˆ’r,r]â¡g^hâ€‹(u).\mathcal{M}\_{h}:=\operatorname\*{arg\,max}\_{u\in[-r,r]}\hat{g}\_{h}(u). |  |

We define

|  |  |  |
| --- | --- | --- |
|  | h^:=minâ¡{hâˆˆâ„‹T:dÂ¯â€‹(â„³h,â„³hâ€²)â‰¤ATâ€‹hâ€²â€‹Â for allÂ â€‹hâ€²âˆˆâ„‹Tâ€‹Â withÂ â€‹hâ€²â‰¥h},\hat{h}:=\min\left\{h\in\mathcal{H}\_{T}:\bar{d}(\mathcal{M}\_{h},\mathcal{M}\_{h^{\prime}})\leq A\_{T}h^{\prime}\text{ for all }h^{\prime}\in\mathcal{H}\_{T}\text{ with }h^{\prime}\geq h\right\}, |  |

where ATA\_{T} is a positive constant and

|  |  |  |
| --- | --- | --- |
|  | dÂ¯(â„³h,â„³hâ€²):=sup{|xâˆ’y|:xâˆˆâ„³h,yâˆˆâ„³hâ€²}.\bar{d}(\mathcal{M}\_{h},\mathcal{M}\_{h^{\prime}}):=\sup\left\{|x-y|:x\in\mathcal{M}\_{h},\,y\in\mathcal{M}\_{h^{\prime}}\right\}. |  |

###### Theorem 4.2.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").
Also, assume 1/Î²Î±â‰¤Î³max1/\beta\_{\alpha}\leq\gamma\_{\max}.
Further, assume ATâ†’âˆA\_{T}\to\infty and AT=oâ€‹(Tc)A\_{T}=o(T^{c}) for any c>0c>0 as Tâ†’âˆT\to\infty.
Then, Î¸^h^=Î¸âˆ—+Opâ€‹(Tâˆ’Î³)\hat{\theta}\_{\hat{h}}=\theta^{\*}+O\_{p}(T^{-\gamma}) for any 0<Î³<1/Î²Î±0<\gamma<1/\beta\_{\alpha}.

[TheoremÂ 4.2](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem2 "Theorem 4.2. â€£ 4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") shows that the estimator Î¸^h^\hat{\theta}\_{\hat{h}} nearly achieves the optimal convergence rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} without requiring the precise value of Î±\alpha.
This result is numerically validated in [SectionÂ 5.3](https://arxiv.org/html/2601.01871v1#S5.SS3 "5.3 Convergence rate and dependence on hyperparameters of Lepskiâ€™s method â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes"), where we also assess the robustness of the estimator with respect to the choice of the tuning parameter ATA\_{T}.
We will see that setting ATA\_{T} to a constant multiple of logâ¡logâ¡T\log\log T performs reasonably well.

### 4.2 Minimax lower bound for the convergence rate

In this subsection, we show that when [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") hold, Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} gives a minimax lower bound for the convergence rate of any estimator for Î¸âˆ—\theta^{\*}.
For this purpose, we consider a subclass of models for NN satisfying [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), which is specified as follows.
Given a probability density function gg on â„\mathbb{R}, we consider a probability measure Pg\operatorname{P}\_{g} on (Î©,â„±)(\Omega,\mathcal{F}) having the following properties:

1. (i)

   N1=âˆ‘i=1âˆÎ´tiN\_{1}=\sum\_{i=1}^{\infty}\delta\_{t\_{i}} is a Poisson process on â„\mathbb{R} with unit intensity under Pg\operatorname{P}\_{g}.
2. (ii)

   N2N\_{2} is of the form N2=âˆ‘i=1âˆÎ´ti+Î³iN\_{2}=\sum\_{i=1}^{\infty}\delta\_{t\_{i}+\gamma\_{i}}, where (Î³i)i=1âˆ(\gamma\_{i})\_{i=1}^{\infty} is a sequence of i.i.d.Â random variables independent of N1N\_{1} such that the law of Î³1\gamma\_{1} has density gg under Pg\operatorname{P}\_{g}.

Under Pg\operatorname{P}\_{g}, NN is a bivariate Poisson process on â„\mathbb{R} in the sense of [daley2006introduction, Example 6.3(e)], where we have Q1=Q2=0Q\_{1}=Q\_{2}=0 and Q3â€‹(dâ€‹xâ€‹dâ€‹y)=gâ€‹(yâˆ’x)â€‹dâ€‹xâ€‹dâ€‹yQ\_{3}(dxdy)=g(y-x)dxdy in their notation.
In particular, under Pg\operatorname{P}\_{g}, the CPCF of NN is given by gg.

We write ğ’¢â€‹(Î¸âˆ—,Î±,Î´,b)\mathcal{G}(\theta^{\*},\alpha,\delta,b) for the class of probability density functions g:â„â†’[0,âˆ]g:\mathbb{R}\to[0,\infty] supported on [âˆ’1,1][-1,1] and satisfying the conditions of [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Note that if gâˆˆğ’¢â€‹(Î¸âˆ—,Î±,Î´,b)g\in\mathcal{G}(\theta^{\*},\alpha,\delta,b), then NN satisfies [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") for some family of constants (Bp)pâ‰¥1(B\_{p})\_{p\geq 1}.
In fact, [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") is evident, while [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) follows from the fact that both N1N\_{1} and N2N\_{2} are Poisson processes on â„\mathbb{R} with unit intensity.
Finally, since gg is supported on [âˆ’1,1][-1,1], Î±c1,c2Nâ€‹(m;r1)=0\alpha\_{c\_{1},c\_{2}}^{N}(m;r\_{1})=0 for mâ‰¥m0m\geq m\_{0}, where m0m\_{0} depends only on rr. Hence, [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) is also satisfied.
Given this consideration, the following theorem shows that Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} gives a minimax lower bound for the convergence rate of any estimator for Î¸âˆ—\theta^{\*} under [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"):

###### Theorem 4.3.

For any Î±âˆˆ(0,1)âˆª(1,âˆ)\alpha\in(0,1)\cup(1,\infty), there exists a constant b>0b>0 such that

|  |  |  |
| --- | --- | --- |
|  | lim infTâ†’âˆinfÎ¸^Tsup|Î¸|â‰¤2â€‹ÏTsupgâˆˆğ’¢â€‹(Î¸,Î±,1/2,b)Pgâ¡(|Î¸^Tâˆ’Î¸|â‰¥ÏT)>0,\liminf\_{T\to\infty}\inf\_{\hat{\theta}\_{T}}\sup\_{|\theta|\leq 2\rho\_{T}}\sup\_{g\in\mathcal{G}(\theta,\alpha,1/2,b)}\operatorname{P}\_{g}\left(|\hat{\theta}\_{T}-\theta|\geq\rho\_{T}\right)>0, |  |

where ÏT:=Tâˆ’1/Î²Î±\rho\_{T}:=T^{-1/\beta\_{\alpha}} and the infimum is taken over all estimators based on Nâˆ©[0,T]N\cap[0,T], i.e.Â all Ïƒâ€‹(Nâˆ©[0,T])\sigma(N\cap[0,T])-measurable random variables.

###### Remark 4.2.

Since the cumulant measure of order (p,q)(p,q) of NN vanishes if pâˆ§q>1p\wedge q>1, condition ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) holds whenever Ï–=1\varpi=1, and also holds for Ï–<2\varpi<2 when gg is bounded.
Therefore, Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} is also a minimax lower bound for the convergence rate of any estimator for Î¸âˆ—\theta^{\*} under the assumptions of [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") when Î±<2\alpha<2.

## 5 Simulation study

Bivariate Hawkes and Neymanâ€“Scott processes equipped with gamma kernels are used to model the relationship between two series of timestamps in high-frequency financial data; for instance, see [potiron2025mutually] and [shiotani2024statistical], respectively.
In our experiments, we employ â€œlaggedâ€ variants of these models as the data-generating processes.
Using simulated data, we numerically investigate the accuracy, convergence rate, and tuning parameter sensitivity of the DS estimator and our proposed estimator.
We adopt the triangular kernel KtriK\_{\mathrm{tri}} for the kernel method in all numerical experiments in this paper.

### 5.1 Models

#### 5.1.1 Lagged bivariate Hawkes process with gamma kernels

First, we introduce a bivariate Hawkes process with conditional intensity functions

|  |  |  |
| --- | --- | --- |
|  | Î»iâ€‹(t)=Î¼i+âˆ‘tk,1<tÏ•iâ€‹1â€‹(tâˆ’tk,1)+âˆ‘tk,2<tÏ•iâ€‹2â€‹(tâˆ’tk,2),i=1,2,\lambda\_{i}(t)=\mu\_{i}+\sum\_{t\_{k,1}<t}\phi\_{i1}(t-t\_{k,1})+\sum\_{t\_{k,2}<t}\phi\_{i2}(t-t\_{k,2}),\qquad i=1,2, |  |

where {tk,i}\{t\_{k,i}\} denotes the kk-th event time in the ii-th component.
We parameterize the kernel functions as
Ï•iâ€‹jâ€‹(t)=Î±iâ€‹jâ€‹hiâ€‹jâ€‹(t)\phi\_{ij}(t)=\alpha\_{ij}h\_{ij}(t) for t>0t>0, where Î±iâ€‹j>0\alpha\_{ij}>0
is the branching ratio and hiâ€‹jâ€‹(t)h\_{ij}(t) is a probability density function
on (0,âˆ)(0,\infty).

In this study, we adopt gamma kernels. Specifically, we assume that hiâ€‹jh\_{ij} follows a gamma density Î“â€‹(Diâ€‹j,Î²iâ€‹j)\Gamma(D\_{ij},\beta\_{ij}):

|  |  |  |
| --- | --- | --- |
|  | hiâ€‹jâ€‹(t)=Î²iâ€‹jDiâ€‹jÎ“â€‹(Diâ€‹j)â€‹tDiâ€‹jâˆ’1â€‹eâˆ’Î²iâ€‹jâ€‹t,t>0,h\_{ij}(t)=\frac{\beta\_{ij}^{D\_{ij}}}{\Gamma(D\_{ij})}t^{D\_{ij}-1}e^{-\beta\_{ij}t},\qquad t>0, |  |

where Diâ€‹j>0D\_{ij}>0 is the shape parameter and Î²iâ€‹j>0\beta\_{ij}>0 is the rate
parameter. When Diâ€‹j=1D\_{ij}=1, this specification reduces to the classical
exponential kernel, so the exponential Hawkes model is included as a special case.
We write ğ=(Î¼1,Î¼2)âŠ¤\boldsymbol{\mu}=(\mu\_{1},\mu\_{2})^{\top} for the baseline
intensity vector, and
ğœ¶=(Î±iâ€‹j)1â‰¤i,jâ‰¤2\boldsymbol{\alpha}=(\alpha\_{ij})\_{1\leq i,j\leq 2},
ğœ·=(Î²iâ€‹j)1â‰¤i,jâ‰¤2\boldsymbol{\beta}=(\beta\_{ij})\_{1\leq i,j\leq 2},
and ğ‘«=(Diâ€‹j)1â‰¤i,jâ‰¤2\boldsymbol{D}=(D\_{ij})\_{1\leq i,j\leq 2}
for the matrices of branching ratios, rate parameters, and shape parameters,
respectively. We then collect all kernel and baseline parameters into

|  |  |  |
| --- | --- | --- |
|  | Î·=(ğ,ğœ¶,ğœ·,ğ‘«)âˆˆ(0,âˆ)2Ã—(0,âˆ)2Ã—2Ã—(0,âˆ)2Ã—2Ã—(0,âˆ)2Ã—2.\eta=(\boldsymbol{\mu},\boldsymbol{\alpha},\boldsymbol{\beta},\boldsymbol{D})\in(0,\infty)^{2}\times(0,\infty)^{2\times 2}\times(0,\infty)^{2\times 2}\times(0,\infty)^{2\times 2}. |  |

We assume the spectral radius of ğœ¶\boldsymbol{\alpha} is smaller than 1 to ensure stationarity.
Following bacry2012non, the intensity is

|  |  |  |
| --- | --- | --- |
|  | Î›=(Î»1â€‹(Î·),Î»2â€‹(Î·))âŠ¤=(I2âˆ’ğœ¶)âˆ’1â€‹ğ\Lambda=(\lambda\_{1}(\eta),\lambda\_{2}(\eta))^{\top}=(I\_{2}-\boldsymbol{\alpha})^{-1}\boldsymbol{\mu} |  |

(Eq.(3) in [bacry2012non]), and the CPCF is

|  |  |  |
| --- | --- | --- |
|  | gâ€‹(u;Î·,Î¸)=1+Î½12â€‹(u;Î·)Î»1â€‹(Î·)â€‹Î»2â€‹(Î·),uâˆˆâ„,g(u;\eta,\theta)=1+\frac{\nu\_{12}(u;\eta)}{\lambda\_{1}(\eta)\,\lambda\_{2}(\eta)},\qquad u\in\mathbb{R}, |  |

where Î½12\nu\_{12} is the (1, 2) component of the infinitesimal covariance matrix Î½\nu of the bivariate Hawkes process (Eq.(8) in [bacry2012non]):

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î½12â€‹(u)=(Î¨â€‹(u)â€‹Î£+Î£â€‹Î¨âŠ¤â€‹(âˆ’u)+Î¨~âˆ—Î£â€‹Î¨âŠ¤â€‹(u))1,2uâˆˆâ„,\nu\_{12}(u)=\Bigl(\Psi(u)\Sigma+\Sigma\Psi^{\top}(-u)+\widetilde{\Psi}\*\Sigma\Psi^{\top}(u)\Bigr)\_{1,2}\qquad u\in\mathbb{R}, |  | (5.1) |

where Î£=diagâ€‹{Î»1,Î»2}\Sigma=\mathrm{diag}\{\lambda\_{1},\lambda\_{2}\},
Î¨â€‹(u)=(Î¨iâ€‹jâ€‹(u))1â‰¤i,jâ‰¤2\Psi(u)=(\Psi\_{ij}(u))\_{1\leq i,j\leq 2} is defined by

|  |  |  |
| --- | --- | --- |
|  | Î¨â€‹(u)=âˆ‘m=1âˆÎ¦(âˆ—m)â€‹(u),Î¦(âˆ—m)=Î¦âˆ—â‹¯âˆ—Î¦âŸmâ€‹times,\Psi(u)=\sum\_{m=1}^{\infty}\Phi^{(\*m)}(u),\qquad\Phi^{(\*m)}=\underbrace{\Phi\*\cdots\*\Phi}\_{m\ \text{times}}, |  |

with kernel matrix
Î¦â€‹(u)=(Ï•iâ€‹jâ€‹(u))1â‰¤i,jâ‰¤2\Phi(u)=\bigl(\phi\_{ij}(u)\bigr)\_{1\leq i,j\leq 2}
and âˆ—\* denoting the matrix convolution,
and Î¨~â€‹(u)=Î¨â€‹(âˆ’u),uâˆˆâ„\widetilde{\Psi}(u)=\Psi(-u),u\in\mathbb{R}.

In addition,
let Î¸âˆˆâ„\theta\in\mathbb{R} denote the lead-lag parameter.
Given a realization of the bivariate Hawkes process N=(N10,N20)N=(N\_{1}^{0},N\_{2}^{0}), we call the shifted process (N1,N2)=(N10,N20(â‹…âˆ’Î¸))(N\_{1},N\_{2})=(N\_{1}^{0},\,N\_{2}^{0}(\cdot-\theta)) a *lagged bivariate Hawkes process with gamma kernels (LBHPG)*.
Its distribution is denoted by

|  |  |  |
| --- | --- | --- |
|  | LBHPGâ€‹(Î·,Î¸).\mathrm{LBHPG}(\eta,\theta). |  |

For the shifted process LBHPGâ€‹(Î·,Î¸)\mathrm{LBHPG}(\eta,\theta), the intensity is still Î›\Lambda, while the crossâ€“covariance density is simply shifted:

|  |  |  |
| --- | --- | --- |
|  | Î½12â€‹(uâˆ’Î¸;Î·),uâˆˆâ„.\nu\_{12}(u-\theta;\eta),\qquad u\in\mathbb{R}. |  |

Also, we have the cross-pair correlation function (CPCF) of LBHPGâ€‹(Î·,Î¸)\mathrm{LBHPG}(\eta,\theta) as

|  |  |  |  |
| --- | --- | --- | --- |
|  | gâ€‹(u;Î·,Î¸)=1+Î½12â€‹(uâˆ’Î¸;Î·)Î»1â€‹(Î·)â€‹Î»2â€‹(Î·),uâˆˆâ„.g(u;\eta,\theta)=1+\frac{\nu\_{12}(u-\theta;\eta)}{\lambda\_{1}(\eta)\,\lambda\_{2}(\eta)},\qquad u\in\mathbb{R}. |  | (5.2) |

In the simulation study, we restrict to the case of common rate parameters, that is, Î²iâ€‹jâ‰¡Î²\beta\_{ij}\equiv\beta for all i,jâˆˆ{1,2}i,j\in\{1,2\}. In such cases,
LBHPGâ€‹(Î·,Î¸)\mathrm{LBHPG}(\eta,\theta) satisfies [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) with Î±=minâ¡{D12,D21}\alpha=\min\{D\_{12},D\_{21}\} if minâ¡{D12,D21}<1\min\{D\_{12},D\_{21}\}<1 (diverging gamma kernel(s)) and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) with Î±=2\alpha=2 if D11=D21=D12=D22=1D\_{11}=D\_{21}=D\_{12}=D\_{22}=1 (exponential kernels).
The former can be obtained by the reproducibility of gamma densities and the local behavior of bilateral gamma densities at the origin [kuchler2008shapes, Thm.Â 6.1]. For details, see AppendixÂ [A.7](https://arxiv.org/html/2601.01871v1#A1.SS7 "A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").
The latter follows from the explicit formula for the CPCF for bivariate Hawkes processes with exponential kernels, which can be obtained by [bacry2015hawkes, Example 3].
The moment condition [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) is guaranteed thanks to Theorem 1 in [leblanc2024exponential].
We also have a bound on the strong mixing rate [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) from Theorem 3.1 in [boly2023mixing], since the gamma kernels decay geometrically.
Therefore, LBHPGâ€‹(Î·,Î¸)\mathrm{LBHPG}(\eta,\theta) satisfies the assumptions in Theorem [4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") with a (smoothing) kernel satisfying Assumption [K] in such special cases.

#### 5.1.2 Lagged bivariate Neyman-Scott process with gamma kernels

First, we recall the construction of a bivariate Neyman-Scott process on â„\mathbb{R}
following Section 5.1 in shiotani2024statistical. Let ğ’\mathcal{C} be a homogeneous
Poisson (parent) process on â„\mathbb{R} with intensity Î»>0\lambda>0. For i=1,2i=1,2 and each
câˆˆğ’c\in\mathcal{C}, let Miâ€‹(c)M\_{i}(c) be the number of offspring in the component ii from the parent cc.
We assume that {Miâ€‹(c)}câˆˆğ’\{M\_{i}(c)\}\_{c\in\mathcal{C}} are i.i.d. copies of a â„¤â‰¥0\mathbb{Z}\_{\geq 0}-valued
random variable MiM\_{i} with finite mean
Ïƒi=ğ”¼â€‹[Mi]âˆˆ(0,âˆ),i=1,2.\sigma\_{i}=\mathbb{E}[M\_{i}]\in(0,\infty),i=1,2.
For simplicity, we assume that MiM\_{i} follows a Poisson distribution Poiâ€‹(Ïƒi),i=1,2\mathrm{Poi}(\sigma\_{i}),i=1,2.
Conditional on Miâ€‹(c)M\_{i}(c), the temporal offsets {diâ€‹(c,m)}m=1Miâ€‹(c)\{d\_{i}(c,m)\}\_{m=1}^{M\_{i}(c)} of the
offspring are i.i.d. with density fif\_{i}, independent over i,c,mi,c,m and independent of
ğ’\mathcal{C} and {Miâ€‹(c)}\{M\_{i}(c)\}.
Then, let

|  |  |  |
| --- | --- | --- |
|  | Ni0=âˆ‘câˆˆğ’âˆ‘m=1Miâ€‹(c)Î´c+diâ€‹(c,m),i=1,2.N\_{i}^{0}=\sum\_{c\in\mathcal{C}}\sum\_{m=1}^{M\_{i}(c)}\delta\_{c+d\_{i}(c,m)},\qquad i=1,2. |  |

We call N0=(N10,N20)N^{0}=(N\_{1}^{0},N\_{2}^{0}) a bivariate Neyman-Scott process.

N0N^{0} is stationary with intensities

|  |  |  |
| --- | --- | --- |
|  | Î»iâ€‹(Î¾)=Î»â€‹Ïƒi,i=1,2.\lambda\_{i}(\xi)=\lambda\,\sigma\_{i},\qquad i=1,2. |  |

Moreover, the crossâ€“intensity
of (N10,N20)(N\_{1}^{0},N\_{2}^{0}) is

|  |  |  |
| --- | --- | --- |
|  | Î»12â€‹(u;Î¾)=Î»2â€‹Ïƒ1â€‹Ïƒ2+Î»â€‹Ïƒ1â€‹Ïƒ2â€‹âˆ«â„f1â€‹(s;Ï„1)â€‹f2â€‹(u+s;Ï„2)â€‹ğ‘‘s,uâˆˆâ„,\lambda\_{12}(u;\xi)=\lambda^{2}\sigma\_{1}\sigma\_{2}+\lambda\sigma\_{1}\sigma\_{2}\int\_{\mathbb{R}}f\_{1}(s;\tau\_{1})f\_{2}(u+s;\tau\_{2})\,ds,\qquad u\in\mathbb{R}, |  |

see Eq.(5.2) and the subsequent calculation in [shiotani2024statistical].
Therefore, the crossâ€“pair correlation function (CPCF) of the bivariate
Neyman-Scott process is

|  |  |  |
| --- | --- | --- |
|  | gâ€‹(u;Î¾)=Î»12â€‹(u;Î¾)Î»1â€‹(Î¾)â€‹Î»2â€‹(Î¾)=1+1Î»â€‹âˆ«â„f1â€‹(s;Ï„1)â€‹f2â€‹(u+s;Ï„2)â€‹ğ‘‘s,uâˆˆâ„,g(u;\xi)=\frac{\lambda\_{12}(u;\xi)}{\lambda\_{1}(\xi)\lambda\_{2}(\xi)}=1+\frac{1}{\lambda}\int\_{\mathbb{R}}f\_{1}(s;\tau\_{1})f\_{2}(u+s;\tau\_{2})\,ds,\qquad u\in\mathbb{R}, |  |

where Î¾\xi collects all parameters introduced above.

In this simulation study, we adopt gamma dispersal kernels as in the NBNSP-G model
of Shiotani and Yoshida [shiotani2024statistical]. Specifically, for i=1,2i=1,2 we assume that

|  |  |  |
| --- | --- | --- |
|  | fiâ€‹(u;Ï„i)=liÎ±iÎ“â€‹(Î±i)â€‹uÎ±iâˆ’1â€‹eâˆ’liâ€‹uâ€‹1(0,âˆ)â€‹(u),uâˆˆâ„,f\_{i}(u;\tau\_{i})=\frac{l\_{i}^{\alpha\_{i}}}{\Gamma(\alpha\_{i})}u^{\alpha\_{i}-1}e^{-l\_{i}u}1\_{(0,\infty)}(u),\qquad u\in\mathbb{R}, |  |

where Ï„i=(Î±i,li)\tau\_{i}=(\alpha\_{i},l\_{i}), Î±i>0\alpha\_{i}>0 is the shape parameter and li>0l\_{i}>0 is the
rate parameter of the gamma law. We then collect the parameters as

|  |  |  |
| --- | --- | --- |
|  | Î¾=(Î»,Ïƒ1,Ïƒ2,Î±1,Î±2,l1,l2)âˆˆ(0,âˆ)7.\xi=(\lambda,\sigma\_{1},\sigma\_{2},\alpha\_{1},\alpha\_{2},l\_{1},l\_{2})\in(0,\infty)^{7}. |  |

Let Î¸âˆˆâ„\theta\in\mathbb{R} denote the leadâ€“lag parameter. Given a realization
N0=(N10,N20)N^{0}=(N\_{1}^{0},N\_{2}^{0}) of the bivariate Neyman-Scott process with gamma kernels described above, we define the lagged process by shifting the second component:

|  |  |  |
| --- | --- | --- |
|  | (N1,N2)=(N10,N20(â‹…âˆ’Î¸)).(N\_{1},N\_{2})=\bigl(N\_{1}^{0},\,N\_{2}^{0}(\,\cdot\,-\theta)\bigr). |  |

We refer to N=(N1,N2)N=(N\_{1},N\_{2}) as the *lagged bivariate Neyman-Scott process with gamma kernels (LBNSPG)* and denote its distribution by

|  |  |  |
| --- | --- | --- |
|  | LBNSPGâ€‹(Î¾,Î¸).\mathrm{LBNSPG}(\xi,\theta). |  |

The intensities of LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta) are still given by
Î»1â€‹(Î¾)\lambda\_{1}(\xi) and Î»2â€‹(Î¾)\lambda\_{2}(\xi), while the crossâ€“intensity is simply shifted:

|  |  |  |
| --- | --- | --- |
|  | Î»12â€‹(uâˆ’Î¸;Î¾),uâˆˆâ„.\lambda\_{12}(u-\theta;\xi),\qquad u\in\mathbb{R}. |  |

Consequently, the CPCF of LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta) is

|  |  |  |
| --- | --- | --- |
|  | gâ€‹(u;Î¾,Î¸)=Î»12â€‹(uâˆ’Î¸;Î¾)Î»1â€‹(Î¾)â€‹Î»2â€‹(Î¾)=1+1Î»â€‹pâ€‹(uâˆ’Î¸;Ï„1,Ï„2),\displaystyle g(u;\xi,\theta)=\frac{\lambda\_{12}(u-\theta;\xi)}{\lambda\_{1}(\xi)\lambda\_{2}(\xi)}=1+\frac{1}{\lambda}p(u-\theta;\tau\_{1},\tau\_{2}), |  |
|  |  |  |
| --- | --- | --- |
|  | pâ€‹(u;Ï„1,Ï„2)=âˆ«â„f1â€‹(s;Ï„1)â€‹f2â€‹(u+s;Ï„2)â€‹ğ‘‘s,uâˆˆâ„.\displaystyle p(u;\tau\_{1},\tau\_{2})=\int\_{\mathbb{R}}f\_{1}(s;\tau\_{1})f\_{2}(u+s;\tau\_{2})\,ds,\qquad u\in\mathbb{R}. |  |

The function pâ€‹(â‹…;Î±1,Î±2,l1,l2)p(\cdot;\alpha\_{1},\alpha\_{2},l\_{1},l\_{2}) is the density of a bilateral gamma distribution.
KÃ¼chler and Tappe [kuchler2008shapes] provide a detailed analysis of the shapes of bilateral gamma densities, including unimodality and the local behavior near zero (see Theorem 6.1 therein).
Combining their results with the above representation shows that gâ€‹(â‹…;Î¾,Î¸)g(\cdot;\xi,\theta) is strictly unimodal with the peak at Î¸\theta whenever the parameters are symmetric, i.e., Î±1=Î±2\alpha\_{1}=\alpha\_{2} and l1=l2l\_{1}=l\_{2}.
We restrict attention to such symmetric cases in our simulation experiments.
Under this restriction, LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta) satisfies [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) if Î±1+Î±2<1\alpha\_{1}+\alpha\_{2}<1 and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) if Î±1+Î±2>1\alpha\_{1}+\alpha\_{2}>1, with Î±=minâ¡{Î±1+Î±2,3}\alpha=\min\{\alpha\_{1}+\alpha\_{2},3\} in both cases.

Note that LBNSPGâ€‹(Î¾,0)\mathrm{LBNSPG}(\xi,0) is the special case (setting the noise process to zero and the distribution of MiM\_{i} to Poisson) of the NBNSP-G model introduced in Section 6.1 in [shiotani2024statistical].
Therefore, LBNSPGâ€‹(Î¾,0)\mathrm{LBNSPG}(\xi,0) satisfies condition [NS] in [shiotani2024statistical], so that LemmaÂ 10.13 there bounds the Î±\alphaâ€“mixing coefficients of LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta) in terms of the tail probabilities of the dispersal kernels:
for all c1â‰¥0c\_{1}\geq 0 and mâ‰¥2â€‹r+2m\geq 2r+2,

|  |  |  |
| --- | --- | --- |
|  | Î±c1,âˆNâ€‹(m;r):=supc2â‰¥0Î±c1,c2Nâ€‹(m;r)â‰¤8â€‹mâ€‹Î»â€‹(m+1+2â€‹r)â€‹âˆ‘i=12Ïƒiâ€‹âˆ«|z|â‰¥m/2âˆ’2â€‹rfiâ€‹(z;Ï„i)â€‹ğ‘‘z.\alpha^{N}\_{c\_{1},\infty}(m;r):=\sup\_{c\_{2}\geq 0}\alpha^{N}\_{c\_{1},c\_{2}}(m;r)\leq 8m\lambda\;(m+1+2r)\sum\_{i=1}^{2}\sigma\_{i}\int\_{|z|\geq m/2-2r}f\_{i}(z;\tau\_{i})\,dz. |  |

Since the gamma kernels have geometrically decaying tails, this implies that
Î±c1,âˆâ€‹(m;r1)\alpha\_{c\_{1},\infty}(m;r\_{1}) decreases faster than any power of mm, so AssumptionÂ [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) holds for LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta).
Moreover, since the Poisson-distributed MiM\_{i} possesses moments of all orders, LemmaÂ 10.14 in [shiotani2024statistical] yields finiteness of moments of Niâ€‹((0,1])N\_{i}((0,1]) of all orders, so that AssumptionÂ [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) is satisfied.
Therefore, LBNSPGâ€‹(Î¾,Î¸)\mathrm{LBNSPG}(\xi,\theta) fulfills Assumptions
[[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and thus is in the scope of TheoremÂ [4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") if Î±1=Î±2\alpha\_{1}=\alpha\_{2}, l1=l2l\_{1}=l\_{2}, and Î±1+Î±2â‰ 1\alpha\_{1}+\alpha\_{2}\neq 1.

#### 5.1.3 Model and parameter specifications in the simulation studies

We consider two types of bivariate stationary point process models, each with three sets of parameter values.
The models are labeled as
hawkes\_gamma\_sym,
hawkes\_gamma\_asym, hawkes\_exp, ns\_gamma\_1, ns\_gamma\_2, and ns\_gamma\_3.

| Name | Family | Î±\alpha | Î²Î±\beta\_{\alpha} | The convergence rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} |
| --- | --- | --- | --- | --- |
| hawkes\_gamma\_sym | LBHPG | 0.4 | 0.4 | Tâˆ’5/2T^{-5/2} |
| hawkes\_gamma\_asym | LBHPG | 0.4 | 0.4 | Tâˆ’5/2T^{-5/2} |
| hawkes\_exp | LBHPG | 2 | 3 | Tâˆ’1/2T^{-1/2} |
| ns\_gamma\_1 | LBNSPG | 0.8 | 0.8 | Tâˆ’5/4T^{-5/4} |
| ns\_gamma\_2 | LBNSPG | 1.6 | 2.2 | Tâˆ’5/11T^{-5/11} |
| ns\_gamma\_3 | LBNSPG | 3 | 5 | Tâˆ’1/5T^{-1/5} |

Table 1: Values of Î±\alpha (the â€œsharpnessâ€ parameter of the CPCF gg in [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"); smaller values imply sharper functions), Î²Î±=Î±âˆ¨(2â€‹Î±âˆ’1)\beta\_{\alpha}=\alpha\vee(2\alpha-1), and the minimax lower bound on the convergence rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} in Theorem [4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") for each model.

All LBHPG models share

|  |  |  |
| --- | --- | --- |
|  | ğ=(0.2,0.2)âŠ¤,ğœ¶=(0.10.10.10.1),ğœ·=(10101010).\boldsymbol{\mu}=(0.2,0.2)^{\top},\qquad\boldsymbol{\alpha}=\begin{pmatrix}0.1&0.1\\ 0.1&0.1\end{pmatrix},\qquad\boldsymbol{\beta}=\begin{pmatrix}10&10\\ 10&10\end{pmatrix}. |  |

We use three specifications for the shape matrix ğ‘«\boldsymbol{D} to cover different degrees of regularity and asymmetry:

|  |  |  |  |
| --- | --- | --- | --- |
|  | hawkes\_gamma\_sym:\displaystyle\texttt{hawkes\\_gamma\\_sym}:\quad | ğ‘«=(0.40.40.40.4);\displaystyle\boldsymbol{D}=\begin{pmatrix}0.4&0.4\\ 0.4&0.4\end{pmatrix}; |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | hawkes\_gamma\_asym:\displaystyle\texttt{hawkes\\_gamma\\_asym}:\quad | ğ‘«=(0.40.40.80.4);\displaystyle\boldsymbol{D}=\begin{pmatrix}0.4&0.4\\ 0.8&0.4\end{pmatrix}; |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | hawkes\_exp:\displaystyle\texttt{hawkes\\_exp}:\quad | ğ‘«=(1111).\displaystyle\boldsymbol{D}=\begin{pmatrix}1&1\\ 1&1\end{pmatrix}. |  |

For the LBNSPG models, we fix

|  |  |  |
| --- | --- | --- |
|  | Î»=0.1,Ïƒ1=Ïƒ2=4\lambda=0.1,\qquad\sigma\_{1}=\sigma\_{2}=4 |  |

and use symmetric dispersal shape and rate parameters.
We select three settings to vary the smoothness of the CPCF around the peak:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ns\_gamma\_1:\displaystyle\texttt{ns\\_gamma\\_1}: | (Î±1,Î±2)=(0.4,0.4),(l1,l2)=(10,10),\displaystyle\quad(\alpha\_{1},\alpha\_{2})=(0.4,0.4),\quad(l\_{1},l\_{2})=(10,10), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ns\_gamma\_2:\displaystyle\texttt{ns\\_gamma\\_2}: | (Î±1,Î±2)=(0.8,0.8),(l1,l2)=(10,10),\displaystyle\quad(\alpha\_{1},\alpha\_{2})=(0.8,0.8),\quad(l\_{1},l\_{2})=(10,10), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ns\_gamma\_3:\displaystyle\texttt{ns\\_gamma\\_3}: | (Î±1,Î±2)=(2.0,2.0),(l1,l2)=(100,100).\displaystyle\quad(\alpha\_{1},\alpha\_{2})=(2.0,2.0),\quad(l\_{1},l\_{2})=(100,100). |  |

### 5.2 Accuracy

In this experiment, we compare the accuracy of the lead-lag time estimators using the root mean squared error (RMSE) across the six scenarios.

For each pair of observation time interval length Tâˆˆ{1000,2000,4000,8000}T\in\{1000,2000,4000,8000\} and the estimator, we generate 50005000 Monte Carlo replicates of sample paths.
In every replicate, the true lead-lag time is drawn as Î¸âˆ—âˆ¼ğ’°â€‹(âˆ’0.1,0.1)\theta^{\*}\sim\mathcal{U}(-0.1,0.1).
For a given estimator Î¸^\hat{\theta}, we report

|  |  |  |
| --- | --- | --- |
|  | RMSE=(15000â€‹âˆ‘b=15000(Î¸^(b)âˆ’Î¸âˆ—(b))2)1/2,\mathrm{RMSE}=\left(\frac{1}{5000}\sum\_{b=1}^{5000}\bigl(\hat{\theta}^{(b)}-\theta^{\*(b)}\bigr)^{2}\right)^{1/2}, |  |

where Î¸^(b)\hat{\theta}^{(b)} and Î¸âˆ—(b)\theta^{\*(b)} denote the estimate and the true lead-lag time in replicate bb.
Randomizing Î¸âˆ—\theta^{\*} across replicates summarizes performance averaged over a range of lead-lag values rather than at a single fixed Î¸âˆ—\theta^{\*}.
The lead-lag time parameter is supposed to be in (âˆ’1,1)(-1,1), i.e., we set r=1r=1.
The bandwidth grid is {10âˆ’1,10âˆ’2,10âˆ’3,10âˆ’4,10âˆ’5,10âˆ’6}\{10^{-1},10^{-2},10^{-3},10^{-4},10^{-5},10^{-6}\} for both the Lepski method and DS estimators.
For the Lepski method, we set AT=logâ¡logâ¡TA\_{T}=\log\log T.
When the contrast function has multiple maximizers on (âˆ’r,r)(-r,r), we select the minimum as a deterministic tie-breaking rule.

![Refer to caption](simulations/graphs/rmse_all_scenarios.png)


Figure 2: RMSE of the estimators for the lead-lag time across six scenarios.
Each panel uses logâ€“log axes with bandwidth hh on the x-axis and RMSE on the y-axis.
Dashed lines with markers trace the DS estimator over the bandwidth grid, while solid horizontal lines show the kernel estimator with the Lepski-selected bandwidth.
Colors indicate the observation-window length Tâˆˆ{1000,2000,4000,8000}T\in\{1000,2000,4000,8000\} and are shared across panels.

Figure [2](https://arxiv.org/html/2601.01871v1#S5.F2 "Figure 2 â€£ 5.2 Accuracy â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes") illustrates two systematic patterns.
First, the performance of the DS estimator is sensitive to the bucket width hh. For each TT, the RMSE curves as a function of hh are typically U-shaped: small buckets lead to high variance due to the scarcity of joint activations, whereas larger buckets introduce a discretization bias because the lead-lag time is constrained to a coarse grid. Moreover, the value of hh that minimizes the RMSE depends on both the underlying model and the observation window length TT.
This confirms that, in practice, the DS estimator requires model-specific tuning of hh.

Second, the kernel estimator with Lepskiâ€™s bandwidth selection achieves lower RMSE than the DS estimator for almost all combinations of TT and data-generating process.
In Figure [2](https://arxiv.org/html/2601.01871v1#S5.F2 "Figure 2 â€£ 5.2 Accuracy â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes"), the horizontal solid lines corresponding to the Lepski estimator lie close to (and often below) the best DS RMSE over the grid in each panel. Importantly, this improvement is obtained without any manual tuning of the bandwidth: once the grid â„‹ğ’¯\mathcal{H\_{T}} and the slowly diverging constant AT=logâ¡logâ¡TA\_{T}=\log\log T are fixed, the procedure automatically adapts the smoothing level to the data. This demonstrates the main practical advantage of the proposed approach over the DS method.

### 5.3 Convergence rate and dependence on hyperparameters of Lepskiâ€™s method

In this experiment, we investigate the convergence rate of the Lepski estimator, as shown in TheoremÂ [4.2](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem2 "Theorem 4.2. â€£ 4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").
We also examine how the estimator behaves as the tuning parameter ATA\_{T} varies.

As in the previous experiment, for each observation-window length Tâˆˆ{1000,2000,4000,8000}T\in\{1000,2000,4000,8000\} and each estimator, we generate 5000 Monte Carlo replicates of sample paths.
In every replicate, the true lead-lag time is drawn as Î¸âˆ—âˆ¼ğ’°â€‹(âˆ’0.1,0.1)\theta^{\*}\sim\mathcal{U}(-0.1,0.1).
The lead-lag time parameter is supposed to be in (âˆ’1,1)(-1,1), i.e., we set r=1r=1.
The bandwidth grid is {10âˆ’1,10âˆ’2,10âˆ’3,10âˆ’4,10âˆ’5,10âˆ’6}\{10^{-1},10^{-2},10^{-3},10^{-4},10^{-5},10^{-6}\}.

![Refer to caption](simulations/graphs/sensitivity_lepski_all_scenarios.png)


Figure 3: RMSE versus observation window TT (logâ€“log scale) across all simulation settings and ATA\_{T} schedules. Theoretical Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} slopes are shown as dashed lines.

Figure [3](https://arxiv.org/html/2601.01871v1#S5.F3 "Figure 3 â€£ 5.3 Convergence rate and dependence on hyperparameters of Lepskiâ€™s method â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes") investigates the convergence rate of the Lepski estimator. In each scenario, the RMSE is plotted against TT on a logâ€“log scale together with the theoretical slope Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} derived from the minimax lower bound in Theorem [4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").
Across all six models, the empirical curves for the Lepski estimator are nearly parallel to the guideline.
Thus, the proposed estimator may attain the optimal convergence rate given by our theory.

The figure also compares three schedules for the tuning parameter ATA\_{T}: 0.5â€‹logâ¡logâ¡T0.5\log\log T, logâ¡logâ¡T\log\log T, and 2â€‹logâ¡logâ¡T2\log\log T.
Across all six models, the three RMSE curves are close and exhibit similar slopes, indicating that the convergence rate is robust to the choice of ATA\_{T} within this range.
The differences across schedules are mostly level shifts, so the precise constant in front of logâ¡logâ¡T\log\log T is not critical for achieving the minimax rate.

## 6 Empirical illustration

An outstanding feature of the method depicted in dobrev2017high is that the DS estimator can effectively capture the fastest speed of information transmission between two geographically separated markets, which is typically close to the speed of light.
Specifically, they analyzed the lead-lag relationships between the cash and futures markets for the 10-Year U.S. Treasury Note and for the S&P 500 index.
The DS estimator stably detected sharp peaks of the cross-market activity measures at 5 milliseconds, which is consistent with the optical propagation time between the futures exchange (in Aurora, Illinois) and the cash market platform (in Secaucus, New Jersey).
In this section, we investigate whether this finding continues to hold even for geographically closer markets, for which sub-millisecond estimates are required to detect such relationships.

More precisely, we examine the lead-lag relationships between the quotes of a single stock on two different exchanges: the NASDAQ (located in Carteret, New Jersey) and BATS (located in Secaucus, New Jersey).
According to [Tiv2020, Table 2], the optical propagation time between the NASDAQ and BATS exchanges is approximately 0.1 milliseconds.
We obtain the timestamps of updates of the best quotes on each exchange in August 2015 from the Daily TAQ dataset, which provides every quote reported to the consolidated tape by all Consolidated Trade Association (CTA) and Unlisted Trading Privileges (UTP) participants.
According to [BM2019], the microsecond timestamps were fully implemented in this dataset on August 6, 2015.
For this reason, we focus on the sample period beginning on August 6, 2015, comprising 18 trading days.
Our analysis covers the component stocks of the NASDAQ-100 in 2015, totally 108 stocks.
We restrict attention to transactions occurring between 9:45 and 15:45, discarding the first and last 15 minutes of the trading day in order to avoid non-stationarities commonly observed at the open and close.

In the Daily TAQ data, each quote record contains two timestamps: Time and Participant Timestamp, which refer to the timestamps published by Securities Information Processors (SIPs) and exchange matching engines, respectively.
Following [BM2019], we refer to the former as the *SIP timestamp* and the latter as the *participant timestamp*.
See [BM2019, Section 2] and [hasbrouck2021price, Section 4] for the institutional background.
In this study, we use the participant timestamp because our preliminary analysis suggests that the SIP timestamp is heavily contaminated by *reporting latencies* in the terminology of [BM2019].
Specifically, even when multiple market events occur simultaneously and share the same participant timestamp, they often receive different SIP timestamps, causing artificial misalignment across market events [schwenkparticipant, wu2025latency, tivnan2018price].
Moreover, reporting latencies fluctuate dynamically due to various latency sources, and their distribution is heavy-tailed (cf.Â [holden2023blink, wu2025latency] and [BM2019, Appendix]), making it difficult to disentangle their effects from genuine leadâ€“lag behavior.
For these reasons, we rely on participant timestamps.
Developing a leadâ€“lag estimator that is robust to such timestamp contamination would be an interesting direction for future research.

For each trading day and for each stock, we compute both our kernel estimator Î¸^h\hat{\theta}\_{h} and the DS estimator Î¸^hDâ€‹S\hat{\theta}^{DS}\_{h}.
For the kernel estimator, we use the triangular kernel and select the bandwidth via the Lepski type method proposed in [SectionÂ 4.1](https://arxiv.org/html/2601.01871v1#S4.SS1 "4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes"), with â„‹T={1â€‹Î¼â€‹s,10â€‹Î¼â€‹s,100â€‹Î¼â€‹s,1000â€‹Î¼â€‹s}\mathcal{H}\_{T}=\{1~\mu\text{s},10~\mu\text{s},100~\mu\text{s},1000~\mu\text{s}\}, AT=logâ¡logâ¡TA\_{T}=\log\log T and T=21600T=21600 (the number of seconds in 6 trading hours).
For the DS estimator, we consider two bucket sizes: h=1â€‹Î¼â€‹sh=1~\mu\text{s} and h=100â€‹Î¼â€‹sh=100~\mu\text{s}.
The former corresponds to the minimum time unit, as suggested in [dobrev2017high], whereas the latter is motivated by the physical transmission time of approximately 100 Î¼\mus between the two exchanges (cf.Â [Tiv2020, Table 2]).
We set r=10â€‹msr=10~\text{ms} for the search range for lead-lag parameters.

[Fig.Â 4](https://arxiv.org/html/2601.01871v1#S6.F4 "In 6 Empirical illustration â€£ On lead-lag estimation of non-synchronously observed point processes") presents violin plots of the lead-lag time estimates for the three estimators.
The estimates of Î¸^h^\hat{\theta}\_{\hat{h}} cluster around several values, most notably around 95 Î¼\mus and 130 Î¼\mus.
These values have clear physical interpretations: According to [Tiv2020, Table 2], the transmission time between NASDAQ and BATS is approximately 95 Î¼\mus via hybrid laser link and 128 Î¼\mus via fiber optic cable.
This also suggests that, in our sample, NASDAQ generally leads BATS in updating best quotes, which is an intuitive result given that all the stocks analyzed are listed on NASDAQ, and NASDAQ tends to have greater market participation.

We observe a similar clustering pattern for the DS estimator with h=1â€‹Î¼â€‹sh=1~\mu\text{s}, although these estimates appear to cluster slightly more around 130 Î¼\mus than 95 Î¼\mus.
However, they also exhibit a few negative â€œoutliersâ€, an issue not present in the kernel estimator.
Using a larger bucket size h=100â€‹Î¼â€‹sh=100~\mu\text{s} eliminates such outliers, but the coarse discretization inherent in the DS estimator significantly distorts the estimated leadâ€“lag parameters.

To highlight the differences between our estimator and the DS estimator with h=1â€‹Î¼â€‹sh=1~\mu\text{s}, [Fig.Â 5](https://arxiv.org/html/2601.01871v1#S6.F5 "In 6 Empirical illustration â€£ On lead-lag estimation of non-synchronously observed point processes") presents a scatter plot of the two sets of estimates, color-coded by n1â€‹n2\sqrt{n\_{1}n\_{2}}, the geometric mean of the sample sizes.
The two estimators yield similar values in many cases, but their estimates diverge as one or both of n1n\_{1} and n2n\_{2} become small. This observation aligns with our theoretical finding that the bucket size in the DS estimator should be increased when the sample size decreases (cf.Â the discussion following [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")).

![Refer to caption](x1.png)


Figure 4: Violin plots of the daily lead-lag time estimates between quotes on the NASDAQ and BATS exchanges, computed for all the component stocks of the NASDAQ-100 in August 6â€“31, 2015.
The top panel shows the entire plots, while the bottom panel zooms in on the interval from 0.07 ms to 0.27 ms.
The smoothing bandwidths for the violin plots are selected by sheather1991reliableâ€™s method implemented as the R function bw.SJ().
The horizontal axis is expressed in milliseconds. A positive estimate implies that the NASDAQ leads the BATS and vice versa.

![Refer to caption](x2.png)


Figure 5: Scatter plot of the estimates of Î¸^hDâ€‹S\hat{\theta}^{DS}\_{h} with h=1â€‹Î¼â€‹sh=1~\mu\text{s} versus Î¸^h^\hat{\theta}\_{\hat{h}}, color-coded by the geometric mean of the sample sizes.
The values are expressed in milliseconds.
The dotted line is the 45-degree line.

## 7 Concluding remarks

In this paper, we have established a theoretical foundation for timestamp-based lead-lag analysis from a point process perspective.
Within this framework, the method of dobrev2017high for analyzing lead-lag relationships can be interpreted as an estimator of the cross-pair correlation function (CPCF) of the bivariate point process generated by two timestamp series.
Accordingly, the prevailing lead-lag time is naturally defined as the location of the sharpest peak of this CPCF.
We have proposed estimating this lead-lag time by maximizing a kernel density estimator of the CPCF.
Theoretically, our estimator nearly attains the optimal convergence rate for estimating the lead-lag time, provided that the bandwidth of the kernel estimator is chosen appropriately.
To this end, we have introduced a Lepski type bandwidth selection method.
In practice, our procedure addresses several shortcomings of the Dobrevâ€“Schaumburg estimator that arise from its discrete nature.
We have demonstrated the superior performance of our estimator through comprehensive simulation studies and an illustrative empirical analysis.

Finally, we discuss several directions for future research to extend the applicability of our framework.
First, extending the proposed method to non-stationary settings is of practical interest.
Since financial market activity typically varies over time, the stationarity assumption imposed in this study may be restrictive for certain empirical applications. A promising avenue is to adopt the concept of transition-invariant cross-pair correlation function (see, e.g., [shaw2021globally]), which allows time-varying intensities while preserving a stable lead-lag structure that depends only on the time lag. Developing similar methods for such inhomogeneous settings would allow more accurate estimation of the lead-lag time.
Second, in practical applications, timestamp series may be contaminated by observation noise.
In such cases, a noise-robust estimator of the lead-lag parameter is required.
This problem is closely related to deconvolution, which has been studied by [cucala2008intensity] in the context of intensity function estimation for point processes and by [meister2011general] in the context of mode estimation for i.i.d.Â data.
Third, empirical CPCF estimates for high-frequency timestamps often exhibit multiple peaks.
These naturally arise because information transmission between two markets is bidirectional (as documented in [dobrev2017high]) and because transmission speeds differ across market participants.
While this paper focuses solely on the sharpest peak, identifying all â€œsignificantâ€ peaks would also be of interest.
Similar questions have been studied in the classical literature on mode estimation; see [chacon2020modal, Section 3] and references therein.
Fourth, it is also worth investigating how the lead-lag parameter is affected by order types, size, and market conditions such as spread and depth. By treating these attributes as marks, we can analyze the lead-lag relationships between marked point processes.

## Appendix

## Appendix A Proofs

Throughout the discussion, we use the following notation and convention.
For two real numbers x,yx,y, we write xâ‰²yx\lesssim y if xâ‰¤Câ€‹yx\leq Cy for some constant C>0C>0 depending only on r,Î±,Î±0,Î´,b,(Bp)pâ‰¥1,(Bp,q)p,qâ‰¥1,Îµr,\alpha,\alpha\_{0},\delta,b,(B\_{p})\_{p\geq 1},(B\_{p,q})\_{p,q\geq 1},\varepsilon and â€–Kâ€–âˆ\|K\|\_{\infty}.
For a real-valued function ff defined on [âˆ’r1,r1][-r\_{1},r\_{1}], we write â€–fâ€–Lp=â€–fâ€–Lpâ€‹([âˆ’r1,r1])\|f\|\_{L^{p}}=\|f\|\_{L^{p}([-r\_{1},r\_{1}])} for each pâˆˆ[1,âˆ]p\in[1,\infty] for short.
We set g0â‰¡1g\_{0}\equiv 1 whenever [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](i)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i1 "Item [A2](i) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") is assumed.

### A.1 Preliminaries

First, we can easily deduce from the definition of the cross-intensity function ([3.1](https://arxiv.org/html/2601.01871v1#S3.E1 "Equation 3.1 â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) that

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[âˆ«DÃ—â„Ï†â€‹(yâˆ’x)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y)]=Lebâ¡(D)â€‹Î»1â€‹Î»2â€‹âˆ«â„Ï†â€‹(u)â€‹gâ€‹(u)â€‹ğ‘‘u\operatorname{E}\left[\int\_{D\times\mathbb{R}}\varphi(y-x)N\_{1}(dx)N\_{2}(dy)\right]=\operatorname{Leb}(D)\lambda\_{1}\lambda\_{2}\int\_{\mathbb{R}}\varphi(u)g(u)du |  |

for any Borel function Ï†:â„â†’[0,âˆ]\varphi:\mathbb{R}\to[0,\infty] and Dâˆˆâ„¬â€‹(â„)D\in\mathcal{B}(\mathbb{R}).
We refer to this identity as Campbellâ€™s formula in the following.

Next, we prove two auxiliary estimates that play a basic role throughout our discussion.
The first is a moment inequality for a sum of dependent random variables in terms of the Î±\alpha-mixing coefficients ([3.2](https://arxiv.org/html/2601.01871v1#S3.E2 "Equation 3.2 â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) and is a simple consequence of [doukhan1999new, Theorem 2] with a truncation argument.

###### Lemma A.1.

Let (Xj)j=0Tâˆ’1(X\_{j})\_{j=0}^{T-1} be a sequence of random variables such that XjX\_{j} is Ïƒâ€‹(Nâˆ©(IjâŠ•r1))\sigma(N\cap(I\_{j}\oplus r\_{1}))-measurable for all jj.
Suppose also that max0â‰¤jâ‰¤Tâˆ’1â¡Eâ¡[Xjq]<âˆ\max\_{0\leq j\leq T-1}\operatorname{E}[X\_{j}^{q}]<\infty for some even integer qâ‰¥2q\geq 2.
Then, there exists a constant CqC\_{q} depending only on qq such that for any M,Ï„>0M,\tau>0,

|  |  |  |
| --- | --- | --- |
|  | âˆ¥âˆ‘j=0Tâˆ’1(Xjâˆ’E[Xj])âˆ¥qâ‰¤Cq{(TÏ„Mmax0â‰¤jâ‰¤Tâˆ’1E[|Xj|]+TM2âˆ‘m=Ï„âˆÎ±q,qN(m;r1))1/2+T1/qM(âˆ‘m=0âˆ(m+1)qâˆ’2Î±q,qN(m;r1))1/q}+2Tmax0â‰¤jâ‰¤Tâˆ’1âˆ¥Xj1{|Xj|>M}âˆ¥q.\left\|\sum\_{j=0}^{T-1}(X\_{j}-\operatorname{E}[X\_{j}])\right\|\_{q}\leq C\_{q}\left\{\left(T\tau M\max\_{0\leq j\leq T-1}\operatorname{E}[|X\_{j}|]+TM^{2}\sum\_{m=\tau}^{\infty}\alpha^{N}\_{q,q}(m;r\_{1})\right)^{1/2}\right.\\ \left.+T^{1/q}M\left(\sum\_{m=0}^{\infty}(m+1)^{q-2}\alpha^{N}\_{q,q}(m;r\_{1})\right)^{1/q}\right\}+2T\max\_{0\leq j\leq T-1}\left\|X\_{j}1\_{\{|X\_{j}|>M\}}\right\|\_{q}. |  |

###### Proof.

Set Yj:=Xjâ€‹1{|Xj|â‰¤M}Y\_{j}:=X\_{j}1\_{\{|X\_{j}|\leq M\}} for j=0,1,â€¦,Tâˆ’1j=0,1,\dots,T-1.
By the triangle inequality,

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–âˆ‘j=0Tâˆ’1(Xjâˆ’Eâ¡[Xj])âˆ’âˆ‘j=0Tâˆ’1(Yjâˆ’Eâ¡[Yj])â€–qâ‰¤âˆ‘j=0Tâˆ’1â€–Xjâ€‹1{|Xj|>M}âˆ’Eâ¡[Xjâ€‹1{|Xj|>M}]â€–qâ‰¤2â€‹Tâ€‹max0â‰¤jâ‰¤Tâˆ’1â¡â€–Xjâ€‹1{|Xj|>M}â€–q.\begin{split}\left\|\sum\_{j=0}^{T-1}(X\_{j}-\operatorname{E}[X\_{j}])-\sum\_{j=0}^{T-1}(Y\_{j}-\operatorname{E}[Y\_{j}])\right\|\_{q}&\leq\sum\_{j=0}^{T-1}\left\|X\_{j}1\_{\{|X\_{j}|>M\}}-\operatorname{E}[X\_{j}1\_{\{|X\_{j}|>M\}}]\right\|\_{q}\\ &\leq 2T\max\_{0\leq j\leq T-1}\left\|X\_{j}1\_{\{|X\_{j}|>M\}}\right\|\_{q}.\end{split} |  | (A.1) |

Meanwhile, for any integers 0â‰¤j1â‰¤â‹¯â‰¤jpâ‰¤Tâˆ’10\leq j\_{1}\leq\cdots\leq j\_{p}\leq T-1 such that jk+1âˆ’jk=mj\_{k+1}-j\_{k}=m for some 0â‰¤k<p0\leq k<p and mâ‰¥0m\geq 0, we have

|  |  |  |
| --- | --- | --- |
|  | |Covâ¡[Yj1â€‹â‹¯â€‹Yjk,Yjk+1â€‹â‹¯â€‹Yjp]|â‰¤minâ¡{2â€‹Mpâˆ’1â€‹max0â‰¤jâ‰¤Tâˆ’1â¡Eâ¡[|Xj|],â€‰4â€‹Mpâ€‹Î±p,pNâ€‹(m;r1)},\begin{split}|\operatorname{Cov}[Y\_{j\_{1}}\cdots Y\_{j\_{k}},Y\_{j\_{k+1}}\cdots Y\_{j\_{p}}]|\leq\min\left\{2M^{p-1}\max\_{0\leq j\leq T-1}\operatorname{E}[|X\_{j}|],\,4M^{p}\alpha^{N}\_{p,p}(m;r\_{1})\right\},\end{split} |  |

where the second upper bound follows by the covariance inequality under strong mixing (see e.g.Â Lemma 3 in [Doukhan1994, Section 1.2]).
Hence, we can apply [doukhan1999new, Theorem 2] to YjY\_{j} with M=M,Î³=C=1M=M,\gamma=C=1 and

|  |  |  |
| --- | --- | --- |
|  | Î¸m=minâ¡{Mâ€‹max0â‰¤jâ‰¤Tâˆ’1â¡Eâ¡[|Xj|],â€‰4â€‹M2â€‹Î±q,qNâ€‹(m;r1)}\theta\_{m}=\min\left\{M\max\_{0\leq j\leq T-1}\operatorname{E}[|X\_{j}|],\,4M^{2}\alpha^{N}\_{q,q}(m;r\_{1})\right\} |  |

in their notation.
Hence, there exists a constant CqC\_{q} depending only on qq such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[|âˆ‘j=0Tâˆ’1(Yjâˆ’Eâ¡[Yj])|q]\displaystyle\operatorname{E}\left[\left|\sum\_{j=0}^{T-1}(Y\_{j}-\operatorname{E}[Y\_{j}])\right|^{q}\right] | â‰¤Cqâ€‹{(Tâ€‹âˆ‘m=0Tâˆ’1Î¸m)q/2+Mqâˆ’2â€‹Tâ€‹âˆ‘m=0Tâˆ’1(m+1)qâˆ’2â€‹Î¸m}\displaystyle\leq C\_{q}\left\{\left(T\sum\_{m=0}^{T-1}\theta\_{m}\right)^{q/2}+M^{q-2}T\sum\_{m=0}^{T-1}(m+1)^{q-2}\theta\_{m}\right\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Cq{(2TÏ„Mmax0â‰¤jâ‰¤Tâˆ’1E[|Xj|]+4TM2âˆ‘m=Ï„âˆÎ±q,qN(m;r1))q/2\displaystyle\leq C\_{q}\left\{\left(2T\tau M\max\_{0\leq j\leq T-1}\operatorname{E}[|X\_{j}|]+4TM^{2}\sum\_{m=\tau}^{\infty}\alpha^{N}\_{q,q}(m;r\_{1})\right)^{q/2}\right. |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +4TMqâˆ‘m=0âˆ(m+1)qâˆ’2Î±q,qN(m;r1)}.\displaystyle\left.\qquad\qquad+4TM^{q}\sum\_{m=0}^{\infty}(m+1)^{q-2}\alpha^{N}\_{q,q}(m;r\_{1})\right\}. |  |

Combining this with ([A.1](https://arxiv.org/html/2601.01871v1#A1.E1 "Equation A.1 â€£ Proof. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives the desired result.
âˆ

The second is an estimate for the kernel-smoothed CPCF.

###### Lemma A.2.

Suppose that KK is bounded and supported on [âˆ’1,1][-1,1].
For hâˆˆ(0,1]h\in(0,1], define a function fh:â„â†’[0,âˆ)f\_{h}:\mathbb{R}\to[0,\infty) as

|  |  |  |  |
| --- | --- | --- | --- |
|  | fhâ€‹(u)=âˆ«â„Khâ€‹(vâˆ’u)â€‹gâ€‹(v)â€‹ğ‘‘v=âˆ«â„Kâ€‹(t)â€‹gâ€‹(u+hâ€‹t)â€‹ğ‘‘t,uâˆˆâ„.f\_{h}(u)=\int\_{\mathbb{R}}K\_{h}(v-u)g(v)dv=\int\_{\mathbb{R}}K(t)g(u+ht)dt,\qquad u\in\mathbb{R}. |  | (A.2) |

Suppose also that there exist constants Î¸âˆ—âˆˆ[âˆ’r,r]\theta^{\*}\in[-r,r], Î±~âˆˆ(0,1]\tilde{\alpha}\in(0,1], b>1b>1 and a function g0âˆˆL11âˆ’Î±~â€‹([âˆ’r1,r1])g\_{0}\in L^{\frac{1}{1-\tilde{\alpha}}}([-r\_{1},r\_{1}]) such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | gâ€‹(u)â‰¤bâ€‹{g0â€‹(u)+|uâˆ’Î¸âˆ—|Î±~âˆ’1}for allÂ â€‹uâˆˆ[âˆ’r1,r1].g(u)\leq b\left\{g\_{0}(u)+|u-\theta^{\*}|^{\tilde{\alpha}-1}\right\}\quad\text{for all }u\in[-r\_{1},r\_{1}]. |  | (A.3) |

Then we have

|  |  |  |
| --- | --- | --- |
|  | fhâ€‹(u)â‰¤2Î±~â€‹â€–Kâ€–âˆâ€‹bâ€‹(â€–g0â€–L1/(1âˆ’Î±~)+2Î±~)â€‹hÎ±~âˆ’1for allÂ uâˆˆ[âˆ’r,r].f\_{h}(u)\leq 2^{\tilde{\alpha}}\|K\|\_{\infty}b\left(\|g\_{0}\|\_{L^{1/(1-\tilde{\alpha})}}+\frac{2}{\tilde{\alpha}}\right)h^{\tilde{\alpha}-1}\quad\text{for all $u\in[-r,r]$}. |  |

###### Proof.

Fix uâˆˆ[âˆ’r,r]u\in[-r,r].
([A.3](https://arxiv.org/html/2601.01871v1#A1.E3 "Equation A.3 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives

|  |  |  |
| --- | --- | --- |
|  | fh(u)â‰¤b(âˆ«â„Kh(vâˆ’u)g0(v)dv+âˆ«â„K(t)|uâˆ’Î¸âˆ—+ht|Î±~âˆ’1dt)=:b(I+II).\displaystyle f\_{h}(u)\leq b\left(\int\_{\mathbb{R}}K\_{h}(v-u)g\_{0}(v)dv+\int\_{\mathbb{R}}K(t)|u-\theta^{\*}+ht|^{\tilde{\alpha}-1}dt\right)=:b(I+II). |  |

Since KhK\_{h} is supported on [âˆ’h,h]âŠ‚[âˆ’1,1][-h,h]\subset[-1,1], we can rewrite II as

|  |  |  |
| --- | --- | --- |
|  | I=âˆ«âˆ’r1r1Khâ€‹(vâˆ’u)â€‹g0â€‹(v)â€‹ğ‘‘v.I=\int\_{-r\_{1}}^{r\_{1}}K\_{h}(v-u)g\_{0}(v)dv. |  |

Hence, Youngâ€™s convolution inequality gives Iâ‰¤â€–Khâ€–L1/Î±~â€‹â€–g0â€–L1/(1âˆ’Î±~)I\leq\|K\_{h}\|\_{L^{1/\tilde{\alpha}}}\|g\_{0}\|\_{L^{1/(1-\tilde{\alpha})}}.
Since

|  |  |  |
| --- | --- | --- |
|  | â€–Khâ€–L1/Î±~â‰¤(2â€‹hâ€‹â€–Khâ€–âˆ1/Î±~)Î±~â‰¤2Î±~â€‹hÎ±~âˆ’1â€‹â€–Kâ€–âˆ,\|K\_{h}\|\_{L^{1/\tilde{\alpha}}}\leq\left(2h\|K\_{h}\|\_{\infty}^{1/\tilde{\alpha}}\right)^{\tilde{\alpha}}\leq 2^{\tilde{\alpha}}h^{\tilde{\alpha}-1}\|K\|\_{\infty}, |  |

we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | Iâ‰¤2Î±~â€‹hÎ±~âˆ’1â€‹â€–Kâ€–âˆâ€‹â€–g0â€–L1/(1âˆ’Î±~).I\leq 2^{\tilde{\alpha}}h^{\tilde{\alpha}-1}\|K\|\_{\infty}\|g\_{0}\|\_{L^{1/(1-\tilde{\alpha})}}. |  | (A.4) |

Meanwhile, for any câˆˆâ„c\in\mathbb{R}, a straightforward computation shows

|  |  |  |
| --- | --- | --- |
|  | âˆ«âˆ’11|c+hâ€‹t|Î±~âˆ’1â€‹ğ‘‘t={||c+h|Î±~âˆ’|câˆ’h|Î±~|Î±~â€‹hifÂ â€‹|c|>h,|c+h|Î±~+|câˆ’h|Î±~Î±~â€‹hifÂ â€‹|c|â‰¤h.\displaystyle\int\_{-1}^{1}|c+ht|^{\tilde{\alpha}-1}dt=\begin{cases}\displaystyle\frac{\left||c+h|^{\tilde{\alpha}}-|c-h|^{\tilde{\alpha}}\right|}{\tilde{\alpha}h}&\text{if }|c|>h,\\ \displaystyle\frac{|c+h|^{\tilde{\alpha}}+|c-h|^{\tilde{\alpha}}}{\tilde{\alpha}h}&\text{if }|c|\leq h.\end{cases} |  |

Noting that |xÎ±~âˆ’yÎ±~|â‰¤|xâˆ’y|Î±~|x^{\tilde{\alpha}}-y^{\tilde{\alpha}}|\leq|x-y|^{\tilde{\alpha}} for any x,yâ‰¥0x,y\geq 0, we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | supcâˆˆâ„âˆ«âˆ’11|c+hâ€‹t|Î±~âˆ’1â€‹ğ‘‘tâ‰¤21+Î±~Î±~â€‹hÎ±~âˆ’1.\sup\_{c\in\mathbb{R}}\int\_{-1}^{1}|c+ht|^{\tilde{\alpha}-1}dt\leq\frac{2^{1+\tilde{\alpha}}}{\tilde{\alpha}}h^{\tilde{\alpha}-1}. |  | (A.5) |

Therefore, Iâ€‹Iâ‰¤â€–Kâ€–âˆâ€‹21+Î±~Î±~â€‹hÎ±~âˆ’1II\leq\|K\|\_{\infty}\frac{2^{1+\tilde{\alpha}}}{\tilde{\alpha}}h^{\tilde{\alpha}-1} since KK is supported on [âˆ’1,1][-1,1].
Combining this with ([A.4](https://arxiv.org/html/2601.01871v1#A1.E4 "Equation A.4 â€£ Proof. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives the desired result.
âˆ

### A.2 Proof of Proposition [3.1](https://arxiv.org/html/2601.01871v1#S3.Thmproposition1 "Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")

In the following two lemmas, we deal with the numerator and denominator of ğ’³hrelâ€‹(â„“)\mathcal{X}^{\mathrm{rel}}\_{h}(\ell) separately.

###### Lemma A.3.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Suppose that there exist constants Î¸âˆ—âˆˆ[âˆ’r,r]\theta^{\*}\in[-r,r], Î±~âˆˆ(0,1]\tilde{\alpha}\in(0,1], b>1b>1 and a function g0âˆˆL1/(1âˆ’Î±~)â€‹([âˆ’r1,r1])g\_{0}\in L^{1/(1-\tilde{\alpha})}([-r\_{1},r\_{1}]) such that ([A.3](https://arxiv.org/html/2601.01871v1#A1.E3 "Equation A.3 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
Assume also h=hTâ‰Tâˆ’Î³h=h\_{T}\asymp T^{-\gamma} as Tâ†’âˆT\to\infty for some Î³>0\gamma>0.
Then, for any Îµ>0\varepsilon>0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[maxâ„“âˆˆğ’¢hâ¡|ğ’³hrawâ€‹(â„“)âˆ’Thâ€‹Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]|]=Oâ€‹(1+Tâ€‹hÎ±~âˆ’Îµ).\operatorname{E}\left[\max\_{\ell\in\mathcal{G}\_{h}}\left|\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)-\frac{T}{h}\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]\right|\right]=O\left(1+\sqrt{Th^{\tilde{\alpha}-\varepsilon}}\right). |  | (A.6) |

###### Proof.

Set

|  |  |  |
| --- | --- | --- |
|  | ğ’³h0â€‹(â„“):=âˆ‘k=0T/hâˆ’11{N1â€‹(Ikh)>0,N2â€‹(Ik+â„“h)>0}.\mathcal{X}^{0}\_{h}(\ell):=\sum\_{k=0}^{T/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0,\ N\_{2}(I\_{k+\ell}^{h})>0\}}. |  |

Since

|  |  |  |  |
| --- | --- | --- | --- |
|  | |ğ’³hrawâ€‹(â„“)âˆ’ğ’³h0â€‹(â„“)|\displaystyle|\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)-\mathcal{X}^{0}\_{h}(\ell)| | â‰¤âˆ‘k=0|â„“|âˆ’11{N1â€‹(Ikh)>0}+âˆ‘k=T/hâˆ’|â„“|T/hâˆ’11{N1â€‹(Ikh)>0}\displaystyle\leq\sum\_{k=0}^{|\ell|-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}}+\sum\_{k=T/h-|\ell|}^{T/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤N1â€‹((0,|â„“|â€‹h])+N1â€‹((Tâˆ’|â„“|â€‹h,T]),\displaystyle\leq N\_{1}((0,|\ell|h])+N\_{1}((T-|\ell|h,T]), |  |

we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[maxâ„“âˆˆğ’¢hâ¡|ğ’³hrawâ€‹(â„“)âˆ’ğ’³h0â€‹(â„“)|]â‰¤Eâ¡[N1â€‹((0,r])]+Eâ¡[N1â€‹((Tâˆ’r,T])]=2â€‹Î»1â€‹r=Oâ€‹(1).\operatorname{E}\left[\max\_{\ell\in\mathcal{G}\_{h}}|\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)-\mathcal{X}^{0}\_{h}(\ell)|\right]\leq\operatorname{E}[N\_{1}((0,r])]+\operatorname{E}[N\_{1}((T-r,T])]=2\lambda\_{1}r=O(1). |  | (A.7) |

Also, Eâ¡[ğ’³h0â€‹(â„“)]=(T/h)â€‹Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]=(T/h)\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}] by stationarity.
Therefore, ([A.6](https://arxiv.org/html/2601.01871v1#A1.E6 "Equation A.6 â€£ Lemma A.3. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows once we show

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[maxâ„“âˆˆğ’¢hâ¡|ğ’³h0â€‹(â„“)âˆ’Eâ¡[ğ’³h0â€‹(â„“)]|]=Oâ€‹(Tâ€‹hÎ±~âˆ’Îµ).\operatorname{E}\left[\max\_{\ell\in\mathcal{G}\_{h}}\left|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right|\right]=O\left(\sqrt{Th^{\tilde{\alpha}-\varepsilon}}\right). |  |

For any p>1p>1, Jensenâ€™s inequality gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[maxâ„“âˆˆğ’¢hâ¡|ğ’³h0â€‹(â„“)âˆ’Eâ¡[ğ’³h0â€‹(â„“)]|]\displaystyle\operatorname{E}\left[\max\_{\ell\in\mathcal{G}\_{h}}\left|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right|\right] | â‰¤â€–maxâ„“âˆˆğ’¢hâ¡|ğ’³h0â€‹(â„“)âˆ’Eâ¡[ğ’³h0â€‹(â„“)]|â€–p\displaystyle\leq\left\|\max\_{\ell\in\mathcal{G}\_{h}}\left|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right|\right\|\_{p} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤|ğ’¢h|1/pâ€‹maxâ„“âˆˆğ’¢hâ¡â€–ğ’³h0â€‹(â„“)âˆ’Eâ¡[ğ’³h0â€‹(â„“)]â€–p.\displaystyle\leq|\mathcal{G}\_{h}|^{1/p}\max\_{\ell\in\mathcal{G}\_{h}}\left\|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right\|\_{p}. |  |

Let pp be an even integer such that pâ‰¥4Îµâ€‹(1âˆ§Î³)p\geq\frac{4}{\varepsilon(1\wedge\gamma)}. Then we have |ğ’¢h|1/p=Oâ€‹(hâˆ’Îµ/4)|\mathcal{G}\_{h}|^{1/p}=O(h^{-\varepsilon/4}).
Therefore, it suffices to prove

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡â€–ğ’³h0â€‹(â„“)âˆ’Eâ¡[ğ’³h0â€‹(â„“)]â€–p=Oâ€‹(Tâ€‹hÎ±~âˆ’Îµ/2).\max\_{\ell\in\mathcal{G}\_{h}}\left\|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right\|\_{p}=O\left(\sqrt{Th^{\tilde{\alpha}-\varepsilon/2}}\right). |  | (A.8) |

For each â„“âˆˆğ’¢h\ell\in\mathcal{G}\_{h}, set

|  |  |  |
| --- | --- | --- |
|  | Yjâ€‹(â„“):=âˆ‘k=j/h(j+1)/hâˆ’11{N1â€‹(Ikh)>0,N2â€‹(Ik+â„“h)>0},Y\_{j}(\ell):=\sum\_{k=j/h}^{(j+1)/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0,N\_{2}(I\_{k+\ell}^{h})>0\}}, |  |

so that
ğ’³h0â€‹(â„“)=âˆ‘j=0Tâˆ’1Yjâ€‹(â„“)\mathcal{X}^{0}\_{h}(\ell)=\sum\_{j=0}^{T-1}Y\_{j}(\ell).
Observe that Yjâ€‹(â„“)Y\_{j}(\ell) is Ïƒâ€‹(Nâˆ©(IjâŠ•r))\sigma(N\cap(I\_{j}\oplus r))-measurable.
Also, since

|  |  |  |
| --- | --- | --- |
|  | Yjâ€‹(â„“)â‰¤âˆ‘k=j/h(j+1)/hâˆ’1N1â€‹(Ikh)=N1â€‹(Ij),\displaystyle Y\_{j}(\ell)\leq\sum\_{k=j/h}^{(j+1)/h-1}N\_{1}(I\_{k}^{h})=N\_{1}(I\_{j}), |  |

[[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i) yields

|  |  |  |  |
| --- | --- | --- | --- |
|  | supjâ€–Yjâ€‹(â„“)â€–qâ‰¤â€–N1â€‹(Ij)â€–qâ‰²Î»1\sup\_{j}\|Y\_{j}(\ell)\|\_{q}\leq\|N\_{1}(I\_{j})\|\_{q}\lesssim\lambda\_{1} |  | (A.9) |

for any qâ‰¥1q\geq 1.
Therefore, applying [LemmaÂ A.1](https://arxiv.org/html/2601.01871v1#A1.Thmlemma1 "Lemma A.1. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") to (Yjâ€‹(â„“))j=0Tâˆ’1(Y\_{j}(\ell))\_{j=0}^{T-1} with M=hâˆ’Îµ/4M=h^{-\varepsilon/4} and Ï„=âŒŠhâˆ’Îµ/4âŒ‹\tau=\lfloor h^{-\varepsilon/4}\rfloor gives

|  |  |  |
| --- | --- | --- |
|  | âˆ¥ğ’³h0(â„“)âˆ’E[ğ’³h0(â„“)]âˆ¥pâ‰¤Cp{(Thâˆ’Îµ/2E[Y0(â„“)]+Thâˆ’Îµ/2âˆ‘m=âŒŠhâˆ’Îµ/4âŒ‹âˆÎ±p,pN(m;r1))1/2+T1/phâˆ’Îµ/4(âˆ‘m=0âˆ(m+1)pâˆ’2Î±p,pN(m;r1))1/p}+2Tâˆ¥Y0(â„“)1{Y0â€‹(â„“)>hâˆ’Îµ/4}âˆ¥p,\left\|\mathcal{X}^{0}\_{h}(\ell)-\operatorname{E}[\mathcal{X}^{0}\_{h}(\ell)]\right\|\_{p}\leq C\_{p}\left\{\left(Th^{-\varepsilon/2}\operatorname{E}[Y\_{0}(\ell)]+Th^{-\varepsilon/2}\sum\_{m=\lfloor h^{-\varepsilon/4}\rfloor}^{\infty}\alpha^{N}\_{p,p}(m;r\_{1})\right)^{1/2}\right.\\ \left.+T^{1/p}h^{-\varepsilon/4}\left(\sum\_{m=0}^{\infty}(m+1)^{p-2}\alpha^{N}\_{p,p}(m;r\_{1})\right)^{1/p}\right\}+2T\left\|Y\_{0}(\ell)1\_{\{Y\_{0}(\ell)>h^{-\varepsilon/4}\}}\right\|\_{p}, |  |

where CpC\_{p} is a constant depending only on pp and Î»1\lambda\_{1}.
By [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii),

|  |  |  |
| --- | --- | --- |
|  | âˆ‘m=âŒŠhâˆ’Îµ/4âŒ‹âˆÎ±p,pNâ€‹(m;r1)=Oâ€‹(hÎ±~)andâˆ‘m=0âˆ(m+1)pâˆ’2â€‹Î±p,pNâ€‹(m;r1)=Oâ€‹(1).\displaystyle\sum\_{m=\lfloor h^{-\varepsilon/4}\rfloor}^{\infty}\alpha^{N}\_{p,p}(m;r\_{1})=O(h^{\tilde{\alpha}})\quad\text{and}\quad\sum\_{m=0}^{\infty}(m+1)^{p-2}\alpha^{N}\_{p,p}(m;r\_{1})=O(1). |  |

Also, we have â€–Y0â€‹(â„“)â€‹1{Y0â€‹(â„“)>hâˆ’Îµ/4}â€–pâ‰¤hpâ€‹Îµ/4â€‹(Eâ¡[Y0â€‹(â„“)p2+p])1/p=Oâ€‹(Tâˆ’1)\|Y\_{0}(\ell)1\_{\{Y\_{0}(\ell)>h^{-\varepsilon/4}\}}\|\_{p}\leq h^{p\varepsilon/4}(\operatorname{E}[Y\_{0}(\ell)^{p^{2}+p}])^{1/p}=O(T^{-1}) by ([A.9](https://arxiv.org/html/2601.01871v1#A1.E9 "Equation A.9 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Therefore, ([A.8](https://arxiv.org/html/2601.01871v1#A1.E8 "Equation A.8 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows once we show

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“â¡Eâ¡[Y0â€‹(â„“)]=Oâ€‹(hÎ±~).\max\_{\ell}\operatorname{E}[Y\_{0}(\ell)]=O\left(h^{\tilde{\alpha}}\right). |  | (A.10) |

Observe that

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[Y0â€‹(â„“)]=hâˆ’1â€‹Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]â‰¤hâˆ’1â€‹Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)]\operatorname{E}[Y\_{0}(\ell)]=h^{-1}\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]\leq h^{-1}\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})] |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)]\displaystyle\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})] | =Î»1â€‹Î»2â€‹âˆ«â„21I0hâ€‹(x)â€‹1Iâ„“hâ€‹(x+u)â€‹gâ€‹(u)â€‹ğ‘‘xâ€‹ğ‘‘u\displaystyle=\lambda\_{1}\lambda\_{2}\int\_{\mathbb{R}^{2}}1\_{I\_{0}^{h}}(x)1\_{I\_{\ell}^{h}}(x+u)g(u)dxdu |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =Î»1â€‹Î»2â€‹h2â€‹âˆ«â„Khtriâ€‹(uâˆ’â„“â€‹h)â€‹gâ€‹(u)â€‹ğ‘‘u.\displaystyle=\lambda\_{1}\lambda\_{2}h^{2}\int\_{\mathbb{R}}K^{\mathrm{tri}}\_{h}(u-\ell h)g(u)du. |  | (A.11) |

Therefore, ([A.10](https://arxiv.org/html/2601.01871v1#A1.E10 "Equation A.10 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows from [LemmaÂ A.2](https://arxiv.org/html/2601.01871v1#A1.Thmlemma2 "Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").
âˆ

###### Lemma A.4.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"). Then,

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|1Tâ€‹âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N1â€‹(Ikh)>0}âˆ’Pâ¡(N1â€‹(I0h)>0)h|=Opâ€‹(1T),maxâ„“âˆˆğ’¢hâ¡|1Tâ€‹âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N2â€‹(Ik+â„“h)>0}âˆ’Pâ¡(N2â€‹(I0h)>0)h|=Opâ€‹(1T)\begin{split}&\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{1}{T}\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{1}(I\_{k}^{h})>0\}}-\frac{\operatorname{P}(N\_{1}(I\_{0}^{h})>0)}{h}\right|=O\_{p}\left(\frac{1}{\sqrt{T}}\right),\\ &\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{1}{T}\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{2}(I\_{k+\ell}^{h})>0\}}-\frac{\operatorname{P}(N\_{2}(I\_{0}^{h})>0)}{h}\right|=O\_{p}\left(\frac{1}{\sqrt{T}}\right)\end{split} |  | (A.12) |

and

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|1Tâ€‹minâ¡{âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N1â€‹(Ikh)>0},âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N2â€‹(Ik+â„“h)>0}}âˆ’Î»1âˆ§Î»2|â†’p0\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{1}{T}\min\left\{\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{1}(I\_{k}^{h})>0\}},\ \sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{2}(I\_{k+\ell}^{h})>0\}}\right\}-\lambda\_{1}\wedge\lambda\_{2}\right|\to^{p}0 |  | (A.13) |

as Tâ†’âˆT\to\infty.

###### Proof.

([A.13](https://arxiv.org/html/2601.01871v1#A1.E13 "Equation A.13 â€£ Lemma A.4. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows from (LABEL:ds-denom1) and the definition of intensity (cf.Â Eq.(3.3.4) of [daley2006introduction]), so it remains to prove (LABEL:ds-denom1).
We only prove the first equation of (LABEL:ds-denom1) because the second can be shown by almost the same argument.

First, the same argument as in the proof of ([A.7](https://arxiv.org/html/2601.01871v1#A1.E7 "Equation A.7 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[maxâ„“âˆˆğ’¢hâ¡|âˆ‘k=|â„“|T/hâˆ’1âˆ’|â„“|1{N1â€‹(Ikh)>0}âˆ’âˆ‘k=0T/hâˆ’11{N1â€‹(Ikh)>0}|]=Oâ€‹(1).\displaystyle\operatorname{E}\left[\max\_{\ell\in\mathcal{G}\_{h}}\left|\sum\_{k=|\ell|}^{T/h-1-|\ell|}1\_{\{N\_{1}(I\_{k}^{h})>0\}}-\sum\_{k=0}^{T/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}}\right|\right]=O(1). |  |

Hence it suffices to show

|  |  |  |  |
| --- | --- | --- | --- |
|  | 1Tâ€‹âˆ‘k=0T/hâˆ’11{N1â€‹(Ikh)>0}=Pâ¡(N1â€‹(I0h)>0)h+Opâ€‹(1T).\frac{1}{T}\sum\_{k=0}^{T/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}}=\frac{\operatorname{P}(N\_{1}(I\_{0}^{h})>0)}{h}+O\_{p}\left(\frac{1}{\sqrt{T}}\right). |  | (A.14) |

We rewrite the left hand side as

|  |  |  |
| --- | --- | --- |
|  | 1Tâ€‹âˆ‘k=0T/hâˆ’11{N1â€‹(Ikh)>0}=1Tâ€‹âˆ‘j=0Tâˆ’1Xj,\frac{1}{T}\sum\_{k=0}^{T/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}}=\frac{1}{T}\sum\_{j=0}^{T-1}X\_{j}, |  |

where Xj:=âˆ‘k=j/h(j+1)/hâˆ’11{N1â€‹(Ikh)>0}X\_{j}:=\sum\_{k=j/h}^{(j+1)/h-1}1\_{\{N\_{1}(I\_{k}^{h})>0\}}.
Observe that XjX\_{j} is Ïƒâ€‹(Nâˆ©Ij)\sigma(N\cap I\_{j})-measurable.
Hence,

|  |  |  |
| --- | --- | --- |
|  | Varâ¡[âˆ‘j=0Tâˆ’1Xj]â‰¤âˆ‘j,m=0Tâˆ’1|Covâ¡[Xj,Xj+m]|â‰¤8â€‹âˆ‘j,m=0Tâˆ’1â€–Xjâ€–4â€‹â€–Xmâ€–4â€‹Î±1,1â€‹(m;0)â‰²Tâ€‹â€–X0â€–42,\displaystyle\operatorname{Var}\left[\sum\_{j=0}^{T-1}X\_{j}\right]\leq\sum\_{j,m=0}^{T-1}|\operatorname{Cov}[X\_{j},X\_{j+m}]|\leq 8\sum\_{j,m=0}^{T-1}\|X\_{j}\|\_{4}\|X\_{m}\|\_{4}\sqrt{\alpha\_{1,1}(m;0)}\lesssim T\|X\_{0}\|\_{4}^{2}, |  |

where the second inequality follows by Theorem 3 in [Doukhan1994, Section 1.2] and the third by [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii).
Since |X0|â‰¤N1â€‹(I0)|X\_{0}|\leq N\_{1}(I\_{0}), we obtain

|  |  |  |
| --- | --- | --- |
|  | âˆ‘j=0Tâˆ’1Xj=âˆ‘j=0Tâˆ’1Eâ¡[Xj]+Opâ€‹(T)=Thâ€‹Eâ¡[1{N1â€‹(I0h)>0}]+Opâ€‹(T).\sum\_{j=0}^{T-1}X\_{j}=\sum\_{j=0}^{T-1}\operatorname{E}[X\_{j}]+O\_{p}(\sqrt{T})=\frac{T}{h}\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0\}}]+O\_{p}(\sqrt{T}). |  |

Since Eâ¡[1{N1â€‹(I0h)>0}]=Pâ¡(N1â€‹(I0h)>0)\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0\}}]=\operatorname{P}(N\_{1}(I\_{0}^{h})>0), we obtain ([A.14](https://arxiv.org/html/2601.01871v1#A1.E14 "Equation A.14 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
âˆ

###### Proof of [PropositionÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmproposition1 "Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").

Since gg is bounded, ([A.3](https://arxiv.org/html/2601.01871v1#A1.E3 "Equation A.3 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds for b=supxâˆˆâ„|gâ€‹(x)|b=\sup\_{x\in\mathbb{R}}|g(x)|, Î±~=1\tilde{\alpha}=1 and g0â‰¡0g\_{0}\equiv 0 (with Î¸âˆ—\theta^{\*} arbitrary).
Also, by assumption, Tâ€‹hÎ±~+Îµâ†’âˆTh^{\tilde{\alpha}+\varepsilon}\to\infty as Tâ†’âˆT\to\infty for some Îµ>0\varepsilon>0.
Hence, [LemmaÂ A.3](https://arxiv.org/html/2601.01871v1#A1.Thmlemma3 "Lemma A.3. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|ğ’³hrawâ€‹(â„“)Tâ€‹hâˆ’Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]h2|â†’p0.\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)}{Th}-\frac{\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]}{h^{2}}\right|\to^{p}0. |  | (A.15) |

This particularly gives maxâ„“âˆˆğ’¢hâ¡ğ’³hrawâ€‹(â„“)/Tâ€‹h=Opâ€‹(1)\max\_{\ell\in\mathcal{G}\_{h}}\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)/Th=O\_{p}(1).
Combining this with ([A.13](https://arxiv.org/html/2601.01871v1#A1.E13 "Equation A.13 â€£ Lemma A.4. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives

|  |  |  |
| --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|ğ’³hrelâ€‹(â„“)hâˆ’1Î»1âˆ§Î»2â€‹Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]h2|â†’p0.\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)}{h}-\frac{1}{\lambda\_{1}\wedge\lambda\_{2}}\frac{\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]}{h^{2}}\right|\to^{p}0. |  |

Since Î»1â€‹Î»2/(Î»1âˆ§Î»2)=Î»1âˆ¨Î»2\lambda\_{1}\lambda\_{2}/(\lambda\_{1}\wedge\lambda\_{2})=\lambda\_{1}\vee\lambda\_{2}, we complete the proof once we show

|  |  |  |
| --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]h2âˆ’Î»1â€‹Î»2â€‹âˆ«â„Khtriâ€‹(uâˆ’â„“â€‹h)â€‹gâ€‹(u)â€‹ğ‘‘u|=oâ€‹(1).\displaystyle\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]}{h^{2}}-\lambda\_{1}\lambda\_{2}\int\_{\mathbb{R}}K^{\mathrm{tri}}\_{h}(u-\ell h)g(u)du\right|=o(1). |  |

Observe that

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0\displaystyle 0 | â‰¤Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)]âˆ’Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]\displaystyle\leq\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})]-\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Eâ¡[(N1â€‹(I0h)âˆ’1)+â‹…N2â€‹(Iâ„“h)]+Eâ¡[1{N1â€‹(I0h)>0}â€‹(N2â€‹(Iâ„“h)âˆ’1)+]\displaystyle=\operatorname{E}[(N\_{1}(I\_{0}^{h})-1)\_{+}\cdot N\_{2}(I\_{\ell}^{h})]+\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0\}}(N\_{2}(I\_{\ell}^{h})-1)\_{+}] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Eâ¡[N1â€‹(I0h)â€‹(N1â€‹(I0h)âˆ’1)+â‹…N2â€‹(Iâ„“h)]+Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)â€‹(N2â€‹(Iâ„“h)âˆ’1)+]\displaystyle\leq\operatorname{E}[N\_{1}(I\_{0}^{h})(N\_{1}(I\_{0}^{h})-1)\_{+}\cdot N\_{2}(I\_{\ell}^{h})]+\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})(N\_{2}(I\_{\ell}^{h})-1)\_{+}] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Eâ¡[N1â€‹(I0h)â€‹(N1â€‹(I0h)âˆ’1)â€‹N2â€‹(Iâ„“h)]+Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)â€‹(N2â€‹(Iâ„“h)âˆ’1)].\displaystyle=\operatorname{E}[N\_{1}(I\_{0}^{h})(N\_{1}(I\_{0}^{h})-1)N\_{2}(I\_{\ell}^{h})]+\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})(N\_{2}(I\_{\ell}^{h})-1)]. |  |

Since we assume ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")) for Ï–=1\varpi=1, we obtain

|  |  |  |
| --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)]âˆ’Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]|=oâ€‹(h2).\max\_{\ell\in\mathcal{G}\_{h}}\left|\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})]-\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]\right|=o(h^{2}). |  |

Combining this with ([A.11](https://arxiv.org/html/2601.01871v1#A1.E11 "Equation A.11 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives the desired result.
âˆ

### A.3 Proof of Theorem [3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")

The following lemma summarizes identifiability conditions implied by [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").

###### Lemma A.5.

Assume [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") and define the function fhf\_{h} as in ([A.2](https://arxiv.org/html/2601.01871v1#A1.E2 "Equation A.2 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).

1. (a)

   Assume [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](i)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i1 "Item [A2](i) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"). Then, for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1A>1 and 0<h0<10<h\_{0}<1 depending only on Î±,b,Î´\alpha,b,\delta such that

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)âˆ’supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)â‰¥hÎ±âˆ’1for allÂ h<h0Â andÂ vâˆˆ[h,2â€‹h].f\_{h}(\theta^{\*}+\sigma v)-\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)\geq h^{\alpha-1}\quad\text{for all $h<h\_{0}$ and $v\in[h,2h]$}. |  | (A.16) |
2. (b)

   Assume [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")[[A2](ii)](https://arxiv.org/html/2601.01871v1#S3.I2.i1.I1.i2 "Item [A2](ii) â€£ Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
   Then, for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1,c>0A>1,c>0 and 0<h0<10<h\_{0}<1 depending only on Î±,Î±0,b,Î´,K\alpha,\alpha\_{0},b,\delta,K such that

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)âˆ’supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)â‰¥câ€‹hÎ±âˆ’1for allÂ h<h0Â andÂ vâˆˆ[0,h].f\_{h}(\theta^{\*}+\sigma v)-\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)\geq ch^{\alpha-1}\quad\text{for all $h<h\_{0}$ and $v\in[0,h]$.} |  | (A.17) |

###### Proof.

[(a)](https://arxiv.org/html/2601.01871v1#A1.I1.i1 "Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") By assumption, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | sup0<Ïƒâ€‹(uâˆ’Î¸âˆ—)<Î´gâ€‹(Î¸âˆ—)âˆ’gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1â‰¤b\sup\_{0<\sigma(u-\theta^{\*})<\delta}\frac{g(\theta^{\*})-g(u)}{|u-\theta^{\*}|^{\alpha-1}}\leq b |  | (A.18) |

for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}.
Also, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | gâ€‹(u)â‰¤gâ€‹(Î¸âˆ—)âˆ’bâˆ’1â€‹minâ¡{1,|uâˆ’Î¸âˆ—|Î±âˆ’1}g(u)\leq g(\theta^{\*})-b^{-1}\min\left\{1,|u-\theta^{\*}|^{\alpha-1}\right\} |  | (A.19) |

for all uâˆˆâ„u\in\mathbb{R}.
Now, for any A>1A>1, we have by [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") and ([A.19](https://arxiv.org/html/2601.01871v1#A1.E19 "Equation A.19 â€£ Proof. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"))

|  |  |  |  |
| --- | --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)\displaystyle\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u) | â‰¤gâ€‹(Î¸âˆ—)âˆ’bâˆ’1â€‹supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hâˆ«âˆ’11Kâ€‹(t)â€‹minâ¡{1,|uâˆ’Î¸âˆ—+hâ€‹t|Î±âˆ’1}â€‹ğ‘‘t\displaystyle\leq g(\theta^{\*})-b^{-1}\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}\int\_{-1}^{1}K(t)\min\left\{1,|u-\theta^{\*}+ht|^{\alpha-1}\right\}dt |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤gâ€‹(Î¸âˆ—)âˆ’bâˆ’1â€‹minâ¡{1,(Aâˆ’1)Î±âˆ’1â€‹hÎ±âˆ’1}.\displaystyle\leq g(\theta^{\*})-b^{-1}\min\left\{1,(A-1)^{\alpha-1}h^{\alpha-1}\right\}. |  |

Meanwhile, by ([A.18](https://arxiv.org/html/2601.01871v1#A1.E18 "Equation A.18 â€£ Proof. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")), we have for all h<Î´/3h<\delta/3 and vâˆˆ[h,2â€‹h]v\in[h,2h],

|  |  |  |
| --- | --- | --- |
|  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)â‰¥gâ€‹(Î¸âˆ—)âˆ’bâ€‹âˆ«âˆ’11Kâ€‹(t)â€‹|Ïƒâ€‹v+hâ€‹t|Î±âˆ’1â€‹ğ‘‘tâ‰¥gâ€‹(Î¸âˆ—)âˆ’bâ€‹(3â€‹h)Î±âˆ’1.\displaystyle f\_{h}(\theta^{\*}+\sigma v)\geq g(\theta^{\*})-b\int\_{-1}^{1}K(t)|\sigma v+ht|^{\alpha-1}dt\geq g(\theta^{\*})-b(3h)^{\alpha-1}. |  |

Combining these estimates gives

|  |  |  |
| --- | --- | --- |
|  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)âˆ’supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)â‰¥bâˆ’1â€‹minâ¡{1,(Aâˆ’1)Î±âˆ’1â€‹hÎ±âˆ’1}âˆ’bâ€‹(3â€‹h)Î±âˆ’1.\displaystyle f\_{h}(\theta^{\*}+\sigma v)-\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)\geq b^{-1}\min\left\{1,(A-1)^{\alpha-1}h^{\alpha-1}\right\}-b(3h)^{\alpha-1}. |  |

Therefore, if Aâ‰¥1+(b+3Î±âˆ’1â€‹b2)1/(Î±âˆ’1)A\geq 1+(b+3^{\alpha-1}b^{2})^{1/(\alpha-1)} and h<minâ¡{Î´/3,{bâ€‹(3Î±âˆ’1â€‹b+1)}âˆ’1/(Î±âˆ’1)}h<\min\{\delta/3,\,\{b(3^{\alpha-1}b+1)\}^{-1/(\alpha-1)}\}, we have ([A.16](https://arxiv.org/html/2601.01871v1#A1.E16 "Equation A.16 â€£ Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).

[(b)](https://arxiv.org/html/2601.01871v1#A1.I1.i2 "Item (b) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") By assumption, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | inf0<Ïƒâ€‹(uâˆ’Î¸âˆ—)<Î´gâ€‹(u)|uâˆ’Î¸âˆ—|Î±âˆ’1â‰¥1b\inf\_{0<\sigma(u-\theta^{\*})<\delta}\frac{g(u)}{|u-\theta^{\*}|^{\alpha-1}}\geq\frac{1}{b} |  | (A.20) |

for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}.
Also, we have inftâˆˆ[âˆ’Î´0,Î´0]Kâ€‹(t)â‰¥Kâ€‹(0)/2>0\inf\_{t\in[-\delta\_{0},\delta\_{0}]}K(t)\geq K(0)/2>0 for some 0<Î´0<10<\delta\_{0}<1 by [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").
Combining this with ([A.20](https://arxiv.org/html/2601.01871v1#A1.E20 "Equation A.20 â€£ Proof. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")), we have for all h<Î´/2h<\delta/2 and vâˆˆ[0,h]v\in[0,h]

|  |  |  |
| --- | --- | --- |
|  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)â‰¥Kâ€‹(0)2â€‹bâ€‹âˆ«0Î´0|v+hâ€‹t|Î±âˆ’1â€‹ğ‘‘tâ‰¥Kâ€‹(0)2â€‹bâ€‹hÎ±âˆ’1â€‹âˆ«0Î´0(1+t)Î±âˆ’1â€‹ğ‘‘tâ‰¥Kâ€‹(0)â€‹Î´04â€‹bâ€‹hÎ±âˆ’1.\displaystyle f\_{h}(\theta^{\*}+\sigma v)\geq\frac{K(0)}{2b}\int\_{0}^{\delta\_{0}}|v+ht|^{\alpha-1}dt\geq\frac{K(0)}{2b}h^{\alpha-1}\int\_{0}^{\delta\_{0}}(1+t)^{\alpha-1}dt\geq\frac{K(0)\delta\_{0}}{4b}h^{\alpha-1}. |  |

Meanwhile, applying ([A.4](https://arxiv.org/html/2601.01871v1#A1.E4 "Equation A.4 â€£ Proof. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) to Î±~=Î±0\tilde{\alpha}=\alpha\_{0} gives

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„Khâ€‹(vâˆ’u)â€‹g0â€‹(v)â€‹ğ‘‘vâ‰¤2Î±0â€‹hÎ±0âˆ’1â€‹â€–Kâ€–âˆâ€‹b.\int\_{\mathbb{R}}K\_{h}(v-u)g\_{0}(v)dv\leq 2^{\alpha\_{0}}h^{\alpha\_{0}-1}\|K\|\_{\infty}b. |  |

Hence, for any A>1A>1, we have by [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[K]](https://arxiv.org/html/2601.01871v1#S4.I1.i1 "Item [K] â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")

|  |  |  |  |
| --- | --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)\displaystyle\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u) | â‰¤bâ€‹â€–Kâ€–âˆâ€‹(2Î±0â€‹hÎ±0âˆ’1â€‹b+supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hâˆ«âˆ’11|uâˆ’Î¸âˆ—+hâ€‹t|Î±âˆ’1â€‹ğ‘‘t)\displaystyle\leq b\|K\|\_{\infty}\left(2^{\alpha\_{0}}h^{\alpha\_{0}-1}b+\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}\int\_{-1}^{1}|u-\theta^{\*}+ht|^{\alpha-1}dt\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤2â€‹bâ€‹â€–Kâ€–âˆâ€‹(bâ€‹hÎ±0âˆ’1+hÎ±âˆ’1(Aâˆ’1)1âˆ’Î±).\displaystyle\leq 2b\|K\|\_{\infty}\left(bh^{\alpha\_{0}-1}+\frac{h^{\alpha-1}}{(A-1)^{1-\alpha}}\right). |  |

Therefore, if AA is sufficiently large such that

|  |  |  |
| --- | --- | --- |
|  | 2â€‹â€–Kâ€–âˆâ€‹b(Aâˆ’1)1âˆ’Î±â‰¤Kâ€‹(0)â€‹Î´08â€‹b,\frac{2\|K\|\_{\infty}b}{(A-1)^{1-\alpha}}\leq\frac{K(0)\delta\_{0}}{8b}, |  |

we have

|  |  |  |
| --- | --- | --- |
|  | fhâ€‹(Î¸âˆ—+Ïƒâ€‹v)âˆ’supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)â‰¥Kâ€‹(0)â€‹Î´08â€‹bâ€‹hÎ±âˆ’1âˆ’2â€‹b2â€‹â€–Kâ€–âˆâ€‹hÎ±0âˆ’1.\displaystyle f\_{h}(\theta^{\*}+\sigma v)-\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)\geq\frac{K(0)\delta\_{0}}{8b}h^{\alpha-1}-2b^{2}\|K\|\_{\infty}h^{\alpha\_{0}-1}. |  |

Consequently, ([A.17](https://arxiv.org/html/2601.01871v1#A1.E17 "Equation A.17 â€£ Item (b) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds if

|  |  |  |
| --- | --- | --- |
|  | h0â‰¤minâ¡{Î´2,(Kâ€‹(0)â€‹Î´032â€‹â€–Kâ€–âˆâ€‹b3)1/(Î±0âˆ’Î±)}andcâ‰¤Kâ€‹(0)â€‹Î´016â€‹b.h\_{0}\leq\min\left\{\frac{\delta}{2},\ \left(\frac{K(0)\delta\_{0}}{32\|K\|\_{\infty}b^{3}}\right)^{1/(\alpha\_{0}-\alpha)}\right\}\quad\text{and}\quad c\leq\frac{K(0)\delta\_{0}}{16b}. |  |

This completes the proof.
âˆ

###### Proof of [TheoremÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmtheorem1 "Theorem 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").

Observe that ([A.3](https://arxiv.org/html/2601.01871v1#A1.E3 "Equation A.3 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds for Î±~=Î±âˆ§1\tilde{\alpha}=\alpha\wedge 1 under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Hence, [LemmaÂ A.3](https://arxiv.org/html/2601.01871v1#A1.Thmlemma3 "Lemma A.3. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") gives

|  |  |  |
| --- | --- | --- |
|  | h1âˆ’Î±â€‹maxâ„“âˆˆğ’¢hâ¡|ğ’³hrawâ€‹(â„“)Tâ€‹hâˆ’Eâ€‹[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]h2|=Oâ€‹(hÎ±T+1Tâ€‹hÎ²Î±+Îµ)for anyÂ â€‹Îµ>0,h^{1-\alpha}\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)}{Th}-\frac{E[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]}{h^{2}}\right|=O\left(\frac{h^{\alpha}}{T}+\frac{1}{\sqrt{Th^{\beta\_{\alpha}+\varepsilon}}}\right)\quad\text{for any }\varepsilon>0, |  |

where we used the identity 2â€‹Î±âˆ’Î±âˆ§1=Î²Î±2\alpha-\alpha\wedge 1=\beta\_{\alpha}.
Also, by the proof of [PropositionÂ 3.1](https://arxiv.org/html/2601.01871v1#S3.Thmproposition1 "Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and ([3.4](https://arxiv.org/html/2601.01871v1#S3.E4 "Equation 3.4 â€£ Proposition 3.1. â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")),

|  |  |  |
| --- | --- | --- |
|  | maxâ„“âˆˆğ’¢hâ¡|Eâ¡[N1â€‹(I0h)â€‹N2â€‹(Iâ„“h)]âˆ’Eâ¡[1{N1â€‹(I0h)>0,N2â€‹(Iâ„“h)>0}]|h2=oâ€‹(hÎ±âˆ’1).\max\_{\ell\in\mathcal{G}\_{h}}\frac{\left|\operatorname{E}[N\_{1}(I\_{0}^{h})N\_{2}(I\_{\ell}^{h})]-\operatorname{E}[1\_{\{N\_{1}(I\_{0}^{h})>0,N\_{2}(I\_{\ell}^{h})>0\}}]\right|}{h^{2}}=o(h^{\alpha-1}). |  |

Now, define the function fhf\_{h} in ([A.2](https://arxiv.org/html/2601.01871v1#A1.E2 "Equation A.2 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) with K=KtriK=K^{\mathrm{tri}}.
Recall that hâ‰Tâˆ’Î³h\asymp T^{-\gamma} with 0<Î³<1/Î²Î±0<\gamma<1/\beta\_{\alpha}.
Therefore, combining the above two equations with ([A.11](https://arxiv.org/html/2601.01871v1#A1.E11 "Equation A.11 â€£ Proof. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")), we obtain

|  |  |  |
| --- | --- | --- |
|  | h1âˆ’Î±â€‹maxâ„“âˆˆğ’¢hâ¡|ğ’³hrawâ€‹(â„“)Tâ€‹hâˆ’Î»1â€‹Î»2â€‹fhâ€‹(â„“â€‹h)|â†’p0.h^{1-\alpha}\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)}{Th}-\lambda\_{1}\lambda\_{2}f\_{h}(\ell h)\right|\to^{p}0. |  |

Combining this with [LemmaÂ A.2](https://arxiv.org/html/2601.01871v1#A1.Thmlemma2 "Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") particularly gives maxâ„“âˆˆğ’¢hâ¡ğ’³hrawâ€‹(â„“)/Tâ€‹h=Opâ€‹(hÎ±~âˆ’1)\max\_{\ell\in\mathcal{G}\_{h}}\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)/Th=O\_{p}(h^{\tilde{\alpha}-1}).
Hence, by [LemmaÂ A.4](https://arxiv.org/html/2601.01871v1#A1.Thmlemma4 "Lemma A.4. â€£ A.2 Proof of Proposition 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"),

|  |  |  |
| --- | --- | --- |
|  | h1âˆ’Î±â€‹maxâ„“âˆˆğ’¢hâ¡|Pâ¡(N1â€‹(I0h)>0)âˆ§Pâ¡(N2â€‹(I0h)>0)h2â€‹ğ’³hrelâ€‹(â„“)âˆ’ğ’³hrawâ€‹(â„“)Tâ€‹h|â†’p0.h^{1-\alpha}\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\operatorname{P}(N\_{1}(I\_{0}^{h})>0)\wedge\operatorname{P}(N\_{2}(I\_{0}^{h})>0)}{h^{2}}\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)-\frac{\mathcal{X}^{\mathrm{raw}}\_{h}(\ell)}{Th}\right|\to^{p}0. |  |

Therefore, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | h1âˆ’Î±â€‹Î”Â¯Tâ†’p0asTâ†’âˆ,h^{1-\alpha}\bar{\Delta}\_{T}\to^{p}0\qquad\text{as}\quad T\to\infty, |  | (A.21) |

where

|  |  |  |
| --- | --- | --- |
|  | Î”Â¯T:=maxâ„“âˆˆğ’¢hâ¡|Pâ¡(N1â€‹(I0h)>0)âˆ§Pâ¡(N2â€‹(I0h)>0)Î»1â€‹Î»2â€‹h2â€‹ğ’³hrelâ€‹(â„“)âˆ’fhâ€‹(â„“â€‹h)|.\bar{\Delta}\_{T}:=\max\_{\ell\in\mathcal{G}\_{h}}\left|\frac{\operatorname{P}(N\_{1}(I\_{0}^{h})>0)\wedge\operatorname{P}(N\_{2}(I\_{0}^{h})>0)}{\lambda\_{1}\lambda\_{2}h^{2}}\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)-f\_{h}(\ell h)\right|. |  |

We turn to the main body of the proof.
Consider the case Î±>1\alpha>1.
Then, by [LemmaÂ A.5](https://arxiv.org/html/2601.01871v1#A1.Thmlemma5 "Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1A>1 and 0<h0<10<h\_{0}<1 depending only on Î±,b,Î´\alpha,b,\delta such that ([A.16](https://arxiv.org/html/2601.01871v1#A1.E16 "Equation A.16 â€£ Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
We can find an integer â„“âˆ—\ell^{\*} such that â„“âˆ—â€‹h=Î¸âˆ—+Ïƒâ€‹v\ell^{\*}h=\theta^{\*}+\sigma v for some vâˆˆ[h,2â€‹h]v\in[h,2h].
Observe that â„“âˆ—âˆˆğ’¢h\ell^{\*}\in\mathcal{G}\_{h} for sufficiently small hh.
Then, since Î¸^hDâ€‹S\hat{\theta}\_{h}^{DS} is a maximizer of ğ’¢hâˆ‹â„“â†¦ğ’³hrelâ€‹(â„“)âˆˆ[0,âˆ)\mathcal{G}\_{h}\ni\ell\mapsto\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)\in[0,\infty), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(|Î¸^hDâ€‹Sâˆ’Î¸âˆ—|>(A+4)â€‹h)\displaystyle\operatorname{P}\left(|\hat{\theta}\_{h}^{DS}-\theta^{\*}|>(A+4)h\right) | â‰¤Pâ¡(|Î¸^hDâ€‹Sâˆ’â„“âˆ—â€‹h|>(A+2)â€‹h)\displaystyle\leq\operatorname{P}\left(|\hat{\theta}\_{h}^{DS}-\ell^{\*}h|>(A+2)h\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(ğ’³hrelâ€‹(â„“âˆ—)â‰¤maxâ„“âˆˆğ’¢h:|â„“âˆ’â„“âˆ—|>A+2â¡ğ’³hrelâ€‹(â„“))\displaystyle\leq\operatorname{P}\left(\mathcal{X}^{\mathrm{rel}}\_{h}(\ell^{\*})\leq\max\_{\ell\in\mathcal{G}\_{h}:|\ell-\ell^{\*}|>A+2}\mathcal{X}^{\mathrm{rel}}\_{h}(\ell)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(fhâ€‹(â„“âˆ—â€‹h)â‰¤maxâ„“âˆˆğ’¢h:|â„“âˆ’â„“âˆ—|>A+2â¡fhâ€‹(â„“â€‹h)+2â€‹Î”Â¯T)\displaystyle\leq\operatorname{P}\left(f\_{h}(\ell^{\*}h)\leq\max\_{\ell\in\mathcal{G}\_{h}:|\ell-\ell^{\*}|>A+2}f\_{h}(\ell h)+2\bar{\Delta}\_{T}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(fhâ€‹(â„“âˆ—â€‹h)â‰¤maxâ„“âˆˆğ’¢h:|â„“â€‹hâˆ’Î¸âˆ—|>Aâ€‹hâ¡fhâ€‹(â„“â€‹h)+2â€‹Î”Â¯T).\displaystyle\leq\operatorname{P}\left(f\_{h}(\ell^{\*}h)\leq\max\_{\ell\in\mathcal{G}\_{h}:|\ell h-\theta^{\*}|>Ah}f\_{h}(\ell h)+2\bar{\Delta}\_{T}\right). |  |

Hence, ([A.16](https://arxiv.org/html/2601.01871v1#A1.E16 "Equation A.16 â€£ Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives Pâ¡(|Î¸^hDâ€‹Sâˆ’Î¸âˆ—|>(A+4)â€‹h)â‰¤Pâ¡(2â€‹Î”Â¯Tâ‰¥hÎ±âˆ’1)\operatorname{P}(|\hat{\theta}\_{h}^{DS}-\theta^{\*}|>(A+4)h)\leq\operatorname{P}\left(2\bar{\Delta}\_{T}\geq h^{\alpha-1}\right).
Thus we obtain the desired result by ([A.21](https://arxiv.org/html/2601.01871v1#A1.E21 "Equation A.21 â€£ Proof of Theorem 3.1. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).

Next, consider the case Î±<1\alpha<1.
Then, by [LemmaÂ A.5](https://arxiv.org/html/2601.01871v1#A1.Thmlemma5 "Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1,c>0A>1,c>0 and 0<h0<10<h\_{0}<1 depending only on Î±,Î±0,b,Î´\alpha,\alpha\_{0},b,\delta such that ([A.17](https://arxiv.org/html/2601.01871v1#A1.E17 "Equation A.17 â€£ Item (b) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
We can find an integer â„“âˆ—\ell^{\*} such that â„“âˆ—â€‹h=Î¸âˆ—+Ïƒâ€‹v\ell^{\*}h=\theta^{\*}+\sigma v for some vâˆˆ[0,h]v\in[0,h].
Then, a similar argument to the above shows Pâ¡(|Î¸^hDâ€‹Sâˆ’Î¸âˆ—|>(A+2)â€‹h)â†’0\operatorname{P}(|\hat{\theta}\_{h}^{DS}-\theta^{\*}|>(A+2)h)\to 0 as Tâ†’âˆT\to\infty.
âˆ

### A.4 Proof of Theorem [4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")

Set Î±~:=Î±âˆ§1\tilde{\alpha}:=\alpha\wedge 1.
Note that Î±~â‰¤Î²Î±\tilde{\alpha}\leq\beta\_{\alpha}.
Since the left hand side of ([4.1](https://arxiv.org/html/2601.01871v1#S4.E1 "Equation 4.1 â€£ Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")) is always bounded by 1, we may assume Tâ€‹hÎ²Î±+Îµâ‰¥1Th^{\beta\_{\alpha}+\varepsilon}\geq 1 without loss of generality.

Let us consider the following statistic:

|  |  |  |
| --- | --- | --- |
|  | g~hâ€‹(u):=n1Tâ€‹Î»1â€‹n2Tâ€‹Î»2â€‹g^hâ€‹(u)=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«(0,T]2Khâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y),uâˆˆâ„.\tilde{g}\_{h}(u):=\frac{n\_{1}}{T\lambda\_{1}}\frac{n\_{2}}{T\lambda\_{2}}\hat{g}\_{h}(u)=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{(0,T]^{2}}K\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy),\quad u\in\mathbb{R}. |  |

Observe that Î¸^h\hat{\theta}\_{h} is also a maximizer of g~hâ€‹(u)\tilde{g}\_{h}(u) over uâˆˆ[âˆ’r,r]u\in[-r,r].
Also, we can rewrite it as g~hâ€‹(u)=âˆ‘j=0Tâˆ’1Xj0â€‹(u)\tilde{g}\_{h}(u)=\sum\_{j=0}^{T-1}X^{0}\_{j}(u), where

|  |  |  |
| --- | --- | --- |
|  | Xj0â€‹(u)=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—(0,T]Khâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y).X^{0}\_{j}(u)=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times(0,T]}K\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy). |  |

We introduce an edge-corrected version of Xj0â€‹(u)X\_{j}^{0}(u) as

|  |  |  |
| --- | --- | --- |
|  | Xjâ€‹(u)=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—â„Khâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y).X\_{j}(u)=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times\mathbb{R}}K\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy). |  |

It is not difficult to see that (Xjâ€‹(u))jâˆˆâ„¤(X\_{j}(u))\_{j\in\mathbb{Z}} is stationary.
We first show that replacing Xj0â€‹(u)X\_{j}^{0}(u) by Xjâ€‹(u)X\_{j}(u) does not matter for our argument.

###### Lemma A.6.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Assume also that KK is bounded and supported on [âˆ’1,1][-1,1].
Then,

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[supuâˆˆ[âˆ’r,r]|g~hâ€‹(u)âˆ’âˆ‘j=0Tâˆ’1Xjâ€‹(u)|]â‰²1Tâ€‹h.\operatorname{E}\left[\sup\_{u\in[-r,r]}\left|\tilde{g}\_{h}(u)-\sum\_{j=0}^{T-1}X\_{j}(u)\right|\right]\lesssim\frac{1}{Th}. |  |

###### Proof.

Since KhK\_{h} is supported on [âˆ’h,h]âŠ‚[âˆ’1,1][-h,h]\subset[-1,1], Xj0â€‹(u)=Xjâ€‹(u)X\_{j}^{0}(u)=X\_{j}(u) if r1<j<Tâˆ’1âˆ’r1r\_{1}<j<T-1-r\_{1} for any uâˆˆ[âˆ’r,r]u\in[-r,r].
Therefore,

|  |  |  |
| --- | --- | --- |
|  | |g~hâ€‹(u)âˆ’âˆ‘j=0Tâˆ’1Xjâ€‹(u)|â‰¤â€–Kâ€–âˆTâ€‹hâ€‹Î»1â€‹Î»2â€‹âˆ‘0â‰¤jâ‰¤r1â€‹Â orÂ â€‹Tâˆ’1âˆ’r1â‰¤jâ‰¤Tâˆ’1N1â€‹(Ij)â€‹N2â€‹(IjâŠ•r1).\displaystyle\left|\tilde{g}\_{h}(u)-\sum\_{j=0}^{T-1}X\_{j}(u)\right|\leq\frac{\|K\|\_{\infty}}{Th\lambda\_{1}\lambda\_{2}}\sum\_{0\leq j\leq r\_{1}\text{ or }T-1-r\_{1}\leq j\leq T-1}N\_{1}(I\_{j})N\_{2}(I\_{j}\oplus r\_{1}). |  |

Hence, the desired result follows by [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i).
âˆ

Next, set

|  |  |  |
| --- | --- | --- |
|  | Î”Tâ€‹(u):=âˆ‘j=0Tâˆ’1{Xjâ€‹(u)âˆ’Eâ¡[Xjâ€‹(u)]},uâˆˆ[âˆ’r,r].\Delta\_{T}(u):=\sum\_{j=0}^{T-1}\left\{X\_{j}(u)-\operatorname{E}[X\_{j}(u)]\right\},\qquad u\in[-r,r]. |  |

Our next aim is to establish a sufficiently fast convergence of supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|\sup\_{u\in[-r,r]}|\Delta\_{T}(u)|.
We first develop pointwise moment bounds.

###### Lemma A.7.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Assume also that KK is bounded and supported on [âˆ’1,1][-1,1].
If an even integer p>2p>2 satisfies Tâ€‹hpâ€‹Îµ/4â‰¤1Th^{p\varepsilon/4}\leq 1, then

|  |  |  |
| --- | --- | --- |
|  | h1âˆ’Î±~â€‹supuâˆˆ[âˆ’r,r]â€–Î”Tâ€‹(u)â€–pâ‰²CpTâ€‹hÎ±~+Îµ/2,\displaystyle h^{1-\tilde{\alpha}}\sup\_{u\in[-r,r]}\left\|\Delta\_{T}(u)\right\|\_{p}\lesssim\frac{C\_{p}}{\sqrt{Th^{\tilde{\alpha}+\varepsilon/2}}}, |  |

where CpC\_{p} is a constant depending only on pp.

###### Proof.

Fix uâˆˆ[âˆ’r,r]u\in[-r,r].
Since KhK\_{h} is supported on [âˆ’h,h]âŠ‚[âˆ’1,1][-h,h]\subset[-1,1], we can rewrite Xjâ€‹(u)X\_{j}(u) as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Xjâ€‹(u)=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—(IjâŠ•r1)Khâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y).X\_{j}(u)=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times(I\_{j}\oplus r\_{1})}K\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy). |  | (A.22) |

Hence, Xjâ€‹(u)X\_{j}(u) is Ïƒâ€‹(Nâˆ©(IjâŠ•r1))\sigma(N\cap(I\_{j}\oplus r\_{1}))-measurable for every jj.
Also, since â€–Khâ€–âˆâ‰¤hâˆ’1â€‹â€–Kâ€–âˆ\|K\_{h}\|\_{\infty}\leq h^{-1}\|K\|\_{\infty}, we obtain for any q>1q>1

|  |  |  |  |
| --- | --- | --- | --- |
|  | max0â‰¤jâ‰¤Tâˆ’1â¡â€–Xjâ€‹(u)â€–q=â€–X0â€‹(u)â€–qâ‰²1Tâ€‹hâ€‹Î»1â€‹Î»2â€‹â€–N1â€‹(I0)â€‹N2â€‹(I0âŠ•r1)â€–qâ‰²1Tâ€‹h.\max\_{0\leq j\leq T-1}\|X\_{j}(u)\|\_{q}=\|X\_{0}(u)\|\_{q}\lesssim\frac{1}{Th\lambda\_{1}\lambda\_{2}}\|N\_{1}(I\_{0})N\_{2}(I\_{0}\oplus r\_{1})\|\_{q}\lesssim\frac{1}{Th}. |  | (A.23) |

Therefore, applying [LemmaÂ A.1](https://arxiv.org/html/2601.01871v1#A1.Thmlemma1 "Lemma A.1. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") to (Xjâ€‹(u))j=0Tâˆ’1(X\_{j}(u))\_{j=0}^{T-1} with M=hâˆ’Îµ/4/(Tâ€‹h)M=h^{-\varepsilon/4}/(Th) and Ï„=âŒŠhâˆ’Îµ/4âŒ‹\tau=\lfloor h^{-\varepsilon/4}\rfloor gives

|  |  |  |
| --- | --- | --- |
|  | âˆ¥Î”T(u)âˆ¥pâ‰¤Cp{(hâˆ’Îµ/2hE[|X0(u)|]+hâˆ’Îµ/2Tâ€‹h2âˆ‘m=âŒŠhâˆ’Îµ/4âŒ‹âˆÎ±p,pN(m;r1))1/2+T1/pâ€‹hâˆ’Îµ/4Tâ€‹h(âˆ‘m=0âˆ(m+1)pâˆ’2Î±p,pN(m;r1))1/p}+2Tâˆ¥X0(u)1{X0â€‹(u)>hâˆ’Îµ/4/(Tâ€‹h)}âˆ¥p,\left\|\Delta\_{T}(u)\right\|\_{p}\leq C\_{p}\left\{\left(\frac{h^{-\varepsilon/2}}{h}\operatorname{E}[|X\_{0}(u)|]+\frac{h^{-\varepsilon/2}}{Th^{2}}\sum\_{m=\lfloor h^{-\varepsilon/4}\rfloor}^{\infty}\alpha^{N}\_{p,p}(m;r\_{1})\right)^{1/2}\right.\\ \left.+\frac{T^{1/p}h^{-\varepsilon/4}}{Th}\left(\sum\_{m=0}^{\infty}(m+1)^{p-2}\alpha^{N}\_{p,p}(m;r\_{1})\right)^{1/p}\right\}+2T\left\|X\_{0}(u)1\_{\{X\_{0}(u)>h^{-\varepsilon/4}/(Th)\}}\right\|\_{p}, |  |

where CpC\_{p} is a constant depending only on pp.
By [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii),

|  |  |  |
| --- | --- | --- |
|  | âˆ‘m=âŒŠhâˆ’Îµ/4âŒ‹âˆÎ±p,pNâ€‹(m;r1)â‰²hÎ±~andâˆ‘m=0âˆ(m+1)pâˆ’2â€‹Î±p,pNâ€‹(m;r1)â‰²1.\displaystyle\sum\_{m=\lfloor h^{-\varepsilon/4}\rfloor}^{\infty}\alpha^{N}\_{p,p}(m;r\_{1})\lesssim h^{\tilde{\alpha}}\quad\text{and}\quad\sum\_{m=0}^{\infty}(m+1)^{p-2}\alpha^{N}\_{p,p}(m;r\_{1})\lesssim 1. |  |

Also, since ([A.3](https://arxiv.org/html/2601.01871v1#A1.E3 "Equation A.3 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes"), Campbellâ€™s formula and [LemmaÂ A.2](https://arxiv.org/html/2601.01871v1#A1.Thmlemma2 "Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") give

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[X0â€‹(u)]=1Tâ€‹âˆ«âˆ’11Kâ€‹(t)â€‹gâ€‹(u+hâ€‹t)â€‹ğ‘‘tâ‰²1Tâ€‹âˆ«âˆ’11(1+|uâˆ’Î¸âˆ—+hâ€‹t|Î±~âˆ’1)â€‹ğ‘‘tâ‰²1Tâ€‹h1âˆ’Î±~.\operatorname{E}[X\_{0}(u)]=\frac{1}{T}\int\_{-1}^{1}K(t)g(u+ht)dt\lesssim\frac{1}{T}\int\_{-1}^{1}\left(1+|u-\theta^{\*}+ht|^{\tilde{\alpha}-1}\right)dt\lesssim\frac{1}{Th^{1-\tilde{\alpha}}}. |  | (A.24) |

Moreover, by ([A.23](https://arxiv.org/html/2601.01871v1#A1.E23 "Equation A.23 â€£ Proof. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")),

|  |  |  |
| --- | --- | --- |
|  | â€–X0â€‹(u)â€‹1{X0â€‹(u)>hâˆ’Îµ/4/(Tâ€‹h)}â€–pâ‰¤(Tâ€‹hhâˆ’Îµ/4)pâ€‹(Eâ¡[X0â€‹(u)p2+p])1/pâ‰²hpâ€‹Îµ/4Tâ€‹h.\displaystyle\left\|X\_{0}(u)1\_{\{X\_{0}(u)>h^{-\varepsilon/4}/(Th)\}}\right\|\_{p}\leq\left(\frac{Th}{h^{-\varepsilon/4}}\right)^{p}(\operatorname{E}[X\_{0}(u)^{p^{2}+p}])^{1/p}\lesssim\frac{h^{p\varepsilon/4}}{Th}. |  |

Since Tâ€‹hpâ€‹Îµ/4â‰¤1Th^{p\varepsilon/4}\leq 1, we obtain

|  |  |  |
| --- | --- | --- |
|  | h1âˆ’Î±~â€‹â€–Î”Tâ€‹(u)â€–pâ‰²Cpâ€‹(1Tâ€‹hÎ±~+Îµ/2+1Tâ€‹hÎ±~+Îµ/2).\displaystyle h^{1-\tilde{\alpha}}\left\|\Delta\_{T}(u)\right\|\_{p}\lesssim C\_{p}\left(\frac{1}{\sqrt{Th^{\tilde{\alpha}+\varepsilon/2}}}+\frac{1}{Th^{\tilde{\alpha}+\varepsilon/2}}\right). |  |

Since we assume Tâ€‹hÎ±~+Îµ/2â‰¥Tâ€‹hÎ²Î±+Îµâ‰¥1Th^{\tilde{\alpha}+\varepsilon/2}\geq Th^{\beta\_{\alpha}+\varepsilon}\geq 1, this gives the desired result.
âˆ

To upgrade [LemmaÂ A.7](https://arxiv.org/html/2601.01871v1#A1.Thmlemma7 "Lemma A.7. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") to a moment bound for supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|\sup\_{u\in[-r,r]}|\Delta\_{T}(u)|, we need the following technical lemma.

###### Lemma A.8.

Let FF be a bounded non-decreasing function on â„\mathbb{R}.
For any h,Ï>0h,\rho>0, there exist finite points âˆ’r=u0â‰¤u1â‰¤â‹¯â‰¤uN=r-r=u\_{0}\leq u\_{1}\leq\dots\leq u\_{N}=r and universal constants C,dâ‰¥1C,d\geq 1 such that Nâ‰¤Câ€‹Ïâˆ’dN\leq C\rho^{-d} and

|  |  |  |  |
| --- | --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]min0â‰¤aâ‰¤Nâˆ’1â€‹âˆ«âˆ’r1r1{Fhâ€‹(vâˆ’ua)âˆ’Fhâ€‹(vâˆ’ua+1)}â€‹gâ€‹(v)â€‹ğ‘‘vâ‰¤2â€‹Ïâ€‹â€–Fâ€–âˆhâ€‹âˆ«âˆ’r1r1gâ€‹(u)â€‹ğ‘‘u.\sup\_{u\in[-r,r]}\min\_{0\leq a\leq N-1}\int\_{-r\_{1}}^{r\_{1}}\left\{F\_{h}(v-u\_{a})-F\_{h}(v-u\_{a+1})\right\}g(v)dv\leq 2\rho\frac{\|F\|\_{\infty}}{h}\int\_{-r\_{1}}^{r\_{1}}g(u)du. |  | (A.25) |

###### Proof.

Without loss of generality, we may assume âˆ«âˆ’r1r1gâ€‹(u)â€‹ğ‘‘u>0\int\_{-r\_{1}}^{r\_{1}}g(u)du>0 since otherwise the asserted claim is trivial.

By the proof of [gine2016mathematical, Proposition 3.6.12], ğ’¢:={Fh(â‹…âˆ’u):uâˆˆ[âˆ’r,r]}\mathcal{G}:=\{F\_{h}(\cdot-u):u\in[-r,r]\} is a VC subgraph class of functions.
Also, ğ’¢\mathcal{G} admits an envelope â€–Fâ€–âˆ/h\|F\|\_{\infty}/h.
Therefore, by [gine2016mathematical, Theorem 3.3.9], there exist finite points âˆ’r=s0<s1<â‹¯<sL=r-r=s\_{0}<s\_{1}<\dots<s\_{L}=r and universal constants C,dâ‰¥1C,d\geq 1 such that Lâ‰¤Câ€‹Ïâˆ’dL\leq C\rho^{-d} and

|  |  |  |  |
| --- | --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]min0â‰¤aâ‰¤Lâ€‹âˆ«â„|Fhâ€‹(vâˆ’u)âˆ’Fhâ€‹(vâˆ’sa)|â€‹Qâ€‹(dâ€‹v)â‰¤Ïâ€‹â€–Fâ€–âˆh,\sup\_{u\in[-r,r]}\min\_{0\leq a\leq L}\int\_{\mathbb{R}}\left|F\_{h}(v-u)-F\_{h}(v-s\_{a})\right|Q(dv)\leq\rho\frac{\|F\|\_{\infty}}{h}, |  | (A.26) |

where QQ is a probability measure on (â„,â„¬â€‹(â„))(\mathbb{R},\mathcal{B}(\mathbb{R})) defined as

|  |  |  |
| --- | --- | --- |
|  | Qâ€‹(A)=âˆ«Aâˆ©[âˆ’r1,r1]gâ€‹(u)â€‹ğ‘‘uâˆ«âˆ’r1r1gâ€‹(u)â€‹ğ‘‘u,Aâˆˆâ„¬â€‹(â„).Q(A)=\frac{\int\_{A\cap[-r\_{1},r\_{1}]}g(u)du}{\int\_{-r\_{1}}^{r\_{1}}g(u)du},\qquad A\in\mathcal{B}(\mathbb{R}). |  |

Next, define a function Ïˆ:â„â†’â„\psi:\mathbb{R}\to\mathbb{R} as

|  |  |  |
| --- | --- | --- |
|  | Ïˆâ€‹(u)=âˆ«âˆ’r1r1Fhâ€‹(vâˆ’u)â€‹gâ€‹(v)â€‹ğ‘‘v=âˆ«â„Fâ€‹(t)â€‹gâ€‹(u+hâ€‹t)â€‹1[âˆ’r1,r1]â€‹(u+hâ€‹t)â€‹ğ‘‘t,uâˆˆâ„.\psi(u)=\int\_{-r\_{1}}^{r\_{1}}F\_{h}(v-u)g(v)dv=\int\_{\mathbb{R}}F(t)g(u+ht)1\_{[-r\_{1},r\_{1}]}(u+ht)dt,\qquad u\in\mathbb{R}. |  |

Then, ([A.26](https://arxiv.org/html/2601.01871v1#A1.E26 "Equation A.26 â€£ Proof. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives

|  |  |  |
| --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]min0â‰¤aâ‰¤Lâ¡|Ïˆâ€‹(u)âˆ’Ïˆâ€‹(sa)|â‰¤Ïâ€‹â€–Fâ€–âˆhâ€‹âˆ«âˆ’r1r1gâ€‹(u)â€‹ğ‘‘u.\sup\_{u\in[-r,r]}\min\_{0\leq a\leq L}|\psi(u)-\psi(s\_{a})|\leq\rho\frac{\|F\|\_{\infty}}{h}\int\_{-r\_{1}}^{r\_{1}}g(u)du. |  |

Also, since gg is non-negative and FF is non-decreasing, Ïˆ\psi is non-increasing.
Moreover, since gâ€‹1[âˆ’r1,r1]âˆˆL1â€‹(â„)g1\_{[-r\_{1},r\_{1}]}\in L^{1}(\mathbb{R}) and FF is bounded, Ïˆ\psi is continuous (see e.g.Â [malliavin1995integration, Lemma 1.8.1]).
Consequently, for every a=0,â€¦,Lâˆ’1a=0,\dots,L-1, there exists a point taâˆˆ[sa,sa+1]t\_{a}\in[s\_{a},s\_{a+1}] such that Ïˆâ€‹(ta)={Ïˆâ€‹(sa)+Ïˆâ€‹(sa+1)}/2\psi(t\_{a})=\{\psi(s\_{a})+\psi(s\_{a+1})\}/2 by the intermediate value theorem.
Observe that Ïˆâ€‹(sa)âˆ’Ïˆâ€‹(ta)=Ïˆâ€‹(ta)âˆ’Ïˆâ€‹(sa+1)={Ïˆâ€‹(sa)âˆ’Ïˆâ€‹(sa+1)}/2\psi(s\_{a})-\psi(t\_{a})=\psi(t\_{a})-\psi(s\_{a+1})=\{\psi(s\_{a})-\psi(s\_{a+1})\}/2.
Moreover, since Ïˆ\psi is non-increasing,

|  |  |  |
| --- | --- | --- |
|  | min0â‰¤aâ€²â‰¤Lâ¡|Ïˆâ€‹(ta)âˆ’Ïˆâ€‹(saâ€²)|={Ïˆâ€‹(sa)âˆ’Ïˆâ€‹(ta)}âˆ§{Ïˆâ€‹(ta)âˆ’Ïˆâ€‹(sa+1)}=Ïˆâ€‹(sa)âˆ’Ïˆâ€‹(sa+1)2.\min\_{0\leq a^{\prime}\leq L}|\psi(t\_{a})-\psi(s\_{a^{\prime}})|=\{\psi(s\_{a})-\psi(t\_{a})\}\wedge\{\psi(t\_{a})-\psi(s\_{a+1})\}=\frac{\psi(s\_{a})-\psi(s\_{a+1})}{2}. |  |

Therefore, we obtain the desired points by setting u2â€‹a=sau\_{2a}=s\_{a} and u2â€‹a+1=tau\_{2a+1}=t\_{a} for a=0,â€¦,Lâˆ’1a=0,\dots,L-1 and u2â€‹L=sLu\_{2L}=s\_{L}.
âˆ

Combining the previous two lemmas, we can derive the following uniform moment bound for Î”Tâ€‹(u)\Delta\_{T}(u):

###### Lemma A.9.

Assume [[A1]](https://arxiv.org/html/2601.01871v1#S3.I1.i1 "Item [A1] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes") and [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Assume also that KK is of bounded variation and supported on [âˆ’1,1][-1,1].
If hâ‰¤minâ¡{Tâˆ’Î·,â€‰1/2}h\leq\min\{T^{-\eta},\,1/2\} for some Î·>0\eta>0, then

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[h1âˆ’Î±~â€‹supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|]â‰²CÎ·Tâ€‹hÎ±~+Îµ,\displaystyle\operatorname{E}\left[h^{1-\tilde{\alpha}}\sup\_{u\in[-r,r]}\left|\Delta\_{T}(u)\right|\right]\lesssim\frac{C\_{\eta}}{\sqrt{Th^{\tilde{\alpha}+\varepsilon}}}, |  |

where CÎ·C\_{\eta} depends only on Î·\eta.

###### Proof.

Since KK is of bounded variation and supported on [âˆ’1,1][-1,1], there exist two non-decreasing functions F1,F2F\_{1},F\_{2} on â„\mathbb{R} such that K=(F1âˆ’F2)â€‹1[âˆ’1,1]K=(F\_{1}-F\_{2})1\_{[-1,1]} and |F1|âˆ¨|F2|â‰¤â€–Kâ€–âˆ|F\_{1}|\vee|F\_{2}|\leq\|K\|\_{\infty}.
Therefore, without loss of generality, we may assume that KK is of the form K=Fâ€‹1[âˆ’1,1]K=F1\_{[-1,1]} with FF a non-decreasing function on â„\mathbb{R}.
In the remainder of the proof, we proceed in two steps.

##### Step 1.

For Ï=h/T1/Î±~\rho=h/T^{1/\tilde{\alpha}}, let âˆ’r=u0â‰¤u1â‰¤â‹¯â‰¤uN=r-r=u\_{0}\leq u\_{1}\leq\dots\leq u\_{N}=r and dâ‰¥1d\geq 1 be as in [LemmaÂ A.8](https://arxiv.org/html/2601.01871v1#A1.Thmlemma8 "Lemma A.8. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").
Inserting the equi-spaced points âˆ’r+kâ€‹Ï-r+k\rho (k=1,â€¦,âŒŠ2â€‹r/ÏâŒ‹)(k=1,\dots,\lfloor 2r/\rho\rfloor) into the sequence (ua)a=0N(u\_{a})\_{a=0}^{N} if necessary, we may assume max0â‰¤aâ‰¤Nâˆ’1â¡(ua+1âˆ’ua)â‰¤Ï\max\_{0\leq a\leq N-1}(u\_{a+1}-u\_{a})\leq\rho while ([A.25](https://arxiv.org/html/2601.01871v1#A1.E25 "Equation A.25 â€£ Lemma A.8. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) still holds. Note that this operation increases the number of points at most âŒŠ2â€‹r/ÏâŒ‹\lfloor 2r/\rho\rfloor, so we have Nâ‰²Ïâˆ’dN\lesssim\rho^{-d}.

For each uâˆˆ[âˆ’r,r]u\in[-r,r], set

|  |  |  |
| --- | --- | --- |
|  | X~jâ€‹(u):=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—â„1[âˆ’h,h]âŠ•Ïâ€‹(yâˆ’xâˆ’u)â€‹Fhâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y),j=0,1,â€¦,Tâˆ’1\widetilde{X}\_{j}(u):=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times\mathbb{R}}1\_{[-h,h]\oplus\rho}(y-x-u)F\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy),\quad j=0,1,\dots,T-1 |  |

and

|  |  |  |
| --- | --- | --- |
|  | Î”~Tâ€‹(u):=âˆ‘j=0Tâˆ’1{X~jâ€‹(u)âˆ’Eâ¡[X~jâ€‹(u)]}.\widetilde{\Delta}\_{T}(u):=\sum\_{j=0}^{T-1}\left\{\widetilde{X}\_{j}(u)-\operatorname{E}[\widetilde{X}\_{j}(u)]\right\}. |  |

In Step 2, we will show

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[h1âˆ’Î±~â€‹supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|]â‰²Eâ¡[h1âˆ’Î±~â€‹max0â‰¤aâ‰¤Nâ¡|Î”~Tâ€‹(ua)|]+1Tâ€‹hÎ±~.\operatorname{E}\left[h^{1-\tilde{\alpha}}\sup\_{u\in[-r,r]}|\Delta\_{T}(u)|\right]\lesssim\operatorname{E}\left[h^{1-\tilde{\alpha}}\max\_{0\leq a\leq N}|\widetilde{\Delta}\_{T}(u\_{a})|\right]+\frac{1}{\sqrt{Th^{\tilde{\alpha}}}}. |  | (A.27) |

Given this estimate, we can prove the claim of the lemma as follows.
Since Nâ‰²Ïâˆ’dâ‰¤hâˆ’dâ€‹{1+1/(Î±~â€‹Î·)}N\lesssim\rho^{-d}\leq h^{-d\{1+1/(\tilde{\alpha}\eta)\}}, we have N1/pâ‰²hâˆ’Îµ/4N^{1/p}\lesssim h^{-\varepsilon/4} for a sufficiently large even integer pp depending only on Î±\alpha and Î·\eta.
Observe that Jensenâ€™s inequality gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[h1âˆ’Î±~â€‹max0â‰¤aâ‰¤Nâ¡|Î”~Tâ€‹(ua)|]\displaystyle\operatorname{E}\left[h^{1-\tilde{\alpha}}\max\_{0\leq a\leq N}\left|\widetilde{\Delta}\_{T}(u\_{a})\right|\right] | â‰¤h1âˆ’Î±~â€‹(Eâ¡[max0â‰¤aâ‰¤Nâ¡|Î”~Tâ€‹(ua)|p])1/pâ‰¤(N+1)1/pâ€‹h1âˆ’Î±~â€‹max0â‰¤aâ‰¤Nâ¡â€–Î”~Tâ€‹(ua)â€–p.\displaystyle\leq h^{1-\tilde{\alpha}}\left(\operatorname{E}\left[\max\_{0\leq a\leq N}\left|\widetilde{\Delta}\_{T}(u\_{a})\right|^{p}\right]\right)^{1/p}\leq(N+1)^{1/p}h^{1-\tilde{\alpha}}\max\_{0\leq a\leq N}\left\|\widetilde{\Delta}\_{T}(u\_{a})\right\|\_{p}. |  |

Meanwhile, define a function K~:â„â†’â„\widetilde{K}:\mathbb{R}\to\mathbb{R} as K~â€‹(u)=2â€‹Fâ€‹(2â€‹u)â€‹1[âˆ’1,1]âŠ•Tâˆ’1/Î±~â€‹(2â€‹u)\widetilde{K}(u)=2F(2u)1\_{[-1,1]\oplus T^{-1/\tilde{\alpha}}}(2u) for uâˆˆâ„u\in\mathbb{R}. Observe that K~\widetilde{K} is supported on [âˆ’1,1][-1,1] and bounded by 2â€‹â€–Kâ€–âˆ2\|K\|\_{\infty}.
Moreover, we can rewrite X~jâ€‹(u)\widetilde{X}\_{j}(u) as

|  |  |  |
| --- | --- | --- |
|  | X~jâ€‹(u)=1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—â„K~2â€‹hâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y).\widetilde{X}\_{j}(u)=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times\mathbb{R}}\tilde{K}\_{2h}(y-x-u)N\_{1}(dx)N\_{2}(dy). |  |

Therefore, we can apply [LemmaÂ A.7](https://arxiv.org/html/2601.01871v1#A1.Thmlemma7 "Lemma A.7. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") to Î”~Tâ€‹(u)\widetilde{\Delta}\_{T}(u) and thus obtain

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[h1âˆ’Î±~â€‹max0â‰¤aâ‰¤Nâ¡|Î”~Tâ€‹(ua)|]â‰²(N+1)1/pTâ€‹hÎ±~+Îµ/2â‰²1Tâ€‹hÎ±~+Îµ.\displaystyle\operatorname{E}\left[h^{1-\tilde{\alpha}}\max\_{0\leq a\leq N}\left|\widetilde{\Delta}\_{T}(u\_{a})\right|\right]\lesssim\frac{(N+1)^{1/p}}{\sqrt{Th^{\tilde{\alpha}+\varepsilon/2}}}\lesssim\frac{1}{\sqrt{Th^{\tilde{\alpha}+\varepsilon}}}. |  |

Combining this with ([A.27](https://arxiv.org/html/2601.01871v1#A1.E27 "Equation A.27 â€£ Step 1. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives the claim of the lemma.

##### Step 2.

It remains to prove ([A.27](https://arxiv.org/html/2601.01871v1#A1.E27 "Equation A.27 â€£ Step 1. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Fix uâˆˆ[âˆ’r,r]u\in[-r,r]. We can find an index 0â‰¤a<N0\leq a<N such that uaâ‰¤uâ‰¤ua+1u\_{a}\leq u\leq u\_{a+1}.
Since uâˆ’uaâ‰¤ua+1âˆ’uaâ‰¤Ïu-u\_{a}\leq u\_{a+1}-u\_{a}\leq\rho and FF is non-decreasing, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Xjâ€‹(u)\displaystyle X\_{j}(u) | =1Tâ€‹Î»1â€‹Î»2â€‹âˆ«IjÃ—â„1[âˆ’h,h]â€‹(yâˆ’xâˆ’u)â€‹Fhâ€‹(yâˆ’xâˆ’u)â€‹N1â€‹(dâ€‹x)â€‹N2â€‹(dâ€‹y)â‰¤X~jâ€‹(ua)\displaystyle=\frac{1}{T\lambda\_{1}\lambda\_{2}}\int\_{I\_{j}\times\mathbb{R}}1\_{[-h,h]}(y-x-u)F\_{h}(y-x-u)N\_{1}(dx)N\_{2}(dy)\leq\widetilde{X}\_{j}(u\_{a}) |  |

for all jj.
Campbellâ€™s formula gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[X~jâ€‹(ua)]\displaystyle\operatorname{E}[\widetilde{X}\_{j}(u\_{a})] | =1Tâ€‹âˆ«â„1[âˆ’h,h]âŠ•Ïâ€‹(vâˆ’ua)â€‹Khâ€‹(vâˆ’ua)â€‹gâ€‹(v)â€‹ğ‘‘v\displaystyle=\frac{1}{T}\int\_{\mathbb{R}}1\_{[-h,h]\oplus\rho}(v-u\_{a})K\_{h}(v-u\_{a})g(v)dv |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =1Tâ€‹âˆ«âˆ’r1r11[âˆ’h,h]âŠ•Ïâ€‹(vâˆ’ua)â€‹Khâ€‹(vâˆ’ua)â€‹gâ€‹(v)â€‹ğ‘‘v,\displaystyle=\frac{1}{T}\int\_{-r\_{1}}^{r\_{1}}1\_{[-h,h]\oplus\rho}(v-u\_{a})K\_{h}(v-u\_{a})g(v)dv, |  |

where the second equality follows from uaâˆˆ[âˆ’r,r]u\_{a}\in[-r,r] and h+Ïâ‰¤2â€‹hâ‰¤1h+\rho\leq 2h\leq 1.
Observe that 1[âˆ’h,h]âŠ•Ïâ€‹(vâˆ’ua)=1Jh,uâ€‹(vâˆ’u)1\_{[-h,h]\oplus\rho}(v-u\_{a})=1\_{J\_{h,u}}(v-u) with Jh,u:=([âˆ’h,h]âŠ•Ï)+(uaâˆ’u)J\_{h,u}:=([-h,h]\oplus\rho)+(u\_{a}-u).
Note that Jh,uâŠƒ[âˆ’h,h]J\_{h,u}\supset[-h,h] because uâˆ’uaâ‰¤Ïu-u\_{a}\leq\rho.
Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Eâ¡[X~jâ€‹(ua)]âˆ’1Tâ€‹âˆ«âˆ’r1r11[âˆ’h,h]â€‹(vâˆ’u)â€‹Khâ€‹(vâˆ’ua)â€‹gâ€‹(v)â€‹ğ‘‘v|\displaystyle\left|\operatorname{E}[\widetilde{X}\_{j}(u\_{a})]-\frac{1}{T}\int\_{-r\_{1}}^{r\_{1}}1\_{[-h,h]}(v-u)K\_{h}(v-u\_{a})g(v)dv\right| | â‰¤â€–Kâ€–âˆTâ€‹hâ€‹âˆ«âˆ’r1r11Jh,uâˆ–[âˆ’h,h]â€‹(vâˆ’u)â€‹gâ€‹(v)â€‹ğ‘‘v.\displaystyle\leq\frac{\|K\|\_{\infty}}{Th}\int\_{-r\_{1}}^{r\_{1}}1\_{J\_{h,u}\setminus[-h,h]}(v-u)g(v)dv. |  |

Noting that â€–g0â€–L1/(1âˆ’Î±~/2)â‰²1\|g\_{0}\|\_{L^{1/(1-\tilde{\alpha}/2)}}\lesssim 1 by Jensenâ€™s inequality (if Î±<1\alpha<1) and âˆ«âˆ’r1r1|uâˆ’Î¸âˆ—|Î±âˆ’11âˆ’Î±~/2â€‹ğ‘‘uâ‰²1\int\_{-r\_{1}}^{r\_{1}}|u-\theta^{\*}|^{\frac{\alpha-1}{1-\tilde{\alpha}/2}}du\lesssim 1 because Î±âˆ’11âˆ’Î±~/2>âˆ’1\frac{\alpha-1}{1-\tilde{\alpha}/2}>-1, we have â€–gâ€–L1/(1âˆ’Î±~/2)â‰²1\|g\|\_{L^{1/(1-\tilde{\alpha}/2)}}\lesssim 1 by [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes").
Then, since Lebâ¡(Jh,uâˆ–[âˆ’h,h])â‰²Ï\operatorname{Leb}(J\_{h,u}\setminus[-h,h])\lesssim\rho, Youngâ€™s inequality gives

|  |  |  |
| --- | --- | --- |
|  | |Eâ¡[X~jâ€‹(ua)]âˆ’1Tâ€‹âˆ«âˆ’r1r11[âˆ’h,h]â€‹(vâˆ’u)â€‹Khâ€‹(vâˆ’ua)â€‹gâ€‹(v)â€‹ğ‘‘v|â‰²ÏÎ±~/2Tâ€‹h.\displaystyle\left|\operatorname{E}[\widetilde{X}\_{j}(u\_{a})]-\frac{1}{T}\int\_{-r\_{1}}^{r\_{1}}1\_{[-h,h]}(v-u)K\_{h}(v-u\_{a})g(v)dv\right|\lesssim\frac{\rho^{\tilde{\alpha}/2}}{Th}. |  |

Meanwhile, by Campbellâ€™s formula again,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[Xjâ€‹(u)]\displaystyle\operatorname{E}[X\_{j}(u)] | =1Tâ€‹âˆ«â„1[âˆ’h,h]â€‹(vâˆ’u)â€‹Khâ€‹(vâˆ’u)â€‹gâ€‹(v)â€‹ğ‘‘v.\displaystyle=\frac{1}{T}\int\_{\mathbb{R}}1\_{[-h,h]}(v-u)K\_{h}(v-u)g(v)dv. |  |

Therefore, ([A.25](https://arxiv.org/html/2601.01871v1#A1.E25 "Equation A.25 â€£ Lemma A.8. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives

|  |  |  |
| --- | --- | --- |
|  | |Eâ¡[Xjâ€‹(u)]âˆ’1Tâ€‹âˆ«âˆ’r1r11[âˆ’h,h]â€‹(vâˆ’u)â€‹Khâ€‹(vâˆ’ua)â€‹gâ€‹(v)â€‹ğ‘‘v|â‰²ÏTâ€‹h.\displaystyle\left|\operatorname{E}[X\_{j}(u)]-\frac{1}{T}\int\_{-r\_{1}}^{r\_{1}}1\_{[-h,h]}(v-u)K\_{h}(v-u\_{a})g(v)dv\right|\lesssim\frac{\rho}{Th}. |  |

Consequently,

|  |  |  |
| --- | --- | --- |
|  | Xjâ€‹(u)âˆ’Eâ¡[Xjâ€‹(u)]â‰¤X~jâ€‹(ua)âˆ’Eâ¡[X~jâ€‹(ua)]+C0â€‹ÏÎ±~/2Tâ€‹h,\displaystyle X\_{j}(u)-\operatorname{E}[X\_{j}(u)]\leq\widetilde{X}\_{j}(u\_{a})-\operatorname{E}[\widetilde{X}\_{j}(u\_{a})]+C\_{0}\frac{\rho^{\tilde{\alpha}/2}}{Th}, |  |

where C0>0C\_{0}>0 is a constant depending only on r,Î±,Î±0,Î´,b,(Bp)pâ‰¥1,(Bp,q)p,qâ‰¥1,Îµr,\alpha,\alpha\_{0},\delta,b,(B\_{p})\_{p\geq 1},(B\_{p,q})\_{p,q\geq 1},\varepsilon and â€–Kâ€–âˆ\|K\|\_{\infty}.
Similarly, we also have

|  |  |  |
| --- | --- | --- |
|  | Xjâ€‹(u)âˆ’Eâ¡[Xjâ€‹(u)]â‰¥X~jâ€‹(ua+1)âˆ’Eâ¡[X~jâ€‹(ua+1)]âˆ’C0â€‹ÏÎ±~/2Tâ€‹h.\displaystyle X\_{j}(u)-\operatorname{E}[X\_{j}(u)]\geq\widetilde{X}\_{j}(u\_{a+1})-\operatorname{E}[\widetilde{X}\_{j}(u\_{a+1})]-C\_{0}\frac{\rho^{\tilde{\alpha}/2}}{Th}. |  |

Thus, we conclude

|  |  |  |
| --- | --- | --- |
|  | supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|â‰¤max0â‰¤aâ‰¤Nâ¡|Î”~Tâ€‹(ua)|+C0â€‹ÏÎ±~/2h.\sup\_{u\in[-r,r]}|\Delta\_{T}(u)|\leq\max\_{0\leq a\leq N}|\widetilde{\Delta}\_{T}(u\_{a})|+C\_{0}\frac{\rho^{\tilde{\alpha}/2}}{h}. |  |

Therefore, ([A.27](https://arxiv.org/html/2601.01871v1#A1.E27 "Equation A.27 â€£ Step 1. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows from the definition of Ï\rho.
âˆ

###### Proof of [TheoremÂ 4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").

Define the function fhf\_{h} by ([A.2](https://arxiv.org/html/2601.01871v1#A1.E2 "Equation A.2 â€£ Lemma A.2. â€£ A.1 Preliminaries â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) and
set Î”Â¯T:=supuâˆˆ[âˆ’r,r]|g~hâ€‹(u)âˆ’fhâ€‹(u)|\bar{\Delta}\_{T}:=\sup\_{u\in[-r,r]}\left|\tilde{g}\_{h}(u)-f\_{h}(u)\right|.
Since Eâ¡[Xjâ€‹(u)]=fhâ€‹(u)\operatorname{E}[X\_{j}(u)]=f\_{h}(u) for all jj, [LemmaÂ A.6](https://arxiv.org/html/2601.01871v1#A1.Thmlemma6 "Lemma A.6. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | Eâ¡[Î”Â¯T]â‰²Eâ¡[supuâˆˆ[âˆ’r,r]|Î”Tâ€‹(u)|]+1Tâ€‹h.\operatorname{E}\left[\bar{\Delta}\_{T}\right]\lesssim\operatorname{E}\left[\sup\_{u\in[-r,r]}|\Delta\_{T}(u)|\right]+\frac{1}{Th}. |  | (A.28) |

Now, consider the case Î±>1\alpha>1.
Then, by [LemmaÂ A.5](https://arxiv.org/html/2601.01871v1#A1.Thmlemma5 "Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1A>1 and 0<h0<10<h\_{0}<1 depending only on Î±,b,Î´\alpha,b,\delta such that ([A.16](https://arxiv.org/html/2601.01871v1#A1.E16 "Equation A.16 â€£ Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
Since Î¸^h\hat{\theta}\_{h} is a maximizer of [âˆ’r,r]âˆ‹uâ†¦g~hâ€‹(u)âˆˆ[0,âˆ)[-r,r]\ni u\mapsto\tilde{g}\_{h}(u)\in[0,\infty), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(|Î¸^hâˆ’Î¸âˆ—|>Aâ€‹h)\displaystyle\operatorname{P}\left(|\hat{\theta}\_{h}-\theta^{\*}|>Ah\right) | â‰¤Pâ¡(g~hâ€‹(Î¸âˆ—+Ïƒâ€‹h)â‰¤supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hg~hâ€‹(u))\displaystyle\leq\operatorname{P}\left(\tilde{g}\_{h}(\theta^{\*}+\sigma h)\leq\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}\tilde{g}\_{h}(u)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(fhâ€‹(Î¸âˆ—+Ïƒâ€‹h)â‰¤supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)+2â€‹Î”Â¯T).\displaystyle\leq\operatorname{P}\left(f\_{h}(\theta^{\*}+\sigma h)\leq\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)+2\bar{\Delta}\_{T}\right). |  |

Therefore, ([A.16](https://arxiv.org/html/2601.01871v1#A1.E16 "Equation A.16 â€£ Item (a) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) gives Pâ¡(|Î¸^hâˆ’Î¸âˆ—|>Aâ€‹h)â‰¤Pâ¡(2â€‹Î”Â¯Tâ‰¥hÎ±âˆ’1)\operatorname{P}\left(|\hat{\theta}\_{h}-\theta^{\*}|>Ah\right)\leq\operatorname{P}\left(2\bar{\Delta}\_{T}\geq h^{\alpha-1}\right).
Hence, the desired result follows by Markovâ€™s inequality, ([A.28](https://arxiv.org/html/2601.01871v1#A1.E28 "Equation A.28 â€£ Proof of Theorem 4.1. â€£ Step 2. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) and [LemmaÂ A.9](https://arxiv.org/html/2601.01871v1#A1.Thmlemma9 "Lemma A.9. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").

Next, consider the case Î±<1\alpha<1.
Then, by [LemmaÂ A.5](https://arxiv.org/html/2601.01871v1#A1.Thmlemma5 "Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), for some Ïƒâˆˆ{âˆ’1,1}\sigma\in\{-1,1\}, there exist constants A>1,c>0A>1,c>0 and 0<h0<10<h\_{0}<1 depending only on Î±,Î±0,b,Î´,K\alpha,\alpha\_{0},b,\delta,K such that ([A.17](https://arxiv.org/html/2601.01871v1#A1.E17 "Equation A.17 â€£ Item (b) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
Since Î¸^h\hat{\theta}\_{h} is a maximizer of [âˆ’r,r]âˆ‹uâ†¦g~hâ€‹(u)âˆˆ[0,âˆ)[-r,r]\ni u\mapsto\tilde{g}\_{h}(u)\in[0,\infty),

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(|Î¸^hâˆ’Î¸âˆ—|>Aâ€‹h)\displaystyle\operatorname{P}\left(|\hat{\theta}\_{h}-\theta^{\*}|>Ah\right) | â‰¤Pâ¡(g~hâ€‹(Î¸âˆ—)â‰¤supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hg~hâ€‹(u))\displaystyle\leq\operatorname{P}\left(\tilde{g}\_{h}(\theta^{\*})\leq\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}\tilde{g}\_{h}(u)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(fhâ€‹(Î¸âˆ—)â‰¤supuâˆˆ[âˆ’r,r]:|uâˆ’Î¸âˆ—|>Aâ€‹hfhâ€‹(u)+2â€‹Î”Â¯T)\displaystyle\leq\operatorname{P}\left(f\_{h}(\theta^{\*})\leq\sup\_{u\in[-r,r]:|u-\theta^{\*}|>Ah}f\_{h}(u)+2\bar{\Delta}\_{T}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Pâ¡(2â€‹Î”Â¯Tâ‰¥câ€‹hÎ±âˆ’1),\displaystyle\leq\operatorname{P}\left(2\bar{\Delta}\_{T}\geq ch^{\alpha-1}\right), |  |

where the last line follows from ([A.17](https://arxiv.org/html/2601.01871v1#A1.E17 "Equation A.17 â€£ Item (b) â€£ Lemma A.5. â€£ A.3 Proof of Theorem 3.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Therefore, the desired result follows by Markovâ€™s inequality, ([A.28](https://arxiv.org/html/2601.01871v1#A1.E28 "Equation A.28 â€£ Proof of Theorem 4.1. â€£ Step 2. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) and [LemmaÂ A.9](https://arxiv.org/html/2601.01871v1#A1.Thmlemma9 "Lemma A.9. â€£ A.4 Proof of Theorem 4.1 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") again.
âˆ

### A.5 Proof of Theorem [4.2](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem2 "Theorem 4.2. â€£ 4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")

Below we assume TT is sufficiently large TT such that jminâ‰¤logaâ¡(TmaxÎ³)j\_{\min}\leq\log\_{a}(T^{\gamma}\_{\max}).
For 0<Î³â‰¤Î³max0<\gamma\leq\gamma\_{\max}, we write hâˆ—â€‹(Î³)h^{\*}(\gamma) for the largest element hâˆˆâ„‹Th\in\mathcal{H}\_{T} such that hâ‰¤Tâˆ’Î³h\leq T^{-\gamma}.
Note that hâˆ—â€‹(Î³)h^{\*}(\gamma) is well-defined because Î³â‰¤Î³max\gamma\leq\gamma\_{\max}.
Also, aâ€‹hâˆ—â€‹(Î³)>Tâˆ’Î³ah^{\*}(\gamma)>T^{-\gamma} for sufficiently large TT by construction, so hâˆ—â€‹(Î³)â‰Tâˆ’Î³h^{\*}(\gamma)\asymp T^{-\gamma} as Tâ†’âˆT\to\infty.

###### Lemma A.10.

Under the assumptions of [TheoremÂ 4.2](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem2 "Theorem 4.2. â€£ 4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes"), for any 0<Î³<1/Î²Î±0<\gamma<1/\beta\_{\alpha}, Pâ¡(h^>Tâˆ’Î³)â†’0\operatorname{P}(\hat{h}>T^{-\gamma})\to 0 as Tâ†’âˆT\to\infty.

###### Proof.

Write hâˆ—=hâˆ—â€‹(Î³)h^{\*}=h^{\*}(\gamma) for short.
Observe that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(h^>Tâˆ’Î³)\displaystyle\operatorname{P}(\hat{h}>T^{-\gamma}) | â‰¤Pâ¡(h^>hâˆ—)â‰¤Pâ¡(dÂ¯â€‹(â„³hâˆ—,â„³hâ€²)>ATâ€‹hâ€²â€‹Â for someÂ â€‹hâ€²âˆˆâ„‹Tâ€‹Â withÂ â€‹hâ€²â‰¥hâˆ—)\displaystyle\leq\operatorname{P}(\hat{h}>h^{\*})\leq\operatorname{P}(\bar{d}(\mathcal{M}\_{h^{\*}},\mathcal{M}\_{h^{\prime}})>A\_{T}h^{\prime}\text{ for some }h^{\prime}\in\mathcal{H}\_{T}\text{ with }h^{\prime}\geq h^{\*}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ‘hâ€²âˆˆâ„‹T:hâ€²â‰¥hâˆ—Pâ¡(dÂ¯â€‹(â„³hâˆ—,â„³hâ€²)>ATâ€‹hâ€²).\displaystyle\leq\sum\_{h^{\prime}\in\mathcal{H}\_{T}:h^{\prime}\geq h^{\*}}\operatorname{P}(\bar{d}(\mathcal{M}\_{h^{\*}},\mathcal{M}\_{h^{\prime}})>A\_{T}h^{\prime}). |  |

Since dÂ¯â€‹(â„³hâˆ—,â„³hâ€²)â‰¤dÂ¯â€‹(â„³hâˆ—,{Î¸âˆ—})+dÂ¯â€‹(â„³hâ€²,{Î¸âˆ—})\bar{d}(\mathcal{M}\_{h^{\*}},\mathcal{M}\_{h^{\prime}})\leq\bar{d}(\mathcal{M}\_{h^{\*}},\{\theta^{\*}\})+\bar{d}(\mathcal{M}\_{h^{\prime}},\{\theta^{\*}\}), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(h^>Tâˆ’Î³)\displaystyle\operatorname{P}(\hat{h}>T^{-\gamma}) | â‰¤âˆ‘hâ€²âˆˆâ„‹T:hâ€²â‰¥hâˆ—{Pâ¡(dÂ¯â€‹(â„³hâˆ—,{Î¸âˆ—})>ATâ€‹hâ€²/2)+Pâ¡(dÂ¯â€‹(â„³hâ€²,{Î¸âˆ—})>ATâ€‹hâ€²/2)}\displaystyle\leq\sum\_{h^{\prime}\in\mathcal{H}\_{T}:h^{\prime}\geq h^{\*}}\left\{\operatorname{P}(\bar{d}(\mathcal{M}\_{h^{\*}},\{\theta^{\*}\})>A\_{T}h^{\prime}/2)+\operatorname{P}(\bar{d}(\mathcal{M}\_{h^{\prime}},\{\theta^{\*}\})>A\_{T}h^{\prime}/2)\right\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤2â€‹|â„‹T|â€‹maxhâˆˆâ„‹T:hâ‰¥hâˆ—â¡Pâ¡(dÂ¯â€‹(â„³h,{Î¸âˆ—})>ATâ€‹h/2).\displaystyle\leq 2|\mathcal{H}\_{T}|\max\_{h\in\mathcal{H}\_{T}:h\geq h^{\*}}\operatorname{P}(\bar{d}(\mathcal{M}\_{h},\{\theta^{\*}\})>A\_{T}h/2). |  |

For every hâˆˆâ„‹Th\in\mathcal{H}\_{T}, we can find a random variable Î¸~hâˆˆâ„³h\tilde{\theta}\_{h}\in\mathcal{M}\_{h} such that |Î¸~hâˆ’Î¸âˆ—|>ATâ€‹h/2|\tilde{\theta}\_{h}-\theta^{\*}|>A\_{T}h/2 on the event dÂ¯â€‹(â„³h,{Î¸âˆ—})>ATâ€‹h/2\bar{d}(\mathcal{M}\_{h},\{\theta^{\*}\})>A\_{T}h/2. Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pâ¡(h^>Tâˆ’Î³)\displaystyle\operatorname{P}(\hat{h}>T^{-\gamma}) | â‰¤2â€‹|â„‹T|â€‹maxhâˆˆâ„‹T:hâ‰¥hâˆ—â¡Pâ¡(|Î¸~hâˆ’Î¸âˆ—|>ATâ€‹h/2).\displaystyle\leq 2|\mathcal{H}\_{T}|\max\_{h\in\mathcal{H}\_{T}:h\geq h^{\*}}\operatorname{P}(|\tilde{\theta}\_{h}-\theta^{\*}|>A\_{T}h/2). |  |

Thus, for any Îµ>0\varepsilon>0, [TheoremÂ 4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") gives

|  |  |  |
| --- | --- | --- |
|  | Pâ¡(h^T>Tâˆ’Î³)=Oâ€‹(|â„‹T|â€‹maxhâˆˆâ„‹T:hâ‰¥hâˆ—â¡1Tâ€‹hÎ²Î±+Îµ)=Oâ€‹(|â„‹T|Tâ€‹(hâˆ—)Î²Î±+Îµ).\displaystyle\operatorname{P}(\hat{h}\_{T}>T^{-\gamma})=O\left(|\mathcal{H}\_{T}|\max\_{h\in\mathcal{H}\_{T}:h\geq h^{\*}}\frac{1}{\sqrt{Th^{\beta\_{\alpha}+\varepsilon}}}\right)=O\left(\frac{|\mathcal{H}\_{T}|}{\sqrt{T(h^{\*})^{\beta\_{\alpha}+\varepsilon}}}\right). |  |

Since Î³<1/Î²Î±\gamma<1/\beta\_{\alpha} and |â„‹T|=Oâ€‹(logâ¡T)|\mathcal{H}\_{T}|=O(\log T), we obtain the desired result by taking Îµ\varepsilon so that Î³â€‹(Î²Î±+Îµ)<1\gamma(\beta\_{\alpha}+\varepsilon)<1.
âˆ

###### Proof of [TheoremÂ 4.2](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem2 "Theorem 4.2. â€£ 4.1 Bandwidth selection by Lepskiâ€™s method â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").

Let Î³â€²\gamma^{\prime} be a constant such that Î³<Î³â€²<1/Î²Î±\gamma<\gamma^{\prime}<1/\beta\_{\alpha}. Then, ATâ€‹Tâˆ’Î³â€²=oâ€‹(Tâˆ’Î³)A\_{T}T^{-\gamma^{\prime}}=o(T^{-\gamma}) by assumption.
Hence it is enough to prove Pâ¡(|Î¸^h^âˆ’Î¸âˆ—|>2â€‹ATâ€‹Tâˆ’Î³â€²)â†’0\operatorname{P}(|\hat{\theta}\_{\hat{h}}-\theta^{\*}|>2A\_{T}T^{-\gamma^{\prime}})\to 0.
Moreover, thanks to [LemmaÂ A.10](https://arxiv.org/html/2601.01871v1#A1.Thmlemma10 "Lemma A.10. â€£ A.5 Proof of Theorem 4.2 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), it suffices to show

|  |  |  |
| --- | --- | --- |
|  | Pâ¡(|Î¸^h^âˆ’Î¸âˆ—|>2â€‹ATâ€‹Tâˆ’Î³â€²,h^â‰¤Tâˆ’Î³â€²)â†’0.\operatorname{P}(|\hat{\theta}\_{\hat{h}}-\theta^{\*}|>2A\_{T}T^{-\gamma^{\prime}},\hat{h}\leq T^{-\gamma^{\prime}})\to 0. |  |

On the event h^â‰¤Tâˆ’Î³â€²\hat{h}\leq T^{-\gamma^{\prime}}, we have h^â‰¤hâˆ—â€‹(Î³â€²)\hat{h}\leq h^{\*}(\gamma^{\prime}), so

|  |  |  |
| --- | --- | --- |
|  | |Î¸^h^âˆ’Î¸âˆ—|â‰¤|Î¸^h^âˆ’Î¸^hâˆ—â€‹(Î³â€²)|+|Î¸^hâˆ—â€‹(Î³â€²)âˆ’Î¸âˆ—|â‰¤ATâ€‹hâˆ—â€‹(Î³â€²)+|Î¸^hâˆ—â€‹(Î³â€²)âˆ’Î¸âˆ—|â‰¤ATâ€‹Tâˆ’Î³â€²+|Î¸^hâˆ—â€‹(Î³â€²)âˆ’Î¸âˆ—|,\displaystyle|\hat{\theta}\_{\hat{h}}-\theta^{\*}|\leq|\hat{\theta}\_{\hat{h}}-\hat{\theta}\_{h^{\*}(\gamma^{\prime})}|+|\hat{\theta}\_{h^{\*}(\gamma^{\prime})}-\theta^{\*}|\leq A\_{T}h^{\*}(\gamma^{\prime})+|\hat{\theta}\_{h^{\*}(\gamma^{\prime})}-\theta^{\*}|\leq A\_{T}T^{-\gamma^{\prime}}+|\hat{\theta}\_{h^{\*}(\gamma^{\prime})}-\theta^{\*}|, |  |

where the second inequality follows by the definition of h^\hat{h}.
Therefore,

|  |  |  |
| --- | --- | --- |
|  | Pâ¡(|Î¸^h^âˆ’Î¸âˆ—|>2â€‹ATâ€‹Tâˆ’Î³â€²,h^â‰¤Tâˆ’Î³â€²)â‰¤Pâ¡(|Î¸^hâˆ—â€‹(Î³â€²)âˆ’Î¸âˆ—|>ATâ€‹Tâˆ’Î³â€²).\operatorname{P}(|\hat{\theta}\_{\hat{h}}-\theta^{\*}|>2A\_{T}T^{-\gamma^{\prime}},\hat{h}\leq T^{-\gamma^{\prime}})\leq\operatorname{P}(|\hat{\theta}\_{h^{\*}(\gamma^{\prime})}-\theta^{\*}|>A\_{T}T^{-\gamma^{\prime}}). |  |

Since Pâ¡(|Î¸^hâˆ—â€‹(Î³â€²)âˆ’Î¸âˆ—|>ATâ€‹Tâˆ’Î³â€²)â†’0\operatorname{P}(|\hat{\theta}\_{h^{\*}(\gamma^{\prime})}-\theta^{\*}|>A\_{T}T^{-\gamma^{\prime}})\to 0 by [TheoremÂ 4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes"), we obtain the desired result.
âˆ

### A.6 Proof of Theorem [4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes")

The proof of [TheoremÂ 4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes") relies on Theorem 2.2 in [tsybakov2008nonparametric], which requires the notion of the Hellinger distance.
Recall that the Hellinger distance between two probability measures PP and QQ defined on a common measurable space (ğ’³,ğ’œ)(\mathcal{X},\mathcal{A}) is defined as

|  |  |  |
| --- | --- | --- |
|  | Hâ€‹(P,Q):=âˆ«ğ’³(dâ€‹Pdâ€‹Î½âˆ’dâ€‹Qdâ€‹Î½)2â€‹ğ‘‘Î½,H(P,Q):=\sqrt{\int\_{\mathcal{X}}\left(\sqrt{\frac{dP}{d\nu}}-\sqrt{\frac{dQ}{d\nu}}\right)^{2}d\nu}, |  |

where Î½\nu is any Ïƒ\sigma-finite measure on (ğ’³,ğ’œ)(\mathcal{X},\mathcal{A}) dominating both PP and QQ.
By Lemmas 2.9 and 2.10(1) in [strasser1985mathematical],

|  |  |  |  |
| --- | --- | --- | --- |
|  | H2â€‹(P,Q)=2â€‹(1âˆ’âˆ«ğ’³dâ€‹Qdâ€‹Pâ€‹ğ‘‘P),H^{2}(P,Q)=2\left(1-\int\_{\mathcal{X}}\sqrt{\frac{dQ}{dP}}dP\right), |  | (A.29) |

where dâ€‹Q/dâ€‹P:=dâ€‹Qa/dâ€‹PdQ/dP:=dQ^{a}/dP with QaQ^{a} the absolutely continuous part of QQ with respect to PP.
Note that strasser1985mathematical defines the Hellinger distance as Hâ€‹(P,Q)/2H(P,Q)/\sqrt{2} in our notation.

###### Proof of [TheoremÂ 4.3](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Minimax lower bound for the convergence rate â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes").

Define a point process N~\tilde{N} on â„2\mathbb{R}^{2} as N~:=âˆ‘i=1âˆÎ´(ti,ti+Î³i)\tilde{N}:=\sum\_{i=1}^{\infty}\delta\_{(t\_{i},t\_{i}+\gamma\_{i})}.
Since N1(â‹…)=N~(â‹…Ã—â„)N\_{1}(\cdot)=\tilde{N}(\cdot\times\mathbb{R}) and N2(â‹…)=N~(â„Ã—â‹…)N\_{2}(\cdot)=\tilde{N}(\mathbb{R}\times\cdot), we have Ïƒâ€‹(Nâˆ©[0,T])âŠ‚Ïƒâ€‹(N~âˆ©[0,T]2)\sigma(N\cap[0,T])\subset\sigma(\tilde{N}\cap[0,T]^{2}).
Also, with DT:=[0,T]Ã—[âˆ’1,T+1]D\_{T}:=[0,T]\times[-1,T+1], we evidently have Ïƒâ€‹(N~âˆ©[0,T]2)âŠ‚Ïƒâ€‹(N~âˆ©DT)\sigma(\tilde{N}\cap[0,T]^{2})\subset\sigma(\tilde{N}\cap D\_{T}).
Therefore, it suffices to show that there exists a constant b>0b>0 such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim infTâ†’âˆinfÎ¸~Tsup|Î¸|â‰¤2â€‹ÏTsupgâˆˆğ’¢â€‹(Î¸,Î±,1/2,b)Pgâ¡(|Î¸~Tâˆ’Î¸|â‰¥ÏT)>0,\liminf\_{T\to\infty}\inf\_{\tilde{\theta}\_{T}}\sup\_{|\theta|\leq 2\rho\_{T}}\sup\_{g\in\mathcal{G}(\theta,\alpha,1/2,b)}\operatorname{P}\_{g}\left(|\tilde{\theta}\_{T}-\theta|\geq\rho\_{T}\right)>0, |  | (A.30) |

where the infimum is taken over all estimators based on N~âˆ©DT\tilde{N}\cap D\_{T}.
For every probability density gg on â„\mathbb{R}, we denote by PT,gP\_{T,g} the law of N~âˆ©DT\tilde{N}\cap D\_{T} induced on (ğ’©DT#,â„¬â€‹(ğ’©DT#))(\mathcal{N}^{\#}\_{D\_{T}},\mathcal{B}(\mathcal{N}^{\#}\_{D\_{T}})) under Pg\operatorname{P}\_{g}, where ğ’©DT#\mathcal{N}^{\#}\_{D\_{T}} denotes the space of all counting measures on DTD\_{T} equipped with the w#w^{\#}-topology; see [daley2006introduction, Appendix A2.6] and [daley2007introduction, Definition 9.1.II] for details.
According to Eq.(2.9) and Theorem 2.2 in [tsybakov2008nonparametric], we obtain ([A.30](https://arxiv.org/html/2601.01871v1#A1.E30 "Equation A.30 â€£ Proof of Theorem 4.3. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) once we find gTâˆˆğ’¢â€‹(2â€‹ÏT,Î±,1/2,b)g\_{T}\in\mathcal{G}(2\rho\_{T},\alpha,1/2,b) and g0âˆˆğ’¢â€‹(0,Î±,1/2,b)g\_{0}\in\mathcal{G}(0,\alpha,1/2,b) such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim supTâ†’âˆH2â€‹(PT,gT,PT,g0)<2.\limsup\_{T\to\infty}H^{2}(P\_{T,g\_{T}},P\_{T,g\_{0}})<2. |  | (A.31) |

Let us compute H2â€‹(PT,gT,PT,g0)H^{2}(P\_{T,g\_{T}},P\_{T,g\_{0}}).
Observe that N~\tilde{N} can be viewed as a cluster process on â„\mathbb{R} with centre process N1N\_{1} and component processes {Î´(ti,ti+Î³i):iâˆˆâ„•}\{\delta\_{(t\_{i},t\_{i}+\gamma\_{i})}:i\in\mathbb{N}\}.
Hence, by Proposition 6.3.III in [daley2006introduction], the probability generating functional (p.g.fl) of N~\tilde{N} under Pg\operatorname{P}\_{g} for gâˆˆ{g0,gT}g\in\{g\_{0},g\_{T}\} is given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ggâ€‹(Ï†)\displaystyle G\_{g}(\varphi) | =expâ¡(âˆ’âˆ«â„(1âˆ’âˆ«â„Ï†â€‹(x,y)â€‹gâ€‹(yâˆ’x)â€‹ğ‘‘y)â€‹ğ‘‘x)\displaystyle=\exp\left(-\int\_{\mathbb{R}}\left(1-\int\_{\mathbb{R}}\varphi(x,y)g(y-x)dy\right)dx\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =expâ¡(âˆ«â„2(Ï†â€‹(x,y)âˆ’1)â€‹gâ€‹(yâˆ’x)â€‹ğ‘‘xâ€‹ğ‘‘y)\displaystyle=\exp\left(\int\_{\mathbb{R}^{2}}\left(\varphi(x,y)-1\right)g(y-x)dxdy\right) |  |

for every measurable function Ï†:â„2â†’(0,1]\varphi:\mathbb{R}^{2}\to(0,1] such that the support of 1âˆ’Ï†1-\varphi is bounded.
Since gg is supported on [âˆ’1,1][-1,1],

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ggâ€‹(1âˆ’1DT+Ï†â€‹1DT)\displaystyle G\_{g}(1-1\_{D\_{T}}+\varphi 1\_{D\_{T}}) | =eâˆ’Tâ€‹expâ¡(âˆ«[0,T]Ã—â„Ï†â€‹(x,y)â€‹gâ€‹(yâˆ’x)â€‹ğ‘‘xâ€‹ğ‘‘y).\displaystyle=e^{-T}\exp\left(\int\_{[0,T]\times\mathbb{R}}\varphi(x,y)g(y-x)dxdy\right). |  |

Therefore, in view of Eq.(5.5.14) in [daley2006introduction], the local Janossy densities of N~\tilde{N} on DTD\_{T} under Pg\operatorname{P}\_{g} are given by

|  |  |  |
| --- | --- | --- |
|  | jn,gâ€‹((x1,y1),â€¦,(xn,yn)âˆ£DT)=eâˆ’Tâ€‹âˆi=1ngâ€‹(yiâˆ’xi)â€‹1[0,T]â€‹(xi)(n=1,2,â€¦).j\_{n,g}((x\_{1},y\_{1}),\dots,(x\_{n},y\_{n})\mid D\_{T})=e^{-T}\prod\_{i=1}^{n}g(y\_{i}-x\_{i})1\_{[0,T]}(x\_{i})\quad(n=1,2,\dots). |  |

This gives

|  |  |  |
| --- | --- | --- |
|  | dâ€‹PT,gTdâ€‹PT,g0â€‹(N~)=âˆi:tiâˆˆ[0,T]gTâ€‹(Î³i)g0â€‹(Î³i)Pg0-a.s.\frac{dP\_{T,g\_{T}}}{dP\_{T,g\_{0}}}(\tilde{N})=\prod\_{i:t\_{i}\in[0,T]}\frac{g\_{T}(\gamma\_{i})}{g\_{0}(\gamma\_{i})}\quad\text{$\operatorname{P}\_{g\_{0}}$-a.s.} |  |

Here, recall that dâ€‹PT,gT/dâ€‹PT,g0:=dâ€‹PT,gTa/dâ€‹PT,g0dP\_{T,g\_{T}}/dP\_{T,g\_{0}}:=dP\_{T,g\_{T}}^{a}/dP\_{T,g\_{0}} with PT,gTaP\_{T,g\_{T}}^{a} the absolutely continuous part of PT,gTP\_{T,g\_{T}} with respect to PT,g0P\_{T,g\_{0}}.
Thus, by ([A.29](https://arxiv.org/html/2601.01871v1#A1.E29 "Equation A.29 â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")),

|  |  |  |
| --- | --- | --- |
|  | H2(PT,gT,PT,g0)=2(1âˆ’Eg0[âˆi:tiâˆˆ[0,T]gTâ€‹(Î³i)g0â€‹(Î³i)])=:2(1âˆ’aT),\displaystyle H^{2}(P\_{T,g\_{T}},P\_{T,g\_{0}})=2\left(1-\operatorname{E}\_{g\_{0}}\left[\prod\_{i:t\_{i}\in[0,T]}\sqrt{\frac{g\_{T}(\gamma\_{i})}{g\_{0}(\gamma\_{i})}}\right]\right)=:2(1-a\_{T}), |  |

where Eg0\operatorname{E}\_{g\_{0}} denotes expectation under Pg0\operatorname{P}\_{g\_{0}}.
Therefore, ([A.31](https://arxiv.org/html/2601.01871v1#A1.E31 "Equation A.31 â€£ Proof of Theorem 4.3. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) follows once we show
lim infTâ†’âˆaT>0.\liminf\_{T\to\infty}a\_{T}>0.
Recall that under Pg0\operatorname{P}\_{g\_{0}}, (Î³i)i=1âˆ(\gamma\_{i})\_{i=1}^{\infty} is i.i.d.Â with common density g0g\_{0} and independent of N1N\_{1}.
Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | aT\displaystyle a\_{T} | =Eg0â¡[(âˆ«gTâ€‹(x)â€‹g0â€‹(x)â€‹ğ‘‘x)N1â€‹([0,T])].\displaystyle=\operatorname{E}\_{g\_{0}}\left[\left(\int\sqrt{g\_{T}(x)g\_{0}(x)}dx\right)^{N\_{1}([0,T])}\right]. |  |

Since N1â€‹([0,T])N\_{1}([0,T]) follows the Poisson distribution with intensity TT under Pg0\operatorname{P}\_{g\_{0}},

|  |  |  |  |
| --- | --- | --- | --- |
|  | aT\displaystyle a\_{T} | =expâ¡(Tâ€‹(âˆ«gTâ€‹(x)â€‹g0â€‹(x)â€‹ğ‘‘xâˆ’1))=expâ¡(âˆ’T2â€‹âˆ«(gTâ€‹(x)âˆ’g0â€‹(x))2â€‹ğ‘‘x).\displaystyle=\exp\left(T\left(\int\sqrt{g\_{T}(x)g\_{0}(x)}dx-1\right)\right)=\exp\left(-\frac{T}{2}\int\left(\sqrt{g\_{T}(x)}-\sqrt{g\_{0}(x)}\right)^{2}dx\right). |  |

Therefore, we complete the proof once we show that there exists a constant b>0b>0 such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«(gTâ€‹(x)âˆ’g0â€‹(x))2â€‹ğ‘‘x=Oâ€‹(Tâˆ’1)\int\left(\sqrt{g\_{T}(x)}-\sqrt{g\_{0}(x)}\right)^{2}dx=O(T^{-1}) |  | (A.32) |

for some gTâˆˆğ’¢â€‹(2â€‹ÏT,Î±,1/2,b)g\_{T}\in\mathcal{G}(2\rho\_{T},\alpha,1/2,b) and g0âˆˆğ’¢â€‹(0,Î±,1/2,b)g\_{0}\in\mathcal{G}(0,\alpha,1/2,b).

##### Case 1: 0<Î±<10<\alpha<1.

For every Î¸âˆˆ[0,1]\theta\in[0,1], define a function fÎ¸:â„â†’[0,âˆ)f\_{\theta}:\mathbb{R}\to[0,\infty) as

|  |  |  |
| --- | --- | --- |
|  | fÎ¸â€‹(x)=Î±â€‹|xâˆ’Î¸|Î±âˆ’1â€‹1[âˆ’1,0)â€‹(xâˆ’Î¸)(xâˆˆâ„).f\_{\theta}(x)=\alpha|x-\theta|^{\alpha-1}1\_{[-1,0)}(x-\theta)\quad(x\in\mathbb{R}). |  |

By construction, we evidently have fÎ¸âˆˆğ’¢â€‹(Î¸,Î±,1/2,b)f\_{\theta}\in\mathcal{G}(\theta,\alpha,1/2,b) for some constant b>0b>0 depending only on Î±\alpha.
Moreover, since f0f\_{0} satisfies Eq.(1.9) of [ibragimov2013statistical, Chapter VI] in a neighborhood of z=0z=0 with Î±=Î±âˆ’1\alpha=\alpha-1, pâ‰¡1p\equiv 1 and qâ‰¡0q\equiv 0 in their notation, f0f\_{0} has one singularity of order Î±âˆ’1\alpha-1 located at 0 in the sense of Definition 1.1 of [ibragimov2013statistical, Chapter VI].
Therefore, Theorem 1.1 in [ibragimov2013statistical, Chapter VI] gives ([A.32](https://arxiv.org/html/2601.01871v1#A1.E32 "Equation A.32 â€£ Proof of Theorem 4.3. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) for gT=f2â€‹ÏTg\_{T}=f\_{2\rho\_{T}} and g0=f0g\_{0}=f\_{0}.

##### Case 2: Î±>1\alpha>1.

We employ a minor variant of the construction used in the proof of [arias2022estimation, Theorem 2].
For every Î¸âˆˆ[0,1/2)\theta\in[0,1/2), define functions ÏˆÎ¸:â„â†’â„\psi\_{\theta}:\mathbb{R}\to\mathbb{R} and fÎ¸:â„â†’â„f\_{\theta}:\mathbb{R}\to\mathbb{R} as

|  |  |  |
| --- | --- | --- |
|  | ÏˆÎ¸â€‹(x)=(|x|Î±âˆ’1âˆ’(2â€‹Î¸)Î±âˆ’1)â€‹1(âˆ’2â€‹Î¸,0]â€‹(x)+(|x|Î±âˆ’1+(2â€‹Î¸)Î±âˆ’1âˆ’2Î±â€‹|xâˆ’Î¸|Î±âˆ’1)â€‹1(0,2â€‹Î¸)â€‹(x),xâˆˆâ„\displaystyle\psi\_{\theta}(x)=(|x|^{\alpha-1}-(2\theta)^{\alpha-1})1\_{(-2\theta,0]}(x)+\left(|x|^{\alpha-1}+(2\theta)^{\alpha-1}-2^{\alpha}|x-\theta|^{\alpha-1}\right)1\_{(0,2\theta)}(x),\quad x\in\mathbb{R} |  |

and

|  |  |  |
| --- | --- | --- |
|  | fÎ¸â€‹(x)=Î±2â€‹(Î±âˆ’1)â€‹(1âˆ’|x|Î±âˆ’1+ÏˆÎ¸â€‹(x))â€‹1[âˆ’1,1]â€‹(x),xâˆˆâ„.\displaystyle f\_{\theta}(x)=\frac{\alpha}{2(\alpha-1)}\left(1-|x|^{\alpha-1}+\psi\_{\theta}(x)\right)1\_{[-1,1]}(x),\quad x\in\mathbb{R}. |  |

Observe that fÎ¸â‰¥0f\_{\theta}\geq 0 and

|  |  |  |
| --- | --- | --- |
|  | âˆ«âˆ’âˆâˆfÎ¸â€‹(x)â€‹ğ‘‘x=Î±2â€‹Î±âˆ’1â€‹(âˆ«âˆ’11(1âˆ’|x|Î±âˆ’1)â€‹ğ‘‘x+âˆ«âˆ’2â€‹Î¸2â€‹Î¸|x|Î±âˆ’1â€‹ğ‘‘xâˆ’2Î±â€‹âˆ«02â€‹Î¸|xâˆ’Î¸|Î±âˆ’1â€‹ğ‘‘x)=1.\displaystyle\int\_{-\infty}^{\infty}f\_{\theta}(x)dx=\frac{\alpha}{2\alpha-1}\left(\int\_{-1}^{1}(1-|x|^{\alpha-1})dx+\int\_{-2\theta}^{2\theta}|x|^{\alpha-1}dx-2^{\alpha}\int\_{0}^{2\theta}|x-\theta|^{\alpha-1}dx\right)=1. |  |

Hence fÎ¸f\_{\theta} is a probability density function on â„\mathbb{R}.
Moreover, we have for all xâˆˆ[âˆ’1,1]x\in[-1,1]

|  |  |  |  |
| --- | --- | --- | --- |
|  | 22âˆ’Î±â€‹|xâˆ’Î¸|Î±âˆ’1â‰¤2â€‹(Î±âˆ’1)Î±â€‹(fÎ¸â€‹(Î¸)âˆ’fÎ¸â€‹(x))â‰¤2Î±â€‹|xâˆ’Î¸|Î±âˆ’1.2^{2-\alpha}|x-\theta|^{\alpha-1}\leq\frac{2(\alpha-1)}{\alpha}\left(f\_{\theta}(\theta)-f\_{\theta}(x)\right)\leq 2^{\alpha}|x-\theta|^{\alpha-1}. |  | (A.33) |

In fact, a straightforward computation shows

|  |  |  |  |
| --- | --- | --- | --- |
|  | 2â€‹(Î±âˆ’1)Î±â€‹(fÎ¸â€‹(Î¸)âˆ’fÎ¸â€‹(x))\displaystyle\frac{2(\alpha-1)}{\alpha}\left(f\_{\theta}(\theta)-f\_{\theta}(x)\right) | ={2â€‹(2â€‹Î¸)Î±âˆ’1ifÂ âˆ’2â€‹Î¸<xâ‰¤0,2Î±â€‹|xâˆ’Î¸|Î±âˆ’1ifÂ â€‹0<x<2â€‹Î¸,|x|Î±âˆ’1+(2â€‹Î¸)Î±âˆ’1otherwise.\displaystyle=\begin{cases}2(2\theta)^{\alpha-1}&\text{if }-2\theta<x\leq 0,\\ 2^{\alpha}|x-\theta|^{\alpha-1}&\text{if }0<x<2\theta,\\ |x|^{\alpha-1}+(2\theta)^{\alpha-1}&\text{otherwise}.\end{cases} |  |

Hence ([A.33](https://arxiv.org/html/2601.01871v1#A1.E33 "Equation A.33 â€£ Case 2: ğ›¼>1. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) is evident if 0<x<2â€‹Î¸0<x<2\theta.
If âˆ’2â€‹Î¸<xâ‰¤0-2\theta<x\leq 0, then Î¸â‰¤|xâˆ’Î¸|â‰¤3â€‹Î¸\theta\leq|x-\theta|\leq 3\theta, so
2â€‹(2â€‹Î¸)Î±âˆ’1â‰¤2Î±â€‹|xâˆ’Î¸|Î±âˆ’12(2\theta)^{\alpha-1}\leq 2^{\alpha}|x-\theta|^{\alpha-1}
and
2â€‹(2â€‹Î¸)Î±âˆ’1â‰¥2â€‹(2â€‹|xâˆ’Î¸|/3)Î±âˆ’1â‰¥22âˆ’Î±â€‹|xâˆ’Î¸|Î±âˆ’12(2\theta)^{\alpha-1}\geq 2(2|x-\theta|/3)^{\alpha-1}\geq 2^{2-\alpha}|x-\theta|^{\alpha-1}. Hence ([A.33](https://arxiv.org/html/2601.01871v1#A1.E33 "Equation A.33 â€£ Case 2: ğ›¼>1. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds.
Also, Jensenâ€™s inequality gives
|xâˆ’Î¸|Î±âˆ’1â‰¤2Î±âˆ’2â€‹(|x|Î±âˆ’1+Î¸Î±âˆ’1)â‰¤2Î±âˆ’2â€‹(|x|Î±âˆ’1+(2â€‹Î¸)Î±âˆ’1).|x-\theta|^{\alpha-1}\leq 2^{\alpha-2}(|x|^{\alpha-1}+\theta^{\alpha-1})\leq 2^{\alpha-2}(|x|^{\alpha-1}+(2\theta)^{\alpha-1}).
Hence the lower bound of ([A.33](https://arxiv.org/html/2601.01871v1#A1.E33 "Equation A.33 â€£ Case 2: ğ›¼>1. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds if |x|â‰¥2â€‹Î¸|x|\geq 2\theta.
Moreover, if xâ‰¤âˆ’2â€‹Î¸x\leq-2\theta, then |x|â‰¥2â€‹Î¸|x|\geq 2\theta and |xâˆ’Î¸|=Î¸âˆ’xâ‰¥âˆ’x=|x||x-\theta|=\theta-x\geq-x=|x|, so

|  |  |  |
| --- | --- | --- |
|  | |x|Î±âˆ’1+(2â€‹Î¸)Î±âˆ’1â‰¤2â€‹|x|Î±âˆ’1â‰¤2â€‹|xâˆ’Î¸|Î±âˆ’1.\displaystyle|x|^{\alpha-1}+(2\theta)^{\alpha-1}\leq 2|x|^{\alpha-1}\leq 2|x-\theta|^{\alpha-1}. |  |

If xâ‰¥2â€‹Î¸x\geq 2\theta, then xâˆ’Î¸â‰¥Î¸x-\theta\geq\theta and thus

|  |  |  |
| --- | --- | --- |
|  | |x|Î±âˆ’1+(2â€‹Î¸)Î±âˆ’1â‰¤2Î±âˆ’2â€‹|xâˆ’Î¸|Î±âˆ’1+3â‹…2Î±âˆ’2â€‹Î¸Î±âˆ’1â‰¤2Î±â€‹|xâˆ’Î¸|Î±âˆ’1,\displaystyle|x|^{\alpha-1}+(2\theta)^{\alpha-1}\leq 2^{\alpha-2}|x-\theta|^{\alpha-1}+3\cdot 2^{\alpha-2}\theta^{\alpha-1}\leq 2^{\alpha}|x-\theta|^{\alpha-1}, |  |

where the first inequality is by Jensenâ€™s inequality.
Therefore, the upper bound of ([A.33](https://arxiv.org/html/2601.01871v1#A1.E33 "Equation A.33 â€£ Case 2: ğ›¼>1. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) also holds if |x|â‰¥2â€‹Î¸|x|\geq 2\theta.
Consequently, fÎ¸âˆˆğ’¢â€‹(Î¸,Î±,1/2,b)f\_{\theta}\in\mathcal{G}(\theta,\alpha,1/2,b) for some constant b>0b>0 depending only on Î±\alpha.

Now, Eq.(2.27) of [tsybakov2008nonparametric] gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«(fÎ¸â€‹(x)âˆ’f0â€‹(x))2â€‹ğ‘‘x\displaystyle\int\left(\sqrt{f\_{\theta}(x)}-\sqrt{f\_{0}(x)}\right)^{2}dx | â‰¤âˆ«âˆ’11(fÎ¸â€‹(x)f0â€‹(x)âˆ’1)2â€‹f0â€‹(x)â€‹ğ‘‘x\displaystyle\leq\int\_{-1}^{1}\left(\frac{f\_{\theta}(x)}{f\_{0}(x)}-1\right)^{2}f\_{0}(x)dx |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Î±2â€‹(Î±âˆ’1)â€‹âˆ«âˆ’2â€‹Î¸2â€‹Î¸ÏˆÎ¸â€‹(x)21âˆ’|x|Î±âˆ’1â€‹ğ‘‘xâ‰¤Î±2â€‹(Î±âˆ’1)â€‹3â€‹(2â€‹Î¸)2â€‹Î±âˆ’11âˆ’(2â€‹Î¸)Î±âˆ’1.\displaystyle=\frac{\alpha}{2(\alpha-1)}\int\_{-2\theta}^{2\theta}\frac{\psi\_{\theta}(x)^{2}}{1-|x|^{\alpha-1}}dx\leq\frac{\alpha}{2(\alpha-1)}\frac{3(2\theta)^{2\alpha-1}}{1-(2\theta)^{\alpha-1}}. |  |

Hence ([A.32](https://arxiv.org/html/2601.01871v1#A1.E32 "Equation A.32 â€£ Proof of Theorem 4.3. â€£ A.6 Proof of Theorem 4.3 â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) holds for gT=f2â€‹ÏTg\_{T}=f\_{2\rho\_{T}} and g0=f0g\_{0}=f\_{0}.
âˆ

### A.7 Proof of Assumption [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) for LBHPG with gamma kernels

In this section, we show that LBHPG\mathrm{LBHPG} with common rate parameters Î²iâ€‹jâ‰¡Î²>0,i,j=1,2\beta\_{ij}\equiv\beta>0,i,j=1,2 satisfies [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) with Î±=minâ¡{D12,D21}\alpha=\min\{D\_{12},D\_{21}\} when minâ¡{D12,D21}<1\min\{D\_{12},D\_{21}\}<1 and the stationary assumption (spectral radius Ïâ€‹(ğœ¶)\rho(\boldsymbol{\alpha}) of the matrix ğœ¶\boldsymbol{\alpha} is smaller than 11) holds.
Let

|  |  |  |
| --- | --- | --- |
|  | haâ€‹(t):=Î²aÎ“â€‹(a)â€‹taâˆ’1â€‹eâˆ’Î²â€‹tâ€‹ğŸ(0,âˆ)â€‹(t),tâˆˆâ„,a>0,h\_{a}(t):=\frac{\beta^{a}}{\Gamma(a)}t^{a-1}e^{-\beta t}\mathbf{1}\_{(0,\infty)}(t),\qquad t\in\mathbb{R},a>0, |  |

ğ‘¯=(hDiâ€‹j)1â‰¤i,jâ‰¤2\boldsymbol{H}=(h\_{D\_{ij}})\_{1\leq i,j\leq 2} , Î±âˆ—=minâ¡{D12,D21}(<1)\alpha\_{\*}=\min\{D\_{12},D\_{21}\}(<1), and Dâˆ—=minâ¡{D11,D12,D21,D22}D\_{\*}=\min\{D\_{11},D\_{12},D\_{21},D\_{22}\}.
Then, we have Î¦=ğœ¶âŠ™ğ‘¯\Phi=\boldsymbol{\alpha}\odot\boldsymbol{H} by definition, where âŠ™\odot is the Hadamard product.
Recall Î¨=âˆ‘mâ‰¥1Î¦(âˆ—m)\Psi=\sum\_{m\geq 1}\Phi^{(\*m)} converges in L1â€‹(â„)L^{1}(\mathbb{R}) componentwise.

By ([5.1](https://arxiv.org/html/2601.01871v1#S5.E1 "Equation 5.1 â€£ 5.1.1 Lagged bivariate Hawkes process with gamma kernels â€£ 5.1 Models â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes")) and ([5.2](https://arxiv.org/html/2601.01871v1#S5.E2 "Equation 5.2 â€£ 5.1.1 Lagged bivariate Hawkes process with gamma kernels â€£ 5.1 Models â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes")) , it is sufficient to show the following proposition:

###### Proposition A.1.

Under the assumptions above, there exist C>0C>0 and Î´>0\delta>0 such that

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Î±iâ€‹jâ€‹hDiâ€‹jâ€‹(u)\displaystyle\alpha\_{ij}h\_{D\_{ij}}(u) | â‰¤Î¨iâ€‹jâ€‹(u),\displaystyle\leq\Psi\_{ij}(u), | u>0,(i,j)âˆˆ{(1,2),(2,1)},\displaystyle u>0,\ (i,j)\in\{(1,2),(2,1)\}, |  | (A.34) |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | maxâ¡{Î¨12â€‹(u),Î¨21â€‹(u)}\displaystyle\max\{\Psi\_{12}(u),\Psi\_{21}(u)\} | â‰¤Câ€‹uÎ±âˆ—âˆ’1,\displaystyle\leq Cu^{\alpha\_{\*}-1}, | 0<u<Î´,\displaystyle 0<u<\delta, |  | (A.35) |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | 0â‰¤âˆ«â„Î¨iâ€‹1â€‹(s)â€‹Î¨iâ€‹2â€‹(s+u)â€‹ğ‘‘s\displaystyle 0\leq\int\_{\mathbb{R}}\Psi\_{i1}(s)\Psi\_{i2}(s+u)\,ds | â‰¤Câ€‹|u|Î±âˆ—âˆ’1,\displaystyle\leq C|u|^{\alpha\_{\*}-1}, | 0<|u|<Î´,iâˆˆ{1,2}.\displaystyle 0<|u|<\delta,i\in\{1,2\}. |  | (A.36) |

In the following, we first provide several lemmas and then use them to establish
Proposition [A.1](https://arxiv.org/html/2601.01871v1#A1.Thmproposition1 "Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").
Before proceeding, we decompose Î¨\Psi as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î¨=Î¨s+Î¨b,\Psi=\Psi^{s}+\Psi^{b}, |  | (A.37) |

where

|  |  |  |
| --- | --- | --- |
|  | Î¨s:=âˆ‘m=1Mâˆ’1Î¦(âˆ—m),Î¨b:=âˆ‘m=MâˆÎ¦(âˆ—m),M=âŒˆ1/Dâˆ—âŒ‰+1.\Psi^{s}:=\sum\_{m=1}^{M-1}\Phi^{(\*m)},\qquad\Psi^{b}:=\sum\_{m=M}^{\infty}\Phi^{(\*m)},\qquad M=\lceil 1/D\_{\*}\rceil+1. |  |

###### Lemma A.11.

For mâ‰¥1m\geq 1, i,jâˆˆ{1,2}i,j\in\{1,2\} and t>0t>0,

|  |  |  |
| --- | --- | --- |
|  | (Î¦(âˆ—m))iâ€‹jâ€‹(t)=âˆ‘(i0,â€¦,im)âˆˆ{1,2}m+1,i0=j,im=i(âˆâ„“=1mÎ±iâ„“â€‹iâ„“âˆ’1)â€‹hâˆ‘â„“=1mDiâ„“â€‹iâ„“âˆ’1â€‹(t).(\Phi^{(\*m)})\_{ij}(t)=\sum\_{\begin{subarray}{c}(i\_{0},\dots,i\_{m})\in\{1,2\}^{m+1},\\ i\_{0}=j,\;i\_{m}=i\end{subarray}}\Bigl(\prod\_{\ell=1}^{m}\alpha\_{i\_{\ell}i\_{\ell-1}}\Bigr)\,h\_{\sum\_{\ell=1}^{m}D\_{i\_{\ell}i\_{\ell-1}}}(t). |  |

###### Proof.

The result follows from the gamma distributionâ€™s reproducibility.
âˆ

###### Lemma A.12.

For every aâ‰¥1a\geq 1, â€–haâ€–âˆâ‰¤Î²\|h\_{a}\|\_{\infty}\leq\beta.

###### Proof.

Fix aâ‰¥1a\geq 1.
Since the gamma density hah\_{a} is log-concave on [0,âˆ)[0,\infty), we have

|  |  |  |
| --- | --- | --- |
|  | â€–haâ€–âˆâ‰¤1Ïƒa\|h\_{a}\|\_{\infty}\leq\frac{1}{\sigma\_{a}} |  |

by [saumard2014log, Eq.Â (5.8)], where Ïƒa\sigma\_{a} is the standard deviation of hah\_{a}.
Since the standard deviation of hah\_{a} is Ïƒa=a/Î²\sigma\_{a}=\sqrt{a}/\beta, we conclude that

|  |  |  |
| --- | --- | --- |
|  | â€–haâ€–âˆâ‰¤Î²aâ‰¤Î².\|h\_{a}\|\_{\infty}\leq\frac{\beta}{\sqrt{a}}\leq\beta. |  |

âˆ

###### Lemma A.13.

Each component of Î¨b\Psi^{b} is bounded on â„\mathbb{R}.

###### Proof.

By LemmaÂ [A.11](https://arxiv.org/html/2601.01871v1#A1.Thmlemma11 "Lemma A.11. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), for mâ‰¥Mm\geq M every component of Î¦(âˆ—m)\Phi^{(\*m)} is a gamma density
with shape parameter at least mâ€‹Dâˆ—>1mD\_{\*}>1. Hence LemmaÂ [A.12](https://arxiv.org/html/2601.01871v1#A1.Thmlemma12 "Lemma A.12. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") yields

|  |  |  |
| --- | --- | --- |
|  | â€–(Î¦(âˆ—m))iâ€‹jâ€–âˆâ‰¤Î²â€‹âˆ‘(i0,â€¦,im)âˆˆ{1,2}m+1,i0=j,im=iâˆâ„“=1mÎ±iâ„“â€‹iâ„“âˆ’1=Î²â€‹(ğœ¶m)iâ€‹j.\|(\Phi^{(\*m)})\_{ij}\|\_{\infty}\leq\beta\sum\_{\begin{subarray}{c}(i\_{0},\dots,i\_{m})\in\{1,2\}^{m+1},\\ i\_{0}=j,\;i\_{m}=i\end{subarray}}\prod\_{\ell=1}^{m}\alpha\_{i\_{\ell}i\_{\ell-1}}=\beta(\boldsymbol{\alpha}^{m})\_{ij}. |  |

Since Ïâ€‹(ğœ¶)<1\rho(\boldsymbol{\alpha})<1, the series âˆ‘mâ‰¥1ğœ¶m\sum\_{m\geq 1}\boldsymbol{\alpha}^{m} converges entrywise, hence
âˆ‘mâ‰¥M(ğœ¶m)iâ€‹j<âˆ\sum\_{m\geq M}(\boldsymbol{\alpha}^{m})\_{ij}<\infty and therefore

|  |  |  |
| --- | --- | --- |
|  | â€–Î¨iâ€‹jbâ€–âˆâ‰¤âˆ‘m=Mâˆâ€–(Î¦(âˆ—m))iâ€‹jâ€–âˆâ‰¤Î²â€‹âˆ‘mâ‰¥M(ğœ¶m)iâ€‹j<âˆ.\|\Psi^{b}\_{ij}\|\_{\infty}\leq\sum\_{m=M}^{\infty}\|(\Phi^{(\*m)})\_{ij}\|\_{\infty}\leq\beta\sum\_{m\geq M}(\boldsymbol{\alpha}^{m})\_{ij}<\infty. |  |

âˆ

###### Proof of Proposition [A.1](https://arxiv.org/html/2601.01871v1#A1.Thmproposition1 "Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes").

Throughout the proof, C>0C>0 and Î´>0\delta>0 denote generic constants.

Proof of ([A.34](https://arxiv.org/html/2601.01871v1#A1.E34 "Equation A.34 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Since Î¨=âˆ‘mâ‰¥1Î¦(âˆ—m)\Psi=\sum\_{m\geq 1}\Phi^{(\*m)} and each term is nonnegative, we have Î¨iâ€‹jâ‰¥Î¦iâ€‹j=Î±iâ€‹jâ€‹hDiâ€‹j\Psi\_{ij}\geq\Phi\_{ij}=\alpha\_{ij}h\_{D\_{ij}}
on (0,âˆ)(0,\infty), which yields ([A.34](https://arxiv.org/html/2601.01871v1#A1.E34 "Equation A.34 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).

Proof of ([A.35](https://arxiv.org/html/2601.01871v1#A1.E35 "Equation A.35 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Fix (i,j)âˆˆ{(1,2),(2,1)}(i,j)\in\{(1,2),(2,1)\}. By ([A.37](https://arxiv.org/html/2601.01871v1#A1.E37 "Equation A.37 â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")),

|  |  |  |
| --- | --- | --- |
|  | Î¨iâ€‹jâ€‹(u)=Î¨iâ€‹jsâ€‹(u)+Î¨iâ€‹jbâ€‹(u),u>0.\Psi\_{ij}(u)=\Psi^{s}\_{ij}(u)+\Psi^{b}\_{ij}(u),\qquad u>0. |  |

By LemmaÂ [A.11](https://arxiv.org/html/2601.01871v1#A1.Thmlemma11 "Lemma A.11. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") and the definition of Î¨s\Psi^{s} as a finite sum,
Î¨iâ€‹js\Psi^{s}\_{ij} is a finite nonnegative linear combination of gamma densities hah\_{a} (with common rate Î²\beta) whose shape parameters satisfy aâ‰¥Diâ€‹jâ‰¥Î±âˆ—a\geq D\_{ij}\geq\alpha\_{\*}.
Hence, there exists Cs>0C\_{s}>0 such that Î¨iâ€‹jsâ€‹(u)â‰¤Csâ€‹uÎ±âˆ—âˆ’1\Psi^{s}\_{ij}(u)\leq C\_{s}u^{\alpha\_{\*}-1} for all uâˆˆ(0,1)u\in(0,1).
Moreover, LemmaÂ [A.13](https://arxiv.org/html/2601.01871v1#A1.Thmlemma13 "Lemma A.13. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes") gives â€–Î¨iâ€‹jbâ€–âˆ<âˆ\|\Psi^{b}\_{ij}\|\_{\infty}<\infty.
Choose Î´âˆˆ(0,1)\delta\in(0,1) so that uÎ±âˆ—âˆ’1â‰¥1u^{\alpha\_{\*}-1}\geq 1 on (0,Î´)(0,\delta). Then for uâˆˆ(0,Î´)u\in(0,\delta),

|  |  |  |
| --- | --- | --- |
|  | Î¨iâ€‹jâ€‹(u)â‰¤Csâ€‹uÎ±âˆ—âˆ’1+â€–Î¨iâ€‹jbâ€–âˆâ‰¤(Cs+â€–Î¨iâ€‹jbâ€–âˆ)â€‹uÎ±âˆ—âˆ’1.\Psi\_{ij}(u)\leq C\_{s}u^{\alpha\_{\*}-1}+\|\Psi^{b}\_{ij}\|\_{\infty}\leq(C\_{s}+\|\Psi^{b}\_{ij}\|\_{\infty})\,u^{\alpha\_{\*}-1}. |  |

Taking the maximum over (i,j)=(1,2),(2,1)(i,j)=(1,2),(2,1) yields ([A.35](https://arxiv.org/html/2601.01871v1#A1.E35 "Equation A.35 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).

Proof of ([A.36](https://arxiv.org/html/2601.01871v1#A1.E36 "Equation A.36 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
Fix iâˆˆ{1,2}i\in\{1,2\} and set

|  |  |  |
| --- | --- | --- |
|  | Iiâ€‹(u):=âˆ«â„Î¨iâ€‹1â€‹(s)â€‹Î¨iâ€‹2â€‹(s+u)â€‹ğ‘‘s,uâˆˆâ„.I\_{i}(u):=\int\_{\mathbb{R}}\Psi\_{i1}(s)\Psi\_{i2}(s+u)\,ds,\qquad u\in\mathbb{R}. |  |

Non-negativity implies Iiâ€‹(u)â‰¥0I\_{i}(u)\geq 0. We will prove the upper bound.

Using ([A.37](https://arxiv.org/html/2601.01871v1#A1.E37 "Equation A.37 â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) and âˆ«â„fâ€‹(s)â€‹gâ€‹(s+u)â€‹ğ‘‘sâ‰¤â€–fâ€–1â€‹â€–gâ€–âˆ\int\_{\mathbb{R}}f(s)g(s+u)\,ds\leq\|f\|\_{1}\|g\|\_{\infty} for nonnegative f,gf,g, we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | Iiâ€‹(u)\displaystyle I\_{i}(u) | =âˆ«â„(Î¨iâ€‹1s+Î¨iâ€‹1b)â€‹(s)â€‹(Î¨iâ€‹2s+Î¨iâ€‹2b)â€‹(s+u)â€‹ğ‘‘s\displaystyle=\int\_{\mathbb{R}}(\Psi^{s}\_{i1}+\Psi^{b}\_{i1})(s)\,(\Psi^{s}\_{i2}+\Psi^{b}\_{i2})(s+u)\,ds |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ«â„Î¨iâ€‹1sâ€‹(s)â€‹Î¨iâ€‹2sâ€‹(s+u)â€‹ğ‘‘s+â€–Î¨iâ€‹1â€–1â€‹â€–Î¨iâ€‹2bâ€–âˆ+â€–Î¨iâ€‹1bâ€–âˆâ€‹â€–Î¨iâ€‹2â€–1,\displaystyle\leq\int\_{\mathbb{R}}\Psi^{s}\_{i1}(s)\Psi^{s}\_{i2}(s+u)\,ds+\|\Psi\_{i1}\|\_{1}\|\Psi^{b}\_{i2}\|\_{\infty}+\|\Psi^{b}\_{i1}\|\_{\infty}\|\Psi\_{i2}\|\_{1}, |  |

where we used Î¨iâ€‹ksâ‰¤Î¨iâ€‹k\Psi^{s}\_{ik}\leq\Psi\_{ik} and Î¨iâ€‹kbâ‰¤Î¨iâ€‹k\Psi^{b}\_{ik}\leq\Psi\_{ik}.
Since â€–Î¦iâ€‹jâ€–1=Î±iâ€‹j\|\Phi\_{ij}\|\_{1}=\alpha\_{ij} and â€–(Î¦(âˆ—m))iâ€‹jâ€–1=(ğœ¶m)iâ€‹j\|(\Phi^{(\*m)})\_{ij}\|\_{1}=(\boldsymbol{\alpha}^{m})\_{ij}, the assumption
Ïâ€‹(ğœ¶)<1\rho(\boldsymbol{\alpha})<1 implies â€–Î¨iâ€‹kâ€–1=âˆ‘mâ‰¥1(ğœ¶m)iâ€‹k<âˆ\|\Psi\_{ik}\|\_{1}=\sum\_{m\geq 1}(\boldsymbol{\alpha}^{m})\_{ik}<\infty.
By LemmaÂ [A.13](https://arxiv.org/html/2601.01871v1#A1.Thmlemma13 "Lemma A.13. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"), â€–Î¨iâ€‹kbâ€–âˆ<âˆ\|\Psi^{b}\_{ik}\|\_{\infty}<\infty. Hence, the last two terms are finite constants
independent of uu, and since Î±âˆ—<1\alpha\_{\*}<1 we may shrink Î´âˆˆ(0,1)\delta\in(0,1) so that these constants are absorbed by
Câ€‹|u|Î±âˆ—âˆ’1C|u|^{\alpha\_{\*}-1} on 0<|u|<Î´0<|u|<\delta (using |u|Î±âˆ—âˆ’1â‰¥1|u|^{\alpha\_{\*}-1}\geq 1 there).
Therefore, it suffices to show that

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«â„Î¨iâ€‹1sâ€‹(s)â€‹Î¨iâ€‹2sâ€‹(s+u)â€‹ğ‘‘sâ‰¤Câ€‹|u|Î±âˆ—âˆ’1,0<|u|<Î´.\int\_{\mathbb{R}}\Psi^{s}\_{i1}(s)\Psi^{s}\_{i2}(s+u)\,ds\leq C|u|^{\alpha\_{\*}-1},\qquad 0<|u|<\delta. |  | (A.38) |

For a,b>0a,b>0, define

|  |  |  |
| --- | --- | --- |
|  | fa,bBGâ€‹(u):=âˆ«â„haâ€‹(s)â€‹hbâ€‹(s+u)â€‹ğ‘‘s,uâˆˆâ„.f^{\mathrm{BG}}\_{a,b}(u):=\int\_{\mathbb{R}}h\_{a}(s)\,h\_{b}(s+u)\,ds,\qquad u\in\mathbb{R}. |  |

Then, fa,bBGf^{\mathrm{BG}}\_{a,b} is the probability density function of a bilateral gamma distribution [kuchler2008shapes] with parameters
  
(Î±+,Î»+,Î±âˆ’,Î»âˆ’)=(b,Î²,a,Î²)(\alpha\_{+},\lambda\_{+},\alpha\_{-},\lambda\_{-})=(b,\beta,a,\beta).
By kuchler2008shapes, as uâ†’0u\to 0 the density satisfies
fa,bBGâ€‹(u)=Oâ€‹(|u|a+bâˆ’1)f^{\mathrm{BG}}\_{a,b}(u)=O(|u|^{a+b-1}) if a+b<1a+b<1, and fa,bBGâ€‹(u)=Oâ€‹(Mâ€‹(|u|))f^{\mathrm{BG}}\_{a,b}(u)=O(M(|u|)) if a+b=1a+b=1, where MM is slowly varying at 0. If a+b>1a+b>1, then fa,bBGf^{\mathrm{BG}}\_{a,b} is bounded in a neighborhood of 0.
Consequently, for any a,b>0a,b>0 with a+b>Î±âˆ—a+b>\alpha\_{\*}, there exists Ca,b>0C\_{a,b}>0 and
Î´a,bâˆˆ(0,1)\delta\_{a,b}\in(0,1) such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | fa,bBGâ€‹(u)â‰¤Ca,bâ€‹|u|Î±âˆ—âˆ’1,0<|u|<Î´a,bf^{\mathrm{BG}}\_{a,b}(u)\leq C\_{a,b}|u|^{\alpha\_{\*}-1},\qquad 0<|u|<\delta\_{a,b} |  | (A.39) |

since Î±âˆ—<1\alpha^{\*}<1 by the assumption.
Next, by LemmaÂ [A.11](https://arxiv.org/html/2601.01871v1#A1.Thmlemma11 "Lemma A.11. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes"),
each Î¨iâ€‹ks\Psi^{s}\_{ik} is a finite nonnegative linear combination of gamma densities hah\_{a}. Hence, the left-hand side of
([A.38](https://arxiv.org/html/2601.01871v1#A1.E38 "Equation A.38 â€£ Proof of Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) is a finite nonnegative linear combination of fa,bBGâ€‹(u)f^{\mathrm{BG}}\_{a,b}(u).
If i=1i=1, then Î¨12s\Psi^{s}\_{12} only involves shapes bâ‰¥D12â‰¥Î±âˆ—b\geq D\_{12}\geq\alpha\_{\*}, while shapes aa in Î¨11s\Psi^{s}\_{11} are strictly positive; thus a+b>Î±âˆ—a+b>\alpha\_{\*}.
If i=2i=2, then Î¨21s\Psi^{s}\_{21} only involves shapes aâ‰¥D21â‰¥Î±âˆ—a\geq D\_{21}\geq\alpha\_{\*}, while shapes bb in Î¨22s\Psi^{s}\_{22} are strictly
positive; thus again a+b>Î±âˆ—a+b>\alpha\_{\*}.
Therefore, ([A.39](https://arxiv.org/html/2601.01871v1#A1.E39 "Equation A.39 â€£ Proof of Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")) applies to all pairs (a,b)(a,b) appearing in the linear combination, we can
take a common Î´>0\delta>0 and C>0C>0, which yields ([A.38](https://arxiv.org/html/2601.01871v1#A1.E38 "Equation A.38 â€£ Proof of Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")). This proves ([A.36](https://arxiv.org/html/2601.01871v1#A1.E36 "Equation A.36 â€£ Proposition A.1. â€£ A.7 Proof of Assumption [A2](ii) for LBHPG with gamma kernels â€£ Appendix A Proofs â€£ On lead-lag estimation of non-synchronously observed point processes")).
âˆ

## Appendix B Implementation and computational complexity

In this section, we discuss the efficient computation of the kernel density estimator g^hâ€‹(u)\hat{g}\_{h}(u) and the search strategy for its maximizer Î¸^h\hat{\theta}\_{h}.
In our implementation, the expected time complexity for computing Î¸^h\hat{\theta}\_{h} from observations on [0,T][0,T] with bandwidth hh scales as

|  |  |  |
| --- | --- | --- |
|  | {Oâ€‹(Tâ€‹logâ¡T+T2â€‹h),under AssumptionÂ [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i),Oâ€‹(Tâ€‹logâ¡T+T2â€‹hÎ±),under AssumptionÂ [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii) withÂ â€‹0<Î±<1.\begin{cases}O\!\left(T\log T+T^{2}h\right),&\text{under Assumption~\ref{ass:cpcf}(i)},\\ O\!\left(T\log T+T^{2}h^{\alpha}\right),&\text{under Assumption~\ref{ass:cpcf}(ii) with }0<\alpha<1.\end{cases} |  |

This is better than a naive Oâ€‹(T2)O(T^{2}) approach that evaluates g^hâ€‹(u)\hat{g}\_{h}(u) at each candidate uu by summing over all pairs, especially when the bandwidth hh is small.

### B.1 Algorithm for computing g^h\hat{g}\_{h} on a grid

Directly evaluating g^h\hat{g}\_{h} on a grid {u1,â€¦,uM}âŠ‚â„\{u\_{1},\dots,u\_{M}\}\subset\mathbb{R} may be computationally expensive, roughly scaling with the product of the grid size and the number of data pairs.
To reduce computational cost, we employ an algorithm that iterates over relevant timestamp pairs and distributes their kernel weights onto nearby grid points.
This approach is particularly efficient when the bandwidth hh is small relative to the gridâ€™s range.

Let N1N\_{1} and N2N\_{2} be the underlying point processes, observed over the window [0,T][0,T], and let
ğ’¯i:={ti,1<â‹¯<ti,ni}âŠ‚[0,T],ni:=Niâ€‹([0,T]),i=1,2\mathcal{T}\_{i}:=\{t\_{i,1}<\cdots<t\_{i,n\_{i}}\}\subset[0,T],\ n\_{i}:=N\_{i}([0,T]),\ i=1,2
denote the corresponding observed event times.
Let ğ’°={u1<â‹¯<uM}\mathcal{U}=\{u\_{1}<\cdots<u\_{M}\} be a sorted grid where we wish to evaluate the estimator, and define
umin:=u1u\_{\min}:=u\_{1} and umax:=uMu\_{\max}:=u\_{M}.
For any a<ba<b, define the set of relevant pairs in the lag window [a,b][a,b] and the corresponding set of differences by

|  |  |  |
| --- | --- | --- |
|  | ğ’«â€‹(a,b):={(x,y)âˆˆğ’¯1Ã—ğ’¯2:yâˆ’xâˆˆ[a,b]},Npairsâ€‹(a,b):=|ğ’«â€‹(a,b)|,\mathcal{P}(a,b):=\{(x,y)\in\mathcal{T}\_{1}\times\mathcal{T}\_{2}:\ y-x\in[a,b]\},\qquad N\_{\mathrm{pairs}}(a,b):=|\mathcal{P}(a,b)|, |  |

|  |  |  |
| --- | --- | --- |
|  | ğ’Ÿâ€‹(a,b):={yâˆ’x:(x,y)âˆˆğ’«â€‹(a,b)}âŠ‚[a,b].\mathcal{D}(a,b):=\{y-x:\ (x,y)\in\mathcal{P}(a,b)\}\subset[a,b]. |  |

AlgorithmÂ [1](https://arxiv.org/html/2601.01871v1#alg1 "Algorithm 1 â€£ B.1 Algorithm for computing ğ‘”Ì‚_â„ on a grid â€£ Appendix B Implementation and computational complexity â€£ On lead-lag estimation of non-synchronously observed point processes") outlines the procedure.
Instead of fixing uu and summing over all pairs, we iterate through each observed time xâˆˆğ’¯1x\in\mathcal{T}\_{1}.
Using binary search in ğ’¯2\mathcal{T}\_{2}, we identify the range of yâˆˆğ’¯2y\in\mathcal{T}\_{2} for which the difference
d=yâˆ’xd=y-x lies within the lag window [uminâˆ’h,umax+h][u\_{\min}-h,\,u\_{\max}+h], i.e., the set of lags that can influence at least one grid point through a bandwidth-hh kernel.
For each such difference dd, we find the subset of grid points in ğ’°âˆ©[dâˆ’h,d+h]\mathcal{U}\cap[d-h,d+h] (again via binary search) and accumulate the kernel contribution at those grid points.
Throughout this section, we assume that KK is supported on [âˆ’1,1][-1,1].

Algorithm 1  Computation of g^hâ€‹(u)\hat{g}\_{h}(u) on a grid

Sorted event times ğ’¯1\mathcal{T}\_{1}, ğ’¯2\mathcal{T}\_{2}, sorted grid ğ’°={u1,â€¦,uM}\mathcal{U}=\{u\_{1},\dots,u\_{M}\}, bandwidth hh,

kernel KK supported on [âˆ’1,1][-1,1].

Values G=(G1,â€¦,GM)G=(G\_{1},\dots,G\_{M}) corresponding to (g^hâ€‹(u1),â€¦,g^hâ€‹(uM))(\hat{g}\_{h}(u\_{1}),\dots,\hat{g}\_{h}(u\_{M})).

Initialize Gâ†(0,â€¦,0)G\leftarrow(0,\dots,0)

uminâ†u1,umaxâ†uMu\_{\min}\leftarrow u\_{1},\quad u\_{\max}\leftarrow u\_{M}

for xâˆˆğ’¯1x\in\mathcal{T}\_{1} do

Identify indices [jstart,jend][j\_{\text{start}},j\_{\text{end}}] for ğ’¯2âˆ©[x+uminâˆ’h,x+umax+h]\mathcal{T}\_{2}\cap[x+u\_{\min}-h,\ x+u\_{\max}+h]

for jâ†jstartj\leftarrow j\_{\text{start}} to jendj\_{\text{end}} do

yâ†ğ’¯2â€‹[j]y\leftarrow\mathcal{T}\_{2}[j]

dâ†yâˆ’xd\leftarrow y-x

Identify indices [kstart,kend][k\_{\text{start}},k\_{\text{end}}] for ğ’°âˆ©[dâˆ’h,d+h]\mathcal{U}\cap[d-h,\ d+h]

for kâ†kstartk\leftarrow k\_{\text{start}} to kendk\_{\text{end}} do

Gkâ†Gk+1hâ€‹Kâ€‹(dâˆ’ukh)G\_{k}\leftarrow G\_{k}+\frac{1}{h}K\!\left(\frac{d-u\_{k}}{h}\right)

end for

end for

end for

Scale GG by Tn1â€‹n2\frac{T}{n\_{1}n\_{2}}, i.e., Gâ†Tn1â€‹n2â€‹GG\leftarrow\frac{T}{n\_{1}n\_{2}}G

return GG

##### Computational complexity.

Only pairs in the lag window [uminâˆ’h,umax+h][u\_{\min}-h,\ u\_{\max}+h] contribute to g^h\hat{g}\_{h} evaluated on ğ’°\mathcal{U}, and the number of such pairs is
Npairsâ€‹(uminâˆ’h,umax+h)N\_{\mathrm{pairs}}(u\_{\min}-h,\ u\_{\max}+h).
For each xâˆˆğ’¯1x\in\mathcal{T}\_{1}, we locate the index range of
ğ’¯2âˆ©[x+uminâˆ’h,x+umax+h]\mathcal{T}\_{2}\cap[x+u\_{\min}-h,\ x+u\_{\max}+h] by binary search in ğ’¯2\mathcal{T}\_{2}, which costs Oâ€‹(logâ¡n2)O(\log n\_{2}) per xx
(and thus Oâ€‹(n1â€‹logâ¡n2)O(n\_{1}\log n\_{2}) in total).
For each relevant pair (x,y)âˆˆğ’«â€‹(uminâˆ’h,umax+h)(x,y)\in\mathcal{P}(u\_{\min}-h,\ u\_{\max}+h) with d=yâˆ’xd=y-x, we perform a binary search on ğ’°\mathcal{U} to locate
ğ’°âˆ©[dâˆ’h,d+h]\mathcal{U}\cap[d-h,d+h], which costs Oâ€‹(logâ¡M)O(\log M), and then update all grid points in that subarray.
Let Mh:=supuâˆˆâ„|ğ’°âˆ©[uâˆ’h,u+h]|M\_{h}:=\sup\_{u\in\mathbb{R}}|\mathcal{U}\cap[u-h,u+h]| denote the maximum local grid occupancy at scale hh.
Thus, the total complexity is bounded by

|  |  |  |
| --- | --- | --- |
|  | Oâ€‹(n1â€‹logâ¡n2+Npairsâ€‹(uminâˆ’h,umax+h)â€‹(logâ¡M+Mh)).O\!\left(n\_{1}\log n\_{2}+N\_{\mathrm{pairs}}(u\_{\min}-h,\ u\_{\max}+h)\bigl(\log M+M\_{h}\bigr)\right). |  |

This is significantly faster than the naive Oâ€‹(Mâ‹…Npairsâ€‹(uminâˆ’h,umax+h))O\!\left(M\cdot N\_{\mathrm{pairs}}(u\_{\min}-h,\ u\_{\max}+h)\right) approach when Mhâ‰ªMM\_{h}\ll M,
which typically occurs when the bandwidth hh is small.
As suggested by TheoremÂ [4.1](https://arxiv.org/html/2601.01871v1#S4.Thmtheorem1 "Theorem 4.1. â€£ 4 New estimator â€£ On lead-lag estimation of non-synchronously observed point processes"), small bandwidths are desirable in practice, especially when gg exhibits a sharp peak,
where the proposed implementation yields a substantial computational gain.

### B.2 Finding the maximizer of g^h\hat{g}\_{h}

To compute the estimator Î¸^h\hat{\theta}\_{h}, we need to find the global maximizer of g^hâ€‹(u)\hat{g}\_{h}(u) within the range [âˆ’r,r][-r,r].
The objective function g^h\hat{g}\_{h} may have many local optima, making it difficult for standard numerical optimization to converge to the global maximum.
However, when KK is piecewise linear, g^hâ€‹(u)\hat{g}\_{h}(u) is also piecewise linear.
Hence, a maximizer over [âˆ’r,r][-r,r] can be found by evaluating g^h\hat{g}\_{h} only at the kink locations induced by the differences d=yâˆ’xd=y-x,
xâˆˆğ’¯1x\in\mathcal{T}\_{1}, yâˆˆğ’¯2y\in\mathcal{T}\_{2}.

Let ğ’Ÿr,h:=ğ’Ÿâ€‹(âˆ’râˆ’h,r+h)\mathcal{D}\_{r,h}:=\mathcal{D}(-r-h,\ r+h) denote the set of lag differences in the window [âˆ’râˆ’h,r+h][-r-h,r+h].
In particular, for the triangular kernel Ktriâ€‹(x)=(1âˆ’|x|)â€‹ğŸ[âˆ’1,1]â€‹(x)K^{\mathrm{tri}}(x)=(1-|x|)\mathbf{1}\_{[-1,1]}(x), the function may change slope only at
u=dâˆ’h,u=d,u=d+hu=d-h,\ u=d,\ u=d+h for each lag difference dâˆˆğ’Ÿr,hd\in\mathcal{D}\_{r,h}.
Therefore, to obtain the maximizer Î¸^h\hat{\theta}\_{h}, it suffices to evaluate g^h\hat{g}\_{h} on the candidate set

|  |  |  |
| --- | --- | --- |
|  | ğ’°kink:=(ğ’Ÿr,hâˆª(ğ’Ÿr,h+h)âˆª(ğ’Ÿr,hâˆ’h)âˆª{âˆ’r,r})âˆ©[âˆ’r,r].\mathcal{U}\_{\mathrm{kink}}:=\Bigl(\mathcal{D}\_{r,h}\ \cup\ \bigl(\mathcal{D}\_{r,h}+h\bigr)\ \cup\ \bigl(\mathcal{D}\_{r,h}-h\bigr)\cup\ \{-r,r\}\Bigr)\cap[-r,r]. |  |

In an implementation, it is recommended to remove duplicates in ğ’°kink\mathcal{U}\_{\mathrm{kink}}
before sorting; otherwise the grid may contain repeated points and incur unnecessary work.

##### Computational complexity.

The set ğ’Ÿr,h\mathcal{D}\_{r,h} can be constructed while enumerating the relevant pairs ğ’«â€‹(âˆ’râˆ’h,r+h)\mathcal{P}(-r-h,r+h), which takes
Oâ€‹(Npairsâ€‹(âˆ’râˆ’h,r+h))O\!\left(N\_{\mathrm{pairs}}(-r-h,\ r+h)\right) time up to constant-factor overhead.
Building ğ’°kink\mathcal{U}\_{\mathrm{kink}} from ğ’Ÿr,h\mathcal{D}\_{r,h} is linear in |ğ’°kink||\mathcal{U}\_{\mathrm{kink}}|, and we may sort
ğ’°kink\mathcal{U}\_{\mathrm{kink}} once to apply AlgorithmÂ [1](https://arxiv.org/html/2601.01871v1#alg1 "Algorithm 1 â€£ B.1 Algorithm for computing ğ‘”Ì‚_â„ on a grid â€£ Appendix B Implementation and computational complexity â€£ On lead-lag estimation of non-synchronously observed point processes").
Evaluating g^h\hat{g}\_{h} on ğ’°kink\mathcal{U}\_{\mathrm{kink}} using AlgorithmÂ [1](https://arxiv.org/html/2601.01871v1#alg1 "Algorithm 1 â€£ B.1 Algorithm for computing ğ‘”Ì‚_â„ on a grid â€£ Appendix B Implementation and computational complexity â€£ On lead-lag estimation of non-synchronously observed point processes") has the same form as above, with MM replaced by
|ğ’°kink||\mathcal{U}\_{\mathrm{kink}}| and with MhM\_{h} defined as above but computed on the grid ğ’°kink\mathcal{U}\_{\mathrm{kink}}:

|  |  |  |
| --- | --- | --- |
|  | Oâ€‹(n1â€‹logâ¡n2+Npairsâ€‹(âˆ’râˆ’h,r+h)â€‹(logâ¡|ğ’°kink|+Mh)).O\!\left(n\_{1}\log n\_{2}+N\_{\mathrm{pairs}}(-r-h,\ r+h)\bigl(\log|\mathcal{U}\_{\mathrm{kink}}|+M\_{h}\bigr)\right). |  |

Finally, the maximizer is obtained by a single pass over the evaluated values, which costs Oâ€‹(|ğ’°kink|)O(|\mathcal{U}\_{\mathrm{kink}}|).

##### Scaling in TT and hh.

For the simple stationary bivariate point process N=(N1,N2)N=(N\_{1},N\_{2}) with intensities Î»1,Î»2\lambda\_{1},\lambda\_{2} and CPCF gg, we have Eâ¡[ni]=Î»iâ€‹T\operatorname{E}[n\_{i}]=\lambda\_{i}T for i=1,2i=1,2.
Moreover, by the definition of the cross-intensity function, we have

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[Npairsâ€‹(a,b)]=âˆ«(0,T]2ğŸâ€‹{yâˆ’xâˆˆ[a,b]}â€‹Î»12â€‹(yâˆ’x)â€‹ğ‘‘xâ€‹ğ‘‘yâ‰ˆÎ»1â€‹Î»2â€‹Tâ€‹âˆ«abgâ€‹(u)â€‹ğ‘‘u.\operatorname{E}\!\left[N\_{\mathrm{pairs}}(a,b)\right]=\int\_{(0,T]^{2}}\mathbf{1}\{y-x\in[a,b]\}\,\lambda\_{12}(y-x)\,dx\,dy\approx\lambda\_{1}\lambda\_{2}\,T\int\_{a}^{b}g(u)\,du. |  |

If Tâ‰«r+hT\gg r+h and [a,b]âŠ‚[âˆ’râˆ’h,r+h][a,b]\subset[-r-h,r+h], then Eâ¡[Npairsâ€‹(a,b)]â‰Î»1â€‹Î»2â€‹Tâ€‹âˆ«abgâ€‹(u)â€‹ğ‘‘u\operatorname{E}[N\_{\mathrm{pairs}}(a,b)]\asymp\lambda\_{1}\lambda\_{2}\,T\int\_{a}^{b}g(u)\,du.
In particular,

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[Npairsâ€‹(âˆ’râˆ’h,r+h)]=Oâ€‹(T),Eâ¡[n1â€‹logâ¡n2]=Oâ€‹(Tâ€‹logâ¡T),\operatorname{E}\!\left[N\_{\mathrm{pairs}}(-r-h,r+h)\right]=O(T),\qquad\operatorname{E}[n\_{1}\log n\_{2}]=O(T\log T), |  |

where the hidden constant depends on gg through its mass on [âˆ’râˆ’h,r+h][-r-h,r+h].

Next, note that |ğ’°kink|â‰¤3â€‹|ğ’Ÿr,h|+2â‰¤3â€‹Npairsâ€‹(âˆ’râˆ’h,r+h)+2|\mathcal{U}\_{\mathrm{kink}}|\leq 3|\mathcal{D}\_{r,h}|+2\leq 3N\_{\mathrm{pairs}}(-r-h,r+h)+2,
so |ğ’°kink|=Oâ€‹(T)|\mathcal{U}\_{\mathrm{kink}}|=O(T) in expectation, and the one-time sorting cost is Oâ€‹(Tâ€‹logâ¡T)O(T\log T).
For the local update cost on the kink grid, observe that for any uâˆˆ[âˆ’r,r]u\in[-r,r],

|  |  |  |
| --- | --- | --- |
|  | |ğ’°kinkâˆ©[uâˆ’h,u+h]|â‰¤â€„3â€‹|ğ’Ÿr,hâˆ©[uâˆ’2â€‹h,u+2â€‹h]|+2â‰¤â€„3â€‹Npairsâ€‹(uâˆ’2â€‹h,u+2â€‹h)+2.|\mathcal{U}\_{\mathrm{kink}}\cap[u-h,u+h]|\;\leq\;3\,|\mathcal{D}\_{r,h}\cap[u-2h,u+2h]|+2\;\leq\;3\,N\_{\mathrm{pairs}}(u-2h,u+2h)+2. |  |

Taking expectations yields

|  |  |  |
| --- | --- | --- |
|  | Eâ¡[|ğ’°kinkâˆ©[uâˆ’h,u+h]|]=Oâ€‹(Tâ€‹âˆ«uâˆ’2â€‹hu+2â€‹hgâ€‹(v)â€‹ğ‘‘v).\operatorname{E}\!\left[|\mathcal{U}\_{\mathrm{kink}}\cap[u-h,u+h]|\right]=O\!\left(T\int\_{u-2h}^{u+2h}g(v)\,dv\right). |  |

Taking the supremum over uâˆˆ[âˆ’r,r]u\in[-r,r] gives the worst-case bound

|  |  |  |
| --- | --- | --- |
|  | Mh=Oâ€‹(Tâ€‹supuâˆˆ[âˆ’r,r]âˆ«uâˆ’2â€‹hu+2â€‹hgâ€‹(v)â€‹ğ‘‘v).M\_{h}=O\!\left(T\sup\_{u\in[-r,r]}\int\_{u-2h}^{u+2h}g(v)\,dv\right). |  |

In particular, if gg is bounded (e.g., under [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(i)), then
âˆ«uâˆ’2â€‹hu+2â€‹hgâ€‹(v)â€‹ğ‘‘v=Oâ€‹(h)\int\_{u-2h}^{u+2h}g(v)\,dv=O(h) uniformly in uu, so Mh=Oâ€‹(Tâ€‹h)M\_{h}=O(Th) and the expected time bound
reduces to Oâ€‹(Tâ€‹logâ¡T+T2â€‹h)O(T\log T+T^{2}h).
If gg is unbounded at Î¸âˆ—\theta^{\ast} as in [[A2]](https://arxiv.org/html/2601.01871v1#S3.I2.i1 "Item [A2] â€£ 3 Proposed framework â€£ On lead-lag estimation of non-synchronously observed point processes")(ii), then
âˆ«Î¸âˆ—âˆ’2â€‹hÎ¸âˆ—+2â€‹hgâ€‹(v)â€‹ğ‘‘v=Oâ€‹(hÎ±)\int\_{\theta^{\ast}-2h}^{\theta^{\ast}+2h}g(v)\,dv=O(h^{\alpha}).
Thus, we may have Mh=Oâ€‹(Tâ€‹hÎ±)M\_{h}=O(Th^{\alpha}), leading to an expected time bound of Oâ€‹(Tâ€‹logâ¡T+T2â€‹hÎ±)O(T\log T+T^{2}h^{\alpha}).
On the other hand, the naive implementation costs Oâ€‹(NpairsÃ—|ğ’°kink|)â‰ˆOâ€‹(T2)O(N\_{\mathrm{pairs}}\times|\mathcal{U}\_{\mathrm{kink}}|)\approx O(T^{2}).

## Appendix C Bandwidth selection by cross-validation

In this section, we introduce additional bandwidth-selection methods for the estimator Î¸^h\hat{\theta}\_{h} based on cross-validation and assess their performance in simulation studies.

In the context of modal regression, chen2016nonparametric propose choosing the bandwidth by minimizing the size of prediction sets associated with the modal regression function, while zhou2019bandwidth introduce a cross-validation criterion (CVM) that penalizes the squared distance between the responses and the estimated modal set and includes an explicit penalty for the number of modes.
Motivated by these developments, we design a cross-validation scheme that directly evaluates how well the maximizer set obtained from the training part of the point process predicts the empirical lag differences observed in the test part.

Fix an integer Kcvâ‰¥2K\_{\mathrm{cv}}\geq 2 and split the observation window [0,T][0,T] into KcvK\_{\mathrm{cv}} disjoint subintervals
I1,â€¦,IKcvI\_{1},\dots,I\_{K\_{\mathrm{cv}}} of equal length. Here KcvK\_{\mathrm{cv}} denotes the number of folds. For the jjth fold, we regard IjI\_{j} as a test interval and
[0,T]âˆ–Ij[0,T]\setminus I\_{j} as the corresponding training interval.
On the training interval we compute the kernel estimator g^h(âˆ’j)\hat{g}\_{h}^{(-j)} based on
Nâˆ©([0,T]âˆ–Ij)N\cap([0,T]\setminus I\_{j}) and its (possibly set-valued) maximizer set

|  |  |  |
| --- | --- | --- |
|  | Mh(âˆ’j):=argâ€‹maxuâˆˆ[âˆ’r,r]â¡g^h(âˆ’j)â€‹(u),hâˆˆâ„‹T,M\_{h}^{(-j)}:=\operatorname\*{arg\,max}\_{u\in[-r,r]}\hat{g}^{(-j)}\_{h}(u),\qquad h\in\mathcal{H}\_{T}, |  |

where â„‹T\mathcal{H}\_{T} is the finite bandwidth grid.

For a set
MâŠ‚[âˆ’r,r]M\subset[-r,r] and zâˆˆâ„z\in\mathbb{R} we write

|  |  |  |
| --- | --- | --- |
|  | dâ€‹(z,M):=infuâˆˆM|zâˆ’u|d(z,M):=\inf\_{u\in M}|z-u| |  |

for the distance from zz to MM. Given a test interval IjI\_{j}, we define the set of observed lag
differences restricted to [âˆ’r,r][-r,r] by

|  |  |  |
| --- | --- | --- |
|  | Î”j(r):={yâˆ’x;xâˆˆğ’¯1,j,yâˆˆğ’¯2,j,âˆ’râ‰¤yâˆ’xâ‰¤r},\Delta\_{j}(r):=\bigl\{y-x;x\in\mathcal{T}\_{1,j},\ y\in\mathcal{T}\_{2,j},\ -r\leq y-x\leq r\bigr\}, |  |

where ğ’¯i,j\mathcal{T}\_{i,j} denotes the (finite) set of event times of NiN\_{i} that fall in IjI\_{j}
for iâˆˆ{1,2}i\in\{1,2\}. We interpret Î”jâ€‹(r)\Delta\_{j}(r) as a multiset, i.e., lag differences are counted
with multiplicity, and write nj:=|Î”jâ€‹(r)|n\_{j}:=|\Delta\_{j}(r)| for the number of elements.
In practice, the fold length should be chosen large relative to rr so that each IjI\_{j} contains
enough pairs with lag in [âˆ’r,r][-r,r].
When njâ‰¥1n\_{j}\geq 1, we enumerate the elements of Î”jâ€‹(r)\Delta\_{j}(r) as (dj,1,â€¦,dj,nj)(d\_{j,1},\dots,d\_{j,n\_{j}}) (in an arbitrary order) and introduce the
distances

|  |  |  |
| --- | --- | --- |
|  | Î´j,â„“â€‹(M):=dâ€‹(dj,â„“,M),â„“=1,â€¦,nj,\delta\_{j,\ell}(M):=d(d\_{j,\ell},M),\qquad\ell=1,\dots,n\_{j}, |  |

with order statistics
Î´j,(1)â€‹(M)â‰¤â‹¯â‰¤Î´j,(nj)â€‹(M)\delta\_{j,(1)}(M)\leq\cdots\leq\delta\_{j,(n\_{j})}(M).
Fix a trimming parameter Ï„âˆˆ(0,1]\tau\in(0,1] and a minimum count nminâˆˆâ„•n\_{\min}\in\mathbb{N}, and set

|  |  |  |
| --- | --- | --- |
|  | kj:=maxâ¡{âŒˆÏ„â€‹njâŒ‰,nmin},Îµjâ€‹(M):={Î´j,(kj)â€‹(M),njâ‰¥kj,+âˆ,nj<kj.k\_{j}:=\max\{\lceil\tau n\_{j}\rceil,\ n\_{\min}\},\qquad\varepsilon\_{j}(M):=\begin{cases}\delta\_{j,(k\_{j})}(M),&n\_{j}\geq k\_{j},\\[2.0pt] +\infty,&n\_{j}<k\_{j}.\end{cases} |  |

If nj<kjn\_{j}<k\_{j}, we set Lnearestâ€‹(M;Ij)=+âˆL\_{\mathrm{nearest}}(M;I\_{j})=+\infty, regardless of MM, effectively discarding bandwidths for which the test fold contains too few lag differences.
Under this notation, we consider the following loss functions on IjI\_{j} for a finite candidate maximizer set MâŠ‚[âˆ’r,r]M\subset[-r,r] (so |M||M| is its cardinality):

* â€¢

  MSE-type loss:

  |  |  |  |
  | --- | --- | --- |
  |  | Lmseâ€‹(M;Ij):=|M|2njâ€‹âˆ‘â„“=1njÎ´j,â„“â€‹(M)2,L\_{\mathrm{mse}}(M;I\_{j}):=\frac{|M|^{2}}{n\_{j}}\sum\_{\ell=1}^{n\_{j}}\delta\_{j,\ell}(M)^{2}, |  |

  with the convention that folds with nj=0n\_{j}=0 are excluded from the CV average.
  The factor |M|2|M|^{2} penalizes bandwidths that produce many maximizers, playing a stabilizing role in the spirit of zhou2019bandwidth.
* â€¢

  Nearest-range loss:

  |  |  |  |
  | --- | --- | --- |
  |  | Lnearestâ€‹(M;Ij):=Lebâ€‹({xâˆˆâ„:dâ€‹(x,M)â‰¤Îµjâ€‹(M)}).L\_{\mathrm{nearest}}(M;I\_{j}):=\mathrm{Leb}\bigl(\{x\in\mathbb{R}:d(x,M)\leq\varepsilon\_{j}(M)\}\bigr). |  |

  The set
  {xâˆˆâ„:dâ€‹(x,M)â‰¤Îµ}\{x\in\mathbb{R}:d(x,M)\leq\varepsilon\} is the Îµ\varepsilon-neighborhood of MM, and
  Lebâ€‹(â‹…)\mathrm{Leb}(\cdot) is its total length. By construction, Îµjâ€‹(M)\varepsilon\_{j}(M) is chosen
  so that at least kj=maxâ¡{âŒˆÏ„â€‹njâŒ‰,nmin}k\_{j}=\max\{\lceil\tau n\_{j}\rceil,n\_{\min}\} of the test lag differences
  lie within distance Îµjâ€‹(M)\varepsilon\_{j}(M) of MM, so Lnearestâ€‹(M;Ij)L\_{\mathrm{nearest}}(M;I\_{j}) is the
  length of the smallest neighborhood of MM covering that trimmed fraction. The minimum
  count nminn\_{\min} improves numerical stability. This loss function is based on the
  prediction set approach of chen2016nonparametric.

Let J:={jâˆˆ{1,â€¦,Kcv}:njâ‰¥1}J:=\{j\in\{1,\dots,K\_{\mathrm{cv}}\}:n\_{j}\geq 1\} denote the set of folds with at least one lag
difference in [âˆ’r,r][-r,r].
Given a choice of loss function Lâˆˆ{Lmse,Lnearest}L\in\{L\_{\mathrm{mse}},L\_{\mathrm{nearest}}\}, we define the
KcvK\_{\mathrm{cv}}-fold CV score for hâˆˆâ„‹Th\in\mathcal{H}\_{T} by

|  |  |  |
| --- | --- | --- |
|  | CVâ€‹(h):=1|J|â€‹âˆ‘jâˆˆJLâ€‹(Mh(âˆ’j);Ij).\mathrm{CV}(h):=\frac{1}{|J|}\sum\_{j\in J}L\bigl(M\_{h}^{(-j)};I\_{j}\bigr). |  |

Our cross-validated bandwidth is then chosen as

|  |  |  |
| --- | --- | --- |
|  | h^CVâˆˆargâ¡minhâˆˆâ„‹Tâ¡CVâ€‹(h)\hat{h}\_{\mathrm{CV}}\in\arg\min\_{h\in\mathcal{H}\_{T}}\mathrm{CV}(h) |  |

If the minimizer is not unique, we select the smallest hh in â„‹T\mathcal{H}\_{T}.
We finally obtain the adaptive estimator Î¸^h^CV\hat{\theta}\_{\hat{h}\_{\mathrm{CV}}}.

To compare the performance of different loss functions and their accompanying tuning parameters, we conduct a series of simulation experiments under the following common design. The candidate bandwidths are hâˆˆ{10âˆ’1,10âˆ’2,10âˆ’3,10âˆ’4,10âˆ’5,10âˆ’6}h\in\{10^{-1},10^{-2},10^{-3},10^{-4},10^{-5},10^{-6}\}, r=1r=1, and the observation window is [0,T][0,T]. The observation horizon takes the values Tâˆˆ{1000,2000,4000,8000}T\in\{1000,2000,4000,8000\}; for each combination of model, estimator, and TT, we generate 50005000 Monte Carlo replicates.
The cross-validation criteria considered are the nearest-range loss LnearestL\_{\mathrm{nearest}} with trimming levels Ï„âˆˆ{0.01,0.025,0.05}\tau\in\{0.01,0.025,0.05\} and the MSE-type loss LmseL\_{\mathrm{mse}}.
For comparison, we also include the Lepski selector with AT=logâ¡logâ¡TA\_{T}=\log\log T.
In the plots, the nearest-range CV curves for different Ï„\tau are distinguished by a red color gradient; the MSE-based CV curves are shown in blue; and the curve of the Lepski estimator is shown in green.
We set Kcv=5K\_{\mathrm{cv}}=5 and nmin=5n\_{\min}=5. For reference, each panel also shows the theoretical rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} as a black dashed line.

![Refer to caption](simulations/graphs/sensitivity_cv_all_scenarios_nearest2-mse-lepski_loglogt.png)


Figure 6: Performance comparisons between the bandwidth-selection methods across scenarios: RMSE versus TT on logâ€“log axes for CV using LnearestL\_{\mathrm{nearest}} (red gradient by Ï„\tau), CV using LmseL\_{\mathrm{mse}} (blue), and Lepskiâ€™s method with AT=logâ¡logâ¡TA\_{T}=\log\log T (green); the dashed black line shows the theoretical rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}}.

Figure [6](https://arxiv.org/html/2601.01871v1#A3.F6 "Figure 6 â€£ Appendix C Bandwidth selection by cross-validation â€£ On lead-lag estimation of non-synchronously observed point processes") compares the finite-sample performance of the different bandwidth selection schemes across the six data-generating models described in Section [5.1](https://arxiv.org/html/2601.01871v1#S5.SS1 "5.1 Models â€£ 5 Simulation study â€£ On lead-lag estimation of non-synchronously observed point processes"). Several systematic patterns emerge.

First, the cross-validation criterion based on the MSE-type loss is somewhat unstable.
In five out of the six models, the RMSE of the MSE-CV estimator decreases only slowly, and sometimes not at all, as TT increases, compared to the theoretical slope. This suggests that the MSE-type loss is not well-suited to selecting the bandwidth for our cases.

The nearest-range loss LnearestL\_{\mathrm{nearest}} behaves more favorably, but its performance depends on the trimming parameter Ï„\tau. For models with sharper CPCFs, i.e., with Î±\alpha smaller than 11, smaller values of Ï„\tau tend to work better.
In contrast, for smoother models with Î±>1\alpha>1, larger values of Ï„\tau become competitive or even preferable.
In other words, the optimal choice of Ï„\tau appears to be Î±\alpha-dependent: aggressive trimming is beneficial when gg has a very sharp peak, whereas milder trimming is adequate when gg is flatter around its maximum.
A notable exception is the asymmetric Hawkes model (hawkes\_gamma\_asym).
In this case, the nearest-range CV estimator improves more slowly and less regularly with TT
across the Ï„\tau-values considered. One possible contributing factor is that
LnearestL\_{\mathrm{nearest}} is built from symmetric neighborhoods of the estimated maximizer set,
while the within-fold lag differences in this asymmetric setting may be skewed in finite samples;
in such cases, symmetric neighborhoods may be less informative for selecting hh.

When compared with the Lepski-type procedure, the nearest-range CV estimator is inferior in the small-Î±\alpha models. Indeed, for hawkes\_gamma\_sym, hawkes\_gamma\_asym, and ns\_gamma\_1, the Lepski estimator shows lower RMSE.
For smoother models with Î±>1\alpha>1, however, the best-tuned nearest-range CV estimator becomes competitive.
Overall, these experiments indicate that cross-validation based on LnearestL\_{\mathrm{nearest}} is a promising alternative, but it may require a delicate choice of Ï„\tau.

Taken together, our findings suggest the following practical recommendation.
Among the bandwidth selectors we have examined, the Lepski method stands out as the most robust option. It requires only the slowly diverging threshold ATA\_{T}, shows stable behavior across all models, and nearly attains the minimax rate Tâˆ’1/Î²Î±T^{-1/\beta\_{\alpha}} both theoretically and in numerical experiments.
Nearest-range cross-validation can be competitive, especially for smoother CPCFs, but it requires
choosing the trimming level Ï„\tau in addition to the bandwidth, and its best choice is not yet
well understood theoretically.
For this reason, we currently recommend the Lepski-type bandwidth choice as a default method for estimating the lead-lag time.

##### Acknowledgements

We thank participants at the â€œBig Data and Artificial Intelligence in Econometrics, Finance, and Statisticsâ€ workshop at University of Chicago, October 2-4, 2025, the quantitative finance seminar at National University of Singapore, October 24, 2025, the KAKENHI symposium at Tsukuba University, October 30-31, 2025, Nakanoshima Workshop at Osaka University, December 5-6, 2025, and CFE-CMStatistics 2025 at University of London, December 13-15, 2025, for insightful comments and constructive suggestions on this work.
Takaaki Shiotaniâ€™s work was partly supported by Grant-in-Aid for JSPS Fellows (25KJ0933) and World-leading Innovative Graduate Study for Frontiers of Mathematical Sciences and Physics.
Yuta Koikeâ€™s work was partly supported by JST CREST Grant Number JPMJCR2115 and JSPS KAKENHI Grant Numbers JP22H00834, JP22H01139.