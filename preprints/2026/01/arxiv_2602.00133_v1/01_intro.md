---
authors:
- Avi Arora
- Ritesh Malpani
doc_id: arxiv:2602.00133v1
family_id: arxiv:2602.00133
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: 'PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading
  Agents on Prediction Markets'
url_abs: http://arxiv.org/abs/2602.00133v1
url_html: https://arxiv.org/html/2602.00133v1
venue: arXiv q-fin
version: 1
year: 2026
---


Avi Arora
  
avi@oddpool.com
Oddpool: [oddpool.com](https://oddpool.com)  |  Code: [PredictionMarketBench](https://github.com/Oddpool/PredictionMarketBench).
  
Ritesh Malpani
  
ritesh.malpani7@gmail.com

###### Abstract

Prediction markets offer a natural testbed for trading agents: contracts have binary payoffs, prices can be interpreted as probabilities, and realized performance depends critically on market microstructure, fees, and settlement risk. We introduce PredictionMarketBench, a SWE-bench-style benchmark for evaluating algorithmic and LLM-based trading agents on prediction markets via deterministic, event-driven replay of historical limit-order-book and trade data.

PredictionMarketBench standardizes (i) episode construction from raw exchange streams (orderbooks, trades, lifecycle, settlement), (ii) an execution-realistic simulator with maker/taker semantics and fee modeling, and (iii) a tool-based agent interface that supports both classical strategies and tool-calling LLM agents with reproducible trajectories. We release four Kalshi-based episodes spanning cryptocurrency, weather, and sports.

We report baseline results for a RandomAgent, a tool-calling LLM agent (gpt-4.1-nano), and a classic Bollinger Bands mean-reversion strategy, illustrating that naive activity can underperform due to transaction costs and settlement losses, while fee-aware algorithmic alphas can remain competitive in volatile episodes.

## 1 Introduction

Prediction markets are exchange-traded contracts whose prices can often be interpreted as collective probabilistic forecasts about real-world events. Under appropriate design and participation, they can aggregate dispersed information and yield accurate predictions [[17](https://arxiv.org/html/2602.00133v1#bib.bib1 "Prediction markets"), [1](https://arxiv.org/html/2602.00133v1#bib.bib6 "The promise of prediction markets")]. Empirically, election prediction markets such as the Iowa Electronic Markets have been shown to outperform traditional polls at longer horizons [[3](https://arxiv.org/html/2602.00133v1#bib.bib11 "Prediction market accuracy in the long run")], while the broader literature highlights the importance of market design and susceptibility to manipulation in determining forecast quality [[4](https://arxiv.org/html/2602.00133v1#bib.bib12 "Market design, manipulation, and accuracy in political prediction markets: lessons from the iowa electronic markets")].

A key practical feature of modern prediction markets is that liquidity may be thin or fragmented across many related questions. Automated market makers and cost-function market makers (e.g., LMSR) provide continuous pricing under sparse order flow and have become foundational to the study of prediction market design [[9](https://arxiv.org/html/2602.00133v1#bib.bib7 "Combinatorial information market design")]. At the same time, many venues (including regulated exchanges) operate as electronic limit-order markets, where execution outcomes depend on microstructure: spreads, queue position, and fees [[16](https://arxiv.org/html/2602.00133v1#bib.bib8 "Market microstructure theory")].

These properties make prediction markets a compelling but challenging environment for algorithmic and AI trading agents. Agents must reason under discrete settlement payoffs, horizon-dependent risk, and high transaction costs; furthermore, naive backtests can be misleading due to selection effects and overfitting [[2](https://arxiv.org/html/2602.00133v1#bib.bib3 "The probability of backtest overfitting")]. Prior work has studied prediction markets through agent-based modeling and trader behavior, emphasizing how heterogeneous beliefs and bounded-rational strategies map into aggregate price dynamics [[18](https://arxiv.org/html/2602.00133v1#bib.bib13 "Agent-based modeling of the prediction markets")].

Recently, LLM-based and agentic AI systems have begun to be applied to prediction markets and related financial tasks, for example by using natural-language understanding to cluster market questions and derive tradable signals [[7](https://arxiv.org/html/2602.00133v1#bib.bib14 "Semantic trading: agentic ai for clustering and relationship discovery in prediction markets")]. However, systematic evaluation remains difficult: results often depend on dataset choice, execution assumptions, and opaque experimental details.

This paper introduces PredictionMarketBench, an event-driven benchmark framework for backtesting trading agents on prediction-market data with execution-realistic replay. The design is inspired by harness-first evaluation approaches in other agent domains—most notably SWE-bench, which evaluates agents against standardized task instances with an executable harness [[11](https://arxiv.org/html/2602.00133v1#bib.bib2 "SWE-bench: can language models resolve real-world GitHub issues?")]. PredictionMarketBench adapts this idea to trading: we define standardized *episodes* (events), a deterministic replay *simulator* over historical market data streams, and a consistent set of metrics for apples-to-apples comparisons across heterogeneous agent implementations.

Our primary contributions are:

* •

  An episode construction pipeline that converts raw exchange data into self-contained benchmark instances (metadata, orderbooks, trades, settlements).
* •

  A deterministic, event-driven simulator supporting maker/taker execution semantics and fee modeling appropriate for binary contracts.
* •

  An agent interface and benchmark harness that standardize evaluation, logging, and metric computation for both algorithmic and tool-calling LLM agents.

## 2 PredictionMarketBench

PredictionMarketBench is a replay-based benchmark for evaluating trading agents on *binary event contracts* (YES/NO) listed on prediction markets. Each benchmark instance is an *episode* corresponding to a single underlying event (e.g., a price threshold, a weather outcome, or a sports result). The benchmark couples (i) an episode format that makes historical market data portable and self-contained and (ii) a deterministic, event-driven simulator that replays historical market microstructure.

The current benchmark targets data collected from Kalshi, a U.S. prediction market regulated by the Commodity Futures Trading Commission (CFTC) as a Designated Contract Market (DCM) [[12](https://arxiv.org/html/2602.00133v1#bib.bib4 "How is kalshi regulated?"), [8](https://arxiv.org/html/2602.00133v1#bib.bib9 "CFTC issues order granting kalshiEX designation as a contract market")].

### 2.1 Benchmark Construction

#### Data collection.

The benchmark is built from three primary historical streams:

* •

  Orderbook updates capturing limit-order-book depth over time.
* •

  Trade prints capturing executed transactions (used to model maker fills).
* •

  Market lifecycle and settlement events capturing trading halts/closures and final outcomes.

These streams are aligned to a unified UTC timeline and then grouped by event identifier into episodes.

#### Episode representation.

Each episode is stored as a directory containing:

* •

  metadata.json (episode configuration, tickers, time bounds, bankroll, execution mode, fee model version),
* •

  orderbook.parquet (time-series orderbook snapshots),
* •

  trades.parquet (historical trades; when available),
* •

  settlement.json (final YES/NO outcome per ticker).

This format is designed to be (i) *portable* (each episode is self-contained), (ii) *replayable* (the simulator depends only on the episode directory), and (iii) *extensible* (new fields/streams can be added without invalidating older episodes).

#### Harness and simulator.

The benchmark harness loads episodes, initializes the simulator with a fixed configuration, runs an agent through each episode under a per-step tool-call budget, and collects standardized outputs (trade logs, equity curves, and per-episode metrics). The simulator processes market events in timestamp order (using sequence numbers to break ties), updates the orderbook state, applies the execution model, and resolves contracts at settlement.

Episode files
metadata / orderbook / trades / settlement

BenchmarkHarness
(iterates episodes)

Event-driven simulator
(replay + execution)

Portfolio
cash + positions
fees + P&L

Agent
policy / LLM / rules

AgentContext (tools)
orderbook, positions,
place/cancel
loadinit + runfills, MTMinvokeactions (orders)observations / APImetrics + logs


Execution loop (cadence Δ​t\Delta t)


Figure 1: PredictionMarketBench execution flow. The harness iterates over episodes, the simulator replays historical events, and the agent interacts through a Kalshi-like context API at a fixed cadence.

### 2.2 Task formulation

We formulate each episode as a finite-horizon sequential decision problem over a historical timeline.

#### Decision points and termination.

The agent is invoked at a fixed cadence (e.g., every 5 seconds). Between invocations, the simulator advances by processing all market events up to the next decision time. The episode terminates once settlement is processed and all positions are marked-to-settlement.

#### Observations.

At each decision point the agent may query: (i) market summaries (best bid/ask per ticker), (ii) full orderbooks (optionally depth-limited), (iii) positions and cash/equity, and (iv) open resting orders.

#### Actions.

Agents act by submitting orders defined by side (YES/NO), direction (buy/sell), order type (market/limit), size, and time-in-force (IOC/GTC/post-only, depending on execution mode).

### 2.3 Features of PredictionMarketBench

#### Binary contract semantics.

Binary contracts pay $1 if the event occurs and $0 otherwise (and analogously for NO). This structure supports a probability interpretation of prices and makes prediction markets a natural domain for studying belief formation and information aggregation [[17](https://arxiv.org/html/2602.00133v1#bib.bib1 "Prediction markets")].

#### Maker/taker execution realism.

PredictionMarketBench supports both a taker-only mode (orders must cross immediately) and a maker-taker mode in which resting limit orders join a queue behind existing displayed volume. Maker/taker fee schedules are widely used by electronic venues to incentivize liquidity provision [[15](https://arxiv.org/html/2602.00133v1#bib.bib5 "Maker-taker")].

#### Fee-aware evaluation.

Fees are applied per fill and accounted for in P&L and equity curves. Explicit fee modeling is essential because transaction costs can dominate marginal strategy improvements, especially in binary contracts where notional amounts are bounded.

#### Deterministic, event-driven replay.

All state transitions are driven by recorded market events (orderbook updates, trades, settlement). Given the same episode files, simulator configuration, and agent code (with fixed seeds), runs are deterministic, enabling reproducible comparisons and regression testing.

#### Standardized outputs and metrics.

The harness produces trade logs, equity curves, and per-episode/aggregate metrics including P&L, drawdown, Sharpe ratio, fees, slippage, and fill ratio.

## 3 Data

The initial public release of PredictionMarketBench contains 4 episodes collected from Kalshi in January 2026, covering three event types: cryptocurrency (Bitcoin daily high), weather (NYC high temperature), and sports (college football and NFL outcomes). Table [1](https://arxiv.org/html/2602.00133v1#S3.T1 "Table 1 ‣ 3 Data ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets") summarizes each episode and its size.

| Episode ID | Domain | Tickers | Duration (hrs) | Orderbook snaps | Trades |
| --- | --- | --- | --- | --- | --- |
| KXBTCD-26JAN2017 | Crypto | 23 | 37.4 | 311,998 | 6,283 |
| KXHIGHNY-26JAN20 | Weather | 6 | 37.4 | 50,231 | 8,044 |
| KXNCAAF-26 | Sports | 2 | 37.4 | 8,320 | 171,786 |
| KXNFLGAME-26JAN11BUFJAC | Sports | 2 | 67.4 | 8,047 | 111,160 |
| Total | — | 33 | — | 378,596 | 297,273 |

Table 1: Episodes included in the PredictionMarketBench initial release.

## 4 Agents

PredictionMarketBench exposes a lightweight Agent interface designed to support both traditional algorithmic strategies (e.g., rule-based, market-making, statistical arbitrage) and LLM-driven agents that reason over the current state and call tools.

Agents interact with the environment exclusively through an AgentContext that provides Kalshi-like API primitives (e.g., querying markets and orderbooks, inspecting positions and cash, and placing/canceling orders). This design decouples strategy logic from simulator internals and enables plug-and-play evaluation of heterogeneous agent implementations under a shared harness.

All observations and actions are timestamped on a unified UTC timeline, allowing agents to align market state with external data sources during replay. For example, in the weather episode(s), an agent can query a historical weather API at the episode timestamp to produce exogenous features, while preserving strict temporal consistency with the market data.

## 5 Experiments

### 5.1 LLM agent

We evaluate a tool-calling LLM trading agent that operates in a stateless per-step loop: at each decision time, the harness constructs a textual summary of the current state (cash, equity, time-to-settlement, top-of-book quotes, and current positions), and the model responds with zero or more tool calls.

The agent is provider-agnostic and interacts only through the benchmark AgentContext interface (market data queries, portfolio queries, and order placement/cancellation). The full production system prompt is provided in Appendix [A](https://arxiv.org/html/2602.00133v1#A1 "Appendix A LLM system prompt ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"). Unless otherwise stated, we use a deterministic decoding configuration (temperature 0.0).

#### Run configuration.

|  |  |
| --- | --- |
| Parameter | Value |
| Model | gpt-4.1-nano |
| Temperature | 0.0 |
| Max tool rounds per step | 3 |
| Agent call cadence | 300s (5 minutes) |
| Equity sampling interval | 60s |
| Maker queue mode | trade\_only |

Table 2: LLM agent production-run configuration.

#### Logging and reproducibility.

We log full trajectories (state messages, tool calls, and tool results) together with per-step timestamps to enable exact replay and post-hoc analysis. The production runner checkpoints the trajectory every 50 steps and records aggregate outputs (trade logs and equity curves).

### 5.2 Random agent baseline

As a low-complexity baseline, we include a RandomAgent that (with probability 0.1 per step) selects a random quoted market and submits a small market order (1–3 contracts) on a random side, subject to a per-ticker position cap of ±10\pm 10 contracts. The RNG is seeded per-episode (via the episode identifier) for determinism. The random baseline uses the same simulator cadence (300s) and observation interface as the LLM agent.

### 5.3 Bollinger Bands (mean-reversion alpha)

We also evaluate a classic Bollinger Bands mean-reversion strategy [[5](https://arxiv.org/html/2602.00133v1#bib.bib10 "Bollinger on bollinger bands")] adapted to binary contract prices. At each step, for each ticker, the agent maintains a rolling mid-price history, computes a simple moving average (period 20) and standard-deviation bands (k=2k=2), and trades only on band crossings (buy near the lower band; sell/hedge near the upper band). To reduce fee impact, the strategy primarily uses maker GTC limit orders.

## 6 Results

We report results for three baselines: a tool-calling LLM agent (gpt-4.1-nano), a simple RandomAgent, and a classic Bollinger Bands mean-reversion strategy [[5](https://arxiv.org/html/2602.00133v1#bib.bib10 "Bollinger on bollinger bands")]. All are evaluated on the same four episodes with $1,000 initial bankroll per episode and a 5-minute agent cadence.

### 6.1 Per-episode results

| Episode | PnL ($) | Return (%) | Max DD (%) | Contracts | Fill (%) |
| --- | --- | --- | --- | --- | --- |
| RandomAgent | | | | | |
| KXBTCD-26JAN2017 | -2.89 | -0.29 | 0.83 | 32 | 100.0 |
| KXHIGHNY-26JAN20 | -0.75 | -0.07 | 0.78 | 33 | 100.0 |
| KXNCAAF-26 | +0.62 | +0.06 | 0.08 | 3 | 100.0 |
| KXNFLGAME-26JAN11BUFJAC | -2.11 | -0.21 | 0.44 | 15 | 100.0 |
| Total | -5.13 | -0.13 | — | 83 | 100.0 |

Table 3: RandomAgent performance by episode (run date: 2026-01-27).



| Episode | PnL ($) | Return (%) | Max DD (%) | Contracts | Fill (%) |
| --- | --- | --- | --- | --- | --- |
| LLM agent (gpt-4.1-nano) | | | | | |
| KXBTCD-26JAN2017 | -64.79 | -6.48 | 36.0 | 1,318 | 100.0 |
| KXHIGHNY-26JAN20 | +7.49 | +0.75 | 3.4 | 234 | 71.6 |
| KXNCAAF-26 | -34.07 | -3.41 | 3.6 | 145 | 100.0 |
| KXNFLGAME-26JAN11BUFJAC | -19.25 | -1.93 | 3.0 | 380 | 66.2 |
| Total | -110.62 | -2.77 | — | 2,077 | 84.4 |

Table 4: LLM agent performance by episode (run dates: 2026-01-25 to 2026-01-26).



| Episode | PnL ($) | Return (%) | Max DD (%) | Contracts | Fill (%) |
| --- | --- | --- | --- | --- | --- |
| Bollinger Bands | | | | | |
| KXBTCD-26JAN2017 | 64.10 | 6.41 | 3.18 | 616 | 94.5 |
| KXHIGHNY-26JAN20 | 0.87 | 0.09 | 0.30 | 80 | 100.0 |
| KXNCAAF-26 | 0.00 | 0.00 | 0.00 | 0 | 100.0 |
| KXNFLGAME-26JAN11BUFJAC | 1.71 | 0.17 | 0.05 | 18 | 100.0 |
| Total | 66.68 | 1.67 | 3.18 | 714 | 98.6 |

Table 5: Bollinger Bands performance by episode (mean-reversion alpha).

### 6.2 Aggregate comparison

| Agent | Total PnL ($) | Return (%) | Max DD (%) | Contracts | Orders | Fill (%) |
| --- | --- | --- | --- | --- | --- | --- |
| Bollinger Bands | 66.68 | 1.67 | 3.18 | 714 | — | 98.6 |
| LLM (gpt-4.1-nano) | -110.62 | -2.77 | 36.0 | 2,077 | 603 | 84.4 |
| RandomAgent | -5.13 | -0.13 | 0.83 | 83 | 45 | 100.0 |

Table 6: Aggregate comparison across all four episodes.

Bollinger Bands achieves positive overall P&L, with most profit concentrated in the volatile Bitcoin threshold episode. In contrast, the LLM agent trades far more aggressively and suffers large settlement losses; the RandomAgent loses less primarily due to low trading intensity.

## 7 Related Work

#### Prediction markets and market design.

Prediction markets have been studied as mechanisms for aggregating dispersed information into probabilistic forecasts [[17](https://arxiv.org/html/2602.00133v1#bib.bib1 "Prediction markets"), [1](https://arxiv.org/html/2602.00133v1#bib.bib6 "The promise of prediction markets")]. Empirical work on the Iowa Electronic Markets documents long-horizon accuracy and emphasizes how design choices and manipulation incentives affect information quality [[3](https://arxiv.org/html/2602.00133v1#bib.bib11 "Prediction market accuracy in the long run"), [4](https://arxiv.org/html/2602.00133v1#bib.bib12 "Market design, manipulation, and accuracy in political prediction markets: lessons from the iowa electronic markets")]. On the market-design side, automated market makers and cost-function approaches such as LMSR provide continuous pricing under sparse order flow [[9](https://arxiv.org/html/2602.00133v1#bib.bib7 "Combinatorial information market design")].

#### Market microstructure and execution.

Because many venues operate as limit-order markets, agent performance depends on microstructure effects such as bid–ask spreads, queue priority, and fees [[16](https://arxiv.org/html/2602.00133v1#bib.bib8 "Market microstructure theory")]. These considerations motivate evaluation harnesses that explicitly model execution and transaction costs rather than relying on idealized mid-price fills.

#### Learning and trading agents in market environments.

A broad line of work studies learning agents in market settings, including reinforcement learning for trading and price discovery in limit-order markets [[10](https://arxiv.org/html/2602.00133v1#bib.bib15 "Reinforcement learning in limit order markets")] and agent-based modeling of prediction markets [[18](https://arxiv.org/html/2602.00133v1#bib.bib13 "Agent-based modeling of the prediction markets")]. In financial ML more generally, open-source RL pipelines such as FinRL aim to standardize environments, algorithms, and evaluation for trading tasks [[14](https://arxiv.org/html/2602.00133v1#bib.bib16 "FinRL: deep reinforcement learning framework to automate trading in quantitative finance")].

#### Simulators and benchmarks for agent evaluation.

High-fidelity market simulators such as ABIDES were developed explicitly to support AI-agent research in market applications [[6](https://arxiv.org/html/2602.00133v1#bib.bib17 "ABIDES: towards high-fidelity market simulation for ai research")]. Building on such simulators, recent work trains RL agents for optimal execution in realistic limit-order-book environments [[13](https://arxiv.org/html/2602.00133v1#bib.bib18 "Multi-agent reinforcement learning in a realistic limit order book market simulation")]. PredictionMarketBench is complementary: rather than learning endogenous market dynamics, it focuses on deterministic replay of real prediction-market microstructure (orderbooks, trades, settlement) with maker/taker semantics and fee modeling to enable apples-to-apples backtesting.

#### LLM-based and agentic systems.

Harness-first evaluation has become standard in other agent domains (e.g., SWE-bench) to ensure reproducible, instance-based comparisons [[11](https://arxiv.org/html/2602.00133v1#bib.bib2 "SWE-bench: can language models resolve real-world GitHub issues?")]. In prediction markets, recent work explores agentic AI and semantic structure discovery as a basis for trading signals [[7](https://arxiv.org/html/2602.00133v1#bib.bib14 "Semantic trading: agentic ai for clustering and relationship discovery in prediction markets")]. Our benchmark provides a concrete experimental substrate for such agents by standardizing the observation/action interface, tool budgets, and deterministic replay.

## 8 Discussion and Conclusion

### 8.1 Limitations

PredictionMarketBench is an initial step toward standardized, execution-aware evaluation for prediction-market trading agents, and it has several limitations. First, the current release is small (4 episodes from January 2026) and spans a limited set of event types; broader statistical claims require more diverse markets and time periods. Second, while maker/taker execution and fees are modeled, the simulator is still an abstraction of live trading: latency, exchange-specific priority rules, and strategic interaction with other agents are not modeled explicitly [[16](https://arxiv.org/html/2602.00133v1#bib.bib8 "Market microstructure theory")]. Third, our baseline agents are intentionally simple and are not tuned for out-of-sample robustness; repeated iteration on this dataset risks backtest overfitting [[2](https://arxiv.org/html/2602.00133v1#bib.bib3 "The probability of backtest overfitting")].

### 8.2 Conclusion

We presented PredictionMarketBench, a SWE-bench-style benchmark for backtesting algorithmic and LLM-based trading agents on prediction markets using deterministic replay of real orderbooks, trades, and settlement outcomes. Our initial results illustrate the importance of execution realism and transaction costs: an active LLM agent can incur large settlement losses, while a fee-aware algorithmic alpha (Bollinger Bands) can remain profitable in volatile episodes. We release the benchmark to support reproducible comparisons and encourage future work on expanding the dataset, adding stronger baselines, and studying robust agent design under realistic execution constraints.

## Appendix A LLM system prompt

```
You are a trading agent operating on Kalshi prediction markets.

## Objective
Maximize profit by trading binary event contracts. Each contract pays $1.00 (100 cents) if the event outcome matches (YES wins = $1 for YES holders, NO wins = $1 for NO holders).

## Market Mechanics
- Prices are quoted in cents (1-99)
- A YES contract at 60c means the market implies ~60% probability
- A NO contract at the same market would be at ~40c (100 - 60 = 40)
- You can BUY or SELL on either YES or NO side

## Fee Structure (Critical for Profitability)
- **Taker fee**: 7%  price  (1 - price/100) - applies to market orders and limit orders that cross the spread
- **Maker fee**: 1.75%  price  (1 - price/100) - applies to resting limit orders that provide liquidity
- Example: At 50c, taker fee = 1.75c per contract, maker fee = 0.44c per contract
- Maker orders are 4x cheaper - strongly prefer GTC or POST_ONLY limit orders

## Strategy Guidelines
1. **Edge calculation**: Only trade when expected value > fees. At 50c with 7% taker fee, you need >53.5% edge to profit
2. **Maker orders**: Use limit orders with GTC or POST_ONLY to get the 1.75% maker rate
3. **Position sizing**: Don’t concentrate more than 20% of equity in one position
4. **Settlement awareness**: Contracts settle to $1 or $0 at close - factor time remaining into trades
5. **Spread capture**: Consider placing limit orders inside the spread to capture the bid-ask

## Decision Process
Each step:
1. Call get_markets() to see current prices
2. Evaluate if any prices seem mispriced vs your probability estimates
3. Check your positions with get_positions() before trading
4. If you see opportunity, use limit orders (GTC) to get maker fees
5. Call done() when finished deciding for this step

Be conservative - the fees are high. Only trade when you see clear edge.
```

## References

* [1]
  K. J. Arrow, R. Forsythe, M. Gorham, R. Hahn, R. Hanson, J. O. Ledyard, S. Levmore, R. Litan, P. Milgrom, F. D. Nelson, G. R. Neumann, M. Ottaviani, T. C. Schelling, R. J. Shiller, V. L. Smith, E. Snowberg, C. R. Sunstein, and P. E. Tetlock (2008)
  The promise of prediction markets.
  Science 320 (5878),  pp. 877–878.
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p1.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px1.p1.1 "Prediction markets and market design. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [2]
  D. H. Bailey, J. M. Borwein, M. López de Prado, and Q. J. Zhu (2017)
  The probability of backtest overfitting.
  Journal of Computational Finance.
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p3.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§8.1](https://arxiv.org/html/2602.00133v1#S8.SS1.p1.1 "8.1 Limitations ‣ 8 Discussion and Conclusion ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [3]
  J. E. Berg, F. D. Nelson, and T. A. Rietz (2008)
  Prediction market accuracy in the long run.
  International Journal of Forecasting 24 (2),  pp. 285–300.
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p1.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px1.p1.1 "Prediction markets and market design. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [4]
  J. E. Berg and T. A. Rietz (2014)
  Market design, manipulation, and accuracy in political prediction markets: lessons from the iowa electronic markets.
  PS: Political Science & Politics 47 (2).
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p1.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px1.p1.1 "Prediction markets and market design. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [5]
  J. Bollinger (2001)
  Bollinger on bollinger bands.
   McGraw-Hill.
  Cited by: [§5.3](https://arxiv.org/html/2602.00133v1#S5.SS3.p1.1 "5.3 Bollinger Bands (mean-reversion alpha) ‣ 5 Experiments ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§6](https://arxiv.org/html/2602.00133v1#S6.p1.1 "6 Results ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [6]
  D. Byrd, M. Hybinette, and T. Balch (2019)
  ABIDES: towards high-fidelity market simulation for ai research.
  Note: arXiv preprint arXiv:1904.12066
  Cited by: [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px4.p1.1 "Simulators and benchmarks for agent evaluation. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [7]
  A. Capponi, A. Gliozzo, and B. Zhu (2025)
  Semantic trading: agentic ai for clustering and relationship discovery in prediction markets.
  Note: arXiv preprint arXiv:2512.02436
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p4.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px5.p1.1 "LLM-based and agentic systems. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [8]
  Commodity Futures Trading Commission (2020)
  CFTC issues order granting kalshiEX designation as a contract market.
  Note: CFTC Press ReleaseAccessed 2026-01-28
  Cited by: [§2](https://arxiv.org/html/2602.00133v1#S2.p2.1 "2 PredictionMarketBench ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [9]
  R. Hanson (2003)
  Combinatorial information market design.
  Information Systems Frontiers 5 (1),  pp. 107–119.
  Note: Introduces the logarithmic market scoring rule (LMSR)
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p2.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px1.p1.1 "Prediction markets and market design. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [10]
  X. He and S. Lin (2019)
  Reinforcement learning in limit order markets.
  Note: Quantitative Finance Research Centre, University of Technology Sydney, Research Paper Series No. 403
  Cited by: [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px3.p1.1 "Learning and trading agents in market environments. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [11]
  C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, et al. (2024)
  SWE-bench: can language models resolve real-world GitHub issues?.
  Note: arXiv preprint arXiv:2310.06770
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p5.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px5.p1.1 "LLM-based and agentic systems. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [12]
  Kalshi
  How is kalshi regulated?.
  Note: Kalshi Help CenterAccessed 2026-01-28
  Cited by: [§2](https://arxiv.org/html/2602.00133v1#S2.p2.1 "2 PredictionMarketBench ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [13]
  M. Karpe, J. Fang, Z. Ma, and C. Wang (2020)
  Multi-agent reinforcement learning in a realistic limit order book market simulation.
  Note: arXiv preprint arXiv:2006.05574
  Cited by: [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px4.p1.1 "Simulators and benchmarks for agent evaluation. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [14]
  X. Liu, H. Yang, J. Gao, and C. D. Wang (2021)
  FinRL: deep reinforcement learning framework to automate trading in quantitative finance.
  Note: arXiv preprint arXiv:2111.09395
  Cited by: [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px3.p1.1 "Learning and trading agents in market environments. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [15]
  MarketsWiki
  Maker-taker.
  Note: MarketsWikiAccessed 2026-01-28
  Cited by: [§2.3](https://arxiv.org/html/2602.00133v1#S2.SS3.SSS0.Px2.p1.1 "Maker/taker execution realism. ‣ 2.3 Features of PredictionMarketBench ‣ 2 PredictionMarketBench ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [16]
  M. O’Hara (1995)
  Market microstructure theory.
   Blackwell Publishers.
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p2.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px2.p1.1 "Market microstructure and execution. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§8.1](https://arxiv.org/html/2602.00133v1#S8.SS1.p1.1 "8.1 Limitations ‣ 8 Discussion and Conclusion ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [17]
  J. Wolfers and E. Zitzewitz (2004)
  Prediction markets.
  Technical report
  Technical Report 10504, National Bureau of Economic Research.
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p1.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§2.3](https://arxiv.org/html/2602.00133v1#S2.SS3.SSS0.Px1.p1.1 "Binary contract semantics. ‣ 2.3 Features of PredictionMarketBench ‣ 2 PredictionMarketBench ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px1.p1.1 "Prediction markets and market design. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").
* [18]
  T. Yu and S. Chen (2011)
  Agent-based modeling of the prediction markets.
  Note: Working paper (IDEAS/RePEc)
  Cited by: [§1](https://arxiv.org/html/2602.00133v1#S1.p3.1 "1 Introduction ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets"),
  [§7](https://arxiv.org/html/2602.00133v1#S7.SS0.SSS0.Px3.p1.1 "Learning and trading agents in market environments. ‣ 7 Related Work ‣ PredictionMarketBench: A SWE-bench-Style Framework for Backtesting Trading Agents on Prediction Markets").