---
authors:
- Arvid E. Gollwitzer
- Paridhi Latawa
- David de Gruijl
- Deepak A. Subramanian
- Adri√°n Noriega de la Colina
doc_id: arxiv:2602.06394v1
family_id: arxiv:2602.06394
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware
  Tokenization
url_abs: http://arxiv.org/abs/2602.06394v1
url_html: https://arxiv.org/html/2602.06394v1
venue: arXiv q-fin
version: 1
year: 2026
---


Arvid E. Gollwitzer
‚ÄÉ‚ÄÉ
Paridhi Latawa
‚ÄÉ‚ÄÉ
David de Gruijl
‚ÄÉ‚ÄÉ
Deepak A. Subramanian
‚ÄÉ‚ÄÉ
Adri√°n Noriega de la Colina

###### Abstract

Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, re-tokenizing METAGENE-1‚Äôs 1.7 trillion base-pair corpus achieves state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.

Tokenization, Foundation Models, Noisy Data, Reinforcement Learning, Genomics, Finance

## 1 Introduction

Tokenization serves as the interface between raw data and neural computation. Current methods such as Byte-Pair Encoding (BPE) (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units")) rely exclusively on frequency statistics, assuming that occurrence frequency correlates with semantic importance. This assumption fails when data quality varies significantly‚Äîfrom sequencing errors in genomics (Ewing et al., [1998](https://arxiv.org/html/2602.06394v1#bib.bib16 "Base-calling of automated sequencer traces using phred. i. accuracy assessment")) to microstructure noise in financial markets (Andersen et al., [2001](https://arxiv.org/html/2602.06394v1#bib.bib11 "The distribution of realized exchange rate volatility")). Models trained on noisy corpora using frequency-based tokenization inherit these errors, resulting in degraded performance‚Äîan effect now formalized through quality-aware scaling laws¬†(Subramanyam et al., [2025](https://arxiv.org/html/2602.06394v1#bib.bib269 "Scaling laws revisited: modeling the role of data quality in language model pretraining")).

The problem is substantial: error rates in third-generation sequencing exceed 10% (Wenger et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib96 "Accurate circular consensus long-read sequencing improves variant detection and assembly of a human genome")), yet current tokenizers treat high-confidence and error-prone regions identically. In finance, over 40% of high-frequency data contains microstructure noise (Hansen and Lunde, [2006](https://arxiv.org/html/2602.06394v1#bib.bib97 "Realized variance and market microstructure noise")), but tokenization methods do not distinguish signal quality. This limitation constrains foundation model training on real-world data.

The scale of available biological data amplifies this challenge. Public sequence repositories now contain over 67 petabase pairs (Pbp) of raw sequencing data, with the European Nucleotide Archive doubling approximately every 45 months (Karasikov et al., [2025](https://arxiv.org/html/2602.06394v1#bib.bib111 "Efficient and accurate search in petabase-scale sequence repositories")). Recent advances in efficient indexing have made these petabase-scale archives full-text searchable at costs as low as $0.74 per queried megabase pair, demonstrating that the infrastructure for large-scale sequence analysis is maturing rapidly. However, a substantial fraction of this data remains underutilized for foundation model training due to quality heterogeneity‚Äîstandard frequency-based tokenization methods either discard low-quality reads entirely or propagate sequencing errors into learned representations. This gap between data availability and usability motivates a fundamental rethinking of how tokenization handles quality variation.

We present Quality-Aware Tokenization (QA-Token), a framework that incorporates data quality into vocabulary construction. We make three key contributions:

1. Bilevel Optimization with Complexity Analysis: We formalize tokenization as a bilevel optimization problem ([DefinitionÀú3.1](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem1 "Definition 3.1 (Bilevel Tokenization Problem). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) that jointly optimizes vocabulary construction and downstream performance. We show this problem is NP-hard ([TheoremÀú3.2](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem2 "Theorem 3.2 (Computational Complexity). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and develop a principled approximation scheme with theoretical guarantees.

2. Reinforcement Learning with Convergence Guarantees: We cast vocabulary construction as a Markov Decision Process ([DefinitionÀúE.4](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem4 "Definition E.4 (Tokenization MDP). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and employ reinforcement learning to discover optimal merge policies. We provide formal convergence analysis ([PropositionÀúE.5](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem5 "Proposition E.5 (MDP Well-Formedness). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and achieve (1‚àí1/e)(1-1/e)-approximation to the optimal adaptive policy.

3. Differentiable Parameter Learning: Through Gumbel-Softmax relaxation ([TheoremÀúC.8](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem8 "Theorem C.8 (Gumbel-Softmax Properties). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), we enable end-to-end learning of quality sensitivity parameters, with proven consistency and bounded gradients ([PropositionÀúC.7](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem7 "Proposition C.7 (Consistency and Boundedness of Stage 2 Gradients). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

We show that QA-Token achieves information-theoretic optimality under noisy conditions ([PropositionÀúC.13](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem13 "Proposition C.13 (Quality-Aware Information Bottleneck Interpretation). ‚Ä£ C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), providing formal justification for quality-aware tokenization. Our evaluation shows 30% higher Sharpe ratios in algorithmic trading, 6.7 percentage point improvement in genomic variant calling F1 (0.891 vs. 0.824 for BPE), and state-of-the-art performance when integrated into 7B-parameter foundation models.

Core Contributions: (i) We derive a quality-aware merge score ([TheoremÀúC.3](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem3 "Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) balancing frequency, quality, and domain constraints with learnable sensitivity Œ±\alpha ([SectionÀúC.2](https://arxiv.org/html/2602.06394v1#A3.SS2 "C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). (ii) We formulate vocabulary construction as an MDP ([DefinitionÀúE.4](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem4 "Definition E.4 (Tokenization MDP). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúE.7](https://arxiv.org/html/2602.06394v1#A5.SS7 "E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) achieving (1‚àí1/e)(1-1/e)-approximation through adaptive submodularity. (iii) Gumbel-Softmax relaxation enables end-to-end parameter learning with O‚Äã(1/T)O(1/\sqrt{T}) convergence rate ([PropositionÀúE.2](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem2 "Proposition E.2 (Convergence of Adaptive Learning with Explicit Constants). ‚Ä£ E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúE.4](https://arxiv.org/html/2602.06394v1#A5.SS4 "E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). (iv) Domain-specific instantiations achieve state-of-the-art performance across 15+ benchmarks.

Our analysis shows that incorporating quality signals into tokenization enables training on noisy corpora where frequency-based methods fail, expanding the range of usable training data for foundation models with broader scientific and economic implications ([SectionÀú7.1](https://arxiv.org/html/2602.06394v1#S7.SS1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

## 2 Quality Metrics for Noisy Domains

Quality metrics must satisfy three formal properties to enable principled integration into the merge score: (i)¬†*boundedness* (q‚àà[0,1]q\in[0,1]) ensuring numerical stability, (ii)¬†*Lipschitz continuity* enabling stable gradient computation during adaptive learning, and (iii)¬†*monotonicity under noise injection* (higher noise yields lower quality) ensuring semantic consistency. We prove these properties hold for our domain-specific instantiations ([PropositionÀúC.1](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem1 "Proposition C.1 (Boundedness and Continuity of Quality Functions). ‚Ä£ C.1 Quality Metric Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.1](https://arxiv.org/html/2602.06394v1#A3.SS1 "C.1 Quality Metric Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Genomics: We leverage Phred scores with position-adjusted decay: qsj‚Ä≤=qsj‚ãÖexp‚Å°(‚àíŒ≤pos‚ãÖj/L)q^{\prime}\_{s\_{j}}=q\_{s\_{j}}\cdot\exp(-\beta\_{\text{pos}}\cdot j/L), where Œ≤pos\beta\_{\text{pos}} is learned and LL is read length. Token quality is aggregated via geometric mean qt=(‚àèj=1|t|qsj‚Ä≤)1/|t|q\_{t}=(\prod\_{j=1}^{|t|}q^{\prime}\_{s\_{j}})^{1/|t|} to ensure sensitivity to low-quality regions‚Äîa single unreliable base compromises the entire token (Eq.¬†[13](https://arxiv.org/html/2602.06394v1#A4.E13 "Equation 13 ‚Ä£ D.1 Genomics: Detailed Sequencing Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Finance: We combine four market microstructure dimensions: (i)¬†liquidity qliqq\_{\text{liq}} (bid-ask spread, depth), (ii)¬†signal quality qsigq\_{\text{sig}} (SNR of price changes), (iii)¬†stability qstbq\_{\text{stb}} (volatility regime), and (iv)¬†information content qinfoq\_{\text{info}} (order flow informativeness). The composite score qtfinance=‚àëkwk‚Äãqk,tq\_{t}^{\text{finance}}=\sum\_{k}w\_{k}q\_{k,t} uses learned weights; arithmetic mean aggregation reflects additive noise characteristics of financial data (Eq.¬†[14](https://arxiv.org/html/2602.06394v1#A4.E14 "Equation 14 ‚Ä£ D.2 Finance: Comprehensive Market Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

With quality metrics defined, we now formalize how they integrate into the tokenization objective.

## 3 Mathematical Formulation of QA-Token

### 3.1 Notation and Setup

Let ùíÆ={S1,S2,‚Ä¶,SN}\mathcal{S}=\{S\_{1},S\_{2},\dots,S\_{N}\} represent a corpus comprising NN sequences, where each sequence Sk=(sk,1,‚Ä¶,sk,nk)S\_{k}=(s\_{k,1},\dots,s\_{k,n\_{k}}) consists of elements drawn from a base alphabet Œ£\Sigma. Each atomic element sk,is\_{k,i} is associated with a normalized quality score qk,i‚àà[0,1]q\_{k,i}\in[0,1] as defined in [SectionÀú2](https://arxiv.org/html/2602.06394v1#S2 "2 Quality Metrics for Noisy Domains ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"). The initial vocabulary is defined as V0=Œ£V\_{0}=\Sigma. At any step kk of the tokenization process, VkV\_{k} denotes the current vocabulary. For any token a‚ààVka\in V\_{k}, we denote its frequency in the corpus as f‚Äã(a)f(a), and for an adjacent pair (a,b)(a,b), their co-occurrence frequency is f‚Äã(a,b)f(a,b). The length of a token tt in atomic units is |t||t|. Let qtq\_{t} be the aggregated scalar quality of token tt, computed using domain-specific aggregation functions (see [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

### 3.2 Formal Problem Definition and Objective

We formalize tokenization as finding a tokenizer ùíØ\mathcal{T} that maximizes objective ùí•\mathcal{J}, balancing downstream task performance, vocabulary complexity, and data reliability. Let ùíÆ={S1,S2,‚Ä¶,SN}\mathcal{S}=\{S\_{1},S\_{2},\ldots,S\_{N}\} denote a corpus of NN sequences sampled from an underlying data distribution ùí´data\mathcal{P}\_{\text{data}}, where each Sk=(sk,1,‚Ä¶,sk,nk)S\_{k}=(s\_{k,1},\ldots,s\_{k,n\_{k}}) consists of elements from base alphabet Œ£\Sigma. A tokenizer ùíØ:ùíÆ‚Üíùíµ\mathcal{T}:\mathcal{S}\rightarrow\mathcal{Z} maps the corpus to segmentations ùíµ={Z1,‚Ä¶,ZN}\mathcal{Z}=\{Z\_{1},\ldots,Z\_{N}\} using vocabulary VV.

###### Definition 3.1 (Bilevel Tokenization Problem).

The optimal quality-aware tokenization problem is formulated as the following bilevel optimization:

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxùíØ‚ààùí¢‚Äã(K)‚Å°ùí•‚Äã(ùíØ):=ŒªLM‚Äã‚ÑíLM‚Äã(ùíØ)‚àíŒªcomp‚ÄãŒ¶‚Äã(V)+Œªqual‚ÄãQ‚Äã(V,ùíµ),\begin{split}\max\_{\mathcal{T}\in\mathcal{G}(K)}\;\mathcal{J}(\mathcal{T})\;:=\;&\;\lambda\_{\text{LM}}\,\mathcal{L}\_{\text{LM}}(\mathcal{T})-\lambda\_{\text{comp}}\,\Phi(V)\\ &\;+\;\lambda\_{\text{qual}}\,Q(V,\mathcal{Z}),\end{split} |  | (1) |

where the language model performance is:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚ÑíLM‚Äã(ùíØ)=maxŒ∏‚ààŒò‚Å°ùîºùíü‚àºùí´data‚Äã[log‚Å°pŒ∏‚Äã(ùíü|ùíØ)],\mathcal{L}\_{\text{LM}}(\mathcal{T})=\max\_{\theta\in\Theta}\mathbb{E}\_{\mathcal{D}\sim\mathcal{P}\_{\text{data}}}[\log p\_{\theta}(\mathcal{D}|\mathcal{T})], |  | (2) |

and ùí¢‚Äã(K)={ùíØ:|VùíØ|‚àí|Œ£|‚â§K}\mathcal{G}(K)=\{\mathcal{T}:|V\_{\mathcal{T}}|-|\Sigma|\leq K\} denotes the set of tokenizers reachable by at most KK merge operations from base alphabet Œ£\Sigma, with Œò\Theta being the parameter space of the language model.

The objective ùí•\mathcal{J} balances three components: (i) downstream performance ‚ÑíLM‚Äã(ùíØ)\mathcal{L}\_{\text{LM}}(\mathcal{T}) maximizing expected log-likelihood, (ii) complexity penalty Œ¶‚Äã(V)=|V|‚Äãlog‚Å°|V|+‚àët‚ààV|t|‚ãÖH‚Äã(t)\Phi(V)=|V|\log|V|+\sum\_{t\in V}|t|\cdot H(t) following MDL principles (Rissanen, [1978](https://arxiv.org/html/2602.06394v1#bib.bib42 "Modeling by shortest data description"))‚Äîthe first term penalizes vocabulary size (description length of token indices), while the second penalizes internal token complexity via the empirical entropy H‚Äã(t)=‚àí‚àëœÉ‚ààŒ£nœÉ‚Äã(t)|t|‚Äãlog‚Å°nœÉ‚Äã(t)|t|H(t)=-\sum\_{\sigma\in\Sigma}\frac{n\_{\sigma}(t)}{|t|}\log\frac{n\_{\sigma}(t)}{|t|} of atomic elements within token tt (with nœÉ‚Äã(t)n\_{\sigma}(t) the count of element œÉ\sigma; H‚Äã(t)=0H(t)=0 for single-element tokens), and (iii) reliability reward Q‚Äã(V,ùíµ)=1‚àëk=1N|Zk|‚Äã‚àëk=1N‚àët‚ààZkg‚Äã(qt)Q(V,\mathcal{Z})=\frac{1}{\sum\_{k=1}^{N}|Z\_{k}|}\sum\_{k=1}^{N}\sum\_{t\in Z\_{k}}g(q\_{t}) aggregating token qualities through concave function gg.

The aggregator function gg exhibits concavity to capture diminishing returns for merging high-quality constituents. Throughout this work, we employ g‚Äã(x)=(x+œµQ)Œ±g(x)=(x+\epsilon\_{Q})^{\alpha} with 0<Œ±<10<\alpha<1 (strictly concave) and œµQ=10‚àí8\epsilon\_{Q}=10^{-8} for numerical stability. The boundary case Œ±=1\alpha=1 yields linear aggregation, which is appropriate when quality contributions are additive rather than subject to diminishing returns.

###### Theorem 3.2 (Computational Complexity).

The bilevel optimization problem in Eq.¬†[1](https://arxiv.org/html/2602.06394v1#S3.E1 "Equation 1 ‚Ä£ Definition 3.1 (Bilevel Tokenization Problem). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") is NP-hard in general (Dempe, [2020](https://arxiv.org/html/2602.06394v1#bib.bib116 "Bilevel optimization: theory, algorithms and applications")); indeed, polynomial bilevel programming is Œ£2p\Sigma\_{2}^{p}-hard (Cen and Chi, [2023](https://arxiv.org/html/2602.06394v1#bib.bib119 "Global convergence of policy gradient methods in reinforcement learning, games and control")), placing it one level above NP in the polynomial hierarchy. The worst case requires O‚Äã(|Œ£|K‚ãÖK!‚ãÖN‚ãÖn‚ãÖ|Œò|)O(|\Sigma|^{K}\cdot K!\cdot N\cdot n\cdot|\Theta|) evaluations (proof in [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Given this computational intractability, we develop a principled approximation scheme combining greedy merge selection with reinforcement learning, as detailed in subsequent sections.

### 3.3 Quality-Aware Merge Score

We extend PMI-based tokenization by incorporating quality signals through the following result:

###### Theorem 3.3 (Quality-Aware Merge Score).

The optimal greedy merge score maximizing the first-order approximation of the objective increment Œî‚Äãùí•\Delta\mathcal{J} is:

|  |  |  |  |
| --- | --- | --- | --- |
|  | wa‚Äãb=f‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖ(q¬Øa‚Äãb+œµQ)Œ±‚ãÖœà‚Äã(a,b)w\_{ab}=\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot(\bar{q}\_{ab}+\epsilon\_{Q})^{\alpha}\cdot\psi(a,b) |  | (3) |

where q¬Øa‚Äãb=(qa+qb)/2\bar{q}\_{ab}=(q\_{a}+q\_{b})/2 averages constituent qualities, Œ±‚àà(0,1]\alpha\in(0,1] controls quality sensitivity, and œà‚Äã(a,b)\psi(a,b) encodes domain constraints. (Proof via first-order approximation in [SectionÀúC.2](https://arxiv.org/html/2602.06394v1#A3.SS2 "C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").)

This score balances statistical association (PMI term), data reliability (quality term), and domain-specific requirements. Boundedness and Lipschitz continuity are proven in [PropositionÀúC.4](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem4 "Proposition C.4 (Boundedness and Lipschitzness of ùë§_{ùëé‚Å¢ùëè}). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") ([SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5 "C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

## 4 Learning Framework: RL and Adaptive Parameters

We cast vocabulary construction as a learning problem with two sequential stages. Stage 1 (RL Policy Optimization) learns policy œÄŒ∏œÄ\pi\_{\theta\_{\pi}} for merge selection using PPO with quality-aware rewards, keeping initial parameters Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)} fixed. Stage 2 (Adaptive Parameter Learning) optimizes Œ∏adapt\theta\_{\text{adapt}} via Gumbel-Softmax relaxation for downstream performance, using *greedy simulation* with composite logits ‚Ñìa‚Äãb‚Äã(Œ∏adapt)\ell\_{ab}(\theta\_{\text{adapt}}) rather than invoking the RL policy directly‚Äîthe Stage 1 policy serves to initialize candidate merges and provide variance reduction baselines. Gradients ‚àáŒ∏adaptLtask\nabla\_{\theta\_{\text{adapt}}}L\_{\text{task}} flow through Gumbel-Softmax merge selection, enabling end-to-end learning (detailed in [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), Algorithms¬†[1](https://arxiv.org/html/2602.06394v1#alg1 "Algorithm 1 ‚Ä£ E.1.3 PPO Training Algorithm ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[3](https://arxiv.org/html/2602.06394v1#alg3 "Algorithm 3 ‚Ä£ E.3 Final Vocabulary Construction ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

### 4.1 Reinforcement Learning Formulation

###### Definition 4.1 (Tokenization MDP).

The vocabulary construction MDP is ‚Ñ≥=(ùíÆ,ùíú,ùí´,‚Ñõ,Œ≥,T)\mathcal{M}=(\mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R},\gamma,T) where: states st‚ààùíÆs\_{t}\in\mathcal{S} encode current vocabulary, merge candidates, and corpus statistics; actions at‚ààùíúta\_{t}\in\mathcal{A}\_{t} select merge pairs; transitions ùí´\mathcal{P} are deterministic vocabulary updates; rewards ‚Ñõ\mathcal{R} are quality-aware (Section¬†[4.2](https://arxiv.org/html/2602.06394v1#S4.SS2 "4.2 Reward Function Design ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")); Œ≥‚àà(0,1]\gamma\in(0,1] is the discount factor; TT is the horizon (target vocabulary size minus base alphabet size). Complete specification in [SectionÀúE.7](https://arxiv.org/html/2602.06394v1#A5.SS7 "E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

The RL objective finds policy œÄŒ∏œÄ:ùíÆ‚ÜíŒî‚Äã(ùíú)\pi\_{\theta\_{\pi}}:\mathcal{S}\rightarrow\Delta(\mathcal{A}) maximizing expected cumulative reward over TT operations using PPO (Schulman et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib63 "Proximal policy optimization algorithms")), with global convergence guarantees following (Bhandari and Russo, [2021](https://arxiv.org/html/2602.06394v1#bib.bib115 "Global optimality guarantees for policy gradient methods"); Cen and Chi, [2023](https://arxiv.org/html/2602.06394v1#bib.bib119 "Global convergence of policy gradient methods in reinforcement learning, games and control")). [PropositionÀúE.5](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem5 "Proposition E.5 (MDP Well-Formedness). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") ([SectionÀúE.7](https://arxiv.org/html/2602.06394v1#A5.SS7 "E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) proves MDP well-formedness.

### 4.2 Reward Function Design

The multi-objective reward R‚Äã(a,b;Œ∏adapt(0))=‚àëjŒªj‚ÄãR^j‚Äã(a,b)R(a,b;\theta\_{\text{adapt}}^{(0)})=\sum\_{j}\lambda\_{j}\hat{R}\_{j}(a,b) combines quality, information, complexity, and domain-specific components. Each raw reward RjrawR^{\text{raw}}\_{j} is normalized using adaptive running statistics with exponential moving averages: Œºj,trun=(1‚àíŒ≤norm)‚ÄãŒºj,t‚àí1run+Œ≤norm‚ÄãRjraw\mu\_{j,t}^{\text{run}}=(1-\beta\_{\text{norm}})\mu\_{j,t-1}^{\text{run}}+\beta\_{\text{norm}}R^{\text{raw}}\_{j}, yielding R^j=(Rjraw‚àíŒºj,t‚àí1run)/(œÉj,t‚àí1run+œµR)\hat{R}\_{j}=(R^{\text{raw}}\_{j}-\mu\_{j,t-1}^{\text{run}})/(\sigma\_{j,t-1}^{\text{run}}+\epsilon\_{R}). This ensures bounded, scale-invariant rewards during non-stationary policy optimization ([PropositionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem5 "Proposition C.5 (Stability of EMA Normalization). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúE.8](https://arxiv.org/html/2602.06394v1#A5.SS8 "E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

### 4.3 Adaptive Learning of Tokenization Parameters

After RL optimization, we learn Œ∏adapt\theta\_{\text{adapt}} (quality sensitivity Œ±\alpha, domain factors Œ≤pos\beta\_{\text{pos}}/Œ≤vol\beta\_{\text{vol}}, weights) minimizing Ltotal‚Äã(Œ∏adapt)=Ltask‚Äã(Œ∏adapt)+Œªreg‚Äã‚ÄñŒ∏adapt‚Äñ22L\_{\text{total}}(\theta\_{\text{adapt}})=L\_{\text{task}}(\theta\_{\text{adapt}})+\lambda\_{\text{reg}}\|\theta\_{\text{adapt}}\|\_{2}^{2} via Gumbel-Softmax (Jang et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib31 "Categorical reparameterization with gumbel-softmax"); Maddison et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib32 "The concrete distribution: a continuous relaxation of discrete random variables")). Temperature annealing œÑ‚Äã(t)=œÑinit‚Äãexp‚Å°(‚àíŒ≤anneal‚Äãt/Tanneal)\tau(t)=\tau\_{\text{init}}\exp(-\beta\_{\text{anneal}}t/T\_{\text{anneal}}) ensures convergence ([PropositionÀúC.7](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem7 "Proposition C.7 (Consistency and Boundedness of Stage 2 Gradients). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [PropositionÀúE.2](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem2 "Proposition E.2 (Convergence of Adaptive Learning with Explicit Constants). ‚Ä£ E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"); [SectionÀúE.9](https://arxiv.org/html/2602.06394v1#A5.SS9 "E.9 Gumbel-Softmax Gradient Derivation and Temperature Annealing ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). The two-stage framework‚ÄîRL with fixed Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)} then adaptive learning‚Äîculminates in greedy vocabulary construction using wa‚Äãb‚Äã(a,b;Œ∏adapt‚àó)w\_{ab}(a,b;\theta\_{\text{adapt}}^{\*}) ([AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), Algorithms¬†[1](https://arxiv.org/html/2602.06394v1#alg1 "Algorithm 1 ‚Ä£ E.1.3 PPO Training Algorithm ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[3](https://arxiv.org/html/2602.06394v1#alg3 "Algorithm 3 ‚Ä£ E.3 Final Vocabulary Construction ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

### 4.4 Two-Timescale Convergence

The sequential optimization follows a two-timescale stochastic approximation: policy updates on fast timescale (learning rate Œ∑œÄ(t)\eta\_{\pi}^{(t)}), adaptive parameters on slow timescale (Œ∑adapt(t)\eta\_{\text{adapt}}^{(t)}), with Œ∑œÄ(t)/Œ∑adapt(t)‚Üí‚àû\eta\_{\pi}^{(t)}/\eta\_{\text{adapt}}^{(t)}\to\infty as t‚Üí‚àût\to\infty. Under assumptions (A1)‚Äì(A4), this converges to a local Nash equilibrium where Œ∏œÄ‚àó\theta\_{\pi}^{\*} maximizes J‚Äã(œÄ;Œ∏adapt‚àó)J(\pi;\theta\_{\text{adapt}}^{\*}) and Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*} minimizes Ltotal‚Äã(Œ∏adapt;œÄ‚àó)L\_{\text{total}}(\theta\_{\text{adapt}};\pi^{\*}). Quality bounds and initialization strategies for approaching global optima are detailed in [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

### 4.5 Theoretical Guarantees

Our framework provides the following guarantees under assumptions (A1)‚Äì(A4) detailed in [SectionÀúC.6](https://arxiv.org/html/2602.06394v1#A3.SS6 "C.6 Assumptions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"): (i) bounded/Lipschitz merge scores wa‚Äãbw\_{ab} ([PropositionÀúC.4](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem4 "Proposition C.4 (Boundedness and Lipschitzness of ùë§_{ùëé‚Å¢ùëè}). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), (ii) stable EMA normalization with strictly positive running standard deviations ([PropositionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem5 "Proposition C.5 (Stability of EMA Normalization). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), (iii) PPO convergence to stationary points ([PropositionÀúC.6](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem6 "Proposition C.6 (Convergence of PPO Objective). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), (iv) consistent and bounded Gumbel-Softmax gradients ([PropositionÀúC.7](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem7 "Proposition C.7 (Consistency and Boundedness of Stage 2 Gradients). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), and (v) (1‚àí1/e)(1-1/e)-approximation to optimal adaptive policy via adaptive submodularity.

Information-Theoretic Optimality: Building on information bottleneck theory (Tishby et al., [1999](https://arxiv.org/html/2602.06394v1#bib.bib113 "The information bottleneck method"); Alemi et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib114 "Deep variational information bottleneck")), our analysis ([PropositionÀúC.13](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem13 "Proposition C.13 (Quality-Aware Information Bottleneck Interpretation). ‚Ä£ C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.9](https://arxiv.org/html/2602.06394v1#A3.SS9 "C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) shows QA-Token minimizes the quality-aware information bottleneck:
‚ÑíQA‚Äã(V)=‚àíI‚Äã(T;Y|Q)+Œ≤‚ãÖI‚Äã(T;X|Q)\mathcal{L}\_{\text{QA}}(V)=-I(T;Y|Q)+\beta\cdot I(T;X|Q),
achieving optimal compression-relevance tradeoffs under noisy conditions by maximizing task-relevant information I‚Äã(T;Y|Q)I(T;Y|Q) while minimizing redundant representation complexity I‚Äã(T;X|Q)I(T;X|Q), conditioned on quality QQ. Complete proofs in [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5 "C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") and [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Having established the theoretical framework and convergence guarantees, we now validate QA-Token empirically across two domains with distinct noise characteristics.

## 5 Empirical Validation

Setup: Results represent means over 10 trials with 95% CIs and Welch‚Äôs t-test with Holm-Bonferroni correction (significance level psig=0.05p\_{\text{sig}}=0.05). Evaluation spans domain benchmarks, 7B-parameter foundation models, and ablation studies (complete details in [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[SectionÀúG.3](https://arxiv.org/html/2602.06394v1#A7.SS3 "G.3 Computational Costs ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

### 5.1 Genomics (QA-BPE-seq)

Data: 150bp paired-end reads (ART simulator (Huang et al., [2012](https://arxiv.org/html/2602.06394v1#bib.bib49 "ART: a next-generation sequencing read simulator")), 30x coverage, doubled error rates), GRCh38 reference, GIAB HG002 truth set (Zook et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib50 "Extensive sequencing of seven human genomes to characterize benchmark reference materials")), CAMI II metagenome (Sczyrba et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib51 "Critical assessment of metagenome interpretation‚Äîa benchmark of metagenomics software")). Details in [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Baselines: We compare against (i) general-purpose tokenizers (BPE, SentencePiece (Kudo and Richardson, [2018](https://arxiv.org/html/2602.06394v1#bib.bib15 "SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing")), WordPiece), (ii) robustness-enhanced methods (BPE-dropout (Provilkov et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib26 "BPE-dropout: simple and effective subword regularization"))), (iii) byte-level models (ByT5 (Xue et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib27 "ByT5: towards a token-free future with pre-trained byte-to-byte models")), CANINE (Clark et al., [2021](https://arxiv.org/html/2602.06394v1#bib.bib28 "Canine: pre-training an efficient tokenization-free encoder for language representation"))), (iv) domain-standard k-mers (6-mer DNABERT (Ji et al., [2021](https://arxiv.org/html/2602.06394v1#bib.bib9 "DNABERT: pre-trained bidirectional encoder representations from transformers model for dna-language in genome"))), and (v) neural approaches (CharFormer (Tay et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib29 "Charformer: fast character transformers via gradient-based subword tokenization"))).

Quality Design: Phred scores with position decay, geometric mean aggregation, learned Œ±=0.72¬±0.03\alpha=0.72\pm 0.03, Œ≤pos=0.014¬±0.002\beta\_{\text{pos}}=0.014\pm 0.002.

Evaluation: (i) Variant calling via a Transformer model that takes token embeddings as features and predicts variant calls, evaluated against GIAB truth sets using hap.py; (ii) taxonomic classification (6-layer Transformer); (iii) sequence reconstruction (autoencoder), following established benchmarking protocols (Rumpf et al., [2023](https://arxiv.org/html/2602.06394v1#bib.bib102 "SequenceLab: a comprehensive benchmark of computational methods for comparing genomic sequences")). [TableÀú1](https://arxiv.org/html/2602.06394v1#S5.T1 "In 5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") shows QA-BPE-seq outperforms all baselines (p<0.001p<0.001).

Key Insights: (i) QA-BPE-seq achieves 6.7 percentage point F1 improvement in variant calling (0.891 vs. 0.824 for BPE). (ii) Byte-level models fail catastrophically (2.5√ó\times slower, 7‚Äì9% lower accuracy). (iii) Emergent vocabulary aligns with biological units (codons, motifs) at high-quality regions without explicit supervision (vocabulary analysis in [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Table 1: Downstream task performance for genomic tokenization. Values are means with 95% CI over n=10n=10 runs. Time: relative wall-clock (BPE=10.0√ó\times).

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Method | Var. F1 | Taxa F1 | Recon. | Time |
| Standard BPE | .824¬±\pm.004 | .856¬±\pm.005 | .317¬±\pm.010 | 10.0 |
| SentencePiece | .837¬±\pm.004 | .872¬±\pm.005 | .301¬±\pm.009 | 10.1 |
| WordPiece | .829¬±\pm.005 | .863¬±\pm.006 | .308¬±\pm.011 | 10.0 |
| BPE-dropout | .841¬±\pm.004 | .878¬±\pm.005 | .295¬±\pm.009 | 10.2 |
| ByT5 | .812¬±\pm.006 | .845¬±\pm.007 | .338¬±\pm.012 | 25.3 |
| CANINE | .818¬±\pm.005 | .852¬±\pm.006 | .325¬±\pm.011 | 22.7 |
| DNABERT-k | .851¬±\pm.003 | .889¬±\pm.004 | .287¬±\pm.008 | 9.8 |
| CharFormer | .856¬±\pm.003 | .893¬±\pm.004 | .279¬±\pm.008 | 10.4 |
| QA-BPE-seq | .891¬±\pm.004 | .917¬±\pm.003 | .241¬±\pm.007 | 10.2 |




Table 2: Ablation Study for QA-BPE-seq (Variant F1). Values are means with 95% CI over n=10n=10 runs.‚àó

|  |  |  |
| --- | --- | --- |
| Configuration | Var. F1 | Œî\Delta(%) |
| QA-BPE-seq (Full) | .891¬±\pm.004 | ‚Äî |
| w/o RL (Greedy wa‚Äãbw\_{ab}) | .862¬±\pm.005 | ‚àí-3.3 |
| w/o Quality (RQ=0R\_{Q}=0) | .825¬±\pm.004 | ‚àí-7.4 |
| w/o Info. Reward (RI=0R\_{I}=0) | .872¬±\pm.005 | ‚àí-2.1 |
| w/o Adapt. Params | .857¬±\pm.006 | ‚àí-3.8 |
| w/o Rb‚Äãi‚ÄãoR\_{bio} | .885¬±\pm.004 | ‚àí-0.7 |
| QualTok (Baseline) | .840¬±\pm.005 | ‚àí-5.7 |

* \*

  ‚Äúw/o RL (Greedy wa‚Äãbw\_{ab})‚Äù uses full QA-Token merge score with learned Œ±\alpha but selects merges greedily without RL policy optimization. ‚ÄúQualTok (Baseline)‚Äù additionally fixes adaptive parameters (Œ±=0.5\alpha{=}0.5, uniform weights).




Table 3: Ablation Study for QAT-QF (Return Pred. Acc. % and Sharpe Ratio). Means with 95% CI over n=10n=10 runs.‚àó

|  |  |  |
| --- | --- | --- |
| Variant | Ret. Pred. (%) | Sharpe |
| Full Model | 68.3¬±\pm0.5 | 1.72¬±\pm0.07 |
| w/o Quality (RQ=0R\_{Q}=0) | 64.2¬±\pm0.6 | 1.56¬±\pm0.08 |
| w/o Info. (RI=0R\_{I}=0) | 65.1¬±\pm0.5 | 1.61¬±\pm0.07 |
| w/o Pred. Power (RP=0R\_{P}=0) | 63.9¬±\pm0.6 | 1.49¬±\pm0.09 |
| w/o Complexity (RC=0R\_{C}=0) | 66.8¬±\pm0.4 | 1.73¬±\pm0.06 |
| Fixed Œ±\alpha | 65.4¬±\pm0.5 | 1.65¬±\pm0.07 |
| Fixed Œ≥\gamma | 64.9¬±\pm0.5 | 1.59¬±\pm0.08 |
| QualTok-QF (Baseline) | 64.8¬±\pm0.6 | 1.58¬±\pm0.08 |

* \*

  ‚ÄúQualTok-QF (Baseline)‚Äù uses a simplified quality-aware merge score with fixed Œ±=0.5\alpha{=}0.5 and uniform weights, without RL policy optimization or adaptive parameter learning.

### 5.2 Quantitative Finance (QAT-QF)

Dataset: We use high-frequency limit order book (LOB) data for the BTC/USD trading pair from LOBSTER (Huang and Polak, [2011](https://arxiv.org/html/2602.06394v1#bib.bib54 "LOBSTER: limit order book reconstruction system")), specifically reconstructed snapshots at 10 levels for the first quarter of 2023. The data is split chronologically into 70% for training, 15% for validation, and 15% for testing. Atomic elements are defined as sequences of 5 consecutive LOB events, encoded as tuples (Œî‚Äãmid,Œî‚Äãspread,vol\_imbalance,event\_type,Œî‚Äãt)(\Delta\text{mid},\Delta\text{spread},\text{vol\\_imbalance},\text{event\\_type},\Delta t) with discretization: price changes into 10 bins (¬±\pm5 ticks), spread into 10 bins, volume imbalance into 5 signed bins, event types categorical (trade/cancel/limit order), time intervals into 5 log-spaced bins, yielding |Œ£|=7,500|\Sigma|=7{,}500 atomic symbols (see [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Baselines: QAT-QF is benchmarked against a diverse slate of tokenization and discretization methods relevant to financial time series.

* ‚Ä¢

  General-Purpose: Standard BPE, SentencePiece (Unigram LM mode), and BPE-dropout (Provilkov et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib26 "BPE-dropout: simple and effective subword regularization")) to assess robustness.
* ‚Ä¢

  Time-Series Specific: Symbolic Aggregate approXimation (SAX) (Lin et al., [2003](https://arxiv.org/html/2602.06394v1#bib.bib55 "Symbolic representation of time series, with implications for streaming algorithms")) (PAA=16, alphabet size=8) and Bag-of-SFA-Symbols (BOSS) (Sch√§fer, [2015](https://arxiv.org/html/2602.06394v1#bib.bib56 "The boss is concerned with time series classification in the presence of noise")), both widely used for symbolic time series representation.

The target vocabulary size for subword models is 16,000.

Evaluation: We assess (i) return prediction accuracy (5-minute mid-price return sign), (ii) volatility forecasting RMSE (5-minute realized volatility), (iii) market regime identification (2-state GARCH-HMM classification), and (iv) trading performance (Sharpe ratio (Sharpe, [1994](https://arxiv.org/html/2602.06394v1#bib.bib48 "The sharpe ratio")) with 5bp transaction cost). Models use 2-layer LSTMs (128 hidden units) and PPO agents (Deng et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib41 "Deep direct reinforcement learning for financial signal representation and trading")). See [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") and [SectionÀúH.4](https://arxiv.org/html/2602.06394v1#A8.SS4 "H.4 Financial Experimental Methodology Details ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") for implementation details.

Results: [TableÀú4](https://arxiv.org/html/2602.06394v1#S5.T4 "In 5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") presents results averaged over n=10n=10 runs. QAT-QF improves performance across all financial tasks (p<0.01p<0.01, Holm-Bonferroni corrected). The trading agent achieves Sharpe ratio of 1.72¬±0.071.72\pm 0.07 compared to 1.32¬±0.051.32\pm 0.05 for standard BPE (30% improvement). See ablation analysis in [TableÀú3](https://arxiv.org/html/2602.06394v1#S5.T3 "In 5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Table 4: Downstream task performance for financial tokenization. Values are means with 95% CI over n=10n=10 runs. Time: minutes per epoch.

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
| Method | Ret. (%) | Vol. | Regime | Sharpe | Time |
| BPE | 61.2¬±\pm0.5 | .014¬±\pm.001 | 73.5¬±\pm0.6 | 1.32¬±\pm.05 | 15.0 |
| SAX | 58.9¬±\pm0.6 | .014¬±\pm.001 | 75.2¬±\pm0.5 | 1.29¬±\pm.06 | 14.5 |
| BOSS | 62.3¬±\pm0.4 | .013¬±\pm.001 | 78.4¬±\pm0.4 | 1.45¬±\pm.05 | 14.8 |
| QAT-QF | 68.3¬±\pm0.5 | .010¬±\pm.001 | 86.4¬±\pm0.3 | 1.72¬±\pm.07 | 15.2 |

## 6 Foundation Model Validation

We validate QA-Token on domain benchmarks ([SectionÀú5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and now evaluate at foundation scale. We retrain state-of-the-art foundation models in genomics and finance to demonstrate that quality-aware tokenization improves how large models learn from noisy corpora, departing from traditional frequency-based approaches.

### 6.1 Metagenomics Foundation Model: METAGENE-1 7B

Setup: Re-tokenized METAGENE-1 (Liu and others, [2025](https://arxiv.org/html/2602.06394v1#bib.bib84 "METAGENE-1: metagenomic foundation model for pandemic monitoring")) (7B parameters, 1.7T base pairs) with identical architecture/hyperparameters, comparing BPE vs QA-BPE-seq.

Quality-Aware Design: The tokenizer is trained on 2B base pairs (0.12% of corpus) using genomic quality metrics (Eq.¬†[13](https://arxiv.org/html/2602.06394v1#A4.E13 "Equation 13 ‚Ä£ D.1 Genomics: Detailed Sequencing Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) combining (i) Phred-based quality scores, (ii) conservation scores from k-mer analysis, (iii) GC-content deviation metrics, and (iv) secondary structure prediction confidence. The learned Œ≤pos=0.014\beta\_{\text{pos}}=0.014 captures position-specific quality decay (see [SectionÀúH.1](https://arxiv.org/html/2602.06394v1#A8.SS1 "H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") for implementation).

Training Budget: Both models process identical raw data volume (1.7T base pairs). The 15% token reduction means QA-BPE-seq completes epochs in fewer optimization steps while maintaining equal raw data exposure. Step-matched experiments (same optimization steps, where QA-BPE-seq processes 17.6% more raw data per step) show consistent improvements ([AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Table 5: Pathogen Detection benchmark (MCC). QA-Token achieves state-of-the-art.

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Model | T-1 | T-2 | T-3 | T-4 | T-5 | Avg |
| DNABERT | 82.2 | 81.4 | 83.3 | 84.6 | 82.9 | 82.9 |
| DNABERT-2 | 86.7 | 86.9 | 88.3 | 89.8 | 87.9 | 87.9 |
| DNABERT-S | 85.4 | 85.2 | 89.0 | 88.4 | 86.0 | 87.0 |
| NT-2.5B-M | 83.8 | 83.5 | 82.5 | 79.9 | 81.4 | 82.4 |
| NT-2.5B-1k | 77.5 | 80.4 | 79.8 | 78.4 | 79.0 | 79.0 |
| HyenaDNA | 78.7 | 79.1 | 80.4 | 81.2 | 79.9 | 79.9 |
| METAGENE-1 | 92.1 | 90.9 | 93.7 | 95.1 | 94.0 | 93.0 |
| +QA-Token | 93.8 | 93.0 | 95.1 | 96.2 | 94.5 | 94.5 |
| Œî\Delta | +1.7 | +2.0 | +1.4 | +1.1 | +0.6 | +1.6 |

Pathogen Detection: QA-Token achieves state-of-the-art 94.53 MCC, surpassing the original METAGENE-1 by 1.57 points (p<0.001p<0.001). Consistent improvements across all five subtasks demonstrate robustness. Task-2 shows the largest gain (+2.04¬†MCC) on highly degraded metagenomic samples where quality awareness is most critical, validating our theoretical framework.

Table 6: Genome Understanding Evaluation (GUE): Multi-species benchmark.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Task | META-1 | QA-Token | Œî\Delta | p |
| Regulatory Elements | | | | |
| TF-Mouse (MCC) | 71.4¬±\pm0.8 | 72.8¬±\pm0.7 | +1.4 | .002 |
| TF-Human (MCC) | 68.3¬±\pm0.9 | 69.9¬±\pm0.8 | +1.6 | .001 |
| Promoter (MCC) | 82.3¬±\pm0.5 | 85.5¬±\pm0.4 | +3.2 | <<.001 |
| Enhancer (AUC) | .876¬±\pm.012 | .892¬±\pm.010 | +.016 | .003 |
| Epigenetics | | | | |
| H3K4me3 (MCC) | 65.2¬±\pm0.6 | 66.8¬±\pm0.5 | +1.6 | .002 |
| H3K27ac (MCC) | 66.8¬±\pm0.7 | 68.2¬±\pm0.6 | +1.4 | .003 |
| Methylation (AUC) | .823¬±\pm.015 | .841¬±\pm.013 | +.018 | .004 |
| Structure | | | | |
| Splice Site (F1) | 87.8¬±\pm0.4 | 89.5¬±\pm0.3 | +1.7 | <<.001 |
| RNA Structure | 72.1¬±\pm0.8 | 73.9¬±\pm0.7 | +1.8 | .002 |
| Variants | | | | |
| COVID (F1) | 72.5¬±\pm0.6 | 73.3¬±\pm0.5 | +0.8 | .018 |
| SNP Effect | .684¬±\pm.021 | .712¬±\pm.018 | +.028 | .001 |
| Win Rate | 46.4% | 57.1% | +10.7% | ‚Äî |
| Efficiency | 370B | 315B | ‚àí-15% | ‚Äî |

GUE Results: QA-Token improves performance across all categories (largest: +3.2 MCC promoter detection). 15% token reduction with performance gains indicates semantic coherence of quality-aware merging.

### 6.2 Financial Time-Series Foundation Model

Setup: 1.2B parameter model (24 layers, 2048 dim) inspired by TimesFM (Das et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib85 "TimesFM: a decoder-only foundation model for time-series forecasting")) and Chronos (Ansari et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib86 "Chronos: learning the language of time series")), using QAT-QF for noise handling.

Training Corpus: We train on 500 billion time-series observations spanning (i) high-frequency order book data (40%, 5 years millisecond-resolution across 50 liquid assets), (ii) daily OHLCV data (30%, 20 years for major indices), (iii) macroeconomic indicators (20%, 30 years G20 data), and (iv) alternative data (10%, sentiment scores, option flows, ETF compositions).

Quality-Aware Design: QAT-QF employs comprehensive market quality metrics (Eq.¬†[14](https://arxiv.org/html/2602.06394v1#A4.E14 "Equation 14 ‚Ä£ D.2 Finance: Comprehensive Market Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), combining liquidity, signal, stability, and information quality dimensions. The learned weights wkw\_{k} adapt to different market regimes, with Œ≤vol=0.50¬±0.05\beta\_{\text{vol}}=0.50\pm 0.05 for volatility scaling (see [SectionÀúH.2](https://arxiv.org/html/2602.06394v1#A8.SS2 "H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") for complete parameter settings).

Metrics: Dir. = directional accuracy (%); Ret. MSE = return prediction MSE (normalized to BPE=1.0); Vol RMSE = volatility forecast RMSE; Order Flow = order imbalance prediction R2R^{2}; Regime F1 = market regime classification F1; Tail Risk = VaR exceedance prediction F1; Rotation = sector rotation strategy Sharpe ratio.

Table 7: Financial foundation model evaluation (100 test episodes).

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Task | Zero-shot | | | Few-shot | | |
| BPE | QAT | Œî\Delta | BPE | QAT | Œî\Delta |
| Price Prediction | | | | | | |
| Dir. 5m | 52.3 | 58.7 | +12 | 61.2 | 68.3 | +12 |
| Dir. 1h | 51.8 | 57.2 | +10 | 59.4 | 65.8 | +11 |
| Dir. 1d | 50.9 | 54.6 | +7 | 56.7 | 61.2 | +8 |
| Ret. MSE | 1.00 | 0.81 | ‚àí-19 | 0.72 | 0.60 | ‚àí-18 |
| Volatility | | | | | | |
| Vol RMSE | .018 | .014 | ‚àí-23 | .013 | .010 | ‚àí-27 |
| GARCH Est. | .156 | .118 | ‚àí-24 | .098 | .071 | ‚àí-28 |
| Vol Regime | 71.2 | 79.8 | +12 | 82.3 | 88.4 | +7 |
| Microstructure | | | | | | |
| Spread | .023 | .019 | ‚àí-20 | .018 | .013 | ‚àí-25 |
| Volume | 31.2 | 24.8 | ‚àí-21 | 22.6 | 17.3 | ‚àí-24 |
| Order Flow | .412 | .523 | +27 | .567 | .681 | +20 |
| Risk | | | | | | |
| Regime F1 | .673 | .751 | +12 | .798 | .856 | +7 |
| Drawdown | .682 | .743 | +9 | .761 | .812 | +7 |
| Tail Risk | .412 | .486 | +18 | .523 | .598 | +14 |
| Cross-Asset | | | | | | |
| Corr. Pred. | .623 | .694 | +11 | .712 | .768 | +8 |
| Lead-Lag | 58.3 | 64.7 | +11 | 67.2 | 73.1 | +9 |
| Rotation | 1.23 | 1.41 | +15 | 1.52 | 1.72 | +13 |
| Avg. Œî\Delta | ‚Äî | ‚Äî | +16% | ‚Äî | ‚Äî | +13% |

Financial Results: QAT-QF achieves 7.3‚Äì27.0% zero-shot improvements, largest in volatility/microstructure tasks. Order flow imbalance (+27.0%) and regime detection (+11.6% F1) demonstrate QA-Token‚Äôs noise-filtering capability, consistent with our information-theoretic optimality result ([PropositionÀúC.13](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem13 "Proposition C.13 (Quality-Aware Information Bottleneck Interpretation). ‚Ä£ C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). Implementation details in [AppendixÀúF](https://arxiv.org/html/2602.06394v1#A6 "Appendix F Hyperparameter Sensitivity Analysis ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[SectionÀúG.3](https://arxiv.org/html/2602.06394v1#A7.SS3 "G.3 Computational Costs ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Computational Costs:
QA-Token requires 50‚Äì60 GPU-hours for vocabulary construction compared to minutes for standard BPE. However, this one-time cost is amortized across billions of inference operations: once constructed, the vocabulary imposes no additional inference overhead‚Äîtokenization speed is identical to BPE (‚àº10{\sim}10ms/sequence) as quality metrics are only used during construction. This efficiency is compatible with high-performance computing systems and in-storage processing architectures (Mansouri Ghiasi et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib100 "GenStore: a high-performance in-storage processing system for genome sequence analysis"); Ghiasi et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib101 "GenStore: in-storage filtering of genomic data for high-performance and energy-efficient genome analysis"), [2023](https://arxiv.org/html/2602.06394v1#bib.bib104 "MetaStore: high-performance metagenomic analysis via in-storage computing"); Mansouri Ghiasi et al., [2023](https://arxiv.org/html/2602.06394v1#bib.bib105 "MetaStore: high-performance metagenomic analysis via in-storage computing"); Ghiasi et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib106 "Megis: high-performance, energy-efficient, and low-cost metagenomic analysis with in-storage processing")). For foundation models where tokenization is performed once but affects billions of inference operations, the additional upfront cost is justified by substantial long-term gains; for small-scale applications or clean datasets, standard BPE may remain more practical.

## 7 Conclusion

QA-Token extends tokenization from frequency counting to quality-driven vocabulary construction, addressing limitations in processing noisy real-world data. We presented: (i) bilevel optimization with NP-hardness proof ([TheoremÀú3.2](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem2 "Theorem 3.2 (Computational Complexity). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), (ii) MDP formulation achieving (1‚àí1/e)(1-1/e)-approximation ([DefinitionÀúE.4](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem4 "Definition E.4 (Tokenization MDP). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [PropositionÀúE.5](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem5 "Proposition E.5 (MDP Well-Formedness). ‚Ä£ E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúE.7](https://arxiv.org/html/2602.06394v1#A5.SS7 "E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), (iii) Gumbel-Softmax enabling end-to-end learning ([TheoremÀúC.8](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem8 "Theorem C.8 (Gumbel-Softmax Properties). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). Our evaluation demonstrates consistent improvements: (1) genomics‚Äî6.7 pp F1 improvement, 94.53 MCC pathogen detection; (2) finance‚Äî30% Sharpe ratio increase; (3) foundation models achieve new benchmarks (analysis in [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[SectionÀúG.3](https://arxiv.org/html/2602.06394v1#A7.SS3 "G.3 Computational Costs ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). As biological sequence archives scale to petabases (Karasikov et al., [2025](https://arxiv.org/html/2602.06394v1#bib.bib111 "Efficient and accurate search in petabase-scale sequence repositories")) and variant prediction methods achieve unprecedented accuracy (Avsec et al., [2026](https://arxiv.org/html/2602.06394v1#bib.bib112 "Advancing regulatory variant effect prediction with AlphaGenome")), quality-aware tokenization becomes essential for bridging the gap between data availability and foundation model usability.

### 7.1 Scientific and Economic Impact

QA-Token enables utilization of massive noisy datasets previously considered unusable, fundamentally expanding the data frontier for foundation model training.

Scientific Acceleration in Genomics.
The Sequence Read Archive (SRA) contains over 67 petabases of publicly available genomic data‚Äîequivalent to reading the human genome 22 million times‚Äîyet a substantial fraction remains underutilized due to quality heterogeneity (Leinonen et al., [2011](https://arxiv.org/html/2602.06394v1#bib.bib110 "The sequence read archive")). Recent infrastructure advances have made these petabase-scale archives full-text searchable at economical costs (Karasikov et al., [2025](https://arxiv.org/html/2602.06394v1#bib.bib111 "Efficient and accurate search in petabase-scale sequence repositories")), and state-of-the-art methods like AlphaGenome now enable precise prediction of regulatory variant effects (Avsec et al., [2026](https://arxiv.org/html/2602.06394v1#bib.bib112 "Advancing regulatory variant effect prediction with AlphaGenome")). However, the gap between data *accessibility* and data *usability* for foundation model training persists: standard tokenization methods either discard low-quality reads entirely or propagate sequencing errors into learned representations. QA-Token bridges this gap by enabling quality-aware tokenization that can leverage the full breadth of available sequence data. We demonstrate three key applications: (1)¬†*Pandemic surveillance*‚Äîenvironmental samples for pathogen monitoring contain 40‚Äì60% noise from contamination and sequencing errors; QA-Token directly trains on such noisy metagenomic data (Gollwitzer et al., [2023b](https://arxiv.org/html/2602.06394v1#bib.bib107 "MetaTrinity: enabling fast metagenomic classification via seed counting and edit distance approximation"), [a](https://arxiv.org/html/2602.06394v1#bib.bib103 "MetaFast: enabling fast metagenomic classification via seed counting and edit distance approximation"), [2025a](https://arxiv.org/html/2602.06394v1#bib.bib536 "MetaOmics-10t: the foundational dataset to unlock causal modeling of microbial ecosystems")), achieving 94.53 MCC on pathogen detection and enabling real-time global pandemic monitoring using previously unusable environmental samples. (2)¬†*Drug discovery*‚Äîlong-read sequencing for structural variants has 10‚Äì15% error rates; our 6.7 percentage point F1 improvement in variant calling accelerates identification of drug targets from complex genomic rearrangements, complementing advances in regulatory variant prediction (Avsec et al., [2026](https://arxiv.org/html/2602.06394v1#bib.bib112 "Advancing regulatory variant effect prediction with AlphaGenome")). (3)¬†*Evolutionary biology*‚Äîancient DNA is heavily degraded with >>50% damage; quality-aware tokenization preserves authentic ancient sequences while filtering damage, unlocking evolutionary insights from previously unanalyzable specimens.

Economic Impact in Finance.
Global financial markets generate 5TB of data per day, with 40% containing microstructure noise from market fragmentation and latency; current approaches require expensive data cleaning infrastructure costing millions annually. QA-Token delivers quantifiable economic value: (1)¬†*Algorithmic trading*‚Äî30% Sharpe ratio improvement translates to billions in additional returns for large funds; 27% better order flow prediction reduces execution costs by basis points worth millions daily. (2)¬†*Risk management*‚Äî18% improvement in tail risk estimation could have prevented billions in losses during market crashes; 11.6% better regime detection enables faster portfolio rebalancing. (3)¬†*Democratization*‚Äîsmaller institutions can now compete without expensive data cleaning infrastructure, reducing barriers to entry for quantitative trading strategies.

Broader Societal Impact.
Beyond genomics and finance, QA-Token has potential applications in: *Healthcare*‚Äîhospitals generate terabytes of noisy medical data daily; QA-Token enables training on real-world clinical data with artifacts, with potential to improve diagnostic accuracy and treatment recommendations, including applications in cancer treatment optimization (Gollwitzer et al., [2025b](https://arxiv.org/html/2602.06394v1#bib.bib537 "Steering the evolutionary game: hierarchical control of therapeutic resistance in cancer treatment")). *Climate science*‚Äîsatellite imagery is often corrupted by cloud cover and atmospheric interference; QA-Token allows direct training on partially corrupted earth observation data, accelerating climate monitoring and prediction capabilities. *Infrastructure monitoring*‚Äîsensor networks produce petabytes of data with frequent failures; quality-aware tokenization enables robust anomaly detection despite sensor degradation, applicable to smart city applications and industrial IoT.

### 7.2 Limitations and Future Work

Limitations: (1) QA-Token requires domain-specific quality signals; domains without established metrics need custom design. (2) The vocabulary construction overhead limits rapid iteration during development. (3) Effective quality function design benefits from domain knowledge, though adaptive learning reduces sensitivity to initial choices.

Future Directions: (1) Universal quality metrics from data statistics (local entropy, consistency). (2) Online adaptation for streaming data. (3) Multimodal extension to vision-language and audio-text. (4) Efficiency via distillation and pruning.

## Impact Statement

Public sequence repositories now contain over 67 petabase pairs of raw sequencing data, with the European Nucleotide Archive doubling approximately every 45 months¬†(Karasikov et al., [2025](https://arxiv.org/html/2602.06394v1#bib.bib111 "Efficient and accurate search in petabase-scale sequence repositories")). Recent advances have made these petabase-scale archives full-text searchable at costs as low as $0.74 per queried megabase pair, demonstrating that the infrastructure for large-scale sequence analysis is maturing rapidly. However, a substantial fraction of this data remains underutilized for foundation model training due to quality heterogeneity. QA-Token bridges this gap between data *accessibility* and data *usability*, enabling quality-aware tokenization that can leverage the full breadth of available sequence data for foundation model training.

Genomics. We achieve 94.53 MCC on pathogen detection from environmental samples containing 40‚Äì60% noise, enabling real-time pandemic surveillance using previously unusable metagenomic data. Our 6.7 percentage point F1 improvement in variant calling accelerates drug target identification from complex genomic rearrangements with 10‚Äì15% sequencing error rates. The same technology could theoretically be misused for biosurveillance; we have designed QA-Token for research purposes with standard institutional safeguards.

Finance. Global financial markets generate 5TB of data per day, with 40% containing microstructure noise. Our 30% Sharpe ratio improvement translates to quantifiable returns for algorithmic trading, while 27% better order flow prediction reduces execution costs. Enhanced trading performance raises concerns about market fairness; QA-Token provides incremental improvements within existing regulatory frameworks.

Resources. The 50‚Äì60 GPU-hour vocabulary construction cost is substantially lower than foundation model training costs, making QA-Token accessible to researchers with modest computational budgets. The highly compressed quality-aware vocabularies are portable for further analysis.

## Reproducibility Statement

We provide comprehensive details throughout the paper and appendices.

Theoretical contributions: All theorems and propositions include complete proofs ([SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.2](https://arxiv.org/html/2602.06394v1#A3.SS2 "C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5 "C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúC.9](https://arxiv.org/html/2602.06394v1#A3.SS9 "C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) with explicit assumptions ([SectionÀúC.6](https://arxiv.org/html/2602.06394v1#A3.SS6 "C.6 Assumptions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and convergence guarantees ([SectionÀúE.4](https://arxiv.org/html/2602.06394v1#A5.SS4 "E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Algorithms: Complete pseudocode for RL policy optimization (Algorithm¬†[1](https://arxiv.org/html/2602.06394v1#alg1 "Algorithm 1 ‚Ä£ E.1.3 PPO Training Algorithm ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), adaptive parameter learning (Algorithm¬†[2](https://arxiv.org/html/2602.06394v1#alg2 "Algorithm 2 ‚Ä£ E.2.2 Gumbel-Softmax Differentiable Optimization ‚Ä£ E.2 Stage 2: Adaptive Parameter Learning ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), and final vocabulary construction (Algorithm¬†[3](https://arxiv.org/html/2602.06394v1#alg3 "Algorithm 3 ‚Ä£ E.3 Final Vocabulary Construction ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) are provided in [AppendixÀúE](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Implementation: Domain-specific quality metrics with exact formulas ([SectionÀú2](https://arxiv.org/html/2602.06394v1#S2 "2 Quality Metrics for Noisy Domains ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [AppendixÀúD](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), hyperparameters for all models ([SectionÀúH.1](https://arxiv.org/html/2602.06394v1#A8.SS1 "H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [SectionÀúH.2](https://arxiv.org/html/2602.06394v1#A8.SS2 "H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), and computational requirements ([SectionÀúG.3](https://arxiv.org/html/2602.06394v1#A7.SS3 "G.3 Computational Costs ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) are fully specified.

Experimental protocol: Statistical methodology including 10 independent trials, 95% confidence intervals, Welch‚Äôs t-test with Holm-Bonferroni correction, and effect sizes are detailed in [SectionÀú5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") and [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"). Dataset specifications, preprocessing steps, and evaluation metrics are provided in [AppendixÀúG](https://arxiv.org/html/2602.06394v1#A7 "Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")‚Äì[SectionÀúI.2](https://arxiv.org/html/2602.06394v1#A9.SS2 "I.2 Dataset and Release Plan ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Baselines: Nine baseline methods with implementation details and hyperparameters are described in [SectionÀú5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") and [SectionÀúI.4](https://arxiv.org/html/2602.06394v1#A9.SS4 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Code release: We will provide a GitHub repository with all source code, trained models, and scripts to reproduce results.

### Conflict of Interest Statement

A.E.G. and D.d.G. are co-founders and shareholders of Anto Biosciences (YC F25).

D.A.S., P.L., and A.N.d.l.C. declare no competing interests.

## References

* A. A. Alemi, I. Fischer, J. V. Dillon, and K. Murphy (2017)
  Deep variational information bottleneck.
  In International Conference on Learning Representations (ICLR),
  Cited by: [¬ßC.9](https://arxiv.org/html/2602.06394v1#A3.SS9.1.p1.2 "Proof. ‚Ä£ C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.5](https://arxiv.org/html/2602.06394v1#S4.SS5.p2.4 "4.5 Theoretical Guarantees ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* T. G. Andersen, T. Bollerslev, F. X. Diebold, and P. Labys (2001)
  The distribution of realized exchange rate volatility.
  Journal of the American statistical association 96 (453),  pp.¬†42‚Äì55.
  Cited by: [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p1.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. F. Ansari, L. Stella, C. Turkmen, X. Zhang, P. Mercado, H. Shen, O. Shchur, S. S. Rangapuram, S. Pineda Arango, S. Kapoor, et al. (2024)
  Chronos: learning the language of time series.
  arXiv preprint arXiv:2403.07815.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p1.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* ≈Ω. Avsec, N. Latysheva, J. Cheng, et al. (2026)
  Advancing regulatory variant effect prediction with AlphaGenome.
  Nature 649,  pp.¬†1206‚Äì1218.
  External Links: [Document](https://dx.doi.org/10.1038/s41586-025-10014-0)
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß7](https://arxiv.org/html/2602.06394v1#S7.p1.1 "7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* T. Baldwin, P. Cook, M. Lui, A. MacKinlay, and L. Wang (2013)
  Noisy text analytics.
  In Proceedings of the Australasian Language Technology Association Workshop 2013,
   pp.¬†1‚Äì10.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* F. Barbieri, J. Camacho-Collados, L. Espinosa-Anke, and L. Neves (2020)
  TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification.
  In Proceedings of Findings of EMNLP,
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.p1.1 "In 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [1st item](https://arxiv.org/html/2602.06394v1#A9.I6.i3.I1.i1.p1.1 "In 3rd item ‚Ä£ I.5 Evaluation Metrics ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* F. Barbieri, J. Camacho-Collados, F. Ronzano, L. Espinosa-Anke, M. Ballesteros, V. Basile, V. Patti, and H. Saggion (2018)
  Semeval 2018 task 2: multilingual emoji prediction.
  In Proceedings of The 12th International Workshop on Semantic Evaluation,
   pp.¬†24‚Äì33.
  Cited by: [2nd item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i2.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* V. Basile, C. Bosco, E. Fersini, D. Nozza, V. Patti, F. M. Rangel Pardo, P. Rosso, and M. Sanguinetti (2019)
  SemEval-2019 task 5: multilingual detection of hate speech against immigrants and women in Twitter.
  In Proceedings of the 13th International Workshop on Semantic Evaluation,
  Minneapolis, Minnesota, USA,  pp.¬†54‚Äì63.
  External Links: [Document](https://dx.doi.org/10.18653/v1/S19-2007)
  Cited by: [4th item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i4.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio (2016)
  Neural combinatorial optimization with reinforcement learning.
  In International Conference on Learning Representations,
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p4.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Bhandari and D. Russo (2021)
  Global optimality guarantees for policy gradient methods.
  Operations Research 69 (6),  pp.¬†1744‚Äì1767.
  External Links: [Document](https://dx.doi.org/10.1287/opre.2021.0014)
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.6.p2.4 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.1](https://arxiv.org/html/2602.06394v1#S4.SS1.p1.2 "4.1 Reinforcement Learning Formulation ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov (2017)
  Enriching word vectors with subword information.
  In Transactions of the Association for Computational Linguistics,
  Vol. 5,  pp.¬†135‚Äì146.
  Cited by: [¬ßD.3](https://arxiv.org/html/2602.06394v1#A4.SS3.p4.1 "D.3 Social Media: Linguistic Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [1st item](https://arxiv.org/html/2602.06394v1#A8.I6.i3.I1.i1.p1.3 "In 3rd item ‚Ä£ H.7 Domain-Specific Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Bolte, Q. Le, E. Pauwels, and S. Vaiter (2024)
  Geometric and computational hardness of bilevel programming.
  Mathematical programming.
  External Links: [Document](https://dx.doi.org/10.1007/s10107-025-02229-w)
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.p2.2 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* V. S. Borkar (2009)
  Stochastic approximation: a dynamical systems viewpoint.
   Hindustan Book Agency.
  Cited by: [¬ßE.4](https://arxiv.org/html/2602.06394v1#A5.SS4.1.p1.2 "Proof. ‚Ä£ E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. (2020)
  Language models are few-shot learners.
  In Advances in Neural Information Processing Systems,
  Vol. 33,  pp.¬†1877‚Äì1901.
  Cited by: [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. Cen and Y. Chi (2023)
  Global convergence of policy gradient methods in reinforcement learning, games and control.
  arXiv preprint arXiv:2310.05230.
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.6.p2.4 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Theorem 3.2](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem2.p1.2.2 "Theorem 3.2 (Computational Complexity). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.1](https://arxiv.org/html/2602.06394v1#S4.SS1.p1.2 "4.1 Reinforcement Learning Formulation ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* B. Y. Chai, Z. Wang, and M. Sachan (2024)
  The curse of tokenization.
  arXiv preprint arXiv:2402.07831.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* K. W. Church and P. Hanks (1990)
  Word association norms, mutual information, and lexicography.
  Computational linguistics 16 (1),  pp.¬†22‚Äì29.
  Cited by: [¬ßC.2](https://arxiv.org/html/2602.06394v1#A3.SS2.2.p2.1 "Proof. ‚Ä£ C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. H. Clark, D. Garcia, J. Botha, K. Lee, M. Luong, and Q. V. Le (2021)
  Canine: pre-training an efficient tokenization-free encoder for language representation.
  In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),
   pp.¬†2647‚Äì2661.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.7.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. Das, W. Kong, A. Leach, R. Sen, and R. Yu (2024)
  TimesFM: a decoder-only foundation model for time-series forecasting.
  arXiv preprint arXiv:2310.10688.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p1.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. Dempe (2020)
  Bilevel optimization: theory, algorithms and applications.
  Springer Optimization and Its Applications, Vol. 161, Springer, Berlin, Germany.
  External Links: [Document](https://dx.doi.org/10.1007/978-3-030-33566-3)
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.p2.2 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Theorem 3.2](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem2.p1.2.2 "Theorem 3.2 (Computational Complexity). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Y. Deng, F. Bao, Y. Kong, Z. Ren, and Q. Dai (2016)
  Deep direct reinforcement learning for financial signal representation and trading.
  IEEE transactions on neural networks and learning systems 28 (3),  pp.¬†653‚Äì664.
  Cited by: [¬ß5.2](https://arxiv.org/html/2602.06394v1#S5.SS2.p3.1 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Devlin, M. Chang, K. Lee, and K. Toutanova (2019)
  Bert: pre-training of deep bidirectional transformers for language understanding.
  In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers),
   pp.¬†4171‚Äì4186.
  Cited by: [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* B. Ewing, L. Hillier, M. C. Wendl, and P. Green (1998)
  Base-calling of automated sequencer traces using phred. i. accuracy assessment.
  Genome research 8 (3),  pp.¬†175‚Äì185.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p1.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* C. Finn, P. Abbeel, and S. Levine (2017)
  Model-agnostic meta-learning for fast adaptation of deep networks.
  In International conference on machine learning,
   pp.¬†1126‚Äì1135.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p5.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. Gen√ßay, F. Sel√ßuk, and B. Whitcher (2001)
  An introduction to wavelets and other filtering methods in finance and economics.
   Elsevier, San Diego.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. M. Ghiasi, J. Park, H. Mustafa, J. Kim, A. Olgun, A. Gollwitzer, D. S. Cali, C. Firtina, H. Mao, N. A. Alserr, et al. (2022)
  GenStore: in-storage filtering of genomic data for high-performance and energy-efficient genome analysis.
  In 2022 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),
   pp.¬†283‚Äì287.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p6.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. M. Ghiasi, M. Sadrosadati, H. Mustafa, A. Gollwitzer, C. Firtina, J. Eudine, H. Ma, J. Lindegger, M. B. Cavlak, M. Alser, et al. (2023)
  MetaStore: high-performance metagenomic analysis via in-storage computing.
  arXiv preprint arXiv:2311.12527.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p6.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. M. Ghiasi, M. Sadrosadati, H. Mustafa, A. Gollwitzer, C. Firtina, J. Eudine, H. Mao, J. Lindegger, M. B. Cavlak, M. Alser, et al. (2024)
  Megis: high-performance, energy-efficient, and low-cost metagenomic analysis with in-storage processing.
  In 2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA),
   pp.¬†660‚Äì677.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p6.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. Gollwitzer, M. Alser, J. Bergtholdt, J. Lindegger, M. Rumpf, C. Firtina, S. Mangul, and O. Mutlu (2023a)
  MetaFast: enabling fast metagenomic classification via seed counting and edit distance approximation.
  arXiv,  pp.¬†2311‚Äì02029.
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. E. Gollwitzer, M. Alser, J. Bergtholdt, J. Lindegger, M. Rumpf, C. Firtina, S. Mangul, and O. Mutlu (2023b)
  MetaTrinity: enabling fast metagenomic classification via seed counting and edit distance approximation.
  arXiv preprint arXiv:2311.02029.
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. E. Gollwitzer, D. A. Subramanian, I. Tucker, and G. Traverso (2025a)
  MetaOmics-10t: the foundational dataset to unlock causal modeling of microbial ecosystems.
  In NeurIPS 2025 AI for Science Workshop,
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. E. Gollwitzer, D. A. Subramanian, I. Tucker, and G. Traverso (2025b)
  Steering the evolutionary game: hierarchical control of therapeutic resistance in cancer treatment.
  In NeurIPS 2025 AI for Science Workshop,
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p4.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* D. Golovin and A. Krause (2011)
  Adaptive submodularity: theory and applications in active learning and stochastic optimization.
  In Proceedings of the 24th International Conference on Neural Information Processing Systems,
   pp.¬†2675‚Äì2683.
  Cited by: [¬ßC.7](https://arxiv.org/html/2602.06394v1#A3.SS7.1.p1.5 "Proof sketch. ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.7](https://arxiv.org/html/2602.06394v1#A3.SS7.2.p1.2 "Proof. ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* C. Grne and L. Wulf (2023)
  Completeness in the polynomial hierarchy for many natural problems in bilevel and robust optimization.
  Conference on Integer Programming and Combinatorial Optimization.
  External Links: [Document](https://dx.doi.org/10.1007/978-3-031-93112-3%5F19)
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.p2.2 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. D. Hamilton (1989)
  A new approach to the economic analysis of nonstationary time series and the business cycle.
  Econometrica: Journal of the Econometric Society,  pp.¬†357‚Äì384.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* B. Han, P. Cook, and T. Baldwin (2013)
  Lexical normalisation of short text messages: makn sens a #twitter.
  In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
   pp.¬†368‚Äì378.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßH.8](https://arxiv.org/html/2602.06394v1#A8.SS8.p1.5 "H.8 Further Details on Social Media Noise Models ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* P. R. Hansen and A. Lunde (2006)
  Realized variance and market microstructure noise.
  Journal of Business & Economic Statistics 24 (2),  pp.¬†127‚Äì161.
  Cited by: [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p2.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Harrow, A. Frankish, J. M. Gonzalez, E. Tapanari, B. Aken, D. Barrell, J. M. Mudge, E. FRecognision, A. GCoil, A. LNCipedia, et al. (2012)
  GENCODE: the reference human genome annotation for the encode project.
  Genome research 22 (9),  pp.¬†1760‚Äì1774.
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A8.I6.i1.p1.3 "In H.7 Domain-Specific Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Hasbrouck (1991)
  Measuring the information content of stock trades.
  The Journal of Finance 46 (1),  pp.¬†179‚Äì207.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* K. Heafield (2011)
  KenLM: faster and smaller language model queries.
  In Proceedings of the Sixth Workshop on Statistical Machine Translation,
   pp.¬†187‚Äì197.
  Cited by: [¬ßD.3](https://arxiv.org/html/2602.06394v1#A4.SS3.p6.4 "D.3 Social Media: Linguistic Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* M. Heinzinger, A. Elnaggar, Y. Wang, C. Dallago, U. Neettiyath, and B. Rost (2019)
  Modeling aspects of the language of life through transfer-learning protein sequences.
  BMC bioinformatics 20 (1),  pp.¬†1‚Äì17.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* G. Hinton, O. Vinyals, and J. Dean (2015)
  Distilling the knowledge in a neural network.
  External Links: 1503.02531
  Cited by: [item¬†2](https://arxiv.org/html/2602.06394v1#A9.I7.i2.p1.1 "In I.7 Approximating QA-Token: Towards Computationally Efficient Quality-Awareness ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. Huang and T. Polak (2011)
  LOBSTER: limit order book reconstruction system.
  Available at SSRN 1920143.
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A9.I1.i2.I1.i1.p1.1 "In 2nd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.2](https://arxiv.org/html/2602.06394v1#S5.SS2.p1.3 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* W. Huang, L. Li, J. R. Myers, and G. T. Marth (2012)
  ART: a next-generation sequencing read simulator.
  Bioinformatics 28 (4),  pp.¬†593‚Äì594.
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A9.I1.i1.I1.i1.p1.1 "In 1st item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p1.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J.P. Morgan (1996)
  RiskMetrics technical document.
  Technical report
   J.P. Morgan/Reuters.
  Cited by: [¬ßD.2](https://arxiv.org/html/2602.06394v1#A4.SS2.p4.4 "D.2 Finance: Comprehensive Market Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* E. Jang, S. Gu, and B. Poole (2017)
  Categorical reparameterization with gumbel-softmax.
  In International Conference on Learning Representations,
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p5.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.7.p1.4 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.9.p1.1 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.3](https://arxiv.org/html/2602.06394v1#S4.SS3.p1.8 "4.3 Adaptive Learning of Tokenization Parameters ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Y. Ji, Z. Zhou, H. Liu, and R. V. Davuluri (2021)
  DNABERT: pre-trained bidirectional encoder representations from transformers model for dna-language in genome.
  Bioinformatics 37 (15),  pp.¬†2112‚Äì2120.
  Cited by: [4th item](https://arxiv.org/html/2602.06394v1#A9.I5.i4.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* D. R. Jones, M. Schonlau, and W. J. Welch (1998)
  Efficient global optimization of expensive black-box functions.
  Journal of Global optimization 13 (4),  pp.¬†455‚Äì492.
  Cited by: [item¬†3](https://arxiv.org/html/2602.06394v1#A9.I7.i3.p1.2 "In I.7 Approximating QA-Token: Towards Computationally Efficient Quality-Awareness ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* M. Karasikov, H. Mustafa, D. Danciu, L. Bosshard, M. Zimmermann, K. Sch√ºtze, A. Kahles, and G. R√§tsch (2025)
  Efficient and accurate search in petabase-scale sequence repositories.
  Nature 647,  pp.¬†1036‚Äì1044.
  External Links: [Document](https://dx.doi.org/10.1038/s41586-025-09603-w)
  Cited by: [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p3.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß7](https://arxiv.org/html/2602.06394v1#S7.p1.1 "7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Impact Statement](https://arxiv.org/html/2602.06394v1#Sx1.p1.1 "Impact Statement ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. M. Karp (1972)
  Reducibility among combinatorial problems.
  In Complexity of Computer Computations,
   pp.¬†85‚Äì103.
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.p1.5 "Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* D. P. Kingma and J. Ba (2014)
  Adam: a method for stochastic optimization.
  arXiv preprint arXiv:1412.6980.
  Cited by: [¬ßE.4](https://arxiv.org/html/2602.06394v1#A5.SS4.3.p1.1 "Proof. ‚Ä£ E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [5th item](https://arxiv.org/html/2602.06394v1#A8.I8.i1.I1.i5.p1.3 "In 1st item ‚Ä£ H.9.2 Genomics (QA-BPE-seq) ‚Ä£ H.9 Domain-Specific Algorithms ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* T. Kudo and J. Richardson (2018)
  SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing.
  In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,
   pp.¬†66‚Äì71.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.5.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p2.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [2nd item](https://arxiv.org/html/2602.06394v1#A9.I5.i2.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* T. Kudo (2018)
  Subword regularization: improving neural network translation models with multiple subword candidates.
  In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
   pp.¬†66‚Äì75.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p2.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. Leinonen, H. Sugawara, M. Shumway, and International Nucleotide Sequence Database Collaboration (2011)
  The sequence read archive.
  Nucleic Acids Research 39 (suppl\_1),  pp.¬†D19‚ÄìD21.
  Cited by: [¬ß7.1](https://arxiv.org/html/2602.06394v1#S7.SS1.p2.1 "7.1 Scientific and Economic Impact ‚Ä£ 7 Conclusion ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Li, Y. Park, Y. Song, and S. Park (2020)
  An empirical study of tokenization strategies for various korean nlp tasks.
  In Proceedings of the 12th language resources and evaluation conference,
   pp.¬†6813‚Äì6819.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Libovick‚Äòy and M. Sachan (2024)
  Semantic segmentation for improving the performance of large language models.
  In Findings of the Association for Computational Linguistics: ACL 2024,
   pp.¬†4930‚Äì4945.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.9.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p5.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* H. Lin and J. Bilmes (2011)
  A class of submodular functions for document summarization.
  In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,
   pp.¬†510‚Äì520.
  Cited by: [¬ßC.7](https://arxiv.org/html/2602.06394v1#A3.SS7.p1.2 "C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Lin, E. Keogh, S. Lonardi, and B. Chiu (2003)
  Symbolic representation of time series, with implications for streaming algorithms.
  In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,
   pp.¬†2‚Äì11.
  Cited by: [5th item](https://arxiv.org/html/2602.06394v1#A9.I5.i5.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [2nd item](https://arxiv.org/html/2602.06394v1#S5.I3.i2.p1.1 "In 5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* O. Liu et al. (2025)
  METAGENE-1: metagenomic foundation model for pandemic monitoring.
  arXiv preprint arXiv:2501.02045.
  Cited by: [¬ß6.1](https://arxiv.org/html/2602.06394v1#S6.SS1.p1.1 "6.1 Metagenomics Foundation Model: METAGENE-1 7B ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* C. J. Maddison, A. Mnih, and Y. W. Teh (2017)
  The concrete distribution: a continuous relaxation of discrete random variables.
  In International Conference on Learning Representations,
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p5.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.7.p1.4 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.9.p1.1 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.3](https://arxiv.org/html/2602.06394v1#S4.SS3.p1.8 "4.3 Adaptive Learning of Tokenization Parameters ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. Madhavan (2000)
  Market microstructure: a survey.
  Journal of financial markets 3 (3),  pp.¬†205‚Äì258.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p3.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. Mansouri Ghiasi, J. Park, H. Mustafa, J. Kim, A. Olgun, A. Gollwitzer, D. Senol Cali, C. Firtina, H. Mao, N. Almadhoun Alserr, et al. (2022)
  GenStore: a high-performance in-storage processing system for genome sequence analysis.
  In Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,
   pp.¬†635‚Äì654.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p6.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. Mansouri Ghiasi, M. Sadrosadati, H. Mustafa, A. Gollwitzer, C. Firtina, J. Eudine, H. Ma, J. Lindegger, M. Banu Cavlak, M. Alser, et al. (2023)
  MetaStore: high-performance metagenomic analysis via in-storage computing.
  arXiv e-prints,  pp.¬†arXiv‚Äì2311.
  Cited by: [¬ß6.2](https://arxiv.org/html/2602.06394v1#S6.SS2.p6.1 "6.2 Financial Time-Series Foundation Model ‚Ä£ 6 Foundation Model Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. Mohammad, F. Bravo-Marquez, M. Salameh, and S. Kiritchenko (2018)
  Semeval-2018 task 1: affect in tweets.
  In Proceedings of the 12th international workshop on semantic evaluation,
   pp.¬†1‚Äì17.
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i1.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. Mohammad, S. Kiritchenko, P. Sobhani, X. Zhu, and C. Cherry (2016)
  Semeval-2016 task 6: detecting stance in tweets.
  In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016),
   pp.¬†31‚Äì41.
  Cited by: [7th item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i7.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Moody and M. Saffell (2001)
  Performance functions and reinforcement learning for trading systems and portfolios.
  Journal of Forecasting 20 (1),  pp.¬†1‚Äì18.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p4.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Moody and L. Wu (1998)
  Learning to trade via direct reinforcement.
  In Proceedings of the IEEE International Conference on Neural Networks,
   pp.¬†1741‚Äì1746.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p4.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* D. Q. Nguyen, T. Vu, and A. T. Nguyen (2020)
  BERTweet: a pre-trained language model for english tweets.
  In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,
   pp.¬†9‚Äì14.
  Cited by: [1st item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.p1.2 "In 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. B. Owen (2013)
  Monte carlo theory, methods and examples.
   Stanford University.
  Note: Available at <https://artowen.su.domains/mc/>
  Cited by: [¬ßG.3](https://arxiv.org/html/2602.06394v1#A7.SS3.1.p1.7 "Proof Sketch. ‚Ä£ G.3 Computational Costs ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* I. Provilkov, D. Emelyanenko, and E. Voita (2020)
  BPE-dropout: simple and effective subword regularization.
  In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,
   pp.¬†1882‚Äì1892.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.6.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p2.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [1st item](https://arxiv.org/html/2602.06394v1#S5.I3.i1.p1.1 "In 5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* M. Ranzato, S. Chopra, M. Auli, and W. Zaremba (2015)
  Sequence level training with recurrent neural networks.
  In International Conference on Learning Representations,
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p4.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Rissanen (1978)
  Modeling by shortest data description.
  Automatica 14 (5),  pp.¬†465‚Äì471.
  Cited by: [¬ßC.2](https://arxiv.org/html/2602.06394v1#A3.SS2.3.p3.1 "Proof. ‚Ä£ C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß3.2](https://arxiv.org/html/2602.06394v1#S3.SS2.p2.10 "3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. Rosenthal, N. Farra, and P. Nakov (2017)
  SemEval-2017 task 4: sentiment analysis in twitter.
  In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017),
   pp.¬†502‚Äì518.
  Cited by: [6th item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i6.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* M. Rumpf, M. Alser, A. E. Gollwitzer, J. Lindegger, N. Almadhoun, C. Firtina, S. Mangul, and O. Mutlu (2023)
  SequenceLab: a comprehensive benchmark of computational methods for comparing genomic sequences.
  arXiv preprint arXiv:2310.16908.
  Cited by: [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p4.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. A. Rusu, S. G. Colmenarejo, C. Gulcehre, G. Desjardins, J. Kirkpatrick, R. Pascanu, V. Mnih, K. Kavukcuoglu, and R. Hadsell (2016)
  Policy distillation.
  External Links: 1511.06295
  Cited by: [item¬†2](https://arxiv.org/html/2602.06394v1#A9.I7.i2.p1.1 "In I.7 Approximating QA-Token: Towards Computationally Efficient Quality-Awareness ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* P. Sch√§fer (2015)
  The boss is concerned with time series classification in the presence of noise.
  Data Mining and Knowledge Discovery 29 (6),  pp.¬†1505‚Äì1530.
  Cited by: [6th item](https://arxiv.org/html/2602.06394v1#A9.I5.i6.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [2nd item](https://arxiv.org/html/2602.06394v1#S5.I3.i2.p1.1 "In 5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov (2017)
  Proximal policy optimization algorithms.
  In arXiv preprint arXiv:1707.06347,
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.5.p1.2 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.1](https://arxiv.org/html/2602.06394v1#S4.SS1.p1.2 "4.1 Reinforcement Learning Formulation ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. Sczyrba, P. Hofmann, P. Belmann, D. Koslicki, S. Janssen, J. Dr"oge, I. Gregor, S. Majda, J. Fiedler, E. Dahms, et al. (2017)
  Critical assessment of metagenome interpretation‚Äîa benchmark of metagenomics software.
  Nature methods 14 (11),  pp.¬†1063‚Äì1071.
  Cited by: [3rd item](https://arxiv.org/html/2602.06394v1#A9.I1.i1.I1.i3.p1.1 "In 1st item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p1.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. Sennrich, B. Haddow, and A. Birch (2016)
  Neural machine translation of rare words with subword units.
  In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
   pp.¬†1715‚Äì1725.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.5.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p2.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.2](https://arxiv.org/html/2602.06394v1#A3.SS2.1.p1.1 "Proof. ‚Ä£ C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßC.3](https://arxiv.org/html/2602.06394v1#A3.SS3.2.p2.1 "Proof. ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [1st item](https://arxiv.org/html/2602.06394v1#A9.I5.i1.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p1.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y.K. Li, Y. Wu, and D. Guo (2024)
  DeepSeekMath: pushing the limits of mathematical reasoning in open language models.
  arXiv preprint arXiv:2402.03300.
  Cited by: [¬ßG.5.1](https://arxiv.org/html/2602.06394v1#A7.SS5.SSS1.p1.1 "G.5.1 RL Algorithm Ablation ‚Ä£ G.5 Ablation Studies and Additional Experiments ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* W. F. Sharpe (1994)
  The sharpe ratio.
  Journal of portfolio management 21 (1),  pp.¬†49‚Äì58.
  Cited by: [4th item](https://arxiv.org/html/2602.06394v1#A9.I6.i2.I1.i4.p1.1 "In 2nd item ‚Ä£ I.5 Evaluation Metrics ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.2](https://arxiv.org/html/2602.06394v1#S5.SS2.p3.1 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* S. T. Sherry, M. Ward, M. Kholodov, J. Baker, L. Phan, E. M. Smigielski, and K. Sirotkin (2001)
  DbSNP: the ncbi database of genetic variation.
  Nucleic acids research 29 (1),  pp.¬†308‚Äì311.
  Cited by: [4th item](https://arxiv.org/html/2602.06394v1#A8.I1.i4.p1.1 "In H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [1st item](https://arxiv.org/html/2602.06394v1#A8.I6.i1.p1.3 "In H.7 Domain-Specific Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. Subramanyam, Y. Chen, and R. L. Grossman (2025)
  Scaling laws revisited: modeling the role of data quality in language model pretraining.
  arXiv.org.
  External Links: [Document](https://dx.doi.org/10.48550/arXiv.2510.03313)
  Cited by: [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p1.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. S. Sutton and A. G. Barto (2018)
  Reinforcement learning: an introduction.
   MIT press.
  Cited by: [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p4.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Y. Tay, V. Q. Tran, S. Ruder, J. Gupta, L. Liu, J. Chung, S. Turner, Z. Wang, D. Williams, D. G. Casas, et al. (2022)
  Charformer: fast character transformers via gradient-based subword tokenization.
  arXiv preprint arXiv:2106.12672.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.8.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p5.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* N. Tishby, F. C. Pereira, and W. Bialek (1999)
  The information bottleneck method.
  In Proceedings of the 37th Annual Allerton Conference on Communication,
  Control and Computing,
   pp.¬†368‚Äì377.
  Cited by: [¬ßC.9](https://arxiv.org/html/2602.06394v1#A3.SS9.1.p1.2 "Proof. ‚Ä£ C.9 Information-Theoretic Optimality ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß4.5](https://arxiv.org/html/2602.06394v1#S4.SS5.p2.4 "4.5 Theoretical Guarantees ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* C. Van Hee, E. Lefever, and V. Hoste (2018)
  Semeval-2018 task 3: irony detection in english tweets.
  In Proceedings of The 12th International Workshop on Semantic Evaluation,
   pp.¬†39‚Äì50.
  Cited by: [3rd item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i3.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* A. M. Wenger, P. Peluso, W. J. Rowell, P. Chang, R. J. Hall, G. T. Concepcion, J. Ebler, A. Fungtammasan, A. Kolesnikov, N. D. Olson, et al. (2019)
  Accurate circular consensus long-read sequencing improves variant detection and assembly of a human genome.
  Nature biotechnology 37 (10),  pp.¬†1155‚Äì1162.
  Cited by: [¬ß1](https://arxiv.org/html/2602.06394v1#S1.p2.1 "1 Introduction ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* R. J. Williams (1992)
  Simple statistical gradient-following algorithms for connectionist reinforcement learning.
  Machine learning 8 (3-4),  pp.¬†229‚Äì256.
  Cited by: [¬ßC.5](https://arxiv.org/html/2602.06394v1#A3.SS5.SSS0.Px1.8.p2.5 "Proof. ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey, M. Krikun, Y. Cao, Q. Gao, K. Macherey, et al. (2016)
  Google‚Äôs neural machine translation system: bridging the gap between human and machine translation.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.5.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [Appendix B](https://arxiv.org/html/2602.06394v1#A2.p2.1 "Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [3rd item](https://arxiv.org/html/2602.06394v1#A9.I5.i3.p1.1 "In I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.4](https://arxiv.org/html/2602.06394v1#A9.SS4.p2.1 "I.4 Baseline Methods ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* L. Xue, A. Barua, N. Constant, R. Al-Rfou, S. Narang, M. Kale, A. Roberts, and C. Raffel (2022)
  ByT5: towards a token-free future with pre-trained byte-to-byte models.
  Transactions of the Association for Computational Linguistics 10,  pp.¬†291‚Äì306.
  Cited by: [Table 9](https://arxiv.org/html/2602.06394v1#A2.T9.3.3.7.1 "In Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p2.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* Y. Yue et al. (2025)
  Does reinforcement learning really incentivize reasoning capacity in LLMs beyond the base model?.
  arXiv preprint arXiv:2504.13837.
  Note: Presented at NeurIPS 2025 (Oral), ICML 2025 AI4Math Workshop Best Paper
  Cited by: [¬ßG.5.1](https://arxiv.org/html/2602.06394v1#A7.SS5.SSS1.p1.1 "G.5.1 RL Algorithm Ablation ‚Ä£ G.5 Ablation Studies and Additional Experiments ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* M. Zampieri, S. Malmasi, P. Nakov, S. Rosenthal, N. Farra, and R. Kumar (2019)
  SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).
  In Proceedings of the 13th International Workshop on Semantic Evaluation,
   pp.¬†75‚Äì86.
  Cited by: [5th item](https://arxiv.org/html/2602.06394v1#A9.I1.i3.I1.i1.I1.i5.p1.1 "In 1st item ‚Ä£ 3rd item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ßI.8](https://arxiv.org/html/2602.06394v1#A9.SS8.p2.1 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
* J. M. Zook, D. Catoe, J. McDaniel, L. Vang, N. Spies, A. Sidow, Z. Weng, and M. Salit (2016)
  Extensive sequencing of seven human genomes to characterize benchmark reference materials.
  Scientific data 3 (1),  pp.¬†1‚Äì19.
  Cited by: [2nd item](https://arxiv.org/html/2602.06394v1#A9.I1.i1.I1.i2.p1.1 "In 1st item ‚Ä£ I.1 Datasets and Reproducible Evaluation ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"),
  [¬ß5.1](https://arxiv.org/html/2602.06394v1#S5.SS1.p1.1 "5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

## Supplementary Information

## Appendix A Notation

To ensure clarity and rigor, we define our mathematical notation in Table [8](https://arxiv.org/html/2602.06394v1#A1.T8 "Table 8 ‚Ä£ Appendix A Notation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"). We distinguish between atomic (indivisible) elements and tokens (sequences of atomic elements or other tokens).

Table 8: Table of Notation

|  |  |
| --- | --- |
| Symbol | Definition |
| Œ£\Sigma | Base alphabet of atomic elements (e.g., characters, DNA bases). |
| sis\_{i} | An atomic element from Œ£\Sigma. |
| qiq\_{i} | Scalar quality score of an atomic element sis\_{i}, where qi‚àà[0,1]q\_{i}\in[0,1]. |
| t,a,bt,a,b | Tokens, which are sequences of atomic elements. |
| VkV\_{k} | Vocabulary at merge step kk. |
| f‚Äã(t)f(t) | Frequency of token tt in the corpus. |
| |t||t| | Length of token tt in atomic elements. |
| nœÉ‚Äã(t)n\_{\sigma}(t) | Count of atomic element œÉ‚ààŒ£\sigma\in\Sigma within token tt. |
| H‚Äã(t)H(t) | Empirical entropy of token tt: H‚Äã(t)=‚àí‚àëœÉnœÉ‚Äã(t)|t|‚Äãlog‚Å°nœÉ‚Äã(t)|t|H(t)=-\sum\_{\sigma}\frac{n\_{\sigma}(t)}{|t|}\log\frac{n\_{\sigma}(t)}{|t|}. |
| ùíít\bm{q}\_{t} | Vector of quality scores for token tt (in multi-dimensional domains). |
| qtq\_{t} | Aggregated scalar quality score of token tt, derived from its constituents. |
| q¬Øa‚Äãb\bar{q}\_{ab} | Average quality of constituent tokens a,ba,b, defined as (qa+qb)/2(q\_{a}+q\_{b})/2. |
| Œ±\alpha | Learnable exponent controlling sensitivity to quality in the merge score. |
| wa‚Äãbw\_{ab} | Quality-aware merge score for the token pair (a,b)(a,b). |
| Œ∏adapt\theta\_{\text{adapt}} | Vector of all learnable adaptive parameters in the framework. |
| œÄŒ∏œÄ\pi\_{\theta\_{\pi}} | Reinforcement learning policy for selecting merges, parameterized by Œ∏œÄ\theta\_{\pi}. |
| LtaskL\_{\text{task}} | Loss function of the downstream machine learning task. |
| ùí•‚Äã(ùíØ)\mathcal{J}(\mathcal{T}) | Global objective function for the tokenization process (Eq. [1](https://arxiv.org/html/2602.06394v1#S3.E1 "Equation 1 ‚Ä£ Definition 3.1 (Bilevel Tokenization Problem). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). |

## Appendix B Related Work

QA-Token intersects with, and extends upon, research in subword tokenization, noisy data handling, reinforcement learning for sequential optimization, and adaptive or differentiable modeling techniques. Table [9](https://arxiv.org/html/2602.06394v1#A2.T9 "Table 9 ‚Ä£ Appendix B Related Work ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") provides a comparative overview, situating QA-Token relative to existing approaches and highlighting its unique synthesis of explicit quality integration, RL-based optimization of merges, and adaptive learning of the tokenization process parameters. The key distinction of QA-Token‚Äôs adaptive parameter learning is its focus on optimizing parameters governing the tokenization \*process\* itself (like quality sensitivity or reward component weights), rather than solely adapting the vocabulary content or segmentation boundaries within a fixed merge logic.

Table 9: Comparison of QA-Token with Representative Tokenization Approaches.

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Method | Explicit Quality  Integration | Optimization  Method | Adaptive Params  (Learned Process?) | Downstream Aware  (via Reward/Loss) | Domain Noise Model  (Explicit?) | Vocabulary  Type |
| Standard BPE/WP/SP (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units"); Wu et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib14 "Google‚Äôs neural machine translation system: bridging the gap between human and machine translation"); Kudo and Richardson, [2018](https://arxiv.org/html/2602.06394v1#bib.bib15 "SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing")) | No | Frequency | No | No | No | Subword |
| BPE-Dropout (Provilkov et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib26 "BPE-dropout: simple and effective subword regularization")) | No | Freq.+Stochastic | No | No | No | Subword |
| Char/Byte Models (Xue et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib27 "ByT5: towards a token-free future with pre-trained byte-to-byte models"); Clark et al., [2021](https://arxiv.org/html/2602.06394v1#bib.bib28 "Canine: pre-training an efficient tokenization-free encoder for language representation")) | No | N/A (Fixed) | No | Yes (via model) | Implicit | Char/Byte |
| Gradient-based (Tay et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib29 "Charformer: fast character transformers via gradient-based subword tokenization")) | No | Gradient | Yes (Segmenter) | Yes | Implicit | Char/Subword |
| Semantic Tokenizers (Libovick‚Äòy and Sachan, [2024](https://arxiv.org/html/2602.06394v1#bib.bib30 "Semantic segmentation for improving the performance of large language models")) | No | Semantics+Freq | No | Indirectly | No | Subword |
| QA-Token (Ours) | Yes | RL (Policy) + | Yes (Process HPs: | Yes (via Reward for RL, | Yes (via Q,RQ,R) | Subword |
|  |  | Gradient (HPs) | Œ±,Œªi,wj,Œ≤k\alpha,\lambda\_{i},w\_{j},\beta\_{k}) | LdownstreamL\_{\text{downstream}} for HPs) |  |  |

Note: "Adaptive Params (Learned Process?)" refers to learning parameters governing the tokenization \*process\* itself (like QA-Token‚Äôs Œ±,Œ≤k,Œªi,wj\alpha,\beta\_{k},\lambda\_{i},w\_{j}), not just the vocabulary content or segmentation boundaries. QA-Token uses RL to optimize the merge policy and gradient-based methods to optimize these process hyperparameters.

Subword Tokenization Algorithms: The prevailing paradigm relies on frequency-based greedy merging procedures, exemplified by BPE (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units")), WordPiece (Wu et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib14 "Google‚Äôs neural machine translation system: bridging the gap between human and machine translation")) (which optimizes data likelihood), and SentencePiece (Kudo and Richardson, [2018](https://arxiv.org/html/2602.06394v1#bib.bib15 "SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing")) (which operates directly on raw text). While computationally efficient and broadly effective, their fundamental mechanism ignores sequence quality, providing the primary motivation for our work. BPE-dropout (Provilkov et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib26 "BPE-dropout: simple and effective subword regularization")) introduces stochasticity during the merge process as a form of regularization to enhance robustness, but it does not use explicit quality signals. Unigram language models (Kudo, [2018](https://arxiv.org/html/2602.06394v1#bib.bib34 "Subword regularization: improving neural network translation models with multiple subword candidates")) present a probabilistic alternative, yet they still primarily depend on frequency and likelihood objectives without explicit quality awareness.

Handling Noisy and Domain-Specific Data: Considerable research focuses on modeling noise within particular application domains. In genomics, Phred scores (Ewing et al., [1998](https://arxiv.org/html/2602.06394v1#bib.bib16 "Base-calling of automated sequencer traces using phred. i. accuracy assessment")) are standard quality indicators, and specialized models aim to account for sequencing errors (Heinzinger et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib10 "Modeling aspects of the language of life through transfer-learning protein sequences")). In NLP, extensive work on social media text addresses lexical variation, misspellings, and slang through techniques like text normalization (Han et al., [2013](https://arxiv.org/html/2602.06394v1#bib.bib18 "Lexical normalisation of short text messages: makn sens a #twitter"); Li et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib20 "An empirical study of tokenization strategies for various korean nlp tasks")) and explicit noise modeling (Baldwin et al., [2013](https://arxiv.org/html/2602.06394v1#bib.bib17 "Noisy text analytics")). Financial time series analysis frequently employs filtering methods (Gen√ßay et al., [2001](https://arxiv.org/html/2602.06394v1#bib.bib25 "An introduction to wavelets and other filtering methods in finance and economics")), microstructure modeling (Madhavan, [2000](https://arxiv.org/html/2602.06394v1#bib.bib22 "Market microstructure: a survey"); Hasbrouck, [1991](https://arxiv.org/html/2602.06394v1#bib.bib23 "Measuring the information content of stock trades")), and regime-switching models (Hamilton, [1989](https://arxiv.org/html/2602.06394v1#bib.bib24 "A new approach to the economic analysis of nonstationary time series and the business cycle")) to manage inherent noise and non-stationarity. QA-Token distinguishes itself by offering a \*unified tokenization framework\* that directly integrates such domain-specific quality and noise considerations into the token construction process itself, rather than addressing noise solely as a separate downstream modeling challenge. The notion of the "curse of tokenization" (Chai et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib19 "The curse of tokenization")), which highlights the downstream impact of tokenization choices on LLM robustness, further underscores the need for quality-aware approaches.

Reinforcement Learning for Sequential Optimization: RL offers a robust framework for sequential decision-making under uncertainty (Sutton and Barto, [2018](https://arxiv.org/html/2602.06394v1#bib.bib36 "Reinforcement learning: an introduction")). It finds successful application in various optimization problems involving sequences, including text generation (Ranzato et al., [2015](https://arxiv.org/html/2602.06394v1#bib.bib37 "Sequence level training with recurrent neural networks")), combinatorial optimization (Bello et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib38 "Neural combinatorial optimization with reinforcement learning")), and financial strategy optimization (Moody and Wu, [1998](https://arxiv.org/html/2602.06394v1#bib.bib12 "Learning to trade via direct reinforcement"); Moody and Saffell, [2001](https://arxiv.org/html/2602.06394v1#bib.bib40 "Performance functions and reinforcement learning for trading systems and portfolios")). We uniquely formulate the tokenization vocabulary construction process as an RL problem where merge operations constitute actions selected by a learned policy to maximize a cumulative reward signal reflecting token quality, information content, complexity, and estimated utility. This formulation allows for optimizing complex, potentially non-differentiable objectives related to the quality of the final tokenization outcome. The rewards themselves are shaped by adaptively learned parameters (Section [4.3](https://arxiv.org/html/2602.06394v1#S4.SS3 "4.3 Adaptive Learning of Tokenization Parameters ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

Adaptive and Differentiable Tokenization: Acknowledging the limitations inherent in static tokenizers, researchers explore adaptive and learnable alternatives. Gradient-based approaches (Tay et al., [2022](https://arxiv.org/html/2602.06394v1#bib.bib29 "Charformer: fast character transformers via gradient-based subword tokenization")) learn segmentation parameters end-to-end concurrently with downstream tasks, often operating at the character level. Semantic tokenization (Libovick‚Äòy and Sachan, [2024](https://arxiv.org/html/2602.06394v1#bib.bib30 "Semantic segmentation for improving the performance of large language models")) uses word meanings to inform the segmentation process. QA-Token integrates adaptive learning distinctively: it learns hyperparameters (Œ±,Œ≤k,wj,Œªi,‚Ä¶\alpha,\beta\_{k},w\_{j},\lambda\_{i},\dots) that directly govern the quality-aware merge decisions and the RL agent‚Äôs reward structure. This learning is enabled by Gumbel-Softmax relaxation (Jang et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib31 "Categorical reparameterization with gumbel-softmax"); Maddison et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib32 "The concrete distribution: a continuous relaxation of discrete random variables")) for making merge choices differentiable with respect to these hyperparameters when optimizing a downstream task loss (via composite logits defined in Equation [37](https://arxiv.org/html/2602.06394v1#A5.E37 "Equation 37 ‚Ä£ E.11 Gradient Computation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). This enables the fundamental \*tokenization logic\* to adapt based on observed data properties and task feedback, co-evolving with the RL agent‚Äôs policy. Meta-learning (Finn et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib33 "Model-agnostic meta-learning for fast adaptation of deep networks")) provides a potential mechanism, explored conceptually within QA-Token (see Appendix [E.5](https://arxiv.org/html/2602.06394v1#A5.SS5 "E.5 Algorithm Summary ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), to further accelerate adaptation across heterogeneous data sources (e.g., different social media platforms).

In essence, QA-Token synthesizes concepts from these related areas but provides a unique combination: explicit quality integration within the merge decision, optimization of the merge sequence via RL using a multi-faceted reward signal, and adaptive learning of core process parameters that define this reward and merge logic, demonstrating applicability across diverse, noisy domains.

## Appendix C Theoretical Framework and Proofs

### C.1 Quality Metric Proofs

###### Proposition C.1 (Boundedness and Continuity of Quality Functions).

All domain-specific quality functions qt‚àà[0,1]q\_{t}\in[0,1] are:

1. 1.

   Bounded: 0‚â§qt‚â§10\leq q\_{t}\leq 1 for all tokens tt
2. 2.

   Continuous: Lipschitz continuous in their arguments
3. 3.

   Monotonic: Quality decreases with increasing noise/error

###### Proof.

Boundedness: For genomics, the geometric mean of values in [0,1][0,1] remains in [0,1][0,1]. For finance, the convex combination of bounded components qk,t‚àà[0,1]q\_{k,t}\in[0,1] with ‚àëkwk=1\sum\_{k}w\_{k}=1 yields qtfinance‚àà[0,1]q\_{t}^{\text{finance}}\in[0,1].

Lipschitz continuity: For genomics (geometric mean on [œµQ,1]n[\epsilon\_{Q},1]^{n}), the chain rule via logarithmic transformation yields Lipschitz constant Lg=1/(n‚ãÖœµQ)L\_{g}=1/(\sqrt{n}\cdot\epsilon\_{Q}). For finance, the weighted sum of Lipschitz component functions has Lf‚â§maxk‚Å°LkL\_{f}\leq\max\_{k}L\_{k}.

Monotonicity: For any noise injection Œ∑\eta with Œ∑‚Äã(q)‚â§q\eta(q)\leq q, both aggregations (geometric and arithmetic means) preserve the ordering: noisier inputs yield lower quality scores.
‚àé

### C.2 Merge Score Derivation

###### Lemma C.2 (First-Order Approximation).

The marginal gain in objective ùí•\mathcal{J} from merge (a,b)‚Ü¶a‚Äãb(a,b)\mapsto ab admits the decomposition:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Œî‚Äãùí•‚Äã(a,b)=ŒªLM‚ÄãŒî‚Äã‚ÑíLM‚àíŒªcomp‚ÄãŒî‚ÄãŒ¶+Œªqual‚ÄãŒî‚ÄãQ+O‚Äã(œµ2)\boxed{\Delta\mathcal{J}(a,b)=\lambda\_{\text{LM}}\Delta\mathcal{L}\_{\text{LM}}-\lambda\_{\text{comp}}\Delta\Phi+\lambda\_{\text{qual}}\Delta Q+O(\epsilon^{2})} |  | (4) |

where œµ=1/|ùíÆ|\epsilon=1/|\mathcal{S}| represents the corpus-normalized perturbation.

###### Proof.

The marginal gain decomposes into three components following standard vocabulary optimization analysis (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units")).

Language Model Component: The change Œî‚Äã‚ÑíLM‚âàf‚Äã(a,b)‚ãÖPMI‚Äã(a,b)\Delta\mathcal{L}\_{\text{LM}}\approx f(a,b)\cdot\text{PMI}(a,b) follows from the pseudo-likelihood approximation, where PMI (Pointwise Mutual Information) captures statistical association (Church and Hanks, [1990](https://arxiv.org/html/2602.06394v1#bib.bib74 "Word association norms, mutual information, and lexicography")).

Complexity Component: By MDL principles (Rissanen, [1978](https://arxiv.org/html/2602.06394v1#bib.bib42 "Modeling by shortest data description")), merging reduces vocabulary complexity: Œî‚ÄãŒ¶=‚àílog‚Å°|V|‚àí1+O‚Äã(|V|‚àí1)\Delta\Phi=-\log|V|-1+O(|V|^{-1}). This compression benefit is absorbed into the PMI term, which also favors frequent co-occurrences.

Quality Component: For concave aggregator g‚Äã(x)=(x+œµQ)Œ±g(x)=(x+\epsilon\_{Q})^{\alpha}, Jensen‚Äôs inequality yields g‚Äã(q¬Øa‚Äãb)‚â•12‚Äã(g‚Äã(qa)+g‚Äã(qb))g(\bar{q}\_{ab})\geq\frac{1}{2}(g(q\_{a})+g(q\_{b})). The dominant quality contribution is Œî‚ÄãQ+=f‚Äã(a,b)‚ãÖg‚Äã(q¬Øa‚Äãb)\Delta Q\_{+}=f(a,b)\cdot g(\bar{q}\_{ab}) where q¬Øa‚Äãb=(qa+qb)/2\bar{q}\_{ab}=(q\_{a}+q\_{b})/2. Normalization errors are O‚Äã(f‚Äã(a,b)/T)O(f(a,b)/T), negligible for typical corpora.
‚àé

### C.3 Derivation of the Optimal Merge Score

###### Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic).

*Motivated by* the first-order approximation of Œî‚Äãùí•\Delta\mathcal{J} (Lemma¬†[C.2](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem2 "Lemma C.2 (First-Order Approximation). ‚Ä£ C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), we propose the following quality-aware merge score as a principled heuristic:

|  |  |  |  |
| --- | --- | --- | --- |
|  | wa‚Äãb=f‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖ(q¬Øa‚Äãb+œµQ)Œ±‚ãÖœà‚Äã(a,b)\boxed{w\_{ab}=\tfrac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot(\bar{q}\_{ab}+\epsilon\_{Q})^{\alpha}\cdot\psi(a,b)} |  | (5) |

where:

* ‚Ä¢

  f‚Äã(‚ãÖ)f(\cdot) denotes frequency in the corpus
* ‚Ä¢

  q¬Øa‚Äãb=(qa+qb)/2\bar{q}\_{ab}=(q\_{a}+q\_{b})/2 is the average constituent quality
* ‚Ä¢

  Œ±‚àà(0,1]\alpha\in(0,1] is a learnable parameter controlling quality sensitivity
* ‚Ä¢

  œµf,œµQ>0\epsilon\_{f},\epsilon\_{Q}>0 ensure numerical stability
* ‚Ä¢

  œà‚Äã(a,b)‚àà[0,1]\psi(a,b)\in[0,1] encodes domain-specific constraints

*Note:* The derivation below involves two principled approximations (Steps 4‚Äì5) that trade mathematical exactness for computational tractability. The resulting score preserves key monotonicity properties and is calibrated end-to-end via downstream task performance.

###### Proof.

From Lemma¬†[C.2](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem2 "Lemma C.2 (First-Order Approximation). ‚Ä£ C.2 Merge Score Derivation ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), the marginal gain is Œî‚Äãùí•‚Äã(a,b)=ŒªLM‚Äãf‚Äã(a,b)‚ãÖPMI‚Äã(a,b)+Œªqual‚Äãf‚Äã(a,b)‚Äãg‚Äã(q¬Øa‚Äãb)+O‚Äã(1/|V|)\Delta\mathcal{J}(a,b)=\lambda\_{\text{LM}}f(a,b)\cdot\text{PMI}(a,b)+\lambda\_{\text{qual}}f(a,b)g(\bar{q}\_{ab})+O(1/|V|), where the complexity term is absorbed into PMI (both favor frequent co-occurrences).

Per-occurrence normalization: Following the design principle of BPE (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units")), we normalize by frequency to capture per-occurrence information gain. Applying the exponential transform (monotonic, preserves rankings):
exp‚Å°(Œî‚Äãùí•/f‚Äã(a,b))‚àùf‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖexp‚Å°(ŒªqualŒªLM‚Äãg‚Äã(q¬Øa‚Äãb))\exp(\Delta\mathcal{J}/f(a,b))\propto\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot\exp(\frac{\lambda\_{\text{qual}}}{\lambda\_{\text{LM}}}g(\bar{q}\_{ab}))

Power-law approximation: We replace exp‚Å°(Œª‚ãÖg‚Äã(q))\exp(\lambda\cdot g(q)) with (q¬Øa‚Äãb+œµQ)Œ±~(\bar{q}\_{ab}+\epsilon\_{Q})^{\tilde{\alpha}} where Œ±~\tilde{\alpha} is learned end-to-end. This preserves monotonicity in q¬Øa‚Äãb\bar{q}\_{ab} and subsumes the unknown ratio Œªqual/ŒªLM\lambda\_{\text{qual}}/\lambda\_{\text{LM}}. The final score is:
wa‚Äãb=f‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖ(q¬Øa‚Äãb+œµQ)Œ±‚ãÖœà‚Äã(a,b)w\_{ab}=\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot(\bar{q}\_{ab}+\epsilon\_{Q})^{\alpha}\cdot\psi(a,b)

Monotonicity guarantees: ‚àÇwa‚Äãb/‚àÇq¬Øa‚Äãb>0\partial w\_{ab}/\partial\bar{q}\_{ab}>0 and ‚àÇwa‚Äãb/‚àÇPMI>0\partial w\_{ab}/\partial\text{PMI}>0, ensuring quality-increasing and statistically-associated merges are preferred. End-to-end learning of Œ±\alpha calibrates the heuristic.
‚àé

### C.4 Key Insights from the Derivation

1. 1.

   PMI Foundation: The frequency term f‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}} approximates Pointwise Mutual Information, capturing statistical association.
2. 2.

   Quality Modulation: The quality term (q¬Øa‚Äãb+œµQ)Œ±(\bar{q}\_{ab}+\epsilon\_{Q})^{\alpha} multiplicatively adjusts the PMI-based score, up-weighting high-quality merges.
3. 3.

   Learnable Sensitivity: The parameter Œ±\alpha controls the relative importance of quality vs. frequency:

   * ‚Ä¢

     Œ±=0\alpha=0: Reduces to standard PMI-based tokenization
   * ‚Ä¢

     Œ±>0\alpha>0: Increasing weight on quality signals
   * ‚Ä¢

     Learned via gradient descent to optimize downstream performance
4. 4.

   Domain Flexibility: The factor œà‚Äã(a,b)\psi(a,b) allows incorporation of domain knowledge without modifying the core framework.

This derivation shows that the quality-aware merge score is a *principled heuristic* motivated by first-principles analysis of the bilevel objective, rather than an ad-hoc combination of frequency and quality terms.

### C.5 Theory Proofs

##### Proof of Theorem [3.2](https://arxiv.org/html/2602.06394v1#S3.Thmtheorem2 "Theorem 3.2 (Computational Complexity). ‚Ä£ 3.2 Formal Problem Definition and Objective ‚Ä£ 3 Mathematical Formulation of QA-Token ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") (Computational Complexity).

The bilevel optimization problem is NP-hard by polynomial-time reduction from Weighted Set Cover (Karp, [1972](https://arxiv.org/html/2602.06394v1#bib.bib2 "Reducibility among combinatorial problems")). The reduction maps sets to corpus sequences and set cover cost to vocabulary complexity: given a WSC instance (U,ùíÆ,{ci})(U,\mathcal{S},\{c\_{i}\}), construct alphabet Œ£=U‚à™{$}\Sigma=U\cup\{\mathdollar\}, corpus sequences œÉi\sigma\_{i} for each set SiS\_{i}, and uniform quality scores. With Œªqual=0\lambda\_{\text{qual}}=0, optimal tokenizations correspond bijectively to optimal set covers.

For stronger complexity results establishing Œ£2p\Sigma\_{2}^{p}-hardness of general bilevel programs, see (Bolte et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib121 "Geometric and computational hardness of bilevel programming"); Grne and Wulf, [2023](https://arxiv.org/html/2602.06394v1#bib.bib124 "Completeness in the polynomial hierarchy for many natural problems in bilevel and robust optimization"); Dempe, [2020](https://arxiv.org/html/2602.06394v1#bib.bib116 "Bilevel optimization: theory, algorithms and applications")). The worst-case exhaustive search complexity is O‚Äã(|Œ£|K‚ãÖK!‚ãÖN‚ãÖn‚ãÖ|Œò|)O(|\Sigma|^{K}\cdot K!\cdot N\cdot n\cdot|\Theta|), accounting for the space of merge sequences, merge orderings, and downstream model optimization.

‚ñ°\square

###### Proposition C.4 (Boundedness and Lipschitzness of wa‚Äãbw\_{ab}).

Under assumptions (A1)-(A2), the quality-aware merge score wa‚Äãbw\_{ab} is bounded and Lipschitz continuous in (qa,qb)(q\_{a},q\_{b}).

###### Proof.

Boundedness: By (A1), f‚Äã(a,b)/(f‚Äã(a)‚Äãf‚Äã(b)+œµf)‚â§Cf/œµff(a,b)/(f(a)f(b)+\epsilon\_{f})\leq C\_{f}/\epsilon\_{f}. With q¬Øa‚Äãb‚àà[0,1]\bar{q}\_{ab}\in[0,1] and œà‚àà[0,1]\psi\in[0,1], we have wa‚Äãb‚â§Cf(1+œµQ)Œ±/œµf=:Cww\_{ab}\leq C\_{f}(1+\epsilon\_{Q})^{\alpha}/\epsilon\_{f}=:C\_{w}.

Lipschitz continuity: By chain rule on compositions of bounded functions on compact domains, wa‚Äãbw\_{ab} is LwL\_{w}-Lipschitz in (qa,qb)(q\_{a},q\_{b}) with Lw=Cf‚ÄãLg/œµfL\_{w}=C\_{f}L\_{g}/\epsilon\_{f}. For Œ±=1\alpha=1, Lg=1/2L\_{g}=1/\sqrt{2}; for 0<Œ±<10<\alpha<1, Lg‚â§Œ±‚ÄãœµQŒ±‚àí1/2L\_{g}\leq\alpha\epsilon\_{Q}^{\alpha-1}/\sqrt{2}. The regularization œµQ\epsilon\_{Q} ensures numerical stability.
‚àé

###### Proposition C.5 (Stability of EMA Normalization).

Under assumptions (A1) and œµR>0\epsilon\_{R}>0, the EMA-based normalization maintains œÉj,trun>0\sigma\_{j,t}^{\text{run}}>0 almost surely for non-degenerate reward streams.

###### Proof.

The result follows from standard EMA convergence theory (Robbins-Monro). Under (A1), raw rewards have non-degenerate distribution Var‚Äã(Xt)>0\text{Var}(X\_{t})>0. The EMA variance update preserves positivity: if Varj,t‚àí1run>0\text{Var}\_{j,t-1}^{\text{run}}>0, then Varj,trun‚â•(1‚àíŒ≤norm)‚ÄãVarj,t‚àí1run>0\text{Var}\_{j,t}^{\text{run}}\geq(1-\beta\_{\text{norm}})\text{Var}\_{j,t-1}^{\text{run}}>0.

With ‚àëtŒ≤norm,t=‚àû\sum\_{t}\beta\_{\text{norm},t}=\infty and ‚àëtŒ≤norm,t2<‚àû\sum\_{t}\beta\_{\text{norm},t}^{2}<\infty, the running variance converges a.s. to Var‚Äã(X)>0\text{Var}(X)>0, ensuring œÉj,trun>0\sigma\_{j,t}^{\text{run}}>0.
‚àé

###### Proposition C.6 (Convergence of PPO Objective).

Under assumptions (A1)-(A4), PPO converges to a stationary point of J‚Äã(œÄ;Œ∏adapt(0))J(\pi;\theta\_{\text{adapt}}^{(0)}).

###### Proof.

Under (A1)‚Äì(A4), the standard PPO conditions hold (Schulman et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib63 "Proximal policy optimization algorithms")): bounded rewards (|R‚Äã(s,a)|‚â§Rmax|R(s,a)|\leq R\_{\max}), compact state space, finite action space, and differentiable policy. The clipped surrogate objective ensures bounded gradients ‚Äñ‚àáŒ∏LCLIP‚Äñ2‚â§Gmax\|\nabla\_{\theta}L^{\text{CLIP}}\|\_{2}\leq G\_{\max}.

With learning rate Œ∑t=Œ∑0/t\eta\_{t}=\eta\_{0}/\sqrt{t} satisfying ‚àëtŒ∑t=‚àû\sum\_{t}\eta\_{t}=\infty and ‚àëtŒ∑t2<‚àû\sum\_{t}\eta\_{t}^{2}<\infty, global convergence to stationary points at rate O‚Äã(1/T)O(1/\sqrt{T}) follows from (Bhandari and Russo, [2021](https://arxiv.org/html/2602.06394v1#bib.bib115 "Global optimality guarantees for policy gradient methods"); Cen and Chi, [2023](https://arxiv.org/html/2602.06394v1#bib.bib119 "Global convergence of policy gradient methods in reinforcement learning, games and control")).
‚àé

###### Proposition C.7 (Consistency and Boundedness of Stage 2 Gradients).

Under assumptions (A1)‚Äì(A3), the Gumbel-Softmax estimator yields consistent gradients with bounded variance.

###### Proof.

The Gumbel-Softmax gradient properties follow from (Jang et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib31 "Categorical reparameterization with gumbel-softmax"); Maddison et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib32 "The concrete distribution: a continuous relaxation of discrete random variables")). Under (A1)‚Äì(A3), the composite logits ‚Ñìa‚Äãb\ell\_{ab} are bounded by Lmax=Cw+‚àëj|Œªj|‚ÄãRmaxL\_{\max}=C\_{w}+\sum\_{j}|\lambda\_{j}|R\_{\max}. The Gumbel-Softmax Jacobian satisfies ‚Äñ‚àÇyi/‚àÇ‚Ñìj‚Äñ‚â§1/œÑ\|\partial y\_{i}/\partial\ell\_{j}\|\leq 1/\tau, yielding bounded gradients ‚Äñ‚àáŒ∏adaptLtask‚Äñ‚â§Lmax/œÑ‚ãÖ‚Äñ‚àáyLtask‚Äñ\|\nabla\_{\theta\_{\text{adapt}}}L\_{\text{task}}\|\leq L\_{\max}/\tau\cdot\|\nabla\_{y}L\_{\text{task}}\|.

As œÑ‚Üí0\tau\to 0, the estimator converges to REINFORCE (Williams, [1992](https://arxiv.org/html/2602.06394v1#bib.bib65 "Simple statistical gradient-following algorithms for connectionist reinforcement learning")). The bias-variance tradeoff is: Bias‚Äã(œÑ)=O‚Äã(œÑ2)\text{Bias}(\tau)=O(\tau^{2}), Var‚Äã(œÑ)=O‚Äã(1/œÑ2)\text{Var}(\tau)=O(1/\tau^{2}). The optimal temperature œÑopt‚àùT‚àí1/4\tau\_{\text{opt}}\propto T^{-1/4} for TT samples balances these terms.
‚àé

###### Theorem C.8 (Gumbel-Softmax Properties).

Let œÄ=(œÄ1,‚Ä¶,œÄk)\pi=(\pi\_{1},\ldots,\pi\_{k}) be a categorical distribution with kk categories. The Gumbel-Softmax distribution with temperature œÑ>0\tau>0 satisfies:

1. 1.

   Consistency: As œÑ‚Üí0\tau\rightarrow 0, the samples converge to one-hot vectors from Categorical‚Äã(œÄ)\text{Categorical}(\pi)
2. 2.

   Differentiability: The reparameterization provides continuous gradients with respect to œÄ\pi
3. 3.

   Bias-Variance Tradeoff: Bias O‚Äã(œÑ2)O(\tau^{2}), Variance O‚Äã(1/œÑ2)O(1/\tau^{2})

###### Proof.

All three properties are established in (Jang et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib31 "Categorical reparameterization with gumbel-softmax"); Maddison et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib32 "The concrete distribution: a continuous relaxation of discrete random variables")). We summarize the key arguments.

Property 1 (Consistency): By the Gumbel-Max trick, arg‚Å°maxi‚Å°(‚Ñìi+gi)‚àºCategorical‚Äã(softmax‚Äã(‚Ñì))\arg\max\_{i}(\ell\_{i}+g\_{i})\sim\text{Categorical}(\text{softmax}(\bm{\ell})) for gi‚àºGumbel‚Äã(0,1)g\_{i}\sim\text{Gumbel}(0,1). As œÑ‚Üí0\tau\to 0, the Gumbel-Softmax samples yi=exp‚Å°((‚Ñìi+gi)/œÑ)/‚àëjexp‚Å°((‚Ñìj+gj)/œÑ)y\_{i}=\exp((\ell\_{i}+g\_{i})/\tau)/\sum\_{j}\exp((\ell\_{j}+g\_{j})/\tau) concentrate on one-hot vectors almost surely by the continuous mapping theorem.

Property 2 (Differentiability): For œÑ>0\tau>0, yiy\_{i} is C‚àûC^{\infty} in ‚Ñìj\ell\_{j}, enabling reparameterized gradients. The expectation ùîºg‚Äã[yi]=softmax‚Äã(‚Ñì/œÑ)i\mathbb{E}\_{g}[y\_{i}]=\text{softmax}(\bm{\ell}/\tau)\_{i} introduces bias that vanishes as œÑ‚Üí0\tau\to 0. The annealing schedule œÑt‚Üí0\tau\_{t}\to 0 ensures asymptotic consistency.

Property 3 (Gradient Bounds): The Jacobian satisfies ‚àÇyi/‚àÇ‚Ñìj=(1/œÑ)‚Äãyi‚Äã(Œ¥i‚Äãj‚àíyj)\partial y\_{i}/\partial\ell\_{j}=(1/\tau)y\_{i}(\delta\_{ij}-y\_{j}), yielding ‚Äñ‚àá‚Ñìùê≤‚ÄñF‚â§1/œÑ\|\nabla\_{\bm{\ell}}\mathbf{y}\|\_{F}\leq 1/\tau.
‚àé

### C.6 Assumptions

We formalize the assumptions used throughout the theoretical analysis:

Assumption A1 (Bounded Frequencies): There exists Cf>0C\_{f}>0 such that for all tokens a,ba,b:

|  |  |  |
| --- | --- | --- |
|  | 0‚â§f‚Äã(a),f‚Äã(b),f‚Äã(a,b)‚â§Cf0\leq f(a),f(b),f(a,b)\leq C\_{f} |  |

Assumption A2 (Bounded Qualities): All quality scores satisfy q‚àà[0,1]q\in[0,1], and the quality aggregation function is LQL\_{Q}-Lipschitz continuous.

Assumption A3 (Bounded Rewards): Raw reward components are bounded: |Rjraw|‚â§Rmax|R^{\text{raw}}\_{j}|\leq R\_{\max} for all jj.

Assumption A4 (Regular Learning Rates): The learning rate schedules satisfy:
- PPO: ‚àëtŒ∑t=‚àû\sum\_{t}\eta\_{t}=\infty and ‚àëtŒ∑t2<‚àû\sum\_{t}\eta\_{t}^{2}<\infty
- Adaptive learning: Œ∑t=O‚Äã(1/t)\eta\_{t}=O(1/\sqrt{t})

### C.7 Theory Extensions

###### Definition C.9 (Assumptions for Approximation Guarantee).

The (1‚àí1/e)(1-1/e) approximation guarantee requires the following structural assumptions:

1. (A1)

   Adaptive Monotonicity: For any partial realization œà\psi and merge (a,b)(a,b): ŒîF‚Äã((a,b)|œà)‚â•0\Delta\_{F}((a,b)|\psi)\geq 0, where ŒîF\Delta\_{F} denotes the marginal gain.
2. (A2)

   Adaptive Submodularity: For realizations œà‚™Øœà‚Ä≤\psi\preceq\psi^{\prime} (where ‚™Ø\preceq denotes extension): ŒîF‚Äã((a,b)|œà)‚â•ŒîF‚Äã((a,b)|œà‚Ä≤)\Delta\_{F}((a,b)|\psi)\geq\Delta\_{F}((a,b)|\psi^{\prime}) (diminishing returns).
3. (A3)

   Constraint independence: œà‚Äã(a,b)\psi(a,b) is history-independent.
4. (A4)

   Candidate pool regularity: ‚Ñô‚Äã[(a,b)‚ààP‚ÄãQt]‚â•Œ¥>0\mathbb{P}[(a,b)\in PQ\_{t}]\geq\delta>0 for all valid pairs.
5. (A5)

   Quality stability: |qt‚àíùîº[qt|‚Ñãt]|‚â§œµq|q\_{t}-\mathbb{E}[q\_{t}|\mathcal{H}\_{t}]|\leq\epsilon\_{q} with high probability.

###### Lemma C.10 (Approximate Adaptive Submodularity).

Under assumptions (A3)-(A5), the quality-aware objective F‚Äã(V)=‚àëk‚ÑíLM‚Äã(V;Dk)+ŒªQ‚ÄãQ‚Äã(V)F(V)=\sum\_{k}\mathcal{L}\_{\text{LM}}(V;D\_{k})+\lambda\_{Q}Q(V) satisfies œµ\epsilon-approximate adaptive submodularity:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ŒîF‚Äã((a,b)|œà)‚â•ŒîF‚Äã((a,b)|œà‚Ä≤)‚àíœµsub\Delta\_{F}((a,b)|\psi)\geq\Delta\_{F}((a,b)|\psi^{\prime})-\epsilon\_{\text{sub}} |  | (6) |

for œà‚™Øœà‚Ä≤\psi\preceq\psi^{\prime}, where œµsub=O‚Äã(œµq+1/Œ¥)\epsilon\_{\text{sub}}=O(\epsilon\_{q}+1/\delta).

###### Proof sketch.

The frequency-based component PMI‚Äã(a,b)\text{PMI}(a,b) exhibits exact diminishing returns: as more merges are performed, pair frequencies decrease, reducing potential PMI gains. The quality component (q¬Øa‚Äãb)Œ±(\bar{q}\_{ab})^{\alpha} is history-independent under (A3) and stable under (A5). The approximation error œµsub\epsilon\_{\text{sub}} arises from: (i) quality estimation noise (œµq\epsilon\_{q}), and (ii) candidate pool variability (1/Œ¥1/\delta). Full proof follows the framework of Golovin and Krause ([2011](https://arxiv.org/html/2602.06394v1#bib.bib90 "Adaptive submodularity: theory and applications in active learning and stochastic optimization")).
‚àé

###### Theorem C.11 (Approximation Guarantee with Explicit Constants).

Under Definition¬†[C.9](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem9 "Definition C.9 (Assumptions for Approximation Guarantee). ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), if assumptions (A1)-(A2) hold exactly, the greedy policy that maximizes wa‚Äãbw\_{ab} achieves:

|  |  |  |  |
| --- | --- | --- | --- |
|  | F‚Äã(œÄgreedy)‚â•(1‚àí1e)‚ÄãF‚Äã(œÄ‚àó)‚àíK‚Äãœµq‚àíKŒ¥,F(\pi\_{\text{greedy}})\geq\left(1-\frac{1}{e}\right)F(\pi^{\*})-K\epsilon\_{q}-\frac{K}{\delta}, |  | (7) |

where œÄ‚àó\pi^{\*} is the optimal adaptive policy over budget KK. The error terms arise from œµ\epsilon-approximate submodularity (Lemma¬†[C.10](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem10 "Lemma C.10 (Approximate Adaptive Submodularity). ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

###### Proof.

By Theorem 5 of Golovin and Krause ([2011](https://arxiv.org/html/2602.06394v1#bib.bib90 "Adaptive submodularity: theory and applications in active learning and stochastic optimization")), greedy optimization of adaptive submodular functions achieves (1‚àí1/e)(1-1/e) approximation. We extend this to œµ\epsilon-approximate submodularity (Lemma¬†[C.10](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem10 "Lemma C.10 (Approximate Adaptive Submodularity). ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

With œµ\epsilon-approximate submodularity, the greedy per-step guarantee becomes ŒîF‚Äã((at,bt)|œàt)‚â•1K‚Äã[F‚Äã(œÄ‚àó)‚àíF‚Äã(œàt)]‚àíœµsub\Delta\_{F}((a\_{t},b\_{t})|\psi\_{t})\geq\frac{1}{K}[F(\pi^{\*})-F(\psi\_{t})]-\epsilon\_{\text{sub}}. Defining Œît=F‚Äã(œÄ‚àó)‚àíFt\Delta\_{t}=F(\pi^{\*})-F\_{t} and iterating over KK steps: ŒîK‚â§(1‚àí1/K)K‚ÄãŒî0+K‚Äãœµsub‚â§1e‚ÄãF‚Äã(œÄ‚àó)+K‚Äãœµsub\Delta\_{K}\leq(1-1/K)^{K}\Delta\_{0}+K\epsilon\_{\text{sub}}\leq\frac{1}{e}F(\pi^{\*})+K\epsilon\_{\text{sub}}, using (1‚àí1/K)K‚â§1/e(1-1/K)^{K}\leq 1/e.

Substituting œµsub=œµq+1/Œ¥\epsilon\_{\text{sub}}=\epsilon\_{q}+1/\delta yields F‚Äã(œÄgreedy)‚â•(1‚àí1/e)‚ÄãF‚Äã(œÄ‚àó)‚àíK‚Äãœµq‚àíK/Œ¥F(\pi\_{\text{greedy}})\geq(1-1/e)F(\pi^{\*})-K\epsilon\_{q}-K/\delta.
‚àé

*Remark (Assumptions and Robustness):* Assumptions (A1)‚Äì(A2) (adaptive monotonicity and submodularity) are sufficient conditions for the (1‚àí1/e)(1-1/e) guarantee but may not hold exactly in practice. Specifically:

* ‚Ä¢

  The LM loss ‚ÑíLM\mathcal{L}\_{\text{LM}} is not generally submodular in merge operations; the guarantee applies to the quality-frequency component F‚Äã(V)F(V) as defined.
* ‚Ä¢

  When assumptions are violated, the bound becomes approximate: F‚Äã(œÄgreedy)‚â•(1‚àí1/e)‚ÄãF‚Äã(œÄ‚àó)‚àíK‚Äãœµq‚àíK/Œ¥‚àíœµviolationF(\pi\_{\text{greedy}})\geq(1-1/e)F(\pi^{\*})-K\epsilon\_{q}-K/\delta-\epsilon\_{\text{violation}}, where œµviolation\epsilon\_{\text{violation}} is proportional to the degree of assumption violation.

Empirically, our experiments show the guarantee is meaningful because: (1) tokenization objectives often exhibit near-submodular behavior (Lin and Bilmes, [2011](https://arxiv.org/html/2602.06394v1#bib.bib108 "A class of submodular functions for document summarization")); (2) end-to-end learning of Œ±\alpha compensates for violations by calibrating the quality-frequency trade-off; (3) RL policy exploration in Stage¬†1 helps escape poor local optima that pure greedy would converge to.

### C.8 Robustness Analysis

We analyze robustness under misspecified quality metrics and adversarial quality scores, quantifying interaction effects between RL and adaptive learning stages.

###### Theorem C.12 (Robustness to Quality Corruption).

Let q~=q+Œæ\tilde{q}=q+\xi with Œæ‚àºùí©‚Äã(0,œÉŒæ2)\xi\sim\mathcal{N}(0,\sigma\_{\xi}^{2}). Then

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚Ñí‚Äã(q~)‚àí‚Ñí‚Äã(q)‚â§Œ±‚ÄãœÉŒæ‚Äãùîº‚Äã[‚Äñ‚àáq‚Ñí‚Äñ2].\mathcal{L}(\tilde{q})-\mathcal{L}(q)\leq\alpha\,\sigma\_{\xi}\,\sqrt{\mathbb{E}[\|\nabla\_{q}\mathcal{L}\|^{2}]}. |  | (8) |

###### Proof.

The result follows from Lipschitz stability of the bilevel objective. By the chain rule and Cauchy-Schwarz, |‚Ñí‚Äã(q~)‚àí‚Ñí‚Äã(q)|‚â§‚ÄñŒæ‚Äñ2‚ãÖ‚à´01‚Äñ‚àáq‚Ñí‚Äã(q+t‚ÄãŒæ)‚Äñ2‚Äãùëët|\mathcal{L}(\tilde{q})-\mathcal{L}(q)|\leq\|\xi\|\_{2}\cdot\int\_{0}^{1}\|\nabla\_{q}\mathcal{L}(q+t\xi)\|\_{2}dt.

From Proposition¬†[C.4](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem4 "Proposition C.4 (Boundedness and Lipschitzness of ùë§_{ùëé‚Å¢ùëè}). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), ‚Äñ‚àÇwa‚Äãb/‚àÇq‚Äñ‚â§Œ±‚ÄãœµQŒ±‚àí1\|\partial w\_{ab}/\partial q\|\leq\alpha\epsilon\_{Q}^{\alpha-1}, yielding ‚Äñ‚àáq‚Ñí‚Äñ‚â§Œ±‚ÄãC‚Ñí\|\nabla\_{q}\mathcal{L}\|\leq\alpha C\_{\mathcal{L}}. Taking expectations over Œæ‚àºùí©‚Äã(0,œÉŒæ2‚ÄãI)\xi\sim\mathcal{N}(0,\sigma\_{\xi}^{2}I) with ùîº‚Äã[‚ÄñŒæ‚Äñ2]‚â§œÉŒæ‚Äãd\mathbb{E}[\|\xi\|\_{2}]\leq\sigma\_{\xi}\sqrt{d} gives the stated bound.
‚àé

Empirical Validation. We validate the robustness bound experimentally:

* ‚Ä¢

  20% quality noise: Performance degradation of ‚àí4.2-4.2% (genomics) and ‚àí5.8-5.8% (finance), consistent with the O‚Äã(Œ±‚ÄãœÉŒæ)O(\alpha\sigma\_{\xi}) bound.
* ‚Ä¢

  Adversarial quality (inverted scores): Performance matches standard BPE, as expected when quality signals become uninformative.
* ‚Ä¢

  50% missing quality: Graceful fallback to frequency-only merging via the adaptive Œ±‚Üí0\alpha\to 0 mechanism.

Interaction Effects. We quantify the contribution of each learning stage:

* ‚Ä¢

  RL policy optimization alone: 65% of total improvement over BPE
* ‚Ä¢

  Adaptive parameter learning alone: 45% of total improvement
* ‚Ä¢

  Combined (synergy): Additional +10% from joint optimization

The super-additive effect (65% + 45% >> 100% total) indicates that the two stages reinforce each other: RL discovers promising merge patterns that adaptive learning then calibrates, while learned parameters improve the reward landscape for RL exploration.

### C.9 Information-Theoretic Optimality

This subsection establishes that QA-Token achieves information-theoretic optimality under noisy conditions, providing theoretical justification for quality-aware tokenization.

###### Proposition C.13 (Quality-Aware Information Bottleneck Interpretation).

Let XX denote the input sequence, TT the tokenized representation, and YY the downstream task labels. Under the quality-aware tokenization framework with quality scores QQ, the optimal vocabulary V‚àóV^{\*} minimizes:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚ÑíQA‚Äã(V)=‚àíI‚Äã(T;Y|Q)+Œ≤‚ãÖI‚Äã(T;X|Q)\mathcal{L}\_{\text{QA}}(V)=-I(T;Y|Q)+\beta\cdot I(T;X|Q) |  | (9) |

where I(‚ãÖ;‚ãÖ|‚ãÖ)I(\cdot;\cdot|\cdot) denotes conditional mutual information and Œ≤\beta controls the compression-relevance tradeoff.

*Connection to merge score:* The merge score wa‚Äãbw\_{ab} is consistent with (but not directly derived from) this IB objective. PMI approximates compression efficiency I‚Äã(T;X|Q)I(T;X|Q), while quality weighting ensures high I‚Äã(T;Y|Q)I(T;Y|Q) in reliable regions. The connection is qualitative rather than via direct differentiation of mutual information, which is intractable.

###### Proof.

Following the information bottleneck framework (Tishby et al., [1999](https://arxiv.org/html/2602.06394v1#bib.bib113 "The information bottleneck method")) and its variational extension (Alemi et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib114 "Deep variational information bottleneck")), conditioning on quality QQ yields the objective ‚ÑíQA=‚àíI‚Äã(T;Y|Q)+Œ≤‚ÄãI‚Äã(T;X|Q)\mathcal{L}\_{\text{QA}}=-I(T;Y|Q)+\beta I(T;X|Q).

The merge score wa‚Äãb‚àùPMI‚Äã(a,b)‚ãÖ(q¬Øa‚Äãb)Œ±w\_{ab}\propto\text{PMI}(a,b)\cdot(\bar{q}\_{ab})^{\alpha} is *consistent with* this IB objective: (i) the PMI term approximates compression efficiency I‚Äã(T;X|Q)I(T;X|Q) (high-PMI merges compress efficiently), and (ii) the quality term weights merges by reliability, prioritizing high-quality regions for I‚Äã(T;Y|Q)I(T;Y|Q).

*Caveat:* The exact form of wa‚Äãbw\_{ab} does not follow from direct differentiation of mutual information (intractable). Rather, it is a principled heuristic with end-to-end learning of Œ±\alpha calibrating the quality-compression trade-off.
‚àé

###### Corollary C.14 (Noise Reduction Bound).

For a corpus with noise level œµ\epsilon and quality scores qq satisfying ùîº‚Äã[q|noise]<ùîº‚Äã[q|signal]\mathbb{E}[q|\text{noise}]<\mathbb{E}[q|\text{signal}], the quality-aware tokenizer achieves:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚ÑíQA‚â§‚Ñíuniform‚àíŒ±‚ãÖVar‚Äã(q)‚ãÖœÅ‚Äã(q,œµ)2\mathcal{L}\_{\text{QA}}\leq\mathcal{L}\_{\text{uniform}}-\alpha\cdot\text{Var}(q)\cdot\rho(q,\epsilon)^{2} |  | (10) |

where œÅ‚Äã(q,œµ)\rho(q,\epsilon) is the correlation between quality scores and noise levels.

Key Theoretical Insights. This information-theoretic analysis provides three fundamental insights:

1. 1.

   Automatic Noise Filtering: QA-Token implicitly performs importance sampling, up-weighting high-quality regions during vocabulary construction.
2. 2.

   Optimal Compression: The quality-aware merge process achieves better rate-distortion tradeoffs by allocating more representation capacity to high-quality, informative regions.
3. 3.

   Transfer Learning: Foundation models trained with QA-Token vocabularies learn more robust representations that transfer better to downstream tasks.

## Appendix D Complete Quality Metrics Formulations

### D.1 Genomics: Detailed Sequencing Quality Metrics

In genomic sequencing, each nucleotide base call si‚àà{A,C,G,T,N}s\_{i}\in\{\text{A},\text{C},\text{G},\text{T},\text{N}\} is associated with a Phred quality score Qphred,i‚àà[0,93]Q\_{\text{phred},i}\in[0,93]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Perror‚Äã(i)=10‚àíQphred,i/10P\_{\text{error}}(i)=10^{-Q\_{\text{phred},i}/10} |  | (11) |

The base quality score is qi=1‚àíPerror‚Äã(i)‚àà[0,1]q\_{i}=1-P\_{\text{error}}(i)\in[0,1]. Position-adjusted quality accounts for systematic degradation at read ends:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qi‚Ä≤=qi‚ãÖexp‚Å°(‚àíŒ≤pos‚ãÖ|i‚àí(L‚àí1)/2|(L‚àí1)/2+œµlen)q^{\prime}\_{i}=q\_{i}\cdot\exp\left(-\beta\_{\text{pos}}\cdot\frac{|i-(L-1)/2|}{(L-1)/2+\epsilon\_{\text{len}}}\right) |  | (12) |

where LL is read length, Œ≤pos‚â•0\beta\_{\text{pos}}\geq 0 is learnable, and œµlen=10‚àí6\epsilon\_{\text{len}}=10^{-6}.

For multi-base token t=s1‚Äã‚Ä¶‚Äãs|t|t=s\_{1}...s\_{|t|}, we use geometric mean aggregation:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qtgenomic=(‚àèj=1|t|qsj‚Ä≤)1/|t|=exp‚Å°(1|t|‚Äã‚àëj=1|t|log‚Å°(qsj‚Ä≤+œµQ))q\_{t}^{\text{genomic}}=\left(\prod\_{j=1}^{|t|}q^{\prime}\_{s\_{j}}\right)^{1/|t|}=\exp\left(\frac{1}{|t|}\sum\_{j=1}^{|t|}\log(q^{\prime}\_{s\_{j}}+\epsilon\_{Q})\right) |  | (13) |

### D.2 Finance: Comprehensive Market Quality Metrics

Financial time series quality combines four dimensions:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qifinance=‚àëk=14wk‚ãÖqk,i,‚àëk=14wk=1q\_{i}^{\text{finance}}=\sum\_{k=1}^{4}w\_{k}\cdot q\_{k,i},\quad\sum\_{k=1}^{4}w\_{k}=1 |  | (14) |

1. Liquidity Quality:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qliq‚Äã(t)=sigmoid‚Äã(log‚Å°(volumet/median\_volume)œÉvolume)q\_{\text{liq}}(t)=\text{sigmoid}\left(\frac{\log(\text{volume}\_{t}/\text{median\\_volume})}{\sigma\_{\text{volume}}}\right) |  | (15) |

where œÉvolume\sigma\_{\text{volume}} is the rolling standard deviation of log-volume computed over a lookback window of Lvol=252L\_{\text{vol}}=252 trading days (one year), clipped to [0.1,10][0.1,10] for numerical stability. This normalization ensures that qliqq\_{\text{liq}} responds proportionally to volume deviations relative to typical market activity.

2. Signal Quality:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qsig‚Äã(t)=max‚Å°(0,1‚àí|bid-ask spreadt|mid-pricet‚ãÖŒ±spread)q\_{\text{sig}}(t)=\max\left(0,1-\frac{|\text{bid-ask spread}\_{t}|}{\text{mid-price}\_{t}\cdot\alpha\_{\text{spread}}}\right) |  | (16) |

3. Stability Quality:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qstb‚Äã(t)=exp‚Å°(‚àíŒ≤vol‚ãÖrealized\_voltexpected\_volt)q\_{\text{stb}}(t)=\exp\left(-\beta\_{\text{vol}}\cdot\frac{\text{realized\\_vol}\_{t}}{\text{expected\\_vol}\_{t}}\right) |  | (17) |

where expected\_volt\text{expected\\_vol}\_{t} is the exponentially weighted moving average (EWMA) of realized volatility following the RiskMetrics methodology (J.P. Morgan, [1996](https://arxiv.org/html/2602.06394v1#bib.bib4 "RiskMetrics technical document")): expected\_volt=Œ≥vol‚ãÖexpected\_volt‚àí1+(1‚àíŒ≥vol)‚ãÖrealized\_volt‚àí1\text{expected\\_vol}\_{t}=\gamma\_{\text{vol}}\cdot\text{expected\\_vol}\_{t-1}+(1-\gamma\_{\text{vol}})\cdot\text{realized\\_vol}\_{t-1}, with decay factor Œ≥vol=0.94\gamma\_{\text{vol}}=0.94. The learnable parameter Œ≤vol‚â•0\beta\_{\text{vol}}\geq 0 controls sensitivity to volatility spikes.

4. Information Quality:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qinfo‚Äã(t)=MI‚Äã(tokent,future\_returnt+h)H‚Äã(future\_returnt+h)q\_{\text{info}}(t)=\frac{\text{MI}(\text{token}\_{t},\text{future\\_return}\_{t+h})}{\text{H}(\text{future\\_return}\_{t+h})} |  | (18) |

Token aggregation uses arithmetic mean:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qtfinance=1|t|‚Äã‚àëi‚ààtqifinanceq\_{t}^{\text{finance}}=\frac{1}{|t|}\sum\_{i\in t}q\_{i}^{\text{finance}} |  | (19) |

Rationale for Arithmetic Mean Aggregation: Unlike genomics (which uses geometric mean, Eq.¬†[13](https://arxiv.org/html/2602.06394v1#A4.E13 "Equation 13 ‚Ä£ D.1 Genomics: Detailed Sequencing Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), financial data aggregation employs the arithmetic mean for two principled reasons: (1) *Additive noise model*: Financial market microstructure noise is predominantly additive across time points‚Äîa single noisy tick does not invalidate adjacent observations in the way a single low-quality DNA base compromises an entire read. Empirically, LOB noise sources (latency, partial fills, stale quotes) contribute independently rather than multiplicatively. (2) *Temporal continuity for forecasting*: Financial tokens represent contiguous time windows where downstream tasks (price prediction, volatility forecasting) operate on windowed features. The aggregate quality naturally represents the *average* reliability of observations within the window, which aligns with how prediction models weight inputs. In contrast, genomic tokens represent molecular sequences where any unreliable base compromises biological interpretation (e.g., variant calling), necessitating the conservative geometric mean that penalizes even single low-quality elements.

### D.3 Social Media: Linguistic Quality Metrics

Social media text presents unique quality challenges including orthographic variations, semantic drift, platform-specific conventions, and temporal dynamics. We define a multi-dimensional quality vector for character-level tokens:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ùê™tsocial=(qorth‚Äã(t),qsem‚Äã(t),qtemp‚Äã(t),qplat‚Äã(t))\mathbf{q}\_{t}^{\text{social}}=(q\_{\text{orth}}(t),q\_{\text{sem}}(t),q\_{\text{temp}}(t),q\_{\text{plat}}(t)) |  | (20) |

The scalar quality is obtained via learnable weighted aggregation:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qtsocial=‚àëjwj‚ãÖqj‚Äã(t),wj‚ààŒ∏adaptq\_{t}^{\text{social}}=\sum\_{j}w\_{j}\cdot q\_{j}(t),\quad w\_{j}\in\theta\_{\text{adapt}} |  | (21) |

1. Orthographic Quality: Measures deviation from canonical spelling:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qorth‚Äã(t)=exp‚Å°(‚àíŒªedit‚ãÖdedit‚Äã(t,tcanonical))q\_{\text{orth}}(t)=\exp(-\lambda\_{\text{edit}}\cdot d\_{\text{edit}}(t,t\_{\text{canonical}})) |  | (22) |

where deditd\_{\text{edit}} is the normalized Levenshtein distance to the nearest canonical form in a reference dictionary. The reference dictionary is constructed by combining: (i) the Hunspell en\_US dictionary (2023 release, ‚âà\approx140k entries), (ii) a curated social media slang lexicon (‚âà\approx50k terms aggregated from NoSlang.com and similar sources), and (iii) domain-specific terminology lists for each benchmark task.

2. Semantic Quality: Captures contextual coherence:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qsem‚Äã(t)=max‚Å°(0,cos‚Å°(v‚Üít,v‚Üícontext))q\_{\text{sem}}(t)=\max(0,\cos(\vec{v}\_{t},\vec{v}\_{\text{context}})) |  | (23) |

where v‚Üícontext\vec{v}\_{\text{context}} is the average embedding of surrounding tokens. For efficiency, we use fastText Common Crawl embeddings (cc.en.300.bin, 2M vocabulary) (Bojanowski et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib62 "Enriching word vectors with subword information")). For BERT-based variants requiring subword handling, we use bert-base-uncased from HuggingFace with mean pooling over subword tokens.

3. Temporal Quality: Models relevance decay over time:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qtemp‚Äã(t)=exp‚Å°(‚àíŒ≥decay‚ãÖŒî‚Äãt)q\_{\text{temp}}(t)=\exp(-\gamma\_{\text{decay}}\cdot\Delta t) |  | (24) |

with time difference Œî‚Äãt\Delta t in days from posting time, capturing trending topics and temporal relevance.

4. Platform Quality: Platform-specific noise modeling:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qplat‚Äã(t)=P‚Äã(t|platform)q\_{\text{plat}}(t)=P(t|\text{platform}) |  | (25) |

computed using 3-gram Kneser-Ney language models trained with KenLM (Heafield, [2011](https://arxiv.org/html/2602.06394v1#bib.bib3 "KenLM: faster and smaller language model queries")) on curated platform-specific corpora (‚âà\approx10M tokens each): Twitter (tweets with >>100 likes and <<5% special characters), Reddit (comments with >>10 upvotes from default subreddits), and Facebook (public posts from verified pages). These ‚Äúclean‚Äù subsets establish platform-specific baselines for typical language patterns.

Learned Parameters: For the TweetEval benchmark experiments, the learned parameters were:
worth=0.32¬±0.03w\_{\text{orth}}=0.32\pm 0.03, wsem=0.35¬±0.04w\_{\text{sem}}=0.35\pm 0.04, wtemp=0.18¬±0.02w\_{\text{temp}}=0.18\pm 0.02, wplat=0.15¬±0.02w\_{\text{plat}}=0.15\pm 0.02, Œªedit=0.5\lambda\_{\text{edit}}=0.5, and Œ≥decay=0.01\gamma\_{\text{decay}}=0.01.

## Appendix E Sequential Learning Process: Complete Framework

This section provides detailed algorithms and convergence analysis for QA-Token‚Äôs two-stage sequential learning process.

### E.1 Stage 1: Reinforcement Learning Policy Optimization

#### E.1.1 MDP Formulation

The vocabulary construction process is formulated as a finite-horizon Markov Decision Process (see Section [E.7](https://arxiv.org/html/2602.06394v1#A5.SS7 "E.7 MDP Formulation and Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") for complete specification):

* ‚Ä¢

  States st‚ààùíÆs\_{t}\in\mathcal{S}: Encode current vocabulary VtV\_{t}, merge candidates, corpus statistics, and progress t/Tt/T
* ‚Ä¢

  Actions at‚ààùíúta\_{t}\in\mathcal{A}\_{t}: Select a merge pair (ai,bi)(a\_{i},b\_{i}) from the priority queue
* ‚Ä¢

  Transitions: Deterministic vocabulary updates following merge operations
* ‚Ä¢

  Rewards: Multi-objective reward combining quality, information, and complexity

#### E.1.2 Reward Function Design

The reward function guides the RL agent:

|  |  |  |  |
| --- | --- | --- | --- |
|  | R‚Äã(a,b;Œ∏adapt(0))=‚àëj‚àà{Q,I,C,domain}Œªj‚ÄãR^j‚Äã(a,b)R(a,b;\theta\_{\text{adapt}}^{(0)})=\sum\_{j\in\{Q,I,C,\text{domain}\}}\lambda\_{j}\hat{R}\_{j}(a,b) |  | (26) |

where components are normalized via exponential moving averages (see Section [E.8](https://arxiv.org/html/2602.06394v1#A5.SS8 "E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). The detailed components are:

* ‚Ä¢

  Quality Reward (R^Q\hat{R}\_{Q} from RQrawR^{\text{raw}}\_{Q}): Encourages high intrinsic quality for tmerged=a‚Äãbt\_{\text{merged}}=ab, computed using domain-specific aggregation (Section [D](https://arxiv.org/html/2602.06394v1#A4 "Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
* ‚Ä¢

  Information Reward (R^I\hat{R}\_{I} from RIrawR^{\text{raw}}\_{I}): Rewards statistically significant merges, e.g., RIraw‚Äã(a,b)=log‚Å°P‚Äã(tmerged)P‚Äã(a)‚ÄãP‚Äã(b)+œµpR^{\text{raw}}\_{I}(a,b)=\log\frac{P(t\_{\text{merged}})}{P(a)P(b)+\epsilon\_{p}}.
* ‚Ä¢

  Complexity Penalty (R^C\hat{R}\_{C} from RCrawR^{\text{raw}}\_{C}): Typically negative, e.g., RCraw‚Äã(a,b)=‚àí(|tmerged|‚ãÖlog‚Å°(|Vt|+1))R^{\text{raw}}\_{C}(a,b)=-(|t\_{\text{merged}}|\cdot\log(|V\_{t}|+1)). R^C\hat{R}\_{C} is then scaled to e.g. [‚àí1,0][-1,0].
* ‚Ä¢

  Domain-Specific Rewards (R^domain,k\hat{R}\_{\text{domain},k} from Rdomain,krawR^{\text{raw}}\_{\text{domain},k}): Include conservation scores (genomics) and predictive power (finance).

The EMA-normalized rewards R^j‚Äã(a,b)\hat{R}\_{j}(a,b) are used by the RL agent in Stage 1. For the Gumbel-Softmax logits in Stage 2 (Section [E.9](https://arxiv.org/html/2602.06394v1#A5.SS9 "E.9 Gumbel-Softmax Gradient Derivation and Temperature Annealing ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), raw or batch-normalized reward components are used to ensure direct differentiability with respect to Œ∏adapt\theta\_{\text{adapt}}.

#### E.1.3 PPO Training Algorithm

Algorithm 1  Stage 1: RL Policy Training

1:‚ÄÇInput: Corpus ùíÆ\mathcal{S}, initial Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)}, episodes EE

2:‚ÄÇInitialize policy network œÄŒ∏œÄ\pi\_{\theta\_{\pi}} and value network VœïV\_{\phi}

3:‚ÄÇfor episode e=1e=1 to EE do

4:‚ÄÉ‚ÄÇInitialize vocabulary V0=Œ£V\_{0}=\Sigma

5:‚ÄÉ‚ÄÇfor step t=1t=1 to TT do

6:‚ÄÉ‚ÄÉ‚ÄÇCompute state features sts\_{t} from current vocabulary

7:‚ÄÉ‚ÄÉ‚ÄÇSample action at‚àºœÄŒ∏œÄ‚Äã(a|st)a\_{t}\sim\pi\_{\theta\_{\pi}}(a|s\_{t})

8:‚ÄÉ‚ÄÉ‚ÄÇExecute merge (aat,bat)‚Ü¶a‚Äãb(a\_{a\_{t}},b\_{a\_{t}})\mapsto ab

9:‚ÄÉ‚ÄÉ‚ÄÇCompute reward rt=R‚Äã(aat,bat;Œ∏adapt(0))r\_{t}=R(a\_{a\_{t}},b\_{a\_{t}};\theta\_{\text{adapt}}^{(0)})

10:‚ÄÉ‚ÄÉ‚ÄÇStore trajectory (st,at,rt)(s\_{t},a\_{t},r\_{t})

11:‚ÄÉ‚ÄÇend for

12:‚ÄÉ‚ÄÇUpdate policy using PPO objective:

13:‚ÄÉ‚ÄÇLPPO=ùîºt‚Äã[min‚Å°(rt‚Äã(Œ∏)‚ÄãA^t,clip‚Äã(rt‚Äã(Œ∏),1‚àíœµ,1+œµ)‚ÄãA^t)]\quad L^{\text{PPO}}=\mathbb{E}\_{t}[\min(r\_{t}(\theta)\hat{A}\_{t},\text{clip}(r\_{t}(\theta),1-\epsilon,1+\epsilon)\hat{A}\_{t})]

14:‚ÄÉ‚ÄÇUpdate value network to minimize MSE

15:‚ÄÇend for

16:‚ÄÇOutput: Optimized policy œÄŒ∏œÄ‚àó\pi\_{\theta\_{\pi}}^{\*}

### E.2 Stage 2: Adaptive Parameter Learning

#### E.2.1 Adaptive Parameters Definition

The learnable parameter vector Œ∏adapt‚àà‚Ñùm\theta\_{\text{adapt}}\in\mathbb{R}^{m} includes:

* ‚Ä¢

  Quality sensitivity: Œ±‚àà[0,2]\alpha\in[0,2] controlling quality influence
* ‚Ä¢

  Domain factors: Œ≤pos\beta\_{\text{pos}} (genomics position decay), Œ≤vol\beta\_{\text{vol}} (finance volatility)
* ‚Ä¢

  Quality weights: ùê∞=(w1,‚Ä¶,wk)\mathbf{w}=(w\_{1},\ldots,w\_{k}) for composite quality metrics
* ‚Ä¢

  Reward weights: ùùÄ=(ŒªQ,ŒªI,ŒªC,‚Ä¶)\bm{\lambda}=(\lambda\_{Q},\lambda\_{I},\lambda\_{C},\ldots) for multi-objective rewards

#### E.2.2 Gumbel-Softmax Differentiable Optimization

To enable gradient-based optimization through discrete merge decisions, we employ Gumbel-Softmax relaxation:

Algorithm 2  Stage 2: Adaptive Parameter Learning

1:‚ÄÇInput: Downstream dataset ùíü\mathcal{D}, policy œÄŒ∏œÄ‚àó\pi\_{\theta\_{\pi}}^{\*}, initial Œ∏adapt\theta\_{\text{adapt}}

2:‚ÄÇInitialize temperature œÑ=œÑinit\tau=\tau\_{\text{init}}

3:‚ÄÇfor iteration i=1i=1 to NN do

4:‚ÄÉ‚ÄÇSample batch BB from ùíü\mathcal{D}

5:‚ÄÉ‚ÄÇfor each sequence in batch do

6:‚ÄÉ‚ÄÉ‚ÄÇGenerate top-KK merge candidates via priority queue ranked by wa‚Äãbw\_{ab}

7:‚ÄÉ‚ÄÉ‚ÄÇCompute composite logits: ‚Ñìa‚Äãb=wa‚Äãb‚Äã(a,b;Œ±)+‚àëjŒªj‚ÄãRjraw\ell\_{ab}=w\_{ab}(a,b;\alpha)+\sum\_{j}\lambda\_{j}R\_{j}^{\text{raw}}

8:‚ÄÉ‚ÄÉ‚ÄÇSelect merge via Gumbel-Softmax (differentiable relaxation):

9:‚ÄÉ‚ÄÉ‚ÄÇyi=exp‚Å°((‚Ñìi+gi)/œÑ)‚àëjexp‚Å°((‚Ñìj+gj)/œÑ)\quad y\_{i}=\frac{\exp((\ell\_{i}+g\_{i})/\tau)}{\sum\_{j}\exp((\ell\_{j}+g\_{j})/\tau)}

10:‚ÄÉ‚ÄÉ‚ÄÇConstruct differentiable tokenized representation

11:‚ÄÉ‚ÄÇend for

12:‚ÄÉ‚ÄÇCompute task loss LtaskL\_{\text{task}} on tokenized batch

13:‚ÄÉ‚ÄÇUpdate parameters: Œ∏adapt‚ÜêŒ∏adapt‚àíŒ∑‚Äã‚àáLtotal\theta\_{\text{adapt}}\leftarrow\theta\_{\text{adapt}}-\eta\nabla L\_{\text{total}}

14:‚ÄÉ‚ÄÇAnneal temperature: œÑ‚ÜêœÑ‚ãÖexp‚Å°(‚àíŒ≤anneal)\tau\leftarrow\tau\cdot\exp(-\beta\_{\text{anneal}})

15:‚ÄÇend for

16:‚ÄÇOutput: Optimized parameters Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*}

### E.3 Final Vocabulary Construction

After completing both stages, the final vocabulary for deployment is constructed.

Detailed Process:
Following the completion of Stage 1 (RL policy optimization yielding œÄŒ∏œÄ‚àó\pi\_{\theta\_{\pi}}^{\*}) and Stage 2 (adaptive parameter learning yielding Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*}), the final vocabulary for deployment is typically constructed. While several strategies are possible, our primary approach involves the optimized adaptive parameters Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*} to re-evaluate merge priorities. Specifically, a greedy BPE-like process is executed, starting from the base alphabet. At each step, the merge operation (a,b)(a,b) is chosen that maximizes the quality-aware merge score wa‚Äãb‚Äã(a,b;Œ∏adapt‚àó)w\_{ab}(a,b;\theta\_{\text{adapt}}^{\*}) as defined in Equation [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), using the learned parameters within Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*} (e.g., Œ±‚àó\alpha^{\*}). This process continues until the target vocabulary size is reached. Alternatively, if the RL policy œÄŒ∏œÄ‚àó\pi\_{\theta\_{\pi}}^{\*} is robust across variations in Œ∏adapt\theta\_{\text{adapt}}, it could be used with inputs (state features, merge scores) calculated using Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*}. However, the greedy approach based on wa‚Äãb‚Äã(Œ∏adapt‚àó)w\_{ab}(\theta\_{\text{adapt}}^{\*}) is generally more direct and computationally efficient for deployment, leveraging the refined understanding of "good" merges embodied in Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*}.

Algorithm 3  Final Vocabulary Construction

1:‚ÄÇInput: Corpus ùíÆ\mathcal{S}, optimized Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*}, target size KK

2:‚ÄÇInitialize vocabulary V=Œ£V=\Sigma, merge count m=0m=0

3:‚ÄÇwhile m<Km<K do

4:‚ÄÉ‚ÄÇCompute all merge scores: wa‚Äãb=f‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖ(q¬Øa‚Äãb+œµQ)Œ±‚àó‚ãÖœà‚Äã(a,b)w\_{ab}=\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot(\bar{q}\_{ab}+\epsilon\_{Q})^{\alpha^{\*}}\cdot\psi(a,b)

5:‚ÄÉ‚ÄÇSelect best merge: (a‚àó,b‚àó)=arg‚Å°max(a,b)‚Å°wa‚Äãb(a^{\*},b^{\*})=\arg\max\_{(a,b)}w\_{ab}

6:‚ÄÉ‚ÄÇUpdate vocabulary: V‚ÜêV‚à™{a‚àó‚Äãb‚àó}V\leftarrow V\cup\{a^{\*}b^{\*}\} // Constituents a‚àó,b‚àóa^{\*},b^{\*} remain in VV

7:‚ÄÉ‚ÄÇUpdate corpus statistics and recompute affected frequencies

8:‚ÄÉ‚ÄÇm‚Üêm+1m\leftarrow m+1

9:‚ÄÇend while

10:‚ÄÇOutput: Final vocabulary V‚àóV^{\*}

### E.4 Convergence Properties

The sequential learning process has the following theoretical guarantees:

###### Theorem E.1 (Two-Timescale Convergence).

Under assumptions A1-A4 (Section [C.6](https://arxiv.org/html/2602.06394v1#A3.SS6 "C.6 Assumptions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), the sequential optimization of Œ∏œÄ\theta\_{\pi} (fast timescale) and Œ∏adapt\theta\_{\text{adapt}} (slow timescale) converges to a local Nash equilibrium with probability 1.

###### Proof.

The result follows from two-timescale stochastic approximation (Borkar, [2009](https://arxiv.org/html/2602.06394v1#bib.bib89 "Stochastic approximation: a dynamical systems viewpoint")). Under (A1)‚Äì(A4), the conditions of Theorem 2 in (Borkar, [2009](https://arxiv.org/html/2602.06394v1#bib.bib89 "Stochastic approximation: a dynamical systems viewpoint")) are satisfied: (i) Lipschitz gradients (from bounded rewards and smooth parameterization), (ii) bounded iterates via projection, (iii) martingale noise with bounded variance, and (iv) proper step sizes (‚àëtŒ∑t=‚àû\sum\_{t}\eta\_{t}=\infty, ‚àëtŒ∑t2<‚àû\sum\_{t}\eta\_{t}^{2}<\infty).

With timescale separation Œ∑œÄ(t)/Œ∑adapt(t)‚Üí‚àû\eta\_{\pi}^{(t)}/\eta\_{\text{adapt}}^{(t)}\to\infty, the fast iterate Œ∏œÄ\theta\_{\pi} equilibrates before significant movement in Œ∏adapt\theta\_{\text{adapt}}. The iterates converge almost surely to limit points (Œ∏œÄ‚àó,Œ∏adapt‚àó)(\theta\_{\pi}^{\*},\theta\_{\text{adapt}}^{\*}) satisfying ‚àáŒ∏œÄJ=0\nabla\_{\theta\_{\pi}}J=0 and ‚àáŒ∏adaptLtotal=0\nabla\_{\theta\_{\text{adapt}}}L\_{\text{total}}=0, constituting a local Nash equilibrium.
‚àé

Key Properties:

* ‚Ä¢

  Stage 1 Convergence: PPO converges to a stationary point at rate O‚Äã(1/T)O(1/\sqrt{T}) (Proposition [C.6](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem6 "Proposition C.6 (Convergence of PPO Objective). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"))
* ‚Ä¢

  Stage 2 Convergence: Gumbel-Softmax optimization converges at rate O‚Äã(1/T)+O‚Äã(œÑ2)O(1/\sqrt{T})+O(\tau^{2}) (Proposition [C.7](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem7 "Proposition C.7 (Consistency and Boundedness of Stage 2 Gradients). ‚Ä£ Proof of Theorem 3.2 (Computational Complexity). ‚Ä£ C.5 Theory Proofs ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"))
* ‚Ä¢

  Overall Optimality: The greedy vocabulary construction with Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*} achieves (1‚àí1/e)(1-1/e)-approximation (Theorem [C.11](https://arxiv.org/html/2602.06394v1#A3.Thmtheorem11 "Theorem C.11 (Approximation Guarantee with Explicit Constants). ‚Ä£ C.7 Theory Extensions ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"))

###### Proposition E.2 (Convergence of Adaptive Learning with Explicit Constants).

Under Assumptions A1‚ÄìA4, with Œ∑t=Œ∑0/t\eta\_{t}=\eta\_{0}/\sqrt{t} and Œ∑0‚â§1/(2‚ÄãL)\eta\_{0}\leq 1/(2L), where LL is the Lipschitz constant of ‚àáLtotal\nabla L\_{\text{total}}, we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ùîº‚Äã[‚Äñ‚àáLtotal‚Äã(Œ∏adaptT)‚Äñ2]‚â§2‚Äã(Ltotal‚Äã(Œ∏adapt0)‚àíL‚àó)Œ∑0‚ÄãT+4‚ÄãŒ∑0‚ÄãL‚ÄãœÉ2T,\mathbb{E}[\|\nabla L\_{\text{total}}(\theta\_{\text{adapt}}^{T})\|^{2}]\leq\frac{2(L\_{\text{total}}(\theta\_{\text{adapt}}^{0})-L^{\*})}{\eta\_{0}\sqrt{T}}+\frac{4\eta\_{0}L\sigma^{2}}{\sqrt{T}}, |  | (27) |

where L‚àóL^{\*} is the optimal value and œÉ2\sigma^{2} bounds gradient variance.

###### Proof.

The proof follows standard non-convex SGD analysis (Kingma and Ba, [2014](https://arxiv.org/html/2602.06394v1#bib.bib44 "Adam: a method for stochastic optimization")). By smoothness of LtotalL\_{\text{total}}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ltotal‚Äã(Œ∏t+1)‚â§Ltotal‚Äã(Œ∏t)‚àíŒ∑t‚Äã‚ü®‚àáLtotal‚Äã(Œ∏t),gt‚ü©+L‚ÄãŒ∑t22‚Äã‚Äñgt‚Äñ2L\_{\text{total}}(\theta^{t+1})\leq L\_{\text{total}}(\theta^{t})-\eta\_{t}\langle\nabla L\_{\text{total}}(\theta^{t}),g\_{t}\rangle+\frac{L\eta\_{t}^{2}}{2}\|g\_{t}\|^{2} |  | (28) |

where gtg\_{t} is the stochastic gradient. Taking expectations and using ùîº‚Äã[gt]=‚àáLtotal‚Äã(Œ∏t)\mathbb{E}[g\_{t}]=\nabla L\_{\text{total}}(\theta^{t}) and ùîº‚Äã[‚Äñgt‚Äñ2]‚â§‚Äñ‚àáLtotal‚Äã(Œ∏t)‚Äñ2+œÉ2\mathbb{E}[\|g\_{t}\|^{2}]\leq\|\nabla L\_{\text{total}}(\theta^{t})\|^{2}+\sigma^{2}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ùîº‚Äã[Ltotal‚Äã(Œ∏t+1)]‚â§ùîº‚Äã[Ltotal‚Äã(Œ∏t)]‚àíŒ∑t‚Äã(1‚àíL‚ÄãŒ∑t/2)‚Äãùîº‚Äã[‚Äñ‚àáLtotal‚Äã(Œ∏t)‚Äñ2]+L‚ÄãŒ∑t2‚ÄãœÉ22\mathbb{E}[L\_{\text{total}}(\theta^{t+1})]\leq\mathbb{E}[L\_{\text{total}}(\theta^{t})]-\eta\_{t}(1-L\eta\_{t}/2)\mathbb{E}[\|\nabla L\_{\text{total}}(\theta^{t})\|^{2}]+\frac{L\eta\_{t}^{2}\sigma^{2}}{2} |  | (29) |

Telescoping over TT iterations with Œ∑t=Œ∑0/t\eta\_{t}=\eta\_{0}/\sqrt{t} and Œ∑0‚â§1/(2‚ÄãL)\eta\_{0}\leq 1/(2L) yields the stated bound.

*Remark:* Under temperature annealing œÑt‚Üí0\tau\_{t}\to 0, the Gumbel-Softmax bias term B‚Äã(œÑ)2‚Üí0B(\tau)^{2}\to 0, ensuring asymptotic unbiasedness.
‚àé

###### Theorem E.3 (Local vs Global Optimality).

The two-timescale optimization converges to a local Nash equilibrium (Œ∏œÄ‚àó,Œ∏adapt‚àó)(\theta\_{\pi}^{\*},\theta\_{\text{adapt}}^{\*}) with quality bounds under local strong convexity; probabilistic restarts increase the chance of reaching global optima.

###### Proof.

Part 1: Local Nash Equilibrium. By Theorem¬†[E.1](https://arxiv.org/html/2602.06394v1#A5.Thmtheorem1 "Theorem E.1 (Two-Timescale Convergence). ‚Ä£ E.4 Convergence Properties ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), the limit points satisfy ‚àáŒ∏œÄJ=0\nabla\_{\theta\_{\pi}}J=0 and ‚àáŒ∏adaptLtotal=0\nabla\_{\theta\_{\text{adapt}}}L\_{\text{total}}=0, constituting a local Nash equilibrium.

Part 2: Quality Bounds. Under Œº\mu-strong convexity of LtotalL\_{\text{total}} in neighborhood ‚Ñ¨r‚Äã(Œ∏adapt‚àó)\mathcal{B}\_{r}(\theta\_{\text{adapt}}^{\*}):

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ltotal‚Äã(Œ∏adapt‚àó)‚àíLtotal‚Äã(Œ∏adaptglobal)‚â§12‚ÄãŒº‚Äã‚Äñ‚àáLtotal‚Äã(Œ∏adapt‚àó)‚Äñ2=0L\_{\text{total}}(\theta\_{\text{adapt}}^{\*})-L\_{\text{total}}(\theta\_{\text{adapt}}^{\text{global}})\leq\frac{1}{2\mu}\|\nabla L\_{\text{total}}(\theta\_{\text{adapt}}^{\*})\|^{2}=0 |  | (30) |

if the global optimum lies within the basin of attraction.

Part 3: Probabilistic Restarts. With MM independent runs, ‚Ñô‚Äã[find global]=1‚àí(1‚àípbasin)M‚â•1‚àíe‚àíM‚ãÖpbasin\mathbb{P}[\text{find global}]=1-(1-p\_{\text{basin}})^{M}\geq 1-e^{-M\cdot p\_{\text{basin}}}, achieving probability ‚â•1‚àíŒ¥\geq 1-\delta for M=O‚Äã(log‚Å°(1/Œ¥)/pbasin)M=O(\log(1/\delta)/p\_{\text{basin}}) restarts.
‚àé

### E.5 Algorithm Summary

Algorithm 4  QA-Token: Quality-Aware Tokenization Framework

1:‚ÄÇInput: Corpus ùíû\mathcal{C}, quality scores QQ, vocabulary budget KK

2:‚ÄÇOutput: Optimized vocabulary V‚àóV^{\*}

3:

4:‚ÄÇStage 1: RL Policy Optimization

5:‚ÄÇInitialize policy œÄŒ∏œÄ\pi\_{\theta\_{\pi}}, adaptive parameters Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)}

6:‚ÄÇfor episode e=1e=1 to EE do

7:‚ÄÉ‚ÄÇV‚ÜêŒ£V\leftarrow\Sigma (base alphabet)

8:‚ÄÉ‚ÄÇfor step t=1t=1 to KK do

9:‚ÄÉ‚ÄÉ‚ÄÇCompute priority queue P‚ÄãQtPQ\_{t} with scores wa‚Äãb‚Äã(‚ãÖ;Œ∏adapt(0))w\_{ab}(\cdot;\theta\_{\text{adapt}}^{(0)})

10:‚ÄÉ‚ÄÉ‚ÄÇSelect merge (a,b)‚àºœÄŒ∏œÄ(‚ãÖ|st)(a,b)\sim\pi\_{\theta\_{\pi}}(\cdot|s\_{t}) from P‚ÄãQtPQ\_{t}

11:‚ÄÉ‚ÄÉ‚ÄÇExecute merge: V‚ÜêV‚à™{a‚Äãb}V\leftarrow V\cup\{ab\} // Add merged token

12:‚ÄÉ‚ÄÉ‚ÄÇCompute reward RtR\_{t} using Eq. [26](https://arxiv.org/html/2602.06394v1#A5.E26 "Equation 26 ‚Ä£ E.1.2 Reward Function Design ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")

13:‚ÄÉ‚ÄÇend for

14:‚ÄÉ‚ÄÇUpdate œÄŒ∏œÄ\pi\_{\theta\_{\pi}} via PPO using trajectory rewards

15:‚ÄÇend for

16:

17:‚ÄÇStage 2: Adaptive Parameter Learning

18:‚ÄÇfor iteration i=1i=1 to II do

19:‚ÄÉ‚ÄÇSample mini-batch of merge candidates ‚Ñ¨\mathcal{B}

20:‚ÄÉ‚ÄÇCompute logits ‚Ñìa‚Äãb‚Äã(Œ∏adapt)\ell\_{ab}(\theta\_{\text{adapt}}) using Eq. [37](https://arxiv.org/html/2602.06394v1#A5.E37 "Equation 37 ‚Ä£ E.11 Gradient Computation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")

21:‚ÄÉ‚ÄÇSample Gumbel noise and compute soft selection via Eq. [38](https://arxiv.org/html/2602.06394v1#A5.E38 "Equation 38 ‚Ä£ E.11 Gradient Computation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")

22:‚ÄÉ‚ÄÇEvaluate task loss LtaskL\_{\text{task}} on downstream objective

23:‚ÄÉ‚ÄÇUpdate Œ∏adapt‚ÜêŒ∏adapt‚àíŒ∑i‚Äã‚àáLtotal\theta\_{\text{adapt}}\leftarrow\theta\_{\text{adapt}}-\eta\_{i}\nabla L\_{\text{total}}

24:‚ÄÇend for

25:

26:‚ÄÇFinal Vocabulary Construction

27:‚ÄÇBuild final vocabulary using greedy merges with wa‚Äãb‚Äã(‚ãÖ;Œ∏adapt‚àó)w\_{ab}(\cdot;\theta\_{\text{adapt}}^{\*})

28:‚ÄÇReturn V‚àóV^{\*}




Algorithm 5  QA-Token Integration with Downstream Transformer

1:‚ÄÇInput: Raw sequence XX, trained QA-Token vocab V‚àóV^{\*}, Transformer model MŒ∏M\_{\theta}

2:‚ÄÇOutput: Task predictions Y^\hat{Y}

3:

4:‚ÄÇ// Tokenization (no overhead vs. BPE)

5:‚ÄÇT‚ÜêTokenize‚Äã(X,V‚àó)T\leftarrow\text{Tokenize}(X,V^{\*}) // Standard greedy tokenization

6:

7:‚ÄÇ// Embedding and Encoding

8:‚ÄÇE‚ÜêTokenEmbed‚Äã(T)+PosEmbed‚Äã(positions)E\leftarrow\text{TokenEmbed}(T)+\text{PosEmbed}(\text{positions})

9:‚ÄÇfor layer ‚Ñì=1\ell=1 to LL do

10:‚ÄÉ‚ÄÇE‚ÜêTransformerBlock‚Ñì‚Äã(E)E\leftarrow\text{TransformerBlock}\_{\ell}(E)

11:‚ÄÇend for

12:

13:‚ÄÇ// Task Head

14:‚ÄÇY^‚ÜêTaskHead‚Äã(E)\hat{Y}\leftarrow\text{TaskHead}(E) // Classification, regression, or generation

15:‚ÄÇReturn Y^\hat{Y}

  



Algorithm 6  Meta-Learning Initialization for Adaptive Parameters

0:‚ÄÇTask distribution ùí´‚Äã(ùíØ)\mathcal{P}(\mathcal{T}), base initialization Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)}, inner steps KK, inner lr Œ∑in\eta\_{\text{in}}, outer lr Œ∑out\eta\_{\text{out}}

1:‚ÄÇwhile not converged do

2:‚ÄÉ‚ÄÇSample batch of tasks {ùíØi}‚àºùí´‚Äã(ùíØ)\{\mathcal{T}\_{i}\}\sim\mathcal{P}(\mathcal{T})

3:‚ÄÉ‚ÄÇfor each task ùíØi\mathcal{T}\_{i} do

4:‚ÄÉ‚ÄÉ‚ÄÇSet Œ∏i‚ÜêŒ∏adapt(0)\theta\_{i}\leftarrow\theta\_{\text{adapt}}^{(0)}

5:‚ÄÉ‚ÄÉ‚ÄÇfor k=1‚Äã‚Ä¶‚ÄãKk=1\dots K do

6:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇCompute Ltotal(i)‚Äã(Œ∏i)L\_{\text{total}}^{(i)}(\theta\_{i}) on ùíØi\mathcal{T}\_{i} and update Œ∏i‚ÜêŒ∏i‚àíŒ∑in‚Äã‚àáŒ∏Ltotal(i)‚Äã(Œ∏i)\theta\_{i}\leftarrow\theta\_{i}-\eta\_{\text{in}}\,\nabla\_{\theta}L\_{\text{total}}^{(i)}(\theta\_{i})

7:‚ÄÉ‚ÄÉ‚ÄÇend for

8:‚ÄÉ‚ÄÇend for

9:‚ÄÉ‚ÄÇUpdate initialization: Œ∏adapt(0)‚ÜêŒ∏adapt(0)‚àíŒ∑out‚Äã‚àëi‚àáŒ∏adapt(0)Ltotal(i)‚Äã(Œ∏i)\theta\_{\text{adapt}}^{(0)}\leftarrow\theta\_{\text{adapt}}^{(0)}-\eta\_{\text{out}}\,\sum\_{i}\nabla\_{\theta\_{\text{adapt}}^{(0)}}L\_{\text{total}}^{(i)}(\theta\_{i})

10:‚ÄÇend while

11:

12:‚ÄÇreturn meta-initialization Œ∏adapt‚ãÜ\theta\_{\text{adapt}}^{\star}

### E.6 RL Training Implementation

#### E.6.1 State Representation

The state sts\_{t} provided to the RL agent at merge step tt includes:

* ‚Ä¢

  Global Features: Current vocabulary size |Vt||V\_{t}|; remaining merge steps T‚àítT-t; aggregated token statistics (average length, mean/std of quality scores).
* ‚Ä¢

  Candidate Pair Features (top-KP‚ÄãQK\_{PQ} from priority queue): For each pair (a,b)(a,b): frequencies f‚Äã(a),f‚Äã(b),f‚Äã(a,b)f(a),f(b),f(a,b); qualities qa,qbq\_{a},q\_{b}; lengths |a|,|b||a|,|b|; merge score wa‚Äãbw\_{ab}.
* ‚Ä¢

  Domain Context: Market regime indicators (finance), platform ID (social media), or sequence quality (genomics).

The PPO agent uses an MLP with 2 hidden layers (256 units each, ReLU activations). The policy network outputs action probabilities over KP‚ÄãQK\_{PQ} candidates; the value network outputs a single scalar.

#### E.6.2 Exploration Strategy

An œµ\epsilon-greedy strategy is employed with œµ\epsilon annealed from œµ0=0.5\epsilon\_{0}=0.5 to œµfinal=0.05\epsilon\_{\text{final}}=0.05 over training episodes using exponential decay, balancing exploration and exploitation effectively across all domains.

### E.7 MDP Formulation and Details

###### Definition E.4 (Tokenization MDP).

The tokenization MDP is a tuple ‚Ñ≥=(ùíÆ,ùíú,ùí´,‚Ñõ,Œ≥,T)\mathcal{M}=(\mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R},\gamma,T) where:

1. 1.

   State Space ùíÆ\mathcal{S}: Each state st‚ààùíÆ‚äÇ‚Ñùds\_{t}\in\mathcal{S}\subset\mathbb{R}^{d} encodes:

   * ‚Ä¢

     Current vocabulary VtV\_{t} and its statistics (size, token length distribution)
   * ‚Ä¢

     Priority queue P‚ÄãQt={(ai,bi,wai‚Äãbi)}i=1KP‚ÄãQPQ\_{t}=\{(a\_{i},b\_{i},w\_{a\_{i}b\_{i}})\}\_{i=1}^{K\_{PQ}} of top merge candidates
   * ‚Ä¢

     Corpus statistics: frequency distributions, quality histograms
   * ‚Ä¢

     Progress indicator: t/Tt/T where TT is the merge budget

   Formally, st=[œï‚Äã(Vt),œï‚Äã(P‚ÄãQt),œï‚Äã(ùíÆt),t/T]‚àà‚Ñùds\_{t}=[\phi(V\_{t}),\phi(PQ\_{t}),\phi(\mathcal{S}\_{t}),t/T]\in\mathbb{R}^{d}.

   State Encoding Function œï\phi: The encoding function œï:ùí≥‚Üí‚Ñùdùí≥\phi:\mathcal{X}\to\mathbb{R}^{d\_{\mathcal{X}}} maps variable-size structures to fixed-dimensional vectors:

   * ‚Ä¢

     œï‚Äã(Vt)=[|Vt|/|Œ£|,|t|¬Ø,œÉ|t|,q¬Øt,œÉqt]‚àà‚Ñù5\phi(V\_{t})=[|V\_{t}|/|\Sigma|,\bar{|t|},\sigma\_{|t|},\bar{q}\_{t},\sigma\_{q\_{t}}]\in\mathbb{R}^{5}: vocabulary size ratio, mean/std of token lengths, mean/std of token qualities.
   * ‚Ä¢

     œï‚Äã(P‚ÄãQt)‚àà‚Ñù6‚ãÖKP‚ÄãQ\phi(PQ\_{t})\in\mathbb{R}^{6\cdot K\_{PQ}}: For top-KP‚ÄãQK\_{PQ} candidates, concatenate [wa‚Äãb,qa,qb,|a|,|b|,log‚Å°f‚Äã(a,b)][w\_{ab},q\_{a},q\_{b},|a|,|b|,\log f(a,b)] per pair. Pad with zeros if fewer candidates exist.
   * ‚Ä¢

     œï‚Äã(ùíÆt)‚àà‚Ñù20\phi(\mathcal{S}\_{t})\in\mathbb{R}^{20}: Quality histogram (Bq=10B\_{q}=10 bins over [0,1][0,1]) and log-frequency histogram (Bf=10B\_{f}=10 bins over observed range).

   Total state dimension: d=5+6‚ãÖKP‚ÄãQ+20+1d=5+6\cdot K\_{PQ}+20+1. With KP‚ÄãQ=50K\_{PQ}=50, we have d=326d=326. The MLP policy network processes this representation via two hidden layers (256, 128 units) with ReLU activations (see Appendix¬†[E.6](https://arxiv.org/html/2602.06394v1#A5.SS6 "E.6 RL Training Implementation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
2. 2.

   Action Space ùíút\mathcal{A}\_{t}: At time tt:

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | ùíút={i:(ai,bi)‚ààP‚ÄãQt,i‚â§KP‚ÄãQ}\mathcal{A}\_{t}=\{i:(a\_{i},b\_{i})\in PQ\_{t},i\leq K\_{PQ}\} |  | (31) |

   Each action at‚ààùíúta\_{t}\in\mathcal{A}\_{t} selects a merge pair from the priority queue.
3. 3.

   Transition Dynamics ùí´\mathcal{P}: Deterministic transitions:

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | st+1=ùí´‚Äã(st,at)=UPDATE‚Äã(st,MERGE‚Äã(aat,bat))s\_{t+1}=\mathcal{P}(s\_{t},a\_{t})=\text{UPDATE}(s\_{t},\text{MERGE}(a\_{a\_{t}},b\_{a\_{t}})) |  | (32) |

   where MERGE executes vocabulary update and UPDATE recomputes statistics.
4. 4.

   Reward Function: ‚Ñõ‚Äã(st,at)=R‚Äã(aat,bat;Œ∏adapt(0))\mathcal{R}(s\_{t},a\_{t})=R(a\_{a\_{t}},b\_{a\_{t}};\theta\_{\text{adapt}}^{(0)})
5. 5.

   Discount Factor: Œ≥=1\gamma=1 (undiscounted, finite horizon)
6. 6.

   Horizon: T=KT=K merge operations

###### Proposition E.5 (MDP Well-Formedness).

The tokenization MDP satisfies:

1. 1.

   Markov Property: P‚Äã(st+1|st,at,st‚àí1,‚Ä¶)=P‚Äã(st+1|st,at)P(s\_{t+1}|s\_{t},a\_{t},s\_{t-1},\ldots)=P(s\_{t+1}|s\_{t},a\_{t})
2. 2.

   Bounded State Space: ‚Äñst‚Äñ2‚â§Cs\|s\_{t}\|\_{2}\leq C\_{s}
3. 3.

   Finite Action Space: |ùíút|‚â§KP‚ÄãQ|\mathcal{A}\_{t}|\leq K\_{PQ}

###### Proof.

(1) follows from state containing complete information for transitions. (2) holds as vocabulary size is bounded by |Œ£|+T|\Sigma|+T and frequencies are normalized. (3) is by construction of the priority queue.
‚àé

‚ñ°\square

### E.8 Reward Normalization Details

Each raw reward component Rjraw‚Äã(a,b)R^{\text{raw}}\_{j}(a,b) is normalized using adaptive running statistics. We maintain exponential moving averages (EMAs) for mean Œºj,trun\mu\_{j,t}^{\text{run}} and variance Varj,trun\text{Var}\_{j,t}^{\text{run}}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Œºj,trun=(1‚àíŒ≤norm)‚ÄãŒºj,t‚àí1run+Œ≤norm‚ÄãRjraw‚Äã(a,b)\mu\_{j,t}^{\text{run}}=(1-\beta\_{\text{norm}})\mu\_{j,t-1}^{\text{run}}+\beta\_{\text{norm}}R^{\text{raw}}\_{j}(a,b) |  | (33) |

|  |  |  |  |
| --- | --- | --- | --- |
|  | Varj,trun=(1‚àíŒ≤norm)‚ÄãVarj,t‚àí1run+Œ≤norm‚Äã(Rjraw‚Äã(a,b)‚àíŒºj,t‚àí1run)‚Äã(Rjraw‚Äã(a,b)‚àíŒºj,trun)\text{Var}\_{j,t}^{\text{run}}=(1-\beta\_{\text{norm}})\text{Var}\_{j,t-1}^{\text{run}}+\beta\_{\text{norm}}(R^{\text{raw}}\_{j}(a,b)-\mu\_{j,t-1}^{\text{run}})(R^{\text{raw}}\_{j}(a,b)-\mu\_{j,t}^{\text{run}}) |  | (34) |

where Œ≤norm‚àà[10‚àí3,10‚àí2]\beta\_{\text{norm}}\in[10^{-3},10^{-2}]. The normalized component is:

|  |  |  |  |
| --- | --- | --- | --- |
|  | R^j‚Äã(a,b)=Rjraw‚Äã(a,b)‚àíŒºj,t‚àí1runœÉj,t‚àí1run+œµR\hat{R}\_{j}(a,b)=\frac{R^{\text{raw}}\_{j}(a,b)-\mu\_{j,t-1}^{\text{run}}}{\sigma\_{j,t-1}^{\text{run}}+\epsilon\_{R}} |  | (35) |

with œµR=10‚àí8\epsilon\_{R}=10^{-8} for stability.

### E.9 Gumbel-Softmax Gradient Derivation and Temperature Annealing

### E.10 Temperature Annealing Schedule

We employ an exponential annealing schedule for the temperature parameter:

|  |  |  |  |
| --- | --- | --- | --- |
|  | œÑ‚Äã(t)=œÑinit‚ãÖexp‚Å°(‚àíŒ≤anneal‚ãÖt/Tanneal),\tau(t)=\tau\_{\text{init}}\cdot\exp(-\beta\_{\text{anneal}}\cdot t/T\_{\text{anneal}}), |  | (36) |

where œÑinit=1.0\tau\_{\text{init}}=1.0, Œ≤anneal=3.0\beta\_{\text{anneal}}=3.0, and TannealT\_{\text{anneal}} is the total number of optimization steps.

This schedule ensures:

* ‚Ä¢

  Early exploration: High initial temperature allows exploration of diverse merge patterns
* ‚Ä¢

  Gradual refinement: Exponential decay provides smooth transition to discrete selections
* ‚Ä¢

  Convergence: Low final temperature approaches one-hot categorical sampling

### E.11 Gradient Computation

The composite logits for candidate merge (a,b)(a,b) are:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚Ñìa‚Äãb‚Äã(Œ∏adapt)=wa‚Äãb‚Äã(a,b;Œ±)+‚àëjŒªj‚ÄãRjraw‚Äã(a,b),\ell\_{ab}(\theta\_{\text{adapt}})=w\_{ab}(a,b;\alpha)+\sum\_{j}\lambda\_{j}R^{\text{raw}}\_{j}(a,b), |  | (37) |

which are differentiable with respect to Œ∏adapt\theta\_{\text{adapt}} through both the merge score and reward weights.

The composite logits combine wa‚Äãbw\_{ab} (which incorporates frequency via PMI and quality via q¬Øa‚Äãb\bar{q}\_{ab}) with raw reward components RjrawR^{\text{raw}}\_{j} that also capture quality (RQrawR^{\text{raw}}\_{Q}) and information (RIrawR^{\text{raw}}\_{I}).

Rationale for Intentional Overlap: While there is deliberate overlap between these components (both encode quality and frequency signals), they serve *distinct optimization purposes*:

* ‚Ä¢

  wa‚Äãbw\_{ab} (merge score): Optimized via the RL objective (cumulative discounted reward) during Stage¬†1, capturing *corpus-level* quality-frequency tradeoffs that generalize across merge sequences.
* ‚Ä¢

  ‚àëjŒªj‚ÄãRjraw\sum\_{j}\lambda\_{j}R^{\text{raw}}\_{j} (weighted rewards): Optimized via the downstream task loss LtaskL\_{\text{task}} during Stage¬†2, enabling *task-specific* reweighting of quality vs. information vs. complexity.

This decomposition allows the system to learn *different* quality-frequency tradeoffs for policy learning (Stage¬†1) versus task-specific adaptation (Stage¬†2). The parameter Œ±\alpha controls general token quality preferences learned from reward maximization, while Œªj\lambda\_{j} adjusts relative importance based on task-specific gradients. Ablation studies (Appendix¬†[G.5](https://arxiv.org/html/2602.06394v1#A7.SS5 "G.5 Ablation Studies and Additional Experiments ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), Table¬†[13](https://arxiv.org/html/2602.06394v1#A7.T13 "Table 13 ‚Ä£ G.5.1 RL Algorithm Ablation ‚Ä£ G.5 Ablation Studies and Additional Experiments ‚Ä£ Appendix G Complete Experimental Results ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) confirm that removing either component degrades downstream performance by 3‚Äì8%, validating that both contributions are necessary despite their overlap.

The Gumbel-Softmax distribution provides a differentiable approximation:

|  |  |  |  |
| --- | --- | --- | --- |
|  | yi=exp‚Å°((‚Ñìi+gi)/œÑ)‚àëj=1|ùíû|exp‚Å°((‚Ñìj+gj)/œÑ),gi‚àºGumbel‚Äã(0,1)y\_{i}=\frac{\exp((\ell\_{i}+g\_{i})/\tau)}{\sum\_{j=1}^{|\mathcal{C}|}\exp((\ell\_{j}+g\_{j})/\tau)},\quad g\_{i}\sim\text{Gumbel}(0,1) |  | (38) |

The gradient of the task loss is computed via Monte Carlo sampling:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ‚àáŒ∏adaptLtask=ùîºùê†‚Äã[‚àáŒ∏adaptLtask‚Äã(ùê≤‚Äã(‚Ñì‚Äã(Œ∏adapt),ùê†,œÑ))]\nabla\_{\theta\_{\text{adapt}}}L\_{\text{task}}=\mathbb{E}\_{\mathbf{g}}\left[\nabla\_{\theta\_{\text{adapt}}}L\_{\text{task}}(\mathbf{y}(\bm{\ell}(\theta\_{\text{adapt}}),\mathbf{g},\tau))\right] |  | (39) |

where ùê†\mathbf{g} is sampled Gumbel noise.

Gradient Flow: The gradient flows through:

1. 1.

   Task loss: LtaskL\_{\text{task}} evaluates performance on downstream data
2. 2.

   Soft tokenization: Gumbel-Softmax provides differentiable token boundaries
3. 3.

   Merge logits: ‚Ñìa‚Äãb\ell\_{ab} depends on learnable Œ∏adapt\theta\_{\text{adapt}}
4. 4.

   Quality scores: Through Œ±\alpha and domain parameters Œ≤pos,Œ≤vol\beta\_{\text{pos}},\beta\_{\text{vol}}
5. 5.

   Reward weights: Through ùùÄ\bm{\lambda} in the composite score

## Appendix F Hyperparameter Sensitivity Analysis

We conducted a comprehensive sensitivity analysis on key parameters of the QA-Token framework: the quality sensitivity exponent Œ±\alpha, the primary quality reward weight ŒªQ\lambda\_{Q}, and the domain-specific volatility scaling exponent Œ≤vol\beta\_{\text{vol}} for finance. For each parameter, we varied its value across a specified range while holding all other hyperparameters at their optimal values, as determined during the adaptive learning phase.

The results, summarized in Table¬†[10](https://arxiv.org/html/2602.06394v1#A6.T10 "Table 10 ‚Ä£ Appendix F Hyperparameter Sensitivity Analysis ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), demonstrate that while performance is optimal at the learned parameter values, the framework is not unduly sensitive to minor perturbations. Performance degrades gracefully rather than catastrophically as parameters deviate from their optima, suggesting the model occupies a reasonably wide basin of attraction in the hyperparameter space.

Table 10: Hyperparameter Sensitivity Analysis. Performance on the primary metric is reported as key hyperparameters are varied around their learned optimal value (indicated by \*). Values are means over n=5n=5 runs.

|  |  |  |
| --- | --- | --- |
| Parameter | Value | Performance Metric |
| Genomics (QA-BPE-seq) - Metric: Variant F1 | | |
| Œ±\alpha (Quality Sensitivity) | 0.3 | 0.869 |
|  | 0.5 | 0.879 |
|  | 0.72\* | 0.891 |
|  | 1.0 | 0.884 |
|  | 1.5 | 0.872 |
| ŒªQ\lambda\_{Q} (Quality Reward Weight) | 0.15 | 0.879 |
|  | 0.25 | 0.886 |
|  | 0.35\* | 0.891 |
|  | 0.45 | 0.885 |
|  | 0.55 | 0.878 |
| Finance (QAT-QF) - Metric: Sharpe Ratio | | |
| Œ±\alpha (Quality Sensitivity) | 0.25 | 1.61 |
|  | 0.50 | 1.68 |
|  | 0.95\* | 1.72 |
|  | 1.50 | 1.65 |
|  | 2.00 | 1.58 |
| Œ≤vol\beta\_{\text{vol}} (Volatility Scaling) | 0.10 | 1.63 |
|  | 0.30 | 1.69 |
|  | 0.50\* | 1.72 |
|  | 0.70 | 1.67 |
|  | 1.00 | 1.60 |

## Appendix G Complete Experimental Results

This section provides comprehensive experimental results across all domains, including detailed analysis, foundation-scale evaluations, and ablation studies.

### G.1 Genomics Results: Detailed Analysis

Key Observations: QA-BPE-seq achieves 4.0 percentage point F1 improvement in variant calling over DNABERT-k (0.891 vs. 0.851) with Hedges‚Äô g=8.2g=8.2‚Äîa large effect size. Compared to standard BPE (0.824), the improvement is 6.7 percentage points. Taxonomic classification shows 3.1 percentage point gain over domain-standard k-mer tokenization. Sequence reconstruction improves by 16%, indicating information preservation.

Key Insights:

1. 1.

   Byte-level models fail catastrophically: ByT5 and CANINE show 2.5√ó slower inference with 7-9% lower accuracy, definitively establishing that vocabulary-based tokenization remains essential for genomic sequences.
2. 2.

   Quality awareness is learnable: The converged parameters (Œ±=0.72¬±0.03\alpha=0.72\pm 0.03, Œ≤pos=0.014¬±0.002\beta\_{\text{pos}}=0.014\pm 0.002) demonstrate that optimal quality sensitivity can be discovered through our adaptive learning framework.
3. 3.

   Mechanism of improvement: Analysis of generated vocabularies reveals that QA-BPE-seq creates tokens aligned with biological units (codons, motifs) while breaking at error-prone junctions‚Äîa behavior that emerges without explicit biological supervision.

### G.2 Financial Foundation Model: Detailed Results Analysis

QAT-QF demonstrates remarkable consistency across all financial tasks, with zero-shot improvements ranging from 7.3% to 27.0

Specific Observations:

* ‚Ä¢

  The model‚Äôs superior performance on regime detection (+11.6% F1) and tail risk estimation (+18.0%) suggests that quality-aware tokenization captures market dynamics that frequency-based methods miss.
* ‚Ä¢

  Particularly noteworthy is the 27.0% improvement in order flow imbalance prediction, a task highly sensitive to microstructure noise.
* ‚Ä¢

  These results validate our hypothesis that incorporating quality signals during tokenization enables foundation models to learn more robust representations of financial time series.

### G.3 Computational Costs

Training Time.

* ‚Ä¢

  Standard BPE: 5‚Äì10 minutes (5GB, CPU)
* ‚Ä¢

  QA-Token Stage 1 (RL): 30‚Äì36 GPU-hours (A100)
* ‚Ä¢

  QA-Token Stage 2 (Adaptive): 20‚Äì24 GPU-hours

Memory Requirements.

* ‚Ä¢

  Priority Queue: O‚Äã(KP‚ÄãQ‚ãÖd)O(K\_{PQ}\cdot d) (‚àº10{\sim}10‚ÄâMB for KP‚ÄãQ=200K\_{PQ}{=}200)
* ‚Ä¢

  Quality Statistics: O‚Äã(|V|‚ãÖs)O(|V|\cdot s) (‚àº100{\sim}100‚ÄâMB for 32K vocab)
* ‚Ä¢

  Pair Frequencies: O‚Äã(|V|2)O(|V|^{2}) (‚àº4{\sim}4‚ÄâGB for 32K vocab)
* ‚Ä¢

  Peak: ‚àº16{\sim}16‚ÄâGB GPU

Hierarchical Training via Quality-Stratified Sampling.
For massive corpora where full vocabulary optimization is infeasible, we employ *quality-variance importance sampling*: data points are sampled with probability proportional to Var‚Äã(qi)+œµbase\text{Var}(q\_{i})+\epsilon\_{\text{base}}, prioritizing regions with heterogeneous quality where tokenization decisions have the greatest impact.

###### Definition G.1 (Notation for Hierarchical Training).

Let ùíû\mathcal{C} denote the full corpus and ùíÆ‚äÜùíû\mathcal{S}\subseteq\mathcal{C} a subset with |ùíÆ|=r‚ãÖ|ùíû||\mathcal{S}|=r\cdot|\mathcal{C}| for *subset ratio* r‚àà(0,1]r\in(0,1]. Define:

* ‚Ä¢

  ‚Ñí‚Äã(V;D)=ùîºx‚àºD‚Äã[‚àílog‚Å°PLM‚Äã(x|V)]\mathcal{L}(V;D)=\mathbb{E}\_{x\sim D}[-\log P\_{\text{LM}}(x|V)]: expected language modeling loss on distribution DD using vocabulary VV
* ‚Ä¢

  VùíÆ‚àó=arg‚Å°minV‚Å°‚Ñí‚Äã(V;ùíÆ)V\_{\mathcal{S}}^{\*}=\arg\min\_{V}\mathcal{L}(V;\mathcal{S}): optimal vocabulary for subset ùíÆ\mathcal{S}
* ‚Ä¢

  Vùíû‚àó=arg‚Å°minV‚Å°‚Ñí‚Äã(V;ùíû)V\_{\mathcal{C}}^{\*}=\arg\min\_{V}\mathcal{L}(V;\mathcal{C}): optimal vocabulary for full corpus ùíû\mathcal{C}

###### Proposition G.2 (Hierarchical Training Bound).

Under the following assumptions:

1. (A1)

   The loss ‚Ñí‚Äã(V;‚ãÖ)\mathcal{L}(V;\cdot) is LL-Lipschitz in the data distribution (bounded sensitivity to distribution shift)
2. (A2)

   Quality-variance importance sampling achieves effective sample size neff=r‚ãÖ|ùíû|/(1+CV2)n\_{\text{eff}}=r\cdot|\mathcal{C}|/(1+\text{CV}^{2}) where CV is the coefficient of variation of importance weights

Then the vocabulary VùíÆ‚àóV\_{\mathcal{S}}^{\*} learned on the importance-sampled subset satisfies:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ùîº‚Äã[‚Ñí‚Äã(VùíÆ‚àó;ùíû)]‚â§‚Ñí‚Äã(Vùíû‚àó;ùíû)+O‚Äã(L‚ãÖ1+CV2r‚ãÖ|ùíû|).\mathbb{E}[\mathcal{L}(V\_{\mathcal{S}}^{\*};\mathcal{C})]\leq\mathcal{L}(V\_{\mathcal{C}}^{\*};\mathcal{C})+O\left(L\cdot\sqrt{\frac{1+\text{CV}^{2}}{r\cdot|\mathcal{C}|}}\right). |  | (40) |

###### Proof Sketch.

The bound follows from standard importance sampling theory (Owen, [2013](https://arxiv.org/html/2602.06394v1#bib.bib109 "Monte carlo theory, methods and examples")). Under (A1), the difference |‚Ñí‚Äã(V;ùíÆ)‚àí‚Ñí‚Äã(V;ùíû)||\mathcal{L}(V;\mathcal{S})-\mathcal{L}(V;\mathcal{C})| is controlled by the distributional divergence between ùíÆ\mathcal{S} and ùíû\mathcal{C}. Importance sampling with weights wi‚àùVar‚Äã(qi)+œµbasew\_{i}\propto\text{Var}(q\_{i})+\epsilon\_{\text{base}} reduces this divergence by oversampling high-variance regions where tokenization quality matters most. By the effective sample size formula for importance sampling, the estimation error scales as O‚Äã(1/neff)O(1/\sqrt{n\_{\text{eff}}}), yielding the stated bound. The Lipschitz assumption (A1) ensures that optimization on ùíÆ\mathcal{S} transfers to ùíû\mathcal{C}.
‚àé

Massive-Scale Strategies (>100TB).

1. 1.

   Quality-stratified sampling (0.1‚Äì1%)
2. 2.

   Distributed PPO (8‚Äì32 GPUs)
3. 3.

   Online RL with replay for streams
4. 4.

   Memory-mapped frequency tables

Cost-Benefit.

* ‚Ä¢

  +5‚Äì30% task performance
* ‚Ä¢

  -15‚Äì20% token count (faster inference)
* ‚Ä¢

  One-time cost amortized across applications

### G.4 Foundation-Scale Results (Pathogen Detection, GUE)

Table 11: Pathogen Detection benchmark (MCC).

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Task | DNABERT-2 | DNABERT-S | NT-2.5b-Multi | NT-2.5b-1000g | METAGENE-1 | METAGENE-1 (QA-Token) |
| Pathogen-Detect (avg.) | 87.92 | 87.02 | 82.43 | 79.02 | 92.96 | 94.53 |
| Pathogen-Detect-1 | 86.73 | 85.43 | 83.80 | 77.52 | 92.14 | 93.81 |
| Pathogen-Detect-2 | 86.90 | 85.23 | 83.53 | 80.38 | 90.91 | 92.95 |
| Pathogen-Detect-3 | 88.30 | 89.01 | 82.48 | 79.83 | 93.70 | 95.12 |
| Pathogen-Detect-4 | 89.77 | 88.41 | 79.91 | 78.37 | 95.10 | 96.24 |




Table 12: Genome Understanding Evaluation (GUE). All metrics are MCC except COVID which uses F1.

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Task | CNN | HyenaDNA | DNABERT | NT-2.5B-Multi | DNABERT-2 | METAGENE-1 | METAGENE-1 (QA-Token) |
| TF-Mouse (AVG.) | 45.3 | 51.0 | 57.7 | 67.0 | 68.0 | 71.4 | 72.8 |
| 0 | 31.1 | 35.6 | 42.3 | 63.3 | 56.8 | 61.5 | 62.1 |
| 1 | 59.7 | 80.5 | 79.1 | 83.8 | 84.8 | 83.7 | 84.1 |
| 2 | 63.2 | 65.3 | 69.9 | 71.5 | 79.3 | 83.0 | 84.5 |
| 3 | 45.5 | 54.2 | 55.4 | 69.4 | 66.5 | 82.2 | 83.3 |
| 4 | 27.2 | 19.2 | 42.0 | 47.1 | 52.7 | 46.6 | 47.0 |
| TF-HUMAN (AVG.) | 50.7 | 56.0 | 64.4 | 62.6 | 70.1 | 68.3 | 69.9 |
| 0 | 54.0 | 62.3 | 68.0 | 66.6 | 72.0 | 68.9 | 70.2 |
| 1 | 63.2 | 67.9 | 70.9 | 66.6 | 76.1 | 70.8 | 72.0 |
| 2 | 45.2 | 46.9 | 60.5 | 58.7 | 66.5 | 65.9 | 66.8 |
| 3 | 29.8 | 41.8 | 53.0 | 51.7 | 58.5 | 58.1 | 59.0 |
| 4 | 61.5 | 61.2 | 69.8 | 69.3 | 77.4 | 77.9 | 78.5 |
| EMP (AVG.) | 37.6 | 44.9 | 49.5 | 58.1 | 56.0 | 66.0 | 67.5 |
| H3 | 61.5 | 67.2 | 74.2 | 78.8 | 78.3 | 80.2 | 81.0 |
| H3K14AC | 29.7 | 32.0 | 42.1 | 56.2 | 52.6 | 64.9 | 66.0 |
| H3K36ME3 | 38.6 | 48.3 | 48.5 | 62.0 | 56.9 | 66.7 | 67.8 |
| H3K4ME1 | 26.1 | 35.8 | 43.0 | 55.3 | 50.5 | 55.3 | 56.1 |
| H3K4ME2 | 25.8 | 25.8 | 31.3 | 36.5 | 31.1 | 51.2 | 52.3 |
| H3K4ME3 | 20.5 | 23.1 | 28.9 | 40.3 | 36.3 | 58.5 | 59.5 |
| H3K79ME3 | 46.3 | 54.1 | 60.1 | 64.7 | 67.4 | 73.0 | 74.1 |
| H3K9AC | 40.0 | 50.8 | 50.5 | 56.0 | 55.6 | 65.5 | 66.5 |
| H4 | 62.3 | 73.7 | 78.3 | 81.7 | 80.7 | 82.7 | 83.5 |
| H4AC | 25.5 | 38.4 | 38.6 | 49.1 | 50.4 | 61.7 | 62.8 |
| PD (AVG.) | 77.1 | 35.0 | 84.6 | 88.1 | 84.2 | 82.3 | 85.5 |
| ALL | 75.8 | 47.4 | 90.4 | 91.0 | 86.8 | 86.0 | 88.5 |
| NO-TATA | 85.1 | 52.2 | 93.6 | 94.0 | 94.3 | 93.7 | 94.5 |
| TATA | 70.3 | 5.3 | 69.8 | 79.4 | 71.6 | 67.4 | 73.5 |
| CPD (AVG.) | 62.5 | 48.4 | 73.0 | 71.6 | 70.5 | 69.9 | 71.2 |
| ALL | 58.1 | 37.0 | 70.9 | 70.3 | 69.4 | 66.4 | 68.0 |
| NO-TATA | 60.1 | 35.4 | 69.8 | 71.6 | 68.0 | 68.3 | 69.5 |
| TATA | 69.3 | 72.9 | 78.2 | 73.0 | 74.2 | 75.1 | 76.3 |
| SSD | 76.8 | 72.7 | 84.1 | 89.3 | 85.0 | 87.8 | 89.5 |
| COVID (F1) | 22.2 | 23.3 | 62.2 | 73.0 | 71.9 | 72.5 | 73.3 |
| GLOBAL WIN % | 0.0 | 0.0 | 7.1 | 21.4 | 25.0 | 46.4 | 57.1 |

### G.5 Ablation Studies and Additional Experiments

#### G.5.1 RL Algorithm Ablation

Table 13: Ablation across RL algorithms with training time (GPU-h), inference time (ms/seq), and vocabulary Jaccard similarity vs. PPO.

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
| Domain | Config (Metric) | Metric Value | Train Time (GPU-h) | Inference (ms/seq) | Vocab Jaccard |
| Genomics | QA-Token (PPO) | 0.891 | 34.0 | 10.2 | 1.00 |
|  | QA-Token (GRPO) | 0.890 | 32.5 | 10.3 | 0.98 |
|  | QA-Token (VAPO) | 0.892 | 31.8 | 10.2 | 0.97 |
|  | QA-Token (DAPO) | 0.889 | 34.2 | 10.4 | 0.98 |
| Finance | QA-Token (PPO) | 1.72 | 28.0 | 15.2 | 1.00 |
|  | QA-Token (GRPO) | 1.71 | 26.5 | 15.3 | 0.96 |
|  | QA-Token (VAPO) | 1.73 | 25.0 | 15.1 | 0.95 |
|  | QA-Token (DAPO) | 1.70 | 28.5 | 15.2 | 0.96 |
| Social | QA-Token (PPO) | 74.5 | 30.0 | 12.5 | 1.00 |
|  | QA-Token (GRPO) | 74.2 | 29.0 | 12.6 | 0.97 |
|  | QA-Token (VAPO) | 74.6 | 28.0 | 12.5 | 0.98 |
|  | QA-Token (DAPO) | 74.3 | 31.0 | 12.7 | 0.97 |

We assess the sensitivity of QA-Token to the choice of RL optimizer by replacing PPO with GRPO and VAPO (implementations following (Shao et al., [2024](https://arxiv.org/html/2602.06394v1#bib.bib87 "DeepSeekMath: pushing the limits of mathematical reasoning in open language models"); Yue and others, [2025](https://arxiv.org/html/2602.06394v1#bib.bib88 "Does reinforcement learning really incentivize reasoning capacity in LLMs beyond the base model?"))). Across domains, downstream performance is stable and vocabulary similarity remains high (Jaccard ‚â•\geq 0.95), confirming modularity of the framework.

### G.6 Data Curation Baseline: BPE on Clean Data vs. QA-Token on Noisy Data

A natural question is whether simply filtering to high-quality data and using standard BPE could match QA-Token‚Äôs performance. We evaluate this data curation baseline by training BPE on only the top 20% highest-quality sequences (average Phred score ‚â•30\geq 30) and comparing against QA-Token trained on the full noisy corpus.

Table 14: Data Curation Baseline Comparison (Genomics Variant Calling). QA-Token on noisy data outperforms BPE on curated clean data.

|  |  |  |  |
| --- | --- | --- | --- |
| Method | Training Data | Variant F1 | p-value |
| BPE (full corpus) | 100% (noisy) | 0.824¬±0.0040.824\pm 0.004 | <0.001<0.001 |
| BPE (top 20% clean) | 20% (Q‚â•\geq30) | 0.847¬±0.0050.847\pm 0.005 | <0.001<0.001 |
| QA-Token | 100% (noisy) | 0.891¬±0.004\mathbf{0.891\pm 0.004} | ‚Äî |

Key findings:

* ‚Ä¢

  Data curation (BPE on clean data) improves over BPE on full noisy data: +2.8%+2.8\% F1 (0.8470.847 vs 0.8240.824).
* ‚Ä¢

  However, QA-Token on the *full noisy corpus* outperforms BPE on clean data by +5.2%+5.2\% F1 (0.8910.891 vs 0.8470.847, p<0.001p<0.001).
* ‚Ä¢

  This demonstrates that quality-aware tokenization extracts more value from noisy data than discarding it entirely.

### G.7 Genomics: Real-World Datasets (ONT, UHGG)

Datasets: (i) GIAB HG002 long-read ONT data (high-error, third-generation); (ii) Unified Human Gut Genome (UHGG) collection (large-scale, low-error NGS).

Results: QA-BPE-seq consistently outperforms baselines across both regimes. ONT (high-error) results:

Table 15: ONT (GIAB HG002) results. Means with 95% confidence intervals over n=10n=10 runs.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Method | Variant F1 | Taxa Acc. F1 | Recon. Loss | Inf. Time (ms/seq) |
| Standard BPE | 0.795 ¬±\pm 0.006 | 0.812 ¬±\pm 0.007 | 0.388 ¬±\pm 0.012 | 11.5 ¬±\pm 0.3 |
| SentencePiece | 0.801 ¬±\pm 0.005 | 0.825 ¬±\pm 0.006 | 0.371 ¬±\pm 0.011 | 11.6 ¬±\pm 0.4 |
| WordPiece | 0.798 ¬±\pm 0.006 | 0.819 ¬±\pm 0.007 | 0.379 ¬±\pm 0.013 | 11.5 ¬±\pm 0.3 |
| DNABERT-k (6-mer) | 0.823 ¬±\pm 0.004 | 0.846 ¬±\pm 0.005 | 0.352 ¬±\pm 0.010 | 11.2 ¬±\pm 0.3 |
| QA-BPE-seq (100%) | 0.864 ¬±\pm 0.005 | 0.881 ¬±\pm 0.004 | 0.305 ¬±\pm 0.009 | 11.8 ¬±\pm 0.4 |
| *QA-BPE-seq (70%)* | 0.830 ¬±\pm 0.005 | 0.845 ¬±\pm 0.004 | 0.345 ¬±\pm 0.009 | 11.9 ¬±\pm 0.4 |
| *QA-BPE-seq (50%)* | 0.795 ¬±\pm 0.006 | 0.810 ¬±\pm 0.005 | 0.380 ¬±\pm 0.010 | 12.0 ¬±\pm 0.4 |
| *QA-BPE-seq (30%)* | 0.750 ¬±\pm 0.006 | 0.760 ¬±\pm 0.005 | 0.420 ¬±\pm 0.011 | 12.1 ¬±\pm 0.5 |

NGS (UHGG) results:

Table 16: UHGG (NGS) results. Means with 95% confidence intervals over n=10n=10 runs.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Method | Variant F1 | Taxa Acc. F1 | Recon. Loss | Inf. Time (ms/seq) |
| Standard BPE | 0.852 ¬±\pm 0.003 | 0.881 ¬±\pm 0.004 | 0.295 ¬±\pm 0.008 | 9.8 ¬±\pm 0.2 |
| SentencePiece | 0.860 ¬±\pm 0.003 | 0.893 ¬±\pm 0.004 | 0.280 ¬±\pm 0.007 | 9.9 ¬±\pm 0.2 |
| WordPiece | 0.855 ¬±\pm 0.004 | 0.887 ¬±\pm 0.005 | 0.286 ¬±\pm 0.009 | 9.8 ¬±\pm 0.3 |
| DNABERT-k (6-mer) | 0.875 ¬±\pm 0.002 | 0.908 ¬±\pm 0.003 | 0.264 ¬±\pm 0.006 | 9.5 ¬±\pm 0.2 |
| QA-BPE-seq (100%) | 0.915 ¬±\pm 0.003 | 0.935 ¬±\pm 0.003 | 0.221 ¬±\pm 0.005 | 10.1 ¬±\pm 0.3 |
| *QA-BPE-seq (70%)* | 0.878 ¬±\pm 0.004 | 0.898 ¬±\pm 0.004 | 0.250 ¬±\pm 0.007 | 10.2 ¬±\pm 0.3 |
| *QA-BPE-seq (50%)* | 0.842 ¬±\pm 0.005 | 0.860 ¬±\pm 0.005 | 0.276 ¬±\pm 0.008 | 10.3 ¬±\pm 0.3 |
| *QA-BPE-seq (30%)* | 0.790 ¬±\pm 0.006 | 0.805 ¬±\pm 0.006 | 0.310 ¬±\pm 0.009 | 10.5 ¬±\pm 0.4 |

### G.8 Finance: High-Frequency Equities (AAPL)

Dataset and Setup: High-frequency LOB data for AAPL from LOBSTER.

Results: QAT-QF scales to equities, improving predictive and trading metrics over baselines.

Table 17: AAPL high-frequency results. Means with 95% confidence intervals over n=10n=10 runs.

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
| Method | Ret. Pred. (%) | Vol. RMSE | Regime Acc. (%) | Sharpe | Inf. Time (ms/seq) |
| Standard BPE | 63.1 ¬±\pm 0.6 | 0.0125 ¬±\pm 0.0004 | 75.8 ¬±\pm 0.7 | 1.41 ¬±\pm 0.06 | 14.8 ¬±\pm 0.4 |
| SAX | 61.5 ¬±\pm 0.7 | 0.0121 ¬±\pm 0.0005 | 77.0 ¬±\pm 0.6 | 1.38 ¬±\pm 0.07 | 14.2 ¬±\pm 0.3 |
| BOSS | 64.0 ¬±\pm 0.5 | 0.0113 ¬±\pm 0.0004 | 80.1 ¬±\pm 0.5 | 1.53 ¬±\pm 0.06 | 14.5 ¬±\pm 0.4 |
| QAT-QF | 69.8 ¬±\pm 0.5 | 0.0085 ¬±\pm 0.0003 | 87.9 ¬±\pm 0.4 | 1.81 ¬±\pm 0.08 | 15.0 ¬±\pm 0.5 |

### G.9 Finance: Rolling-Window Temporal Robustness (BTC/USD, Full Year 2023)

To demonstrate temporal robustness beyond a single quarter, we extend our BTC/USD evaluation across all four quarters of 2023 using a strict rolling-window protocol. For each quarter, the vocabulary and downstream models are trained only on data preceding that quarter.

Table 18: Rolling-window out-of-sample Sharpe ratios for BTC/USD across 2023. Each quarter uses models trained strictly on preceding data. Means with 95% confidence intervals over n=10n=10 runs.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Quarter | QAT-QF Sharpe | BPE Sharpe | Œî\Delta (%) | Market Context |
| Q1 2023 | 1.72 ¬±\pm 0.07 | 1.32 ¬±\pm 0.05 | +30.3 | Recovery phase |
| Q2 2023 | 1.58 ¬±\pm 0.09 | 1.21 ¬±\pm 0.06 | +30.6 | Consolidation |
| Q3 2023 | 1.45 ¬±\pm 0.08 | 1.15 ¬±\pm 0.07 | +26.1 | High volatility |
| Q4 2023 | 1.68 ¬±\pm 0.10 | 1.29 ¬±\pm 0.06 | +30.2 | Bull market |
| Average | 1.61 | 1.24 | +29.8 | ‚Äî |

Key Observations: (i) QAT-QF maintains consistent improvements (+26‚Äì31%) across all market regimes. (ii) Q3 2023 exhibited elevated volatility (VIX-equivalent spike); QAT-QF gains persist (+26.1%), demonstrating cross-regime robustness. (iii) The consistency across four quarters with varying market conditions validates generalization beyond a single test period.

## Appendix H Domain-Specific Instantiations

We now detail the instantiation of the QA-Token framework for three distinct domains: genomic sequencing, social media text, and quantitative finance. Detailed pseudocode algorithms for each domain are provided in Section¬†[H.9](https://arxiv.org/html/2602.06394v1#A8.SS9 "H.9 Domain-Specific Algorithms ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

### H.1 Genomics (QA-BPE-seq)

Context: This instantiation targets the analysis of DNA or RNA sequencing reads, which are often affected by base-calling errors, for applications such as genetic variant calling, taxonomic classification, or sequence modeling.
Atomic Elements & Quality: The base alphabet is Œ£={A, C, G, T/U, N}\Sigma=\{\text{A, C, G, T/U, N}\}. The primary quality information for each atomic base sis\_{i} comes from Phred scores Qphred,iQ\_{\text{phred},i}. The error probability is Perror‚Äã(i)=10‚àíQphred,i/10P\_{\text{error}}(i)=10^{-Q\_{\text{phred},i}/10}, leading to an atomic quality score qi=1‚àíPerror‚Äã(i)q\_{i}=1-P\_{\text{error}}(i). To model read end quality degradation, for a base at position ii (0-indexed) in a read of length LL, the position-adjusted quality is:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qi‚Ä≤=qi‚ãÖexp‚Å°(‚àíŒ≤pos‚ãÖ|i‚àí(L‚àí1)/2|(L‚àí1)/2+œµl‚Äãe‚Äãn)q^{\prime}\_{i}=q\_{i}\cdot\exp\left(-\beta\_{\text{pos}}\cdot\frac{|i-(L-1)/2|}{(L-1)/2+\epsilon\_{len}}\right) |  | (41) |

where Œ≤pos‚â•0\beta\_{\text{pos}}\geq 0 is a learnable parameter in Œ∏adapt\theta\_{\text{adapt}}.
Token Quality (qtq\_{t}): For a token t=s1‚Äã‚Ä¶‚Äãs|t|t=s\_{1}...s\_{|t|}, we use the geometric mean of the position-adjusted atomic qualities to compute its aggregated scalar quality: qt=(‚àèj=1|t|qsj‚Ä≤)1/|t|q\_{t}=(\prod\_{j=1}^{|t|}q^{\prime}\_{s\_{j}})^{1/|t|}. The geometric mean is sensitive to low-quality bases. This qtq\_{t} is used for the constituent qualities qaq\_{a} and qbq\_{b} in the merge score (Eq. [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
Merge Score (wa‚Äãbw\_{ab}): The score is calculated using Equation [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), with the geometric mean qualities qa,qbq\_{a},q\_{b}, the learnable parameter Œ±‚ààŒ∏adapt\alpha\in\theta\_{\text{adapt}}, and œà‚Äã(a,b)=1\psi(a,b)=1.
Reward Components (RgenomicR\_{\text{genomic}}): The overall reward (Eq. [26](https://arxiv.org/html/2602.06394v1#A5.E26 "Equation 26 ‚Ä£ E.1.2 Reward Function Design ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) uses weights Œªj‚ààŒ∏adapt\lambda\_{j}\in\theta\_{\text{adapt}}. Specific raw components RrawR^{\text{raw}} include:

* ‚Ä¢

  RQraw‚Äã(a,b)R^{\text{raw}}\_{Q}(a,b): Quality of the newly formed token ta‚Äãbt\_{ab}. This is its geometric mean quality: RQraw‚Äã(a,b)=qa‚Äãb=(‚àèl=1|a|+|b|qsa‚Äãb,l‚Ä≤)1/(|a|+|b|)R^{\text{raw}}\_{Q}(a,b)=q\_{ab}=(\prod\_{l=1}^{|a|+|b|}q^{\prime}\_{s\_{ab,l}})^{1/(|a|+|b|)}.
* ‚Ä¢

  RIraw‚Äã(a,b)R^{\text{raw}}\_{I}(a,b): Log-ratio of probabilities: RIraw‚Äã(a,b)=log‚Å°P‚Äã(ta‚Äãb)P‚Äã(a)‚ÄãP‚Äã(b)+œµpR^{\text{raw}}\_{I}(a,b)=\log\frac{P(t\_{ab})}{P(a)P(b)+\epsilon\_{p}}.
* ‚Ä¢

  RCraw‚Äã(a,b)R^{\text{raw}}\_{C}(a,b): Complexity penalty: RCraw‚Äã(a,b)=‚àí|ta‚Äãb|R^{\text{raw}}\_{C}(a,b)=-|t\_{ab}|.
* ‚Ä¢

  Rb‚Äãi‚ÄãorawR^{\text{raw}}\_{bio} (Optional): A domain-specific reward based on overlap with known genomic features (e.g., genes, regulatory elements from databases like dbSNP (Sherry et al., [2001](https://arxiv.org/html/2602.06394v1#bib.bib46 "DbSNP: the ncbi database of genetic variation"))).

Raw components are normalized using the adaptive EMA method (Eq. [35](https://arxiv.org/html/2602.06394v1#A5.E35 "Equation 35 ‚Ä£ E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
Adaptive Parameters (Œ∏adapt\theta\_{\text{adapt}}): Includes Œ±\alpha, Œ≤pos\beta\_{\text{pos}}, reward weights Œªj\lambda\_{j}, and potentially parameters for soft frequency/quality gating.
Algorithm: The two-stage learning process (Section [E](https://arxiv.org/html/2602.06394v1#A5 "Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) is applied. An RL policy is optimized (Algorithm [1](https://arxiv.org/html/2602.06394v1#alg1 "Algorithm 1 ‚Ä£ E.1.3 PPO Training Algorithm ‚Ä£ E.1 Stage 1: Reinforcement Learning Policy Optimization ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), and then the adaptive parameters Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt} are learned (Algorithm [2](https://arxiv.org/html/2602.06394v1#alg2 "Algorithm 2 ‚Ä£ E.2.2 Gumbel-Softmax Differentiable Optimization ‚Ä£ E.2 Stage 2: Adaptive Parameter Learning ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) by optimizing a downstream task objective.

### H.2 Quantitative Finance (QAT-QF)

Context: This instantiation focuses on analyzing noisy, non-stationary high-frequency financial data for tasks like forecasting price movements or developing trading strategies.
Atomic Elements & Quality: Atomic elements sis\_{i} are discretized events from high-frequency data (e.g., fixed-length segments of LOB events). Each atomic element sis\_{i} is assigned a scalar quality score qi=‚àëkwk‚Äãqk,iq\_{i}=\sum\_{k}w\_{k}q\_{k,i}, where qk,iq\_{k,i} are normalized quality components (e.g., qsnr,qliqq\_{\text{snr}},q\_{\text{liq}}) and wkw\_{k} are learnable weights in Œ∏adapt\theta\_{\text{adapt}}.
Token Quality (qtq\_{t}): For a token tt composed of atomic elements {si}i‚ààt\{s\_{i}\}\_{i\in t}, the aggregated scalar quality is the arithmetic mean: qt=1|t|‚Äã‚àëi‚ààtqiq\_{t}=\frac{1}{|t|}\sum\_{i\in t}q\_{i}. This is used for qa,qbq\_{a},q\_{b} in the merge score.
Merge Score (wa‚Äãbw\_{ab}): Calculated using Equation [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), with qa,qbq\_{a},q\_{b}, learnable Œ±‚ààŒ∏adapt\alpha\in\theta\_{\text{adapt}}, and œà‚Äã(a,b)=1\psi(a,b)=1.
Market Regimes: An identified regime indicator can condition the RL policy and reward components.
Reward Components (RfinanceR\_{\text{finance}}): Raw components RrawR^{\text{raw}} are normalized using the adaptive EMA method.

* ‚Ä¢

  RQraw‚Äã(a,b)R^{\text{raw}}\_{Q}(a,b): Length-weighted average quality: RQraw‚Äã(a,b)=|a|‚Äãqa+|b|‚Äãqb|a|+|b|R^{\text{raw}}\_{Q}(a,b)=\frac{|a|q\_{a}+|b|q\_{b}}{|a|+|b|}.
* ‚Ä¢

  RIraw‚Äã(a,b)R^{\text{raw}}\_{I}(a,b): Information reward blended across regimes: RIraw‚Äã(a,b)=Œ≥regime‚ãÖInormal‚Äã(a,b)+(1‚àíŒ≥regime)‚ãÖIstress‚Äã(a,b)R^{\text{raw}}\_{I}(a,b)=\gamma\_{\text{regime}}\cdot I\_{\text{normal}}(a,b)+(1-\gamma\_{\text{regime}})\cdot I\_{\text{stress}}(a,b), where Iregime=log‚Å°P‚Äã(ta‚Äãb|regime)P‚Äã(a|regime)‚ÄãP‚Äã(b|regime)+œµpI\_{\text{regime}}=\log\frac{P(t\_{ab}|\text{regime})}{P(a|\text{regime})P(b|\text{regime})+\epsilon\_{p}}. The blending factor Œ≥regime\gamma\_{\text{regime}} is a learnable parameter in Œ∏adapt\theta\_{\text{adapt}}.
* ‚Ä¢

  RPraw‚Äã(a,b)R^{\text{raw}}\_{P}(a,b): Predictive Power (Mutual Information with future returns):

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RPraw‚Äã(a,b)=MI‚Äã(ta‚Äãb,Disc‚Äã(RœÑ))NormFactorM‚ÄãI+œµM‚ÄãIR^{\text{raw}}\_{P}(a,b)=\frac{\text{MI}(t\_{ab},\text{Disc}(R\_{\tau}))}{\text{NormFactor}\_{MI}+\epsilon\_{MI}} |  | (42) |

  Disc‚Äã(RœÑ)\text{Disc}(R\_{\tau}) is discretized future return. NormFactorM‚ÄãI\text{NormFactor}\_{MI} is an adaptive normalization factor.
* ‚Ä¢

  RCraw‚Äã(a,b)R^{\text{raw}}\_{C}(a,b): Complexity penalty with volatility scaling:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RCraw‚Äã(a,b)=‚àí(|ta‚Äãb|‚ãÖlog‚Å°(|Vk|+1)‚ãÖVolScale)R^{\text{raw}}\_{C}(a,b)=-\left(|t\_{ab}|\cdot\log(|V\_{k}|+1)\cdot\text{VolScale}\right) |  | (43) |

  where VolScale depends on a learnable parameter Œ≤vol‚ààŒ∏adapt\beta\_{\text{vol}}\in\theta\_{\text{adapt}}.

Adaptive Parameters (Œ∏adapt\theta\_{\text{adapt}}): Includes Œ±\alpha, quality component weights wkw\_{k}, Œ≤vol\beta\_{\text{vol}}, Œ≥regime\gamma\_{\text{regime}}, and reward weights Œªj\lambda\_{j}.
Algorithm: The two-stage learning process is applied as in the genomics domain.

### H.3 Social Media Text (QA-BPE-nlp)

Context: This instantiation addresses the challenges of processing noisy user-generated text for tasks such as sentiment analysis or NER.
Atomic Elements & Quality: The base alphabet consists of characters. Quality for a token tt is modeled using a multi-dimensional vector ùíít=(qorth‚Äã(t),qsem‚Äã(t),‚Ä¶)\bm{q}\_{t}=(q\_{\text{orth}}(t),q\_{\text{sem}}(t),\dots) detailed in Appendix [D.3](https://arxiv.org/html/2602.06394v1#A4.SS3 "D.3 Social Media: Linguistic Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"). The aggregated scalar quality is qt=‚àëjwj‚Äãùíít,jq\_{t}=\sum\_{j}w\_{j}\bm{q}\_{t,j}, where wj‚â•0w\_{j}\geq 0 are learnable weights in Œ∏adapt\theta\_{\text{adapt}}.
Token Quality (qtq\_{t}): The aggregated score qtq\_{t} is used for qa,qbq\_{a},q\_{b} in the merge score.
Merge Score (wa‚Äãbw\_{ab}): Calculated using Equation [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") with qa,qbq\_{a},q\_{b}, learnable Œ±‚ààŒ∏adapt\alpha\in\theta\_{\text{adapt}}, and a semantic compatibility factor œà‚Äã(a,b)\psi(a,b):

|  |  |  |  |
| --- | --- | --- | --- |
|  | œà‚Äã(a,b)=exp‚Å°(Œ≤s‚Äãe‚Äãm‚ãÖcosine‚Äã(ùíóa,ùíób))\psi(a,b)=\exp(\beta\_{sem}\cdot\text{cosine}(\bm{v}\_{a},\bm{v}\_{b})) |  | (44) |

where ùíóa,ùíób\bm{v}\_{a},\bm{v}\_{b} are pre-trained embeddings and Œ≤s‚Äãe‚Äãm‚â•0\beta\_{sem}\geq 0 is a learnable parameter in Œ∏adapt\theta\_{\text{adapt}}.
Noise Models: Probabilistic models P‚Äã(t‚Ä≤|t)P(t^{\prime}|t) capturing likely variations inform the noise robustness reward RNR\_{N}.
Reward Components (RsocialR\_{\text{social}}): Raw components are normalized before being weighted by Œªj\lambda\_{j}.

* ‚Ä¢

  RQraw‚Äã(a,b)R^{\text{raw}}\_{Q}(a,b): Blend of compositional and direct quality: RQraw‚Äã(a,b)=œâ‚Äã|a|‚Äãqa+|b|‚Äãqb|a|+|b|+(1‚àíœâ)‚Äãqa‚ÄãbR^{\text{raw}}\_{Q}(a,b)=\omega\frac{|a|q\_{a}+|b|q\_{b}}{|a|+|b|}+(1-\omega)q\_{ab}, with learnable blending weight œâ‚àà[0,1]\omega\in[0,1].
* ‚Ä¢

  RSraw‚Äã(a,b)R^{\text{raw}}\_{S}(a,b): Semantic Coherence: PMI‚Äã(a,b)‚ãÖcosine\_similarity‚Äã(ùíóa,ùíób)\text{PMI}(a,b)\cdot\text{cosine\\_similarity}(\bm{v}\_{a},\bm{v}\_{b}).
* ‚Ä¢

  RNraw‚Äã(a,b)R^{\text{raw}}\_{N}(a,b): Noise Robustness: Rnoise‚Äã(ta‚Äãb)‚àí|a|‚ÄãRnoise‚Äã(a)+|b|‚ÄãRnoise‚Äã(b)|a|+|b|R\_{\text{noise}}(t\_{ab})-\frac{|a|R\_{\text{noise}}(a)+|b|R\_{\text{noise}}(b)}{|a|+|b|}, based on the noise model.
* ‚Ä¢

  RCraw‚Äã(a,b)R^{\text{raw}}\_{C}(a,b): Complexity penalty: RCraw‚Äã(a,b)=‚àí|ta‚Äãb|R^{\text{raw}}\_{C}(a,b)=-|t\_{ab}|.
* ‚Ä¢

  RVraw‚Äã(a,b)R^{\text{raw}}\_{V}(a,b): Vocabulary Efficiency: log‚Å°(1+f‚Äã(ta‚Äãb))|ta‚Äãb|\frac{\log(1+f(t\_{ab}))}{|t\_{ab}|}.

Adaptive Parameters (Œ∏adapt\theta\_{\text{adapt}}): Includes Œ±,Œ≤s‚Äãe‚Äãm\alpha,\beta\_{sem}, quality dimension weights wjw\_{j}, reward weights Œªj\lambda\_{j}, and the blending weight œâ\omega.
Algorithm: The two-stage learning process is applied as in the other domains.

### H.4 Financial Experimental Methodology Details

All trading simulations and return prediction evaluations for the quantitative finance domain (Section [5.2](https://arxiv.org/html/2602.06394v1#S5.SS2 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) were conducted with rigorous attention to backtesting best practices to ensure the validity of results and avoid common pitfalls.

* ‚Ä¢

  Walk-Forward Validation: A strict walk-forward validation scheme was employed. The dataset was divided into chronological segments. For each segment kk, the model (including the QA-Token vocabulary construction and downstream predictive/trading model) was trained on data up to the start of segment kk, validated on segment k‚àí1k-1 (or a dedicated validation portion of the training data), and then tested out-of-sample only on segment kk. The training window was then rolled forward to include segment kk for training before testing on segment k+1k+1. This process ensures that the model is always tested on data not seen during its training or hyperparameter tuning phases for that specific test period.
* ‚Ä¢

  Lookahead Bias Prevention: Extreme care was taken to prevent any form of lookahead bias. All features, quality scores, token definitions, and trading decisions at any time tt were based strictly on information available up to and including time t‚àí1t-1. Future return labels (Rt+œÑR\_{t+\tau}) used for training predictive models or as part of the RPR\_{P} reward component were sourced from periods strictly after the information used for input features and token construction.
* ‚Ä¢

  Test Set and Data Splitting: The overall dataset (BTC/USD LOB data, Q1 2023) was split chronologically: 70% for the initial training pool, 15% for validation (used for hyperparameter tuning of downstream models and early stopping), and the final 15% (approximately 2 weeks of 1-minute data) as the ultimate out-of-sample test set for reporting final performance metrics like Sharpe Ratio and prediction accuracy. This test set was held out and used only once after all model development and tuning.
* ‚Ä¢

  Transaction Costs: A realistic transaction cost of 5 basis points (0.05%) per trade was applied to simulate market friction. This cost was deducted for both buying and selling actions in the trading simulations.
* ‚Ä¢

  PPO Trading Agent Details: The PPO-based trading agent used a 2-layer MLP policy network and a separate 2-layer MLP value network, each with 128 hidden units and ReLU activation functions. The input to these networks consisted of a sequence of recent token embeddings (generated by QAT-QF or baseline tokenizers from the LOB data) and the agent‚Äôs current market position (long, short, or flat). The agent‚Äôs action space was discrete (buy, sell, hold). The reward function for the PPO agent was the realized profit and loss (PnL) from its trades over a short horizon, adjusted for transaction costs. Standard PPO hyperparameters were used, including a clipping parameter œµ=0.2\epsilon=0.2, GAE Œª=0.95\lambda=0.95, and an entropy bonus for exploration. The PPO agent was re-trained periodically within the walk-forward scheme.
* ‚Ä¢

  Details for RPrawR^{\text{raw}}\_{P} Reward (Eq. [42](https://arxiv.org/html/2602.06394v1#A8.E42 "Equation 42 ‚Ä£ 3rd item ‚Ä£ H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): The parameter MM‚ÄãIM\_{MI} (window for NormFactorM‚ÄãI\text{NormFactor}\_{MI}) was set to 1000 merge steps in our experiments. The future return RœÑR\_{\tau} was for œÑ=5\tau=5 minutes ahead and discretized into 3 bins (negative, neutral, positive) based on empirical quantiles from the training data.

### H.5 Detailed Reward Components

The general structure of the reward R‚Äã(a,b)R(a,b) for merging tokens aa and bb into tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd=a||bt\_{merged}=a||b is:
R‚Äã(a,b)=‚àëjŒªj‚ÄãR^j‚Äã(a,b)R(a,b)=\sum\_{j}\lambda\_{j}\hat{R}\_{j}(a,b), where R^j\hat{R}\_{j} are adaptively normalized components (see Section [4.2](https://arxiv.org/html/2602.06394v1#S4.SS2 "4.2 Reward Function Design ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). The weights Œªj‚â•0\lambda\_{j}\geq 0 (parameterized via ùú∑Œªj\bm{\beta}\_{\lambda\_{j}} and softmax) are part of Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}.

### H.6 Common Components

* ‚Ä¢

  RQraw‚Äã(a,b)R^{\text{raw}}\_{Q}(a,b): Raw Quality reward. This component incentivizes merges that result in high-quality tokens. A common formulation for the raw component is the length-weighted arithmetic mean of the qualities of the constituent tokens aa and bb:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RQraw‚Äã(a,b)=|a|‚Äãqa+|b|‚Äãqb|a|+|b|R^{\text{raw}}\_{Q}(a,b)=\frac{|a|q\_{a}+|b|q\_{b}}{|a|+|b|} |  | (45) |

  where qa,qbq\_{a},q\_{b} are the quality scores of tokens a,ba,b respectively, and |a|,|b||a|,|b| are their lengths.
  For Social Media, a blended approach might be used for RQraw‚Äã(a,b)R^{\text{raw}}\_{Q}(a,b):

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RQraw(a,b)=œâ(|a|‚ÄãQa‚Äãg‚Äãg‚Äã(a)+|b|‚ÄãQa‚Äãg‚Äãg‚Äã(b)|a|+|b|)+(1‚àíœâ)Qa‚Äãg‚Äãg(a||b)R^{\text{raw}}\_{Q}(a,b)=\omega\left(\frac{|a|Q\_{agg}(a)+|b|Q\_{agg}(b)}{|a|+|b|}\right)+(1-\omega)Q\_{agg}(a||b) |  | (46) |

  where Qa‚Äãg‚Äãg‚Äã(t)Q\_{agg}(t) is the aggregate quality score for token tt (from Section [D.3](https://arxiv.org/html/2602.06394v1#A4.SS3 "D.3 Social Media: Linguistic Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) and œâ‚àà[0,1]\omega\in[0,1] is a learnable blending weight in Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}.
* ‚Ä¢

  RIraw‚Äã(a,b)R^{\text{raw}}\_{I}(a,b): Raw Information gain. This rewards merges that are statistically significant. A common formulation:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RIraw‚Äã(a,b)=log‚Å°f‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd)f‚Äã(a)‚Äãf‚Äã(b)+œµfR^{\text{raw}}\_{I}(a,b)=\log\frac{f(t\_{merged})}{f(a)f(b)+\epsilon\_{f}} |  | (47) |

  where f‚Äã(‚ãÖ)f(\cdot) denotes frequency and œµf>0\epsilon\_{f}>0 (e.g., 10‚àí810^{-8}) is for stability.
  For Finance, this can be blended based on market regime: RIraw‚Äã(a,b)=Œ≥regime‚ÄãInormal+(1‚àíŒ≥regime)‚ÄãIstressR^{\text{raw}}\_{I}(a,b)=\gamma\_{\text{regime}}I\_{\text{normal}}+(1-\gamma\_{\text{regime}})I\_{\text{stress}}, where Iregime=log‚Å°f‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd|M=regime)f‚Äã(a|M=regime)‚Äãf‚Äã(b|M=regime)+œµfI\_{\text{regime}}=\log\frac{f(t\_{merged}|M=\text{regime})}{f(a|M=\text{regime})f(b|M=\text{regime})+\epsilon\_{f}}. Œ≥regime‚àà[0,1]\gamma\_{\text{regime}}\in[0,1] is a learnable parameter in Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}.
* ‚Ä¢

  RCraw‚Äã(a,b)R^{\text{raw}}\_{C}(a,b): Raw Complexity penalty. This penalizes overly complex vocabularies and is typically negative. A common formulation:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | RCraw‚Äã(a,b)=‚àílen‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd)‚ãÖlog‚Å°(|Vt|+1)‚ãÖ[ScalingFactor]R^{\text{raw}}\_{C}(a,b)=-\text{len}(t\_{merged})\cdot\log(|V\_{t}|+1)\cdot[\text{ScalingFactor}] |  | (48) |

  For Finance, the ScalingFactor can incorporate market volatility using Œ≤v‚Äão‚Äãl‚ààŒ∏a‚Äãd‚Äãa‚Äãp‚Äãt\beta\_{vol}\in\theta\_{adapt} as per Equation [43](https://arxiv.org/html/2602.06394v1#A8.E43 "Equation 43 ‚Ä£ 4th item ‚Ä£ H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

### H.7 Domain-Specific Components

* ‚Ä¢

  Genomics: Rb‚Äãi‚Äãoraw‚Äã(a,b)=ScoreOverlap‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd,KnownBiologicalFeatures)R^{\text{raw}}\_{bio}(a,b)=\text{Score}\_{\text{Overlap}}(t\_{merged},\text{KnownBiologicalFeatures}). A positive reward if tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãdt\_{merged} significantly overlaps with known biological features (e.g., genes from GENCODE (Harrow et al., [2012](https://arxiv.org/html/2602.06394v1#bib.bib77 "GENCODE: the reference human genome annotation for the encode project")), variants from dbSNP (Sherry et al., [2001](https://arxiv.org/html/2602.06394v1#bib.bib46 "DbSNP: the ncbi database of genetic variation"))). The overlap score was calculated as the Jaccard index between the character span of the merged token tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãdt\_{merged} and the character span of known genomic features. A higher Jaccard index, indicating greater overlap, results in a higher reward.
* ‚Ä¢

  Finance:

  + ‚Äì

    RPraw‚Äã(a,b)R^{\text{raw}}\_{P}(a,b): Predictive Power:

    |  |  |  |  |
    | --- | --- | --- | --- |
    |  | RPraw‚Äã(a,b)=MI‚Äã(tmerged;Disc‚Äã(RœÑ))NormFactorM‚ÄãI+œµM‚ÄãIR^{\text{raw}}\_{P}(a,b)=\frac{\text{MI}(t\_{\text{merged}};\text{Disc}(R\_{\tau}))}{\text{NormFactor}\_{MI}+\epsilon\_{MI}} |  | (49) |

    Uses Mutual Information (MI) MI‚Äã(X;Y)=‚àëx‚ààX,y‚ààYp‚Äã(x,y)‚Äãlog‚Å°p‚Äã(x,y)p‚Äã(x)‚Äãp‚Äã(y)\text{MI}(X;Y)=\sum\_{x\in X,y\in Y}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}. RœÑR\_{\tau} is the discretized future return (e.g., 3 bins for œÑ=5\tau=5 min based on empirical quantiles from the training data). NormFactorM‚ÄãI\text{NormFactor}\_{MI} is the adaptively calculated 95th percentile of MI values from candidate pairs over the last MM‚ÄãIM\_{MI} (e.g., 1000) merge steps within the current RL episode. œµM‚ÄãI>0\epsilon\_{MI}>0 (e.g., 10‚àí810^{-8}). While this adaptive normalization of MI introduces a degree of non-stationarity to the RPR\_{P} reward component within an RL episode, it was found that standard PPO training handled this adequately. The responsiveness of the reward to the informativeness of newly forming tokens was deemed beneficial, and the MM‚ÄãIM\_{MI} window provides some smoothing. Alternatives using a fixed normalization factor (e.g., derived from an initial global scan of MI values) were found to be less responsive to the changing characteristics of tokens as the vocabulary evolved during the RL episode.
* ‚Ä¢

  Social Media:

  + ‚Äì

    RSraw‚Äã(a,b)R^{\text{raw}}\_{S}(a,b): Semantic Coherence: PMI‚Äã(a,b)‚ãÖcosine\_similarity‚Äã(ùíóa,ùíób)\text{PMI}(a,b)\cdot\text{cosine\\_similarity}(\bm{v}\_{a},\bm{v}\_{b}). Pre-trained embeddings ùíóa,ùíób\bm{v}\_{a},\bm{v}\_{b} (e.g., fastText (Bojanowski et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib62 "Enriching word vectors with subword information"))).
  + ‚Äì

    RNraw‚Äã(a,b)R^{\text{raw}}\_{N}(a,b): Noise Robustness:

    |  |  |  |  |
    | --- | --- | --- | --- |
    |  | (Rnoise‚Äã(tmerged)‚àí|a|‚ÄãRnoise‚Äã(a)+|b|‚ÄãRnoise‚Äã(b)|a|+|b|),\left(R\_{\text{noise}}(t\_{\text{merged}})-\frac{|a|R\_{\text{noise}}(a)+|b|R\_{\text{noise}}(b)}{|a|+|b|}\right), |  | (50) |

    where Rn‚Äão‚Äãi‚Äãs‚Äãe‚Äã(t)=1‚àíùîºt‚Ä≤‚àºP(‚ãÖ|t)‚Äã[normalized\_edit\_distance‚Äã(t,t‚Ä≤)]R\_{noise}(t)=1-\mathbb{E}\_{t^{\prime}\sim P(\cdot|t)}[\text{normalized\\_edit\\_distance}(t,t^{\prime})] based on noise model P‚Äã(t‚Ä≤|t)P(t^{\prime}|t) (Appendix [H.8](https://arxiv.org/html/2602.06394v1#A8.SS8 "H.8 Further Details on Social Media Noise Models ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
  + ‚Äì

    RVraw‚Äã(a,b)R^{\text{raw}}\_{V}(a,b): Vocabulary Efficiency: log‚Å°(1+f‚Äã(tmerged))|tmerged|\frac{\log(1+f(t\_{\text{merged}}))}{|t\_{\text{merged}}|}.

### H.8 Further Details on Social Media Noise Models

Formalizing linguistic noise for social media text involves defining probabilistic transformations P‚Äã(t‚Ä≤|t)P(t^{\prime}|t) from a canonical form tt to an observed variant t‚Ä≤t^{\prime} (Han et al., [2013](https://arxiv.org/html/2602.06394v1#bib.bib18 "Lexical normalisation of short text messages: makn sens a #twitter")). These models inform the noise robustness measure Rnoise‚Äã(t)R\_{\text{noise}}(t) (defined in Appendix [H.5](https://arxiv.org/html/2602.06394v1#A8.SS5 "H.5 Detailed Reward Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), Eq. [50](https://arxiv.org/html/2602.06394v1#A8.E50 "Equation 50 ‚Ä£ 2nd item ‚Ä£ 3rd item ‚Ä£ H.7 Domain-Specific Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")). P‚Äã(t‚Ä≤|t)P(t^{\prime}|t) was constructed based on heuristic rules derived from commonly observed error patterns in social media text and principles outlined in existing literature on noisy text processing. The specific noise types modeled include:

* ‚Ä¢

  Character-Level Noise:

  + ‚Äì

    Repetition: Probability of a character cc being realized as cnc^{n} (a sequence of nn identical characters). For n‚â•1n\geq 1, this can be modeled using a geometric-like distribution. If ps‚Äãt‚Äão‚Äãpp\_{stop} is the probability of not repeating an additional time:
    P‚Äã(c‚Üícn)=(1‚àíps‚Äãt‚Äão‚Äãp)n‚àí1‚ãÖps‚Äãt‚Äão‚ÄãpP(c\to c^{n})=(1-p\_{stop})^{n-1}\cdot p\_{stop}. The parameter ps‚Äãt‚Äão‚Äãpp\_{stop} was set empirically to 0.50.5, allowing for moderate repetitions common in social media (e.g., "soooo goood").
  + ‚Äì

    Substitution: P‚Äã(ci‚Üícj)=Msub‚Äã[ci,cj]P(c\_{i}\to c\_{j})=M\_{\text{sub}}[c\_{i},c\_{j}], where MsubM\_{\text{sub}} is a confusion matrix. MsubM\_{\text{sub}} was constructed heuristically, assigning higher probabilities to substitutions between characters that are adjacent on a standard QWERTY keyboard layout and to common phonetic misspellings (e.g., ‚Äôc‚Äô vs ‚Äôk‚Äô). Off-diagonal probabilities were generally small.
  + ‚Äì

    Omission (Deletion): P‚Äã(c‚Üíœµ)=pdel‚Äã(c)P(c\to\epsilon)=p\_{\text{del}}(c) is the character-specific deletion probability. This was set to a small uniform value (e.g., pdel‚Äã(c)=0.01p\_{\text{del}}(c)=0.01) for all characters, reflecting occasional accidental omissions.
* ‚Ä¢

  Word-Level Noise:

  + ‚Äì

    Abbreviation: P‚Äã(w‚Üíabbr‚Äã(w))=fabbr‚Äã(w‚Üíabbr‚Äã(w))P(w\to\text{abbr}(w))=f\_{\text{abbr}}(w\to\text{abbr}(w)). This probability was derived from a compiled dictionary of common internet slang and abbreviations sourced from publicly available online linguistic resources. For words in this dictionary, fabbrf\_{\text{abbr}} was set to a moderate value (e.g., 0.3), and zero otherwise.
  + ‚Äì

    Phonetic Substitution: P‚Äã(w1‚Üíw2)‚àùexp‚Å°(Œªphon‚ãÖphon\_sim‚Äã(w1,w2))P(w\_{1}\to w\_{2})\propto\exp(\lambda\_{\text{phon}}\cdot\text{phon\\_sim}(w\_{1},w\_{2})). The phonetic similarity phon\_sim‚Äã(w1,w2)\text{phon\\_sim}(w\_{1},w\_{2}) was computed using the Double Metaphone algorithm. The scaling factor Œªphon\lambda\_{\text{phon}} was set to 1.01.0.
* ‚Ä¢

  Discourse-Level Noise (examples): For the experiments reported in this paper, the noise modeling primarily focused on character-level and word-level phenomena, as these are highly prevalent and tractable to model. Explicit modeling of discourse-level noise, such as code-switching or complex punctuation patterns, was considered beyond the scope of the current noise component RNR\_{N}, though it represents an interesting avenue for future work.

These probabilistic models are used to define P‚Äã(t‚Ä≤|t)P(t^{\prime}|t), which is then used to compute the expected distance in the noise robustness measure Rnoise‚Äã(t)=1‚àíùîºt‚Ä≤‚àºP(‚ãÖ|t)‚Äã[distnorm‚Äã(t,t‚Ä≤)]R\_{\text{noise}}(t)=1-\mathbb{E}\_{t^{\prime}\sim P(\cdot|t)}[\text{dist}\_{\text{norm}}(t,t^{\prime})]. The normalized distance metric distnorm‚Äã(t,t‚Ä≤)\text{dist}\_{\text{norm}}(t,t^{\prime}) used was the Levenshtein distance divided by the maximum length of the two strings tt and t‚Ä≤t^{\prime}.

### H.9 Domain-Specific Algorithms

This section provides detailed pseudocode for the QA-Token framework as instantiated for Quantitative Finance, Genomics, and Social Media. These algorithms complement the domain instantiations described in Section¬†[H](https://arxiv.org/html/2602.06394v1#A8 "Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), illustrating the core mechanics within each domain.

#### H.9.1 Quantitative Finance (QAT-QF)

Algorithm 7  Quality-Aware Tokenization Merge Score and Reward Calculation (QAT-TOKEN - Finance)

0:‚ÄÇCurrent vocabulary VtV\_{t}, corpus statistics (frequencies f‚Äã(‚ãÖ)f(\cdot)), current adaptive parameters Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt={Œ±,Œ≤v‚Äão‚Äãl,Œ≥regime,fm‚Äãi‚Äãn,Œ¥gate,wk¬†(param by¬†ùú∑w)}\theta\_{adapt}=\{\alpha,\beta\_{vol},\gamma\_{\text{regime}},f\_{min},\delta\_{\text{gate}},w\_{k}\text{ (param by }\bm{\beta}\_{w})\}, reward weights ŒªQ,ŒªI,ŒªP,ŒªC\lambda\_{Q},\lambda\_{I},\lambda\_{P},\lambda\_{C}.

0:‚ÄÇFor each candidate merge pair (a,b)(a,b): quality-aware merge score wa‚Äãbw\_{ab}, total immediate reward R‚Äã(a,b)R(a,b).

1:‚ÄÇIdentify candidate merge pairs CtC\_{t} from corpus (e.g., from priority queue P‚ÄãQtPQ\_{t}).

2:‚ÄÇfor each adjacent token pair (a,b)‚ààCt(a,b)\in C\_{t} do

3:‚ÄÉ‚ÄÇLet tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd‚Üêa||bt\_{merged}\leftarrow a||b.

4:‚ÄÉ‚ÄÇRetrieve/compute frequencies f‚Äã(a)f(a), f‚Äã(b)f(b), and f‚Äã(a,b)f(a,b).

5:‚ÄÉ‚ÄÇRetrieve/compute average qualities qa,qbq\_{a},q\_{b} (using Q‚Äã[i]Q[i] from Section [D.2](https://arxiv.org/html/2602.06394v1#A4.SS2 "D.2 Finance: Comprehensive Market Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), aggregated for tokens a,ba,b, and weights wk=softmax‚Äã(ùú∑w)kw\_{k}=\text{softmax}(\bm{\beta}\_{w})\_{k}).

6:‚ÄÉ‚ÄÇQuality-Aware Merge Score (wa‚Äãbw\_{ab}):
wa‚Äãb‚Üêf‚Äã(a,b)f‚Äã(a)‚ãÖf‚Äã(b)+œµf‚ãÖ((qa+qb2+œµQ)Œ±)‚ãÖœà‚Äã(a,b)w\_{ab}\leftarrow\frac{f(a,b)}{f(a)\cdot f(b)+\epsilon\_{f}}\cdot\left(\left(\frac{q\_{a}+q\_{b}}{2}+\epsilon\_{Q}\right)^{\alpha}\right)\cdot\psi(a,b) // œà‚Äã(a,b)=1\psi(a,b)=1 for finance

7:‚ÄÉ‚ÄÇFrequency Gating (Optional): // Frequency gating not used in final experiments
f~‚Äã(a,b)‚Üêf‚Äã(a,b)\tilde{f}(a,b)\leftarrow f(a,b).

8:‚ÄÉ‚ÄÇRQraw‚Äã(a,b)‚Üê|a|‚ãÖqa+|b|‚ãÖqb|a|+|b|R^{\text{raw}}\_{Q}(a,b)\leftarrow\frac{|a|\cdot q\_{a}+|b|\cdot q\_{b}}{|a|+|b|}.

9:‚ÄÉ‚ÄÇEstimate In‚Äão‚Äãr‚Äãm‚Äãa‚Äãl,Is‚Äãt‚Äãr‚Äãe‚Äãs‚ÄãsI\_{normal},I\_{stress} based on regime-conditioned f~‚Äã(a,b)\tilde{f}(a,b).
RIraw‚Äã(a,b)‚ÜêŒ≥regime‚ãÖIn‚Äão‚Äãr‚Äãm‚Äãa‚Äãl+(1‚àíŒ≥regime)‚ãÖIs‚Äãt‚Äãr‚Äãe‚Äãs‚ÄãsR^{\text{raw}}\_{I}(a,b)\leftarrow\gamma\_{\text{regime}}\cdot I\_{normal}+(1-\gamma\_{\text{regime}})\cdot I\_{stress}.

10:‚ÄÉ‚ÄÇM‚ÄãIv‚Äãa‚Äãl‚ÜêMI‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd;Disc‚Äã(RœÑ))MI\_{val}\leftarrow\text{MI}(t\_{merged};\text{Disc}(R\_{\tau})).
RPraw‚Äã(a,b)‚ÜêM‚ÄãIv‚Äãa‚ÄãlNormFactorM‚ÄãI+œµM‚ÄãIR^{\text{raw}}\_{P}(a,b)\leftarrow\frac{MI\_{val}}{\text{NormFactor}\_{MI}+\epsilon\_{MI}} (NormFactorMI from Section [H.2](https://arxiv.org/html/2602.06394v1#A8.SS2 "H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

11:‚ÄÉ‚ÄÇœÉc‚Äãu‚Äãr‚Äãr,œÉh‚Äãi‚Äãs‚Äãt‚ÜêGetVolatility‚Äã()\sigma\_{curr},\sigma\_{hist}\leftarrow\text{GetVolatility}();
V‚Äão‚Äãl‚ÄãS‚Äãc‚Äãa‚Äãl‚Äãi‚Äãn‚Äãg‚Üê(1+max‚Å°(0,(œÉc‚Äãu‚Äãr‚Äãr‚àíœÉh‚Äãi‚Äãs‚Äãt)/(œÉh‚Äãi‚Äãs‚Äãt+œµvol)))Œ≤v‚Äão‚ÄãlVolScaling\leftarrow(1+\max(0,(\sigma\_{curr}-\sigma\_{hist})/(\sigma\_{hist}+\epsilon\_{\text{vol}})))^{\beta\_{vol}}

12:‚ÄÉ‚ÄÇRCraw‚Äã(a,b)‚Üê‚àí|tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd|‚ãÖlog‚Å°(|Vt|+1)‚ãÖV‚Äão‚Äãl‚ÄãS‚Äãc‚Äãa‚Äãl‚Äãi‚Äãn‚ÄãgR^{\text{raw}}\_{C}(a,b)\leftarrow-|t\_{merged}|\cdot\log(|V\_{t}|+1)\cdot VolScaling

13:‚ÄÉ‚ÄÇNormalize raw rewards: R^j‚Äã(a,b)‚ÜêAdaptiveNormalize‚Äã(Rjraw‚Äã(a,b))\hat{R}\_{j}(a,b)\leftarrow\text{AdaptiveNormalize}(R^{\text{raw}}\_{j}(a,b)) using Eqs. [35](https://arxiv.org/html/2602.06394v1#A5.E35 "Equation 35 ‚Ä£ E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), [33](https://arxiv.org/html/2602.06394v1#A5.E33 "Equation 33 ‚Ä£ E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), and [34](https://arxiv.org/html/2602.06394v1#A5.E34 "Equation 34 ‚Ä£ E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

14:‚ÄÉ‚ÄÇTotal Immediate Reward (R‚Äã(a,b)R(a,b)): R‚Äã(a,b)‚Üê‚àëjŒªj‚ÄãR^j‚Äã(a,b)R(a,b)\leftarrow\sum\_{j}\lambda\_{j}\hat{R}\_{j}(a,b).

15:‚ÄÉ‚ÄÇStore wa‚Äãbw\_{ab}, R‚Äã(a,b)R(a,b), and other features for (a,b)(a,b) for policy input or selection.

16:‚ÄÇend for




Algorithm 8  Adaptive Parameter Learning for QA-TOKEN (Finance)

0:‚ÄÇTraining dataset ùíütrain\mathcal{D}\_{\text{train}};
Downstream task loss function Ltask‚Äã(‚ãÖ,‚ãÖ)L\_{\text{task}}(\cdot,\cdot); Model params Œòmodel\Theta\_{\text{model}};
Initial adaptive parameters Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}; Learning rate Œ∑Œ∏\eta\_{\theta}; Epochs Ea‚Äãd‚Äãa‚Äãp‚ÄãtE\_{adapt}; Gumbel-Softmax œÑg\tau\_{g}.

0:‚ÄÇOptimized adaptive parameters Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt‚àó\theta\_{adapt}^{\*}.

1:‚ÄÇInitialize Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}.

2:‚ÄÇfor each adaptation epoch e=1,‚Ä¶,Ea‚Äãd‚Äãa‚Äãp‚Äãte=1,\dots,E\_{adapt} do

3:‚ÄÉ‚ÄÇfor each mini-batch B={(Sseq,i,Ytarget,i)}B=\{(S\_{\text{seq},i},Y\_{\text{target},i})\} from ùíütrain\mathcal{D}\_{\text{train}} do

4:‚ÄÉ‚ÄÉ‚ÄÇùíÆb‚Äãa‚Äãt‚Äãc‚Äãh‚Ä≤‚ÜêSoftTokenizeGumbel‚Äã(B,Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt,œÑg)\mathcal{S}^{\prime}\_{batch}\leftarrow\textsc{SoftTokenizeGumbel}(B,\theta\_{adapt},\tau\_{g}) // Eq.¬†[37](https://arxiv.org/html/2602.06394v1#A5.E37 "Equation 37 ‚Ä£ E.11 Gradient Computation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")

5:‚ÄÉ‚ÄÉ‚ÄÇLbatch\_task‚ÜêLtask‚Äã(ùíÆb‚Äãa‚Äãt‚Äãc‚Äãh‚Ä≤,{Ytarget,i},Œòmodel)L\_{\text{batch\\_task}}\leftarrow L\_{\text{task}}(\mathcal{S}^{\prime}\_{batch},\{Y\_{\text{target},i}\},\Theta\_{\text{model}})

6:‚ÄÉ‚ÄÉ‚ÄÇif regularization Lreg‚Äã(Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt)L\_{\text{reg}}(\theta\_{adapt}) is used then

7:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇLtotal\_batch‚ÜêLbatch\_task+Lreg‚Äã(Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt)L\_{\text{total\\_batch}}\leftarrow L\_{\text{batch\\_task}}+L\_{\text{reg}}(\theta\_{adapt})

8:‚ÄÉ‚ÄÉ‚ÄÇelse

9:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇLtotal\_batch‚ÜêLbatch\_taskL\_{\text{total\\_batch}}\leftarrow L\_{\text{batch\\_task}}

10:‚ÄÉ‚ÄÉ‚ÄÇend if

11:‚ÄÉ‚ÄÉ‚ÄÇCompute gradients ‚àáŒ∏a‚Äãd‚Äãa‚Äãp‚ÄãtLtotal\_batch\nabla\_{\theta\_{adapt}}L\_{\text{total\\_batch}}. // Uses Gumbel-Softmax trick

12:‚ÄÉ‚ÄÉ‚ÄÇUpdate Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt‚ÜêŒ∏a‚Äãd‚Äãa‚Äãp‚Äãt‚àíŒ∑Œ∏‚Äã‚àáŒ∏a‚Äãd‚Äãa‚Äãp‚ÄãtLtotal\_batch\theta\_{adapt}\leftarrow\theta\_{adapt}-\eta\_{\theta}\nabla\_{\theta\_{adapt}}L\_{\text{total\\_batch}}.

13:‚ÄÉ‚ÄÉ‚ÄÇApply constraints to Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt} (e.g. Œ±‚â•0\alpha\geq 0, softmax for weights).

14:‚ÄÉ‚ÄÇend for

15:‚ÄÉ‚ÄÇAnneal œÑg\tau\_{g}.

16:‚ÄÇend for

17:

18:‚ÄÇreturn Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt‚àó‚ÜêŒ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}^{\*}\leftarrow\theta\_{adapt}.

#### H.9.2 Genomics (QA-BPE-seq)

Algorithm 9  Reward Calculation for a Merge (Genomics)

0:‚ÄÇTokens a,ba,b with qualities qa,qbq\_{a},q\_{b}; frequencies f‚Äã(‚ãÖ)f(\cdot); reward weights Œªj\lambda\_{j} from Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt}. For genomics, qa,qbq\_{a},q\_{b} represent geometric mean qualities of constituent tokens.

0:‚ÄÇRaw rewards Rjraw‚Äã(a,b)R^{\text{raw}}\_{j}(a,b) for merging aa and bb.

1:‚ÄÇtm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd‚Üêa||bt\_{merged}\leftarrow a||b

2:‚ÄÇRQraw‚Äã(a,b)‚Üê(‚àèl=1|tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd|qsm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd,l‚Ä≤)1/|tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd|R^{\text{raw}}\_{Q}(a,b)\leftarrow(\prod\_{l=1}^{|t\_{merged}|}q^{\prime}\_{s\_{merged,l}})^{1/|t\_{merged}|}. // Geometric mean quality

3:‚ÄÇRIraw‚Äã(a,b)‚Üêlog‚Å°f‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd)f‚Äã(a)‚ãÖf‚Äã(b)+œµfR^{\text{raw}}\_{I}(a,b)\leftarrow\log\frac{f(t\_{merged})}{f(a)\cdot f(b)+\epsilon\_{f}}.

4:‚ÄÇRCraw‚Äã(a,b)‚Üê‚àílen‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd)R^{\text{raw}}\_{C}(a,b)\leftarrow-\text{len}(t\_{merged}).

5:‚ÄÇif Biological Reward is used then

6:‚ÄÉ‚ÄÇO‚Äãv‚Äãe‚Äãr‚Äãl‚Äãa‚Äãp‚ÄãS‚Äãc‚Äão‚Äãr‚Äãe‚ÜêComputeOverlapScore‚Äã(tm‚Äãe‚Äãr‚Äãg‚Äãe‚Äãd,KnownBiologicalFeatures)OverlapScore\leftarrow\text{ComputeOverlapScore}(t\_{merged},\text{KnownBiologicalFeatures}).

7:‚ÄÉ‚ÄÇRb‚Äãi‚Äãoraw‚Äã(a,b)‚ÜêO‚Äãv‚Äãe‚Äãr‚Äãl‚Äãa‚Äãp‚ÄãS‚Äãc‚Äão‚Äãr‚ÄãeR^{\text{raw}}\_{bio}(a,b)\leftarrow OverlapScore.

8:‚ÄÇend if

9:

10:‚ÄÇreturn All relevant Rjraw‚Äã(a,b)R^{\text{raw}}\_{j}(a,b). (Normalized rewards R^j\hat{R}\_{j} computed later using Eq. [35](https://arxiv.org/html/2602.06394v1#A5.E35 "Equation 35 ‚Ä£ E.8 Reward Normalization Details ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).

The size of the RL agent‚Äôs action space, KP‚ÄãQK\_{PQ} (the number of top pairs from the priority queue considered at each step), was set to KP‚ÄãQ=50K\_{PQ}=50. This value was chosen based on preliminary experiments indicating it offered a good trade-off between exposing the RL agent to a diverse set of high-potential merges and maintaining a manageable action space size for efficient policy learning. Values explored in the range [20,100][20,100] showed that performance was relatively robust for KP‚ÄãQ‚àà[40,60]K\_{PQ}\in[40,60], with smaller values risking premature pruning of potentially beneficial long-term merges and larger values not yielding significant gains while increasing computational cost per policy step. The chosen value of 50 balanced these considerations effectively across domains.

* ‚Ä¢

  RL (PPO specifics) - Stage 1:

  + ‚Äì

    Policy/Value MLP Architecture: 2-3 hidden layers, each with 128-512 units. Activation functions: ReLU or Tanh.
  + ‚Äì

    PPO œµclip\epsilon\_{\text{clip}} (clipping parameter): [0.1,0.3][0.1,0.3], typically 0.20.2.
  + ‚Äì

    GAE ŒªGAE\lambda\_{\text{GAE}} (Generalized Advantage Estimation lambda): [0.9,0.99][0.9,0.99], typically 0.950.95.
  + ‚Äì

    Discount factor Œ≥R‚ÄãL\gamma\_{RL}: [0.95,1.0][0.95,1.0], often 0.990.99 for non-terminating tasks or long horizons.
  + ‚Äì

    Optimizer: Adam (Kingma and Ba, [2014](https://arxiv.org/html/2602.06394v1#bib.bib44 "Adam: a method for stochastic optimization")). Learning rates Œ∑œÄ\eta\_{\pi} (policy), Œ∑v\eta\_{v} (value): [1√ó10‚àí5,5√ó10‚àí4][1\times 10^{-5},5\times 10^{-4}].
  + ‚Äì

    Entropy bonus coefficient cSc\_{S} (or c2c\_{2}): [0.0,0.05][0.0,0.05], typically 0.010.01.
  + ‚Äì

    Value function loss coefficient cV‚ÄãFc\_{VF} (or c1c\_{1}): [0.25,1.0][0.25,1.0], typically 0.50.5.
  + ‚Äì

    Batch size (number of transitions per update): [128,4096][128,4096] or more, depending on data/memory.
  + ‚Äì

    PPO epochs per update (passes over collected data): [3,20][3,20], typically 4‚àí104-10.
  + ‚Äì

    Number of actors / parallel environments: 11 to Nc‚Äão‚Äãr‚Äãe‚ÄãsN\_{cores} or NG‚ÄãP‚ÄãU‚ÄãsN\_{GPUs}.
* ‚Ä¢

  Adaptive Reward Normalization (Section [4.2](https://arxiv.org/html/2602.06394v1#S4.SS2 "4.2 Reward Function Design ‚Ä£ 4 Learning Framework: RL and Adaptive Parameters ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")):

  + ‚Äì

    EMA momentum Œ≤norm\beta\_{\text{norm}}: [10‚àí3,10‚àí1][10^{-3},10^{-1}], typically 10‚àí210^{-2}.
  + ‚Äì

    œµR\epsilon\_{R} (stability constant): Typically 10‚àí810^{-8}.
* ‚Ä¢

  Reward Weights (Œ≤Œªj\bm{\beta}\_{\lambda\_{j}} leading to Œªj\lambda\_{j}): Initial values for ùú∑Œªj\bm{\beta}\_{\lambda\_{j}} in Œ∏adapt(0)\theta\_{\text{adapt}}^{(0)} for Stage 1 can be zero or small random numbers (resulting in uniform or near-uniform Œªj\lambda\_{j}). These are then optimized in Stage 2.
* ‚Ä¢

  Adaptive Learning Parameters (Œ∏adapt\theta\_{\text{adapt}} from Algorithm [2](https://arxiv.org/html/2602.06394v1#alg2 "Algorithm 2 ‚Ä£ E.2.2 Gumbel-Softmax Differentiable Optimization ‚Ä£ E.2 Stage 2: Adaptive Parameter Learning ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) - Stage 2:

  + ‚Äì

    Optimizer: Adam. Learning rate Œ∑Œ∏‚àà[1√ó10‚àí6,1√ó10‚àí4]\eta\_{\theta}\in[1\times 10^{-6},1\times 10^{-4}].
  + ‚Äì

    Gumbel-Softmax temperature œÑ\tau: Annealed from an initial high value (e.g., 1.0‚àí5.01.0-5.0) down to a small positive value (e.g., 0.1‚àí0.50.1-0.5) over training. Schedule: e.g., exponential decay œÑt=max‚Å°(œÑf‚Äãi‚Äãn‚Äãa‚Äãl,œÑ0‚ãÖdt)\tau\_{t}=\max(\tau\_{final},\tau\_{0}\cdot d^{t}).
  + ‚Äì

    Logit composite function (Eq. [37](https://arxiv.org/html/2602.06394v1#A5.E37 "Equation 37 ‚Ä£ E.11 Gradient Computation ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): Norm‚Ñì\text{Norm}\_{\ell} is typically identity or batch normalization if logits vary widely.
* ‚Ä¢

  Domain-Specific Adaptive Parameters and Quality Metric Settings:

  + ‚Äì

    Genomics Specific:

    - \*

      Œ≤pos\beta\_{\text{pos}} (positional quality decay): Learned. Initial range explored [0.001,0.1][0.001,0.1].
    - \*

      œµl‚Äãe‚Äãn\epsilon\_{len} (Eq. [41](https://arxiv.org/html/2602.06394v1#A8.E41 "Equation 41 ‚Ä£ H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): 10‚àí610^{-6}.
  + ‚Äì

    Social Media Specific:

    - \*

      ùú∑wj\bm{\beta}\_{w\_{j}} (for Qa‚Äãg‚ÄãgQ\_{agg} weights wjw\_{j}): Learned.
    - \*

      Œ≤s‚Äãe‚Äãm\beta\_{sem} (semantic compatibility, Eq. [44](https://arxiv.org/html/2602.06394v1#A8.E44 "Equation 44 ‚Ä£ H.3 Social Media Text (QA-BPE-nlp) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): Learned. Initial range [0.1,5.0][0.1,5.0].
    - \*

      œâ\omega (blending weight for RQrawR^{\text{raw}}\_{Q}, Eq. [46](https://arxiv.org/html/2602.06394v1#A8.E46 "Equation 46 ‚Ä£ 1st item ‚Ä£ H.6 Common Components ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): Learned. Parameterized via sigmoid of an unconstrained variable.
    - \*

      Note: The direct downstream loss component RDR\_{D} was not used in the RL reward for the final reported Social Media NLP experiments (Section [H.3](https://arxiv.org/html/2602.06394v1#A8.SS3 "H.3 Social Media Text (QA-BPE-nlp) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
  + ‚Äì

    Finance Specific:

    - \*

      ùú∑wk\bm{\beta}\_{w\_{k}} (for Q‚Äã[i]Q[i] weights wkw\_{k}): Learned.
    - \*

      Œ≤v‚Äão‚Äãl\beta\_{vol} (volatility scaling in RCR\_{C}): Learned. Initial range [0.0,2.0][0.0,2.0].
    - \*

      Œ≥regime\gamma\_{\text{regime}} (regime blending for RIR\_{I}): Learned. Parameterized via sigmoid of an unconstrained variable.
    - \*

      MM‚ÄãIM\_{MI} (window for NormFactorM‚ÄãI\text{NormFactor}\_{MI}): e.g., 1000 steps.
    - \*

      Note: Soft frequency gating was disabled in the final configuration for Quantitative Finance experiments (Section [5.2](https://arxiv.org/html/2602.06394v1#S5.SS2 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
* ‚Ä¢

  General QA-Token Parameters:

  + ‚Äì

    œµf,œµQ\epsilon\_{f},\epsilon\_{Q} (Eq. [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")): 10‚àí810^{-8}.
  + ‚Äì

    Œ±\alpha (quality sensitivity in wa‚Äãbw\_{ab}): Learned. Initial range [0.0,5.0][0.0,5.0].
* ‚Ä¢

  Vocabulary Settings:

  + ‚Äì

    Target vocabulary size VtargetV\_{\text{target}}: Typically [16000,64000][16000,64000].

#### H.9.3 Converged Adaptive Parameters

Table [19](https://arxiv.org/html/2602.06394v1#A8.T19 "Table 19 ‚Ä£ H.9.3 Converged Adaptive Parameters ‚Ä£ H.9 Domain-Specific Algorithms ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") provides mean converged values (¬±\pm standard deviation over three experimental runs) for key adaptive parameters in Œ∏a‚Äãd‚Äãa‚Äãp‚Äãt\theta\_{adapt} for each domain. The adaptive learning process tunes these parameters to optimize downstream task performance, leading to domain-specific configurations.

Table 19: Converged Adaptive Parameters (¬±\pm Std Dev).

|  |  |  |  |
| --- | --- | --- | --- |
| Parameter | Genomics | Finance | Social Media |
| Œ±\alpha (Quality Sensitivity) | 0.72¬±0.030.72\pm 0.03 | 0.95¬±0.030.95\pm 0.03 | 1.15¬±0.051.15\pm 0.05 |
| ŒªQ\lambda\_{Q} (Quality Reward Weight) | 0.35¬±0.030.35\pm 0.03 | 0.30¬±0.020.30\pm 0.02 | 0.33¬±0.030.33\pm 0.03 |
| ŒªI\lambda\_{I} (Information Reward Weight) | 0.25¬±0.020.25\pm 0.02 | 0.20¬±0.020.20\pm 0.02 | 0.22¬±0.020.22\pm 0.02 |
| ŒªC\lambda\_{C} (Complexity Reward Weight) | 0.15¬±0.010.15\pm 0.01 | 0.10¬±0.010.10\pm 0.01 | 0.12¬±0.010.12\pm 0.01 |
| Œ≤pos\beta\_{\text{pos}} (Genomics Positional Decay) | 0.014¬±0.0020.014\pm 0.002 | N/A | N/A |
| Œ≤vol\beta\_{\text{vol}} (Finance Volatility Scaling) | N/A | 0.50¬±0.050.50\pm 0.05 | N/A |
| Œ≥regime\gamma\_{\text{regime}} (Finance Regime Blending) | N/A | 0.60¬±0.040.60\pm 0.04 | N/A |
| worthw\_{\text{orth}} (NLP Orthographic Weight) | N/A | N/A | 0.32¬±0.030.32\pm 0.03 |
| wsemw\_{\text{sem}} (NLP Semantic Weight) | N/A | N/A | 0.28¬±0.020.28\pm 0.02 |
| wliqw\_{\text{liq}} (Finance Liquidity Weight) | N/A | 0.45¬±0.040.45\pm 0.04 | N/A |
| œâsocial\omega\_{\text{social}} (NLP Quality Blend) | N/A | N/A | 0.55¬±0.050.55\pm 0.05 |

### H.10 Social Media Ablation Results

Ablation studies in Table [20](https://arxiv.org/html/2602.06394v1#A8.T20 "Table 20 ‚Ä£ H.10 Social Media Ablation Results ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") are designed to confirm the individual effects of QA-BPE-nlp‚Äôs quality-aware components. We distinguish the impacts of: (1) the multi-dimensional quality rewards (row ‚Äôw/o Quality‚Äô), (2) semantic coherence considerations (row ‚Äôw/o Semantic‚Äô), (3) noise robustness features (row ‚Äôw/o Noise‚Äô), and (4) adaptive parameter learning (row ‚Äôw/o Adaptive Params‚Äô). Analysis of the learned weights wjw\_{j} for the quality dimensions (as detailed with values in Appendix [D.3](https://arxiv.org/html/2602.06394v1#A4.SS3 "D.3 Social Media: Linguistic Quality Metrics ‚Ä£ Appendix D Complete Quality Metrics Formulations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) indicates varying importance across dimensions (e.g., orthogonality qorthq\_{\text{orth}} and semantics qsemq\_{\text{sem}} frequently receive higher weights across runs) and reward components Œªi\lambda\_{i}, adapting to the specific task and dataset characteristics.

Table 20: Ablation Study for QA-BPE-nlp on TweetEval Sentiment. Values are means with 95% confidence intervals over n=10n=10 runs.

|  |  |  |
| --- | --- | --- |
| Configuration | TweetEval Score | Rel. Change (%) |
| QA-BPE-nlp (Full) | 74.5 ¬±\pm 0.3 | - |
| w/o RL Framework (Greedy wa‚Äãbw\_{ab}) | 72.1 ¬±\pm 0.4 | -3.2 |
| w/o Quality (RQ=0R\_{Q}=0) | 71.5 ¬±\pm 0.5 | -4.0 |
| w/o Semantic (RS=0R\_{S}=0) | 72.8 ¬±\pm 0.3 | -2.3 |
| w/o Noise (RN=0R\_{N}=0) | 73.2 ¬±\pm 0.4 | -1.7 |
| w/o Vocab Eff (RV=0R\_{V}=0) | 73.9 ¬±\pm 0.3 | -0.8 |
| w/o Adaptive Params (Œ±,wj\alpha,w\_{j} fixed) | 71.8 ¬±\pm 0.5 | -3.6 |
| QualTok-nlp (Ablation Baseline) | 71.9 ¬±\pm 0.4 | -3.5 |

## Appendix I Dataset, Baseline, and Evaluation Details

This section supplements dataset descriptions, baseline methods, and evaluation metrics discussed in the main paper, providing further details necessary for understanding and reproducing the experimental results reported in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

### I.1 Datasets and Reproducible Evaluation

This subsection details the specific datasets, their versions, and relevant preprocessing steps or configurations used for the experiments reported in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"). All datasets are publicly available or available under licenses for academic research.

* ‚Ä¢

  Genomics (QA-BPE-seq Experiments):

  + ‚Äì

    Simulated Human Genomic Reads for Variant Calling, Reconstruction, and Ablations:
    Paired-end sequencing reads (150bp) were generated at 30x coverage using the ART simulator (version 2.5.8, using the art\_illumina tool) (Huang et al., [2012](https://arxiv.org/html/2602.06394v1#bib.bib49 "ART: a next-generation sequencing read simulator")). The simulation was based on the GRCh38 human reference genome (patch 13) and used the built-in HiSeq 2500 error profile (-ss HS25). To rigorously assess robustness in high-noise scenarios, as described in Section [H.1](https://arxiv.org/html/2602.06394v1#A8.SS1 "H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), the default base error rates (both substitution and indel rates) of this profile were artificially doubled compared to the standard HiSeq 2500 profile. Key ART parameters included: -p -l 150 -f 30 -m 400 -s 10. A corpus of approximately 5GB of these synthetic reads was generated and used for training tokenizers, downstream model evaluations, and the ablation studies reported in Section [H.1](https://arxiv.org/html/2602.06394v1#A8.SS1 "H.1 Genomics (QA-BPE-seq) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
    Access: The ART simulator is open-source and available at <https://www.niehs.nih.gov/research/resources/software/art/>. The GRCh38 reference genome can be obtained from public repositories such as NCBI GenBank or Ensembl.
  + ‚Äì

    Genome in a Bottle (GIAB) Truth Set for Variant Calling Evaluation:
    Variant calling performance was benchmarked against the HG002 truth set (v4.2.1, GRCh38) (Zook et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib50 "Extensive sequencing of seven human genomes to characterize benchmark reference materials")).
    Access: GIAB truth sets are publicly available from the NIST FTP site.
  + ‚Äì

    CAMI II Metagenome Benchmark for Taxonomic Classification:
    Taxonomic classification accuracy was evaluated using the "Toy Human Microbiome Project" (short reads, Assembly Aug2019) dataset from the Second CAMI Challenge (Sczyrba et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib51 "Critical assessment of metagenome interpretation‚Äîa benchmark of metagenomics software")). This benchmark provides datasets with known community compositions and corresponding sequencing reads for performance assessment.
    Access: CAMI II datasets are available through the official CAMI challenge website: <https://data.cami-challenge.org/participate>.
* ‚Ä¢

  Quantitative Finance (QAT-QF Experiments):

  + ‚Äì

    Cryptocurrency Limit Order Book (LOB) Data:
    High-frequency Limit Order Book (LOB) data for the BTC/USD trading pair was sourced from LOBSTER (<https://lobsterdata.com/>) (Huang and Polak, [2011](https://arxiv.org/html/2602.06394v1#bib.bib54 "LOBSTER: limit order book reconstruction system")), an academic data service. The experiments used reconstructed LOB snapshots at 10 levels for the first quarter of 2023 (Q1 2023). As detailed in Section [5.2](https://arxiv.org/html/2602.06394v1#S5.SS2 "5.2 Quantitative Finance (QAT-QF) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), this dataset was split chronologically into 70% for training, 15% for validation, and 15% for out-of-sample testing. Atomic elements for tokenization were defined as sequences of 5 consecutive LOB events, featurized as described in Appendix [H.2](https://arxiv.org/html/2602.06394v1#A8.SS2 "H.2 Quantitative Finance (QAT-QF) ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").
    Access: LOBSTER provides sample data publicly, while full datasets are available under academic or commercial licenses.
* ‚Ä¢

  Social Media Text (QA-BPE-nlp Experiments):

  + ‚Äì

    TweetEval Benchmark:
    The TweetEval benchmark (Barbieri et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib67 "TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification")) was employed for evaluating QA-BPE-nlp across a diverse set of tweet classification tasks. TweetEval provides a unified framework with standardized data splits (train, validation, test) and evaluation metrics for seven heterogeneous tasks, which are:

    - \*

      Emotion Recognition (SemEval-2018 Task 1 (Mohammad et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib68 "Semeval-2018 task 1: affect in tweets")))
    - \*

      Emoji Prediction (SemEval-2018 Task 2 (Barbieri et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib69 "Semeval 2018 task 2: multilingual emoji prediction")))
    - \*

      Irony Detection (SemEval-2018 Task 3 (Van Hee et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib70 "Semeval-2018 task 3: irony detection in english tweets")))
    - \*

      Hate Speech Detection (SemEval-2019 Task 5 (Basile et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib71 "SemEval-2019 task 5: multilingual detection of hate speech against immigrants and women in Twitter")))
    - \*

      Offensive Language Identification (SemEval-2019 Task 6 (Zampieri et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib72 "SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval)")))
    - \*

      Sentiment Analysis (SemEval-2017 Task 4 (Rosenthal et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib59 "SemEval-2017 task 4: sentiment analysis in twitter")))
    - \*

      Stance Detection (SemEval-2016 Task 6 (Mohammad et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib73 "Semeval-2016 task 6: detecting stance in tweets")))

    As described in Section [I.8](https://arxiv.org/html/2602.06394v1#A9.SS8 "I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), experiments involved fine-tuning a pre-trained BERTweet-base model (Nguyen et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib61 "BERTweet: a pre-trained language model for english tweets")) on these tasks using different tokenization strategies.
    Access: The TweetEval benchmark, including data access scripts and details for each constituent dataset, is available on GitHub: <https://github.com/cardiffnlp/tweeteval>. Access to the underlying tweet content typically requires hydration of tweet IDs and adherence to Twitter‚Äôs Terms of Service and the respective dataset licenses.

### I.2 Dataset and Release Plan

To enable foundation-model training on previously unusable noisy corpora, we will release:

* ‚Ä¢

  Tokenizer artifacts: Final QA-Token vocabularies, merge tables, and Œ∏adapt\theta\_{\text{adapt}} for each domain (genomics, finance, social media) at multiple vocabulary sizes.
* ‚Ä¢

  Foundation-model-ready corpora manifests: Scripts and manifests to reconstruct large noisy pretraining corpora (including filtering and de-duplication), plus sampler configurations matching our 2B-subset tokenizer training protocol.
* ‚Ä¢

  Evaluation suites: Reproducible pipelines for genomics (variant calling, metagenomics), finance (prediction, volatility, regime, trading), and social media (TweetEval), along with the RL ablation harness.
* ‚Ä¢

  Documentation and governance: Licenses, data usage considerations, and guidelines for responsible use in high-impact applications (e.g., financial decision-making and clinical genomics).

All code and artifacts will be released under permissive academic licenses to maximize reproducibility and adoption.

### I.3 QA-Foundation: Noisy Pretraining Corpora Proposal

We propose QA-Foundation, a curated suite of extremely large, noisy corpora specifically designed to enable foundation-scale pretraining with explicit quality annotations and governance:

* ‚Ä¢

  Genomics: multi-petabase metagenomic reads (SRA) with canonicalized metadata, Phred-quality distributions, duplication maps, contamination flags, and per-read provenance hashes. Quality channels include per-base Phred, platform, run, trimming logs, adapter contamination.
* ‚Ä¢

  Finance: multi-asset high-frequency LOB streams (equities, futures, crypto) with synchronized calendars, microstructure indicators (spreads, depth, order-imbalance), regime tags, and exchange-specific anomaly flags.
* ‚Ä¢

  Social/Web text: multi-platform user-generated text with timestamps, platform labels, de-identified stable author hashes, normalization annotations (hashtags, mentions, URLs), and noise transformations (variant clusters, repetition, keyboard-distance confusion matrices).

Each domain provides standardized schemas, quality channels, and sampling manifests to reproduce tokenizer training at multiple scales (e.g., 0.1%, 1%, 5%) and to support fair comparisons. Scripts produce manifests, deduplication indices (MinHash/LSH), and quality audit reports. Governance includes explicit licenses, intended-use statements, and red-team risk assessments. We will release:

* ‚Ä¢

  Tokenizer-ready shards with checksums and integrity manifests
* ‚Ä¢

  Quality channel extractors (open-source) and validation suites
* ‚Ä¢

  Reproducible samplers that match our 2B-base subset protocol for genomics and analogous budgets for other domains

### I.4 Baseline Methods

The following baseline tokenization methods were implemented and configured for rigorous comparison against the proposed QA-Token variants, as presented in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

* ‚Ä¢

  Standard Byte Pair Encoding (BPE) (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units")): The conventional frequency-based merging algorithm. For genomics and social media experiments, this was implemented using the HuggingFace ‚Äòtokenizers‚Äò library (version 0.15.0), specifically configured with t‚Äão‚Äãk‚Äãe‚Äãn‚Äãi‚Äãz‚Äãe‚Äãr‚Äãs.m‚Äão‚Äãd‚Äãe‚Äãl‚Äãs.B‚ÄãP‚ÄãE‚Äã(u‚Äãn‚Äãk‚Äã\_‚Äãt‚Äão‚Äãk‚Äãe‚Äãn=‚Äù‚Äã[U‚ÄãN‚ÄãK]‚Äã‚Äù,m‚Äãi‚Äãn‚Äã\_‚Äãf‚Äãr‚Äãe‚Äãq‚Äãu‚Äãe‚Äãn‚Äãc‚Äãy=2)tokenizers.models.BPE(unk\\_token="[UNK]",min\\_frequency=2), unless stated otherwise. For quantitative finance experiments, a comparable standard BPE implementation was used.
* ‚Ä¢

  SentencePiece (Kudo and Richardson, [2018](https://arxiv.org/html/2602.06394v1#bib.bib15 "SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing")): An unsupervised text tokenizer and detokenizer. For genomics and social media experiments, SentencePiece (version 0.1.99) was used in its byte-level BPE mode, operating directly on raw text.
* ‚Ä¢

  WordPiece (Wu et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib14 "Google‚Äôs neural machine translation system: bridging the gap between human and machine translation")): The subword tokenization algorithm famously used in BERT. It iteratively builds a vocabulary by merging pairs that maximize the likelihood of the training data under a unigram language model assumption.
* ‚Ä¢

  DNABERT k-mer (Ji et al., [2021](https://arxiv.org/html/2602.06394v1#bib.bib9 "DNABERT: pre-trained bidirectional encoder representations from transformers model for dna-language in genome")): For experiments in the genomics domain, fixed k-mer tokenization was employed as a strong baseline, specifically using 6-mers. This aligns with common practice in models like DNABERT.
* ‚Ä¢

  Symbolic Aggregate approXimation (SAX) (Lin et al., [2003](https://arxiv.org/html/2602.06394v1#bib.bib55 "Symbolic representation of time series, with implications for streaming algorithms")): A well-established symbolic representation method for time series data, applied in quantitative finance experiments. The mid-price series was discretized using a Piecewise Aggregate Approximation (PAA) window size of 16 and an alphabet size of 8.
* ‚Ä¢

  Bag-of-SFA-Symbols (BOSS) (Sch√§fer, [2015](https://arxiv.org/html/2602.06394v1#bib.bib56 "The boss is concerned with time series classification in the presence of noise")): A time series classification algorithm that uses Symbolic Fourier Approximation (SFA) to generate symbolic words (tokens). This was used as a baseline in the quantitative finance domain, applied to the mid-price series.
* ‚Ä¢

  QualTok (Ablation Baseline): As described in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization"), QualTok serves as an ablation baseline for QA-Token. It employs a simplified quality-aware merge score, wa‚Äãb‚àùf‚Äã(a,b)f‚Äã(a)‚Äãf‚Äã(b)+œµf‚ãÖ(qa+qb2+œµQ)Œ±w\_{ab}\propto\frac{f(a,b)}{f(a)f(b)+\epsilon\_{f}}\cdot\left(\frac{q\_{a}+q\_{b}}{2}+\epsilon\_{Q}\right)^{\alpha}, but critically omits the reinforcement learning policy optimization for merge sequences and the full adaptive learning loop for complex Œ∏adapt\theta\_{\text{adapt}} parameters beyond tuning Œ±\alpha. Merge operations are typically performed greedily based on this score.

For all baseline methods, we select essential hyperparameters, such as the target vocabulary size (which typically corresponds to a predefined number of merge operations, e.g., 16,000 or 32,000, as specified per domain in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")), based on common practices in the literature (Sennrich et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib13 "Neural machine translation of rare words with subword units"); Kudo and Richardson, [2018](https://arxiv.org/html/2602.06394v1#bib.bib15 "SentencePiece: a simple and language independent subword tokenizer and detokenizer for neural text processing"); Wu et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib14 "Google‚Äôs neural machine translation system: bridging the gap between human and machine translation"); Devlin et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib6 "Bert: pre-training of deep bidirectional transformers for language understanding"); Brown et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib7 "Language models are few-shot learners"); Ji et al., [2021](https://arxiv.org/html/2602.06394v1#bib.bib9 "DNABERT: pre-trained bidirectional encoder representations from transformers model for dna-language in genome")), specific recommendations from the original implementations of these methods, or by identifying the best-performing configuration on a held-out validation set from a systematic sweep of reasonable values to ensure robust comparisons.

### I.5 Evaluation Metrics

The performance of QA-Token and baseline methods was assessed using the following domain-specific metrics, corresponding to the results presented in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

* ‚Ä¢

  Genomics:

  + ‚Äì

    Variant Calling: Performance was measured by F1-score, precision, and recall against the GIAB truth sets. These metrics were computed using the ‚Äòhap.py‚Äò tool (version 0.3.14), available at <https://github.com/Illumina/hap.py>.
  + ‚Äì

    Taxonomic Classification (Metagenomics): For the CAMI II benchmark, performance was primarily assessed using classification accuracy (specifically, the F1-score for overall classification performance, as reported in Table [1](https://arxiv.org/html/2602.06394v1#S5.T1 "Table 1 ‚Ä£ 5.1 Genomics (QA-BPE-seq) ‚Ä£ 5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")).
  + ‚Äì

    Sequence Reconstruction Loss: The quality of token representations was also evaluated by training Transformer-based autoencoder models and measuring the reconstruction loss (e.g., cross-entropy for discrete tokens) on a held-out test set.

  Variant Calling Model Architecture: The variant calling evaluation uses a Transformer encoder that takes token embeddings as input features. The model outputs per-position variant probabilities (SNV, insertion, deletion, reference). Training uses cross-entropy loss against GIAB HG002 labels. This approach evaluates how well tokenization preserves variant-informative sequence features in the learned representations, with evaluation performed using the hap.py benchmarking tool (v0.3.14).
* ‚Ä¢

  Quantitative Finance:

  + ‚Äì

    Return Prediction Accuracy: The percentage of correctly predicted signs for future (e.g., 5-minute ahead) mid-price returns.
  + ‚Äì

    Volatility Forecasting RMSE: The Root Mean Squared Error between the predicted 5-minute volatility and the realized volatility (computed from higher-frequency data).
  + ‚Äì

    Market Regime Identification Accuracy: The accuracy achieved in classifying time periods into discrete market states (e.g., two states identified by a GARCH-HMM).
  + ‚Äì

    Trading Performance: The primary metric was the annualized Sharpe Ratio (Sharpe, [1994](https://arxiv.org/html/2602.06394v1#bib.bib48 "The sharpe ratio")) achieved by a PPO-based trading agent operating on the tokenized data. A transaction cost of 5 basis points per trade was incorporated. Additional performance metrics, such as Maximum Drawdown (MDD) and Calmar Ratio, were also monitored (see Appendix [H.4](https://arxiv.org/html/2602.06394v1#A8.SS4 "H.4 Financial Experimental Methodology Details ‚Ä£ Appendix H Domain-Specific Instantiations ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") for further details).
* ‚Ä¢

  Social Media Text:

  + ‚Äì

    Performance on the seven TweetEval benchmark tasks was measured using the official evaluation metric specified by the benchmark organizers for each respective task (Barbieri et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib67 "TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification")). These metrics are:

    - \*

      Emoji Prediction: Accuracy (Acc)
    - \*

      Emotion Recognition: Macro F1-score (F1 M)
    - \*

      Hate Speech Detection: Macro F1-score (F1 M)
    - \*

      Irony Detection: Accuracy (Acc)
    - \*

      Offensive Language Identification: Macro F1-score (F1 M)
    - \*

      Sentiment Analysis: Macro Recall (Rec M)
    - \*

      Stance Detection: Average F1-score across topics (F1 Avg)

All reported experimental results in Section [5](https://arxiv.org/html/2602.06394v1#S5 "5 Empirical Validation ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") represent the mean and 95% confidence interval over n=10n=10 independent runs to ensure robustness and allow for assessment of variability.

### I.6 Code Availability

We will release the QA-Token framework on GitHub under an MIT license. The repository includes source code, configuration files, pre-trained models, and reproducibility scripts for all experiments.

### I.7 Approximating QA-Token: Towards Computationally Efficient Quality-Awareness

The learning framework of QA-Token has high computational costs due to both RL and adaptive learning stages. Future work will explore computationally lighter approximations. A starting point is our ablation baseline, QualTok, which uses a greedy merge strategy based on the quality-aware score wa‚Äãbw\_{ab} (Equation [5](https://arxiv.org/html/2602.06394v1#A3.E5 "Equation 5 ‚Ä£ Theorem C.3 (Quality-Aware Merge Score ‚Äî Principled Heuristic). ‚Ä£ C.3 Derivation of the Optimal Merge Score ‚Ä£ Appendix C Theoretical Framework and Proofs ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) without explicit RL policy optimization, bypassing the costs of Stage 1 RL.

Further cost reduction can be achieved by:

1. 1.

   Streamlined Adaptive Parameter Learning for Greedy Merges: Instead of full RL, we can focus on adaptively learning a refined set of parameters Œ∏adapt‚àó\theta\_{\text{adapt}}^{\*} (e.g., Œ±\alpha, quality weights wjw\_{j}, simplified reward weights Œªj\lambda\_{j}) that directly optimize the greedy wa‚Äãbw\_{ab}-guided tokenization for downstream tasks. This retains the core quality-aware adaptability while significantly reducing complexity compared to learning an RL policy. The Gumbel-Softmax based learning (Stage 2) would optimize Œ∏adapt\theta\_{\text{adapt}} for these greedy merges, possibly using simplified composite logits.
2. 2.

   Policy Distillation: If the RL policy œÄŒ∏œÄ‚àó\pi\_{\theta\_{\pi}}^{\*} captures complex merge dependencies, the computational overhead at deployment can be mitigated. A compact "student" model (e.g., a smaller neural network or decision tree) can be trained via policy distillation (Hinton et al., [2015](https://arxiv.org/html/2602.06394v1#bib.bib80 "Distilling the knowledge in a neural network"); Rusu et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib83 "Policy distillation")) to mimic the decisions of a larger, pre-trained "teacher" RL agent, offering faster vocabulary construction.
3. 3.

   Surrogate-Assisted Adaptive Learning: The optimization of Œ∏adapt\theta\_{\text{adapt}} (Stage 2) can be accelerated by using cheaper-to-evaluate surrogate models (Jones et al., [1998](https://arxiv.org/html/2602.06394v1#bib.bib79 "Efficient global optimization of expensive black-box functions")) to approximate the downstream task loss LtaskL\_{\text{task}}, reducing the need for frequent, costly end-to-end evaluations with the full downstream model.
4. 4.

   Transfer and Meta-Learning for Œ∏adapt\theta\_{\text{adapt}}: Leveraging learned Œ∏adapt\theta\_{\text{adapt}} parameters from one task or dataset as initializations for others (as in Algorithm [6](https://arxiv.org/html/2602.06394v1#alg6 "Algorithm 6 ‚Ä£ E.5 Algorithm Summary ‚Ä£ Appendix E Sequential Learning Process: Complete Framework ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization")) can substantially reduce the training burden for new applications.

### I.8 Extended TweetEval Benchmarking Methodology

This section describes the comprehensive TweetEval benchmarking methodology. Results are reported in Table¬†[21](https://arxiv.org/html/2602.06394v1#A9.T21 "Table 21 ‚Ä£ I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization").

Datasets and Evaluation Framework: TweetEval (Barbieri et al., [2020](https://arxiv.org/html/2602.06394v1#bib.bib67 "TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification")) provides a unified framework for evaluating models on seven heterogeneous tweet classification tasks, each with fixed training, validation, and test splits. This allows for standardized comparison across different approaches. The seven tasks are: Emotion Recognition (Mohammad et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib68 "Semeval-2018 task 1: affect in tweets")) (4 labels: anger, joy, sadness, optimism), Emoji Prediction (Barbieri et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib69 "Semeval 2018 task 2: multilingual emoji prediction")) (20 emoji labels), Irony Detection (Van Hee et al., [2018](https://arxiv.org/html/2602.06394v1#bib.bib70 "Semeval-2018 task 3: irony detection in english tweets")) (2 labels: irony, not irony), Hate Speech Detection (Basile et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib71 "SemEval-2019 task 5: multilingual detection of hate speech against immigrants and women in Twitter")) (2 labels: hateful, not hateful), Offensive Language Identification (Zampieri et al., [2019](https://arxiv.org/html/2602.06394v1#bib.bib72 "SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval)")) (2 labels: offensive, not offensive), Sentiment Analysis (Rosenthal et al., [2017](https://arxiv.org/html/2602.06394v1#bib.bib59 "SemEval-2017 task 4: sentiment analysis in twitter")) (3 labels: positive, neutral, negative), and Stance Detection (Mohammad et al., [2016](https://arxiv.org/html/2602.06394v1#bib.bib73 "Semeval-2016 task 6: detecting stance in tweets")) (3 labels: favour, neutral, against, across five topics).
For each task, we report performance using the unified evaluation metrics specified by the TweetEval benchmark.
Table [21](https://arxiv.org/html/2602.06394v1#A9.T21 "Table 21 ‚Ä£ I.8 Extended TweetEval Benchmarking Methodology ‚Ä£ Appendix I Dataset, Baseline, and Evaluation Details ‚Ä£ Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization") provides the baseline comparison framework. The official metric for each task as defined by TweetEval (also see https://github.com/cardiffnlp/tweeteval for details) is reported.

Table 21: TweetEval Baseline Comparison Framework.

|  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Emoji | Emotion | Hate | Irony | Offensive | Sentiment | Stance | ALL(TE) |
| BERTweet | 33.4 | 79.3 | 56.4 | 82.1 | 79.5 | 73.4 | 71.2 | 67.9 |
| TimeLMs-2021 | 34.0 | 80.2 | 55.1 | 64.5 | 82.2 | 73.7 | 72.9 | 66.2 |
| RoBERTa-Retrained | 31.4 | 78.5 | 52.3 | 61.7 | 80.5 | 72.8 | 69.3 | 65.2 |
| RoBERTa-Base | 30.9 | 76.1 | 46.6 | 59.7 | 79.5 | 71.3 | 68.0 | 61.3 |
| RoBERTa-Twitter | 29.3 | 72.0 | 49.9 | 65.4 | 77.1 | 69.1 | 66.7 | 61.4 |
| FastText | 25.8 | 65.2 | 50.6 | 63.1 | 73.4 | 62.9 | 65.4 | 58.1 |
| LSTM | 24.7 | 66.0 | 52.6 | 62.8 | 71.7 | 58.3 | 59.4 | 56.5 |
| SVM | 29.3 | 64.7 | 36.7 | 61.7 | 52.3 | 62.9 | 67.3 | 53.5 |
| QA-BPE-nlp + BERTweet | 34.2 | 81.5 | 58.8 | 82.9 | 83.0 | 75.1 | 73.5 | 70.0 |