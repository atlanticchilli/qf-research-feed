---
authors:
- J. J. Prieto-Garcia
- A. G. del Pozo-MartÃ­n
- M. Pino
doc_id: arxiv:2602.15474v1
family_id: arxiv:2602.15474
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Quantum Reservoir Computing for Statistical Classification in a Superconducting
  Quantum Circuit
url_abs: http://arxiv.org/abs/2602.15474v1
url_html: https://arxiv.org/html/2602.15474v1
venue: arXiv q-fin
version: 1
year: 2026
---


J. J. Prieto-Garcia
â€ƒâ€ƒ
A. G. del Pozo-MartÃ­n
â€ƒâ€ƒ
M. Pino
University of Salamanca IUFFyM, Salamanca, Spain

###### Abstract

We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.

## I Introduction

There are several quantum algorithms that have solid computational advantages with respect to their classical counterparts when they are run in a noiseless and scalable quantum computer [[1](https://arxiv.org/html/2602.15474v1#bib.bib1), [2](https://arxiv.org/html/2602.15474v1#bib.bib2), [3](https://arxiv.org/html/2602.15474v1#bib.bib3), [4](https://arxiv.org/html/2602.15474v1#bib.bib4), [5](https://arxiv.org/html/2602.15474v1#bib.bib5), [6](https://arxiv.org/html/2602.15474v1#bib.bib6), [7](https://arxiv.org/html/2602.15474v1#bib.bib7), [8](https://arxiv.org/html/2602.15474v1#bib.bib8)].
Unfortunately, such quantum devices are currently out of reach as quantum computers are still too noisy and error correction has not been scaled up yet [[9](https://arxiv.org/html/2602.15474v1#bib.bib9), [10](https://arxiv.org/html/2602.15474v1#bib.bib10), [11](https://arxiv.org/html/2602.15474v1#bib.bib11), [12](https://arxiv.org/html/2602.15474v1#bib.bib12)]. As a result, it is a fundamental challenge to search for algorithms that can lead to quantum advantages while remaining compatible with current hardware [[13](https://arxiv.org/html/2602.15474v1#bib.bib13), [14](https://arxiv.org/html/2602.15474v1#bib.bib14), [15](https://arxiv.org/html/2602.15474v1#bib.bib15), [16](https://arxiv.org/html/2602.15474v1#bib.bib16)]. An even greater challenge lies in the search for quantum advantages in real-world computational problems. This is the challenge we address in this work.

One algorithm that can help in the search of quantum advantages is the so-called Quantum Reservoir Computing (QRC). It employs a complex quantum system, a reservoir, to perform supervised learning tasks on an input signal [[17](https://arxiv.org/html/2602.15474v1#bib.bib17), [18](https://arxiv.org/html/2602.15474v1#bib.bib18), [19](https://arxiv.org/html/2602.15474v1#bib.bib19), [20](https://arxiv.org/html/2602.15474v1#bib.bib20), [21](https://arxiv.org/html/2602.15474v1#bib.bib21), [22](https://arxiv.org/html/2602.15474v1#bib.bib22)]. The reservoir quantum dynamics is driven by that signal, while an additional classical layer is used to map the reservoir quantum dynamics to the desired output, similarly to classical reservoir computing [[23](https://arxiv.org/html/2602.15474v1#bib.bib23), [24](https://arxiv.org/html/2602.15474v1#bib.bib24), [25](https://arxiv.org/html/2602.15474v1#bib.bib25)]. In analogy with recurrent neural networks [[26](https://arxiv.org/html/2602.15474v1#bib.bib26), [27](https://arxiv.org/html/2602.15474v1#bib.bib27)], the occupation probabilities of the reservoirâ€™s basis states can be viewed as the activations of its neurons. Due to its analog nature, it is relatively easy to implement QRC as only the intrinsic quantum system dynamics are needed with a minimal amount of control. QRC is also robust against a finite amount of noise and it can even benefit from a moderate amount of it [[28](https://arxiv.org/html/2602.15474v1#bib.bib28), [29](https://arxiv.org/html/2602.15474v1#bib.bib29), [30](https://arxiv.org/html/2602.15474v1#bib.bib30)]. Last but not least, QRC is able to analyze correlated time series [[31](https://arxiv.org/html/2602.15474v1#bib.bib31), [32](https://arxiv.org/html/2602.15474v1#bib.bib32), [33](https://arxiv.org/html/2602.15474v1#bib.bib33), [34](https://arxiv.org/html/2602.15474v1#bib.bib34), [35](https://arxiv.org/html/2602.15474v1#bib.bib35)], a feature that allows the treatment of, for instance, real-world problems in economics and finance [[36](https://arxiv.org/html/2602.15474v1#bib.bib36)].

In this work, we analyze QRC for statistical discrimination tasks using as a reservoir a simple superconducting quantum circuit [[37](https://arxiv.org/html/2602.15474v1#bib.bib37), [38](https://arxiv.org/html/2602.15474v1#bib.bib38), [39](https://arxiv.org/html/2602.15474v1#bib.bib39), [40](https://arxiv.org/html/2602.15474v1#bib.bib40)]. This circuit is composed of two capacitively coupled superconducting islands which are connected to the ground via a Josephson junction [[41](https://arxiv.org/html/2602.15474v1#bib.bib41), [42](https://arxiv.org/html/2602.15474v1#bib.bib42), [43](https://arxiv.org/html/2602.15474v1#bib.bib43), [44](https://arxiv.org/html/2602.15474v1#bib.bib44)]. Those junctions, which operate in the transmon regime, provide the key ingredient to obtain rich reservoir dynamics. Indeed, their inclusion results in the low-energy dynamics of the system being described by the Bose-Hubbard model, which has been widely used to describe interacting bosons [[45](https://arxiv.org/html/2602.15474v1#bib.bib45), [22](https://arxiv.org/html/2602.15474v1#bib.bib22), [46](https://arxiv.org/html/2602.15474v1#bib.bib46)], see [Fig. 1(a)](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). We emphasize that our QRC algorithm is fully analog, which is different from previous proposals based on qubit gates [[32](https://arxiv.org/html/2602.15474v1#bib.bib32), [36](https://arxiv.org/html/2602.15474v1#bib.bib36)].

![Refer to caption](x1.png)

![Refer to caption](x2.png)

Figure 1: (a) The quantum reservoir is a superconducting circuit composed of two capacitively coupled superconducting islands, with phase and charge degrees of freedom Î¸j,Nj\theta\_{j},N\_{j}, which are connected to the ground via Josephson junctions. Both islands are connected to an external voltage Vg.V\_{g}. The coupling capacitance is C12,C\_{12}, while each gate capacitance is Cgi.C\_{g\_{i}}. (b) Representation of the QRC framework. The quantum reservoir (large blue circle) evolves in response to the input (green circle). At specific times, a set of observables OiO\_{i} is measured from the reservoir and sent to the readout layer. The reservoir outputs (orange square) are subsequently mapped to the reservoir prediction (yellow square) through a set of trained weights (represented by the weight matrix WW).

We test the performance of our superconducting quantum reservoir on three problems, such as the discrimination of probability distributions and the parameter prediction of fixed distributions. The learning problems we address are difficult, since in some of them we classify distributions that exhibit heavy tails and contain correlations among different input data. Specifically, we first consider the problem of discriminating between two probabilistic families: normal and Laplacian distributions. Second, we tackle the problem of parameter estimation from data generated from Student-t distributions. This requires inferring how heavy the tails of the underlying distribution are, a feature of wide interest in areas such as economics and time forecasting [[47](https://arxiv.org/html/2602.15474v1#bib.bib47), [48](https://arxiv.org/html/2602.15474v1#bib.bib48)]. The third problem is to classify volatility regimes in GARCHâ€‹(1,1)\text{GARCH}(1,1) models, widely used in economic forecasting [[49](https://arxiv.org/html/2602.15474v1#bib.bib49), [50](https://arxiv.org/html/2602.15474v1#bib.bib50)].

We show that our specific realization of QRC provides a general algorithm that is able to compete rather well with some of the best classical counterparts for *each* of the previous tasks. Furthermore, we find that our algorithm improves over classical results when the amount of information from the underlying probability distribution is limited. We will finally argue how our QRC learning approach could be improved by running it in a real superconducting device, where the quantum reservoir can benefit from a much larger Hilbert space.

## II Computational Problems

In this section, we explain each of the problems that we aim to solve with QRC. We are interested in solving questions in the realm of statistical inference. We do not restrict to academic problems, but apply QRC to perform statistical inference of data following probability distributions similar to those that appear in several areas of science, such as finance or climate predictions. As we employ QRC as a supervised learning approach to solve this problems, we require two main stages to characterize the QRC efficiency: training and testing. In the following, we carefully describe the three problems that we will deal with.

### II.1 Normal vs. Laplace distribution inference

The first task is to infer the probability distribution followed by a list of TT data points. We consider data sampled from either a Normal or a Laplacian distribution. That is, our algorithms should decide from which distribution a set of data points has been drawn. The density functions of these two distributions are respectively given by:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | fð’©â€‹(x;Î¼,Ïƒ)\displaystyle f\_{\mathcal{N}}(x;\mu,\sigma) | =12â€‹Ï€â€‹Ïƒ2â€‹expâ¡(âˆ’(xâˆ’Î¼)22â€‹Ïƒ2),\displaystyle=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\!\left(-\frac{(x-\mu)^{2}}{2\sigma^{2}}\right), |  | (1) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | fâ„’â€‹(x;Î¼,b)\displaystyle f\_{\mathcal{L}}(x;\mu,b) | =12â€‹bâ€‹expâ¡(âˆ’|xâˆ’Î¼|b),\displaystyle=\frac{1}{2b}\exp\!\left(-\frac{|x-\mu|}{b}\right), |  | (2) |

where Î¼\mu is the mean of each distribution, Ïƒ>0\sigma>0 is the standard deviation of the Normal distribution, and b>0b>0 is the scale parameter of the Laplacian distribution.

Note that the goal is to predict the type of distribution regardless of the values of its parameters, and hence to identify the shape of the distribution rather than translations or rescaling. We restrict the possible range of each distributionâ€™s parameters to the following: Î¼âˆˆ[1,2]\mu\in[1,2] and Ïƒâ€‹Â orÂ â€‹bâˆˆ[0.1,0.7]\sigma\text{ or }b\in[0.1,0.7]. In particular, during the training phase we sweep over these ranges to cover the full parameter space, while in the test phase the parameters are chosen randomly within the same intervals.

### II.2 Student-t parameter inference

The second task is to infer some of the parameters of data drawn from a Student-t distribution. Specifically, we will predict the degrees of freedom Î½\nu for a probability density function given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | ftâ€‹(x;Î¼,Ïƒ,Î½)=Î“â€‹(Î½+12)Î½â€‹Ï€â€‹Ïƒâ€‹Î“â€‹(Î½2)â€‹(1+1Î½â€‹(xâˆ’Î¼Ïƒ)2)âˆ’Î½+12,f\_{t}(x;\mu,\sigma,\nu)=\frac{\Gamma\!\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\,\sigma\,\Gamma\!\left(\frac{\nu}{2}\right)}\left(1+\frac{1}{\nu}\left(\frac{x-\mu}{\sigma}\right)^{2}\right)^{-\frac{\nu+1}{2}}, |  | (3) |

where Î¼\mu is a location parameter and Ïƒ>0\sigma>0 is a scale parameter.

The weight of the Student-t distributionâ€™s tails depends on Î½\nu. Indeed, the smaller the value of Î½\nu, the heavier the tail, while for large Î½\nu the distribution tends to a Normal distribution. Since the goal of this task is to evaluate the ability of the reservoir to identify heavy-tailed distributions, we restrict to the case Î¼=0\mu=0 and Ïƒ=1\sigma=1. Furthermore, we focus on predicting the quantity 1/Î½1/\nu rather than Î½\nu, since it provides a more linear sensitivity to changes in the tail heaviness. Thus, we sweep 1/Î½1/\nu uniformly over the interval [1/30,1][1/30,1] in the training phase, whereas in the test phase 1/Î½1/\nu is chosen uniformly at random within the same range.

### II.3 GARCH volatility estimation

The final task is of particular importance, since it exhibits time correlations, which are present in many processes in economics and finance. In numerous real-world series, such as asset returns, periods of large fluctuations remain turbulent for a long time, while calmer periods persist in a similar way. The standard framework to study the so-called volatility clustering phenomenon is the GARCH(1,1) family [[49](https://arxiv.org/html/2602.15474v1#bib.bib49), [50](https://arxiv.org/html/2602.15474v1#bib.bib50)], whose dynamics capture how the instantaneous volatility evolves depending on both recent shocks and past volatility levels. Specifically, data at time tt are given by:

|  |  |  |  |
| --- | --- | --- | --- |
|  | xt\displaystyle x\_{t} | =Ïƒtâ€‹zt,\displaystyle=\sigma\_{t}z\_{t}, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Ïƒt2\displaystyle\sigma\_{t}^{2} | =Ï‰+Î±â€‹xtâˆ’12+Î²â€‹Ïƒtâˆ’12,\displaystyle=\omega+\alpha x\_{t-1}^{2}+\beta\sigma\_{t-1}^{2}, |  |

where Ïƒt\sigma\_{t} is the conditional standard deviation at time tt (also referred to as volatility), Ï‰\omega is related to the long-run variance level, Î±\alpha is a short-term volatility response, Î²\beta is a persistence parameter, and ztz\_{t} is sampled from a Normal distribution with mean 0 and variance 11.

A key structural parameter of these models is the sum Î±+Î²\alpha+\beta [[51](https://arxiv.org/html/2602.15474v1#bib.bib51)], which directly determines the persistence of volatility. Shocks dissipate quickly when that sum is small, whereas values close to one correspond to strong volatility clustering and to heavier tails. Hence, characterizing this persistence is crucial for understanding the underlying volatility regime of the process. Thus, our last task consists of classifying sequences of TT data points generated by GARCHâ€‹(1,1)\text{GARCH}(1,1) models into three distinct persistence bandsâ€”low, medium, and highâ€”defined respectively as Î±+Î²âˆˆ[0.2,0.6],Â â€‹Î±+Î²âˆˆ[0.6,0.9],Â orÂ â€‹Î±+Î²âˆˆ[0.9,0.99]\alpha+\beta\in[0.2,0.6],\text{ }\alpha+\beta\in[0.6,0.9],\text{ or }\alpha+\beta\in[0.9,0.99]. For simplicity, we set Ï‰=1\omega=1 and train the reservoir with series whose Î±â€‹Â andÂ â€‹Î²\alpha\text{ and }\beta values are chosen randomly in each interval. The test phase works analogously.

## III Architecture

We now introduce the hardware used to deal with the problems presented in the previous section. We analyze a simple superconducting circuit, which will play the role of the reservoir, and derive its low-energy Hamiltonian. We will find this Hamiltonian to be the Bose-Hubbard one of interacting bosons, whose efficiency for QRC has been thoroughly analyzed in Ref. [[22](https://arxiv.org/html/2602.15474v1#bib.bib22)]. The derivation presented here will help us to understand meaningful experimental parameters which are realizable in a superconducting circuit and obtain valuable knowledge on which hardware modifications can improve the QRC efficiency.

We consider a system composed of two coupled superconducting islands connected to ground via equal Josephson junctions. Those islands are capacitively connected to the same external voltage VgV\_{g}, which allows the system to be externally driven, see [Fig. 1(a)](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). The i-th island can be described in terms of its number of Cooper pairs and phase, NiN\_{i} and Î¸i\theta\_{i} , respectively. These dimensionless variables are canonically conjugate and satisfy [Î¸i,Nj]=iâ€‹Î´i,j[\theta\_{i},N\_{j}]=i\delta\_{i,j} in the quantum description of the system. The Hamiltonian is

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | H=\displaystyle H= | âˆ‘i=1,2Hi+Î”â€‹H,\displaystyle\sum\_{i=1,2}H\_{i}+\Delta H, |  | (4) |

where the Hamiltonian of each island and the coupling between them are given, respectively, by

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Hi\displaystyle H\_{i} | =4â€‹ECâ€‹(Niâˆ’Ng)2âˆ’EJâ€‹cosâ¡(Î¸i)\displaystyle=4E\_{C}(N\_{i}-N\_{g})^{2}-E\_{J}\cos(\theta\_{i}) |  | (5) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î”â€‹H\displaystyle\Delta H | =Tâ€‹N1â€‹N2.\displaystyle=TN\_{1}N\_{2}. |  | (6) |

We denote by EJE\_{J} and ECE\_{C} the Josephson and (renormalized) capacitive energies of the junctions. Notice that the capacitive energy EC=e2/(2â€‹C)E\_{C}=e^{2}/(2C) takes into account the renormalized island capacitance Câˆ’1=(C^+C12+Cg)/C^2C^{-1}=\left(\hat{C}+C\_{12}+C\_{g}\right)/\hat{C}^{2}, and not the bare Josephson junction capacitance C^.\hat{C}. The offset charges are denoted by Ng=Cgâ€‹Vg/(2â€‹e)N\_{g}=C\_{g}V\_{g}/(2e) and depend on the gate capacitor CgC\_{g} and voltage VgV\_{g}. The parameter TT controls the coupling and depends on C12C\_{12} and C^\hat{C}. It is given by T=4â€‹e2â€‹C12/C^2,T=4e^{2}C\_{12}/\hat{C}^{2}, see Ref. [[52](https://arxiv.org/html/2602.15474v1#bib.bib52)] for more information about the renormalization of the capacitance due to the coupling. We will employ a configuration operating in the regime EJâ‰«ECE\_{J}\gg E\_{C}. This is a widely used junction regime, as it corresponds to the regime relevant for transmon qubits, and allows one to map the dynamics of our Hamiltonian in Eq. [4](https://arxiv.org/html/2602.15474v1#S3.E4 "Equation 4 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") to the Bose-Hubbard model [[53](https://arxiv.org/html/2602.15474v1#bib.bib53), [54](https://arxiv.org/html/2602.15474v1#bib.bib54)].

In order to distill the low-energy model of our circuit, we first simplify the Hamiltonian of each superconducting island Hi.H\_{i}. It can be interpreted as a Hamiltonian describing a harmonic oscillator, with frequency Ï‰=8â€‹EJâ€‹EC\omega=\sqrt{8E\_{J}E\_{C}}, plus non-linearities coming from the higher-order terms of the cosine Josephson potential. In the regime in which we are working, EJâ‰«EC,E\_{J}\gg E\_{C}, we obtain EJâ‰«Ï‰E\_{J}\gg\omega, and hence the levels close to the ground state are quite confined around the potential minimum. In this situation, the low-energy states only see a small non-linear correction and it is safe to keep only a few orders in the expansion of the Josephson potential. Considering the cosine expansion up to fourth order in Eq. [5](https://arxiv.org/html/2602.15474v1#S3.E5 "Equation 5 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), we obtain the approximate single-island Hamiltonian

|  |  |  |  |
| --- | --- | --- | --- |
|  | Hi=4â€‹ECâ€‹Ni2+EJ2â€‹Î¸i2âˆ’EJ4!â€‹Î¸i4âˆ’8â€‹ECâ€‹Ngâ€‹Ni.H\_{i}=4E\_{C}N\_{i}^{2}+\dfrac{E\_{J}}{2}\theta\_{i}^{2}-\dfrac{E\_{J}}{4!}\theta\_{i}^{4}-8E\_{C}N\_{g}N\_{i}. |  | (7) |

The first two terms correspond to the ones in a harmonic oscillator with frequency Ï‰.\omega. Hence, using Î¸i=(2â€‹EC/EJ)1/4â€‹(ai+aiâ€ )\theta\_{i}=(2E\_{C}/E\_{J})^{1/4}(a\_{i}+a\_{i}^{\dagger}) and Ni=iâ€‹(EJ/32â€‹EC)1/4â€‹(aiâ€ âˆ’ai)N\_{i}=i(E\_{J}/32E\_{C})^{1/4}(a\_{i}^{\dagger}-a\_{i}), the Hamiltonian takes the form

|  |  |  |  |
| --- | --- | --- | --- |
|  | Hi=Ï‰â€‹aiâ€ â€‹aiâˆ’EC12â€‹(ai+aiâ€ )4âˆ’iâ€‹Îµâ€‹Vgâ€‹(aiâˆ’aiâ€ ).H\_{i}=\omega a\_{i}^{\dagger}a\_{i}-\dfrac{E\_{C}}{12}(a\_{i}+a\_{i}^{\dagger})^{4}-i\varepsilon V\_{g}(a\_{i}-a\_{i}^{\dagger}). |  | (8) |

where Îµ=2â€‹eâˆ’1â€‹ECâ€‹Cgâ€‹(EJ/2â€‹EC)1/4.\varepsilon=2e^{-1}E\_{C}C\_{g}(E\_{J}/2E\_{C})^{1/4}. Since ECâ‰ªEJE\_{C}\ll E\_{J}, it follows that ECâ‰ªÏ‰E\_{C}\ll\omega, and we can therefore apply the Rotating Wave Approximation [[55](https://arxiv.org/html/2602.15474v1#bib.bib55)], retaining only the number-conserving terms. Thus, the final Hamiltonian is given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Hi=Ï‰â€‹niâˆ’EC2â€‹niâ€‹(ni+1)âˆ’iâ€‹Îµâ€‹Vgâ€‹(aiâˆ’aiâ€ ),\displaystyle H\_{i}=\omega n\_{i}-\dfrac{E\_{C}}{2}n\_{i}(n\_{i}+1)-i\varepsilon V\_{g}(a\_{i}-a\_{i}^{\dagger}), |  | (9) |

where ni=aiâ€ â€‹ain\_{i}=a\_{i}^{\dagger}a\_{i} denotes the number operator of oscillator ii. We now simplify the remaining term Î”â€‹H\Delta H in Eq. [6](https://arxiv.org/html/2602.15474v1#S3.E6 "Equation 6 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). To do so, we assume that TT is sufficiently small g=Tâ€‹EJ/(32â€‹EC)â‰ªÏ‰,g=\,T\sqrt{E\_{J}/(32E\_{C})}\ll\omega, so that we can drop counter-rotating terms in the coupling, thus obtaining

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î”â€‹H=gâ€‹(a1â€ â€‹a2+a1â€‹a2â€ ).\Delta H=g(a\_{1}^{\dagger}a\_{2}+a\_{1}a\_{2}^{\dagger}). |  | (10) |

Notice that the simplifications made here are accurate as far as the strong coupling regime is avoided. This occurs roughly for couplings up to gâˆ¼0.1â€‹Ï‰.g\sim 0.1\omega.

We have finally obtained a Bose-Hubbard Hamiltonian with external drive:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | H=âˆ‘i=12Ï‰â€‹niâˆ’U2â€‹niâ€‹(ni+1)+iâ€‹Îµâ€‹Vgâ€‹(aiâˆ’aiâ€ )\displaystyle H=\sum\_{i=1}^{2}\omega n\_{i}-\dfrac{U}{2}n\_{i}(n\_{i}+1)+i\varepsilon V\_{g}(a\_{i}-a\_{i}^{\dagger}) |  | (11) |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +g12â€‹(a1â€ â€‹a2+a1â€‹a2â€ ).\displaystyle+g\_{12}(a\_{1}^{\dagger}a\_{2}+a\_{1}a\_{2}^{\dagger}). |  |

The gate voltage VgV\_{g} will be used to input data into the system. In QRC Îµâ€‹Vg=Îµ0â€‹xj\varepsilon V\_{g}=\varepsilon\_{0}\,x\_{j} will be used, with xjx\_{j} a dimensionless amplitude which contains the data to feed into the system at time tj.t\_{j}. The interacting term is controlled by U=EC,U=E\_{C}, which comes from the nonlinearities of the Josephson cosine potential. The phase diagram of this model is an interesting one, composed of superfluid and Mott-insulator phases. It further contains a Berezinsky-Kosterlitz-Thouless critical point and a re-entrant phase-diagram [[46](https://arxiv.org/html/2602.15474v1#bib.bib46)]. Previous works have reported a good performance of Bose-Hubbard reservoirs in paradigmatic QRC tasks near the phase transition and deep in the superfluid regime [[22](https://arxiv.org/html/2602.15474v1#bib.bib22)]. Although these results were obtained for relatively large systems, here we will focus on the case of a Bose-Hubbard Hamiltonian with only a few sites.

We will use the previous model Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") to explore QRC numerically. First of all, as it is impossible to reach arbitrarily large Hilbert space dimensions, we have used a cutoff nc=5n\_{c}=5 in the occupancies of each bosonic mode. This choice still provides a rich dynamical response of the reservoir while reducing considerably the computational cost of the QRC simulations. We further notice that, in the case of increasing this cutoff, our superconducting circuit Fig. [1](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") may not be well captured by the Bose-Hubbard model Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). The reason is that higher corrections than the quartic one will need to be included in Eq. [7](https://arxiv.org/html/2602.15474v1#S3.E7 "Equation 7 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). This is an interesting avenue of research as the resulting model, a pure rotor one, can display larger non-linearities than those considered here [[56](https://arxiv.org/html/2602.15474v1#bib.bib56)].

We now specify the parameter choice in Eq. ([11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")). We employ a coupling g12â‰ˆ0.05â€‹Ï‰g\_{12}\approx 0.05\,\omega and anharmonicity Uâ‰ˆ1.5â€‹g12U\approx 1.5\,g\_{12}. For typical superconducting devices, we can then use standard Josephson junctions with Ï‰âˆ¼10â€‹Â GHz,\omega\sim 10\text{ GHz}, giving a time scale for the system dynamics on the order of 0.1âˆ’1â€‹ns0.1-1\ {\rm ns}. Although we have treated identical Josephson junctions in our previous analysis, we have implemented the QRC algorithm using slightly different Josephson energies to make the dynamics more complex. Regarding the driving term, it has been intentionally chosen to be relatively large so as to drive transitions toward higher-energy states, as QRC needs to explore such states for better performance, yet sufficiently small to ensure that the population of states near the cutoff remains negligible. Doing so, we guarantee the validity of the truncated Hilbert space description.

Although our theoretical model can be obtained in other quantum hardware, such as optical lattices [[57](https://arxiv.org/html/2602.15474v1#bib.bib57)], we believe that the realization with superconducting circuits can provide several key advantages for QRC. For example, it allows easy variation of model parameters through the fabrication process, individual driving via external voltages or fast operational repetition rates. Similar hardware designs have been used for QRC before [[58](https://arxiv.org/html/2602.15474v1#bib.bib58), [59](https://arxiv.org/html/2602.15474v1#bib.bib59), [31](https://arxiv.org/html/2602.15474v1#bib.bib31)] but mainly using linear oscillators.

## IV Quantum Reservoir Computing

We devote this section to describing the principles of QRC. As shown in [Fig. 1(b)](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), it consists of three main components: the input layer, the quantum reservoir, and the readout layer. The input layer receives a time-dependent signal Xâ‰¡(xj)X\equiv(x\_{j}), typically corresponding to data that are not easily separable into distinct classes, and encodes it into a certain physical parameter of the quantum system. In our implementation, the superconducting circuit of the previous section plays the role of the reservoir, so that the input is encoded in the amplitude of the gate voltage VgV\_{g} in Eq. ([11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")). This encoding modulates the systemâ€™s internal dynamics, causing the reservoir to evolve through a sequence of configurations that depend on the input signal. Through this process, the quantum reservoir performs a nonlinear transformation projecting the input data into a high-dimensional feature space where they become more easily separable.

At certain times during the reservoir evolution, a set of observables OiO\_{i} is measured to extract features that characterize the systemâ€™s state, represented schematically as an orange square in [Fig. 1(b)](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). These measurements are typically chosen so that they correspond to occupation probabilities of selected quantum levels, from which a matrix Fâ€‹(X)F(X) is constructed. Then, the objective of the readout layer is to transform the reservoir outputs Fâ€‹(X)F(X) to the target, encoded in the matrix Y^\hat{Y}, via a weight matrix WW. To that end, the algorithm is divided into two phases: training and test.

In the training phase, WW is determined by fitting the reservoir outputs to known target values using the Mooreâ€“Penrose pseudo-inverse, a standard approach in both classical and quantum reservoir computing [[60](https://arxiv.org/html/2602.15474v1#bib.bib60), [61](https://arxiv.org/html/2602.15474v1#bib.bib61), [58](https://arxiv.org/html/2602.15474v1#bib.bib58)]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | W=Fâ€ â€‹(Xtraining)â‹…Y^training,W=F^{\dagger}(X\_{\text{training}})\cdot\hat{Y}\_{\text{training}}, |  | (12) |

where Fâ€ F^{\dagger} denotes the Mooreâ€“Penrose pseudo-inverse of the matrix FF. In the test phase, the obtained WW and Fâ€‹(Xtest)F(X\_{\text{test}}) are used to compute the predicted values YtestY\_{\text{test}}, which are compared to the test target Y^test\hat{Y}\_{\text{test}} to evaluate performance:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ytest=Fâ€‹(Xtest)â‹…WâŸ·Y^test.Y\_{\text{test}}=F(X\_{\text{test}})\cdot W\longleftrightarrow\hat{Y}\_{\text{test}}. |  | (13) |

We evaluate the performance of our quantum reservoir using two different metrics depending on the nature of the problem that we are dealing with. For discrete classification problemsâ€”those in Secs. [II.1](https://arxiv.org/html/2602.15474v1#S2.SS1 "II.1 Normal vs. Laplace distribution inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") and [II.3](https://arxiv.org/html/2602.15474v1#S2.SS3 "II.3 GARCH volatility estimation â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")â€”the real-valued output produced by the reservoir is mapped to a class according to one or more thresholds. Performance is then quantified in terms of prediction accuracy, which we will denote by A,A, and represents the percentage of correctly classified instances. On the other hand, the prediction of the degrees of freedom in a Student-t distribution, the problem in Sec. [II.2](https://arxiv.org/html/2602.15474v1#S2.SS2 "II.2 Student-t parameter inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), constitutes a continuous regression task. Here, we assess performance through the root mean square error (RMSE), which represents the average deviation between the predicted y^i\hat{y}\_{i} and the target yiy\_{i} values:

|  |  |  |  |
| --- | --- | --- | --- |
|  | RMSE=1Nâ€‹âˆ‘i=1N(yiâˆ’y^i)2,\mathrm{RMSE}=\sqrt{\frac{1}{N}\sum\_{i=1}^{N}\left(y\_{i}-\hat{y}\_{i}\right)^{2}}, |  | (14) |

where NN is the total number of predictions.

## V Methods

### V.1 QRC simulations

We aim to numerically analyze QRC implemented in superconducting hardware described by Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). However, any realistic analysis of a quantum information protocol must take into account the role of noise and its associated decoherence. To do so, we use the density matrix formulation of quantum dynamical evolution, which naturally allows the introduction of decoherence into the system [[37](https://arxiv.org/html/2602.15474v1#bib.bib37)]. Under this formalism, the system is represented by a mixed state with an associated density matrix that we will denote by Ï.\rho. The time evolution of this object is described by a master equation, which can be derived under the Markov approximation to be:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ÏË™=âˆ’iâ€‹[H,Ï]+âˆ‘j=12(Cjâ€‹Ïâ€‹Cjâ€ âˆ’12â€‹Cjâ€ â€‹Cjâ€‹Ïâˆ’12â€‹Ïâ€‹Cjâ€ â€‹Cj),\dot{{\rho}}=-i[{H},{\rho}]+\sum\_{j=1}^{2}\bigg({C}\_{j}{\rho}{C}\_{j}^{\dagger}-\frac{1}{2}{C}\_{j}^{\dagger}{C}\_{j}{\rho}-\frac{1}{2}{\rho}{C}\_{j}^{\dagger}{C}\_{j}\bigg), |  | (15) |

where HH is the Hamiltonian associated with our hardware, see Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), and Cj{C}\_{j} are the collapse operators accounting for the decay of bosonic modes. These operators are given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Cj=Îºjâ€‹aj,{C}\_{j}=\sqrt{\kappa\_{j}}\,{a}\_{j}, |  | (16) |

with Îºj\kappa\_{j} denoting the decay rate of mode jj. Notice that we do not introduce pure dephasing coming from elastic processes, but decay due to inelastic processes. We have simulated Eq. ([15](https://arxiv.org/html/2602.15474v1#S5.E15 "Equation 15 â€£ V.1 QRC simulations â€£ V Methods â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) using the QuTiP library [[62](https://arxiv.org/html/2602.15474v1#bib.bib62)] with a bosonic cutoff in the occupancies of nc=5n\_{c}=5.

Throughout this work, we consider Îº1=Îº2=500â€‹Î¼â€‹sâˆ’1\kappa\_{1}=\kappa\_{2}=500\,\mu\text{s}^{-1}, which is quite reasonable for current experiments with superconducting circuits [[63](https://arxiv.org/html/2602.15474v1#bib.bib63)]. Although this technology allows now for even longer coherence times, there is no need to push our implementation in that direction as QRC naturally benefits from a moderate amount of noise [[28](https://arxiv.org/html/2602.15474v1#bib.bib28), [29](https://arxiv.org/html/2602.15474v1#bib.bib29), [30](https://arxiv.org/html/2602.15474v1#bib.bib30)]. Hence, we deliberately operate in a regime in which dissipation is not very small.

Now, we go into the specific details of the QRC algorithm. For each prediction task, the reservoir processes an entire dataset consisting of a sequence of TT real numbers, which are injected sequentially into it. At the beginning of each dataset, the reservoir is initialized in its ground state. Then, after the evolution associated with each element of the sequence, we measure the occupations of a subset of Fock states |i,jâŸ©\ket{i,j} with 0â‰¤i,jâ‰¤m0\leq i,j\leq m. This choice yields (m+1)2(m+1)^{2} occupation probabilities, which we can interpret as the neurons of the reservoir. In the results presented in this work, we restrict to m=2m=2, corresponding to a total of nine reservoir neurons.

Instead of using the raw time series of occupations directly, we construct the feature matrix Fâ€‹(X)F(X) through a statistical pooling procedure. For each neuron kk, we calculate a few temporal statistics over its trajectory, such as the mean, standard deviation, and correlation measures. These statistics summarize the dynamical response of the reservoir to the entire input sequence. Then, we concatenate the statistics of all neurons, which yields a single feature vector associated with that dataset. Finally, we stack the feature vectors corresponding to different datasets to produce the matrix Fâ€‹(X)F(X) used in the linear readout. Notice that our QRC implementation does not require full quantum state tomography, but only the measurement of the occupation probabilities of the selected reservoir states. This is in contrast to other approaches that rely on full state reconstruction, which may be difficult to achieve in real quantum hardware.

### V.2 Classical algorithms

In order to evaluate the performance of QRC on the different tasks introduced in Sec. [II](https://arxiv.org/html/2602.15474v1#S2 "II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), we compare its results with those obtained using classical benchmarking counterparts. We will use two main classical methods, a generalized likelihood ratio test (GLRT) [[64](https://arxiv.org/html/2602.15474v1#bib.bib64), [65](https://arxiv.org/html/2602.15474v1#bib.bib65)] and a supervised classifier. The first of these methods is used for Gaussian/Laplace discrimination (Sec. [II.1](https://arxiv.org/html/2602.15474v1#S2.SS1 "II.1 Normal vs. Laplace distribution inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) and Student-t parameter inference (Sec. [II.2](https://arxiv.org/html/2602.15474v1#S2.SS2 "II.2 Student-t parameter inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")). The second one is employed for the determination of GARCH volatility regimes (Sec. [II.3](https://arxiv.org/html/2602.15474v1#S2.SS3 "II.3 GARCH volatility estimation â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")). We briefly review each of those methods and how we apply them to the problems explained in Sec. [II](https://arxiv.org/html/2602.15474v1#S2 "II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit").

### V.3 Parameter estimation and uncertainty quantification.

As we just said, GLRT is applied to the discrimination problem between Gaussian and Laplace distributions, Sec. [II.1](https://arxiv.org/html/2602.15474v1#S2.SS1 "II.1 Normal vs. Laplace distribution inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). For each input sequence, the parameters of the Normal and Laplacian distributions are estimated via maximum likelihood, and the sequence is assigned to the distribution for which the log-likelihood is larger. Specifically, given a sample {xi}i=1n\{x\_{i}\}\_{i=1}^{n}, we compare maximized log-likelihoods

|  |  |  |  |
| --- | --- | --- | --- |
|  | m^=argâ¡maxmâˆˆâ„³â¡maxÎ¸mâ€‹âˆ‘i=1nâ„“â€‹(xi;Î¸m).\widehat{m}\;=\;\arg\max\_{m\in\mathcal{M}}\;\max\_{\theta\_{m}}\;\sum\_{i=1}^{n}\ell(x\_{i};\theta\_{m}). |  | (17) |

Note that the log-likelihood functions are â„“â„³=logâ¡(fâ„³)\ell\_{\mathcal{M}}=\log(f\_{\mathcal{M}}), where the functions fâ„³f\_{{\mathcal{M}}} are given in Eq. ([1](https://arxiv.org/html/2602.15474v1#S2.E1 "Equation 1 â€£ II.1 Normal vs. Laplace distribution inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) and Eq. [2](https://arxiv.org/html/2602.15474v1#S2.E2 "Equation 2 â€£ II.1 Normal vs. Laplace distribution inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") for â„³={ð’©,â„’},\mathcal{M}=\left\{\mathcal{N},\mathcal{L}\right\}, respectively. The standard maximum likelihood estimators are Î¼^ð’©=1nâ€‹âˆ‘ixi\hat{\mu}\_{\mathcal{N}}=\frac{1}{n}\sum\_{i}x\_{i}, Ïƒ^ð’©2=1nâ€‹âˆ‘i(xiâˆ’Î¼^ð’©)2\hat{\sigma}^{2}\_{\mathcal{N}}=\frac{1}{n}\sum\_{i}(x\_{i}-\hat{\mu}\_{\mathcal{N}})^{2} for Gaussian and Î¼^â„’=medianâ€‹(xi)\hat{\mu}\_{\mathcal{L}}=\mathrm{median}(x\_{i}), b^â„’=1nâ€‹âˆ‘i|xiâˆ’Î¼^â„’|\hat{b}\_{\mathcal{L}}=\frac{1}{n}\sum\_{i}|x\_{i}-\hat{\mu}\_{\mathcal{L}}| for Laplace distribution, respectively.

For the Student-tt degrees-of-freedom estimation task in Sec. [II.2](https://arxiv.org/html/2602.15474v1#S2.SS2 "II.2 Student-t parameter inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), the classical algorithm reference is also maximum-likelihood estimation of Î½\nu

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î½^=argâ¡maxÎ½â€‹âˆ‘i=1nlogâ¡ftâ€‹(xi;0,1,Î½),\hat{\nu}=\arg\max\_{\nu}\sum\_{i=1}^{n}\log f\_{t}(x\_{i};0,1,\nu), |  | (18) |

where ftf\_{t} is given by the probability density function of the Student-t distribution given in Eq. [3](https://arxiv.org/html/2602.15474v1#S2.E3 "Equation 3 â€£ II.2 Student-t parameter inference â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). We report performance in terms of 1/Î½1/\nu to emphasize the low-Î½\nu regime.

The classical method used as a reference for GARCH problem in Sec. [II.3](https://arxiv.org/html/2602.15474v1#S2.SS3 "II.3 GARCH volatility estimation â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") consists of computing the same features as in our QRC approach, but over the raw data xtx\_{t} rather than the neuron populations of the reservoir. These features are used to train a supervised classifier on a training set, which is then evaluated on a separate test set. This classifier is equivalent to the last readout layer of the QRC. Thus, this approach is based on the prediction given by the matrix WW in Eq. [12](https://arxiv.org/html/2602.15474v1#S4.E12 "Equation 12 â€£ IV Quantum Reservoir Computing â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), but using the Xtâ€‹râ€‹aâ€‹iâ€‹nâ€‹iâ€‹nâ€‹gX\_{training} as the raw data of the input signal. This is one of the standard classical methods for GARCH regime classification in time-series analysis and volatility modeling [[66](https://arxiv.org/html/2602.15474v1#bib.bib66), [67](https://arxiv.org/html/2602.15474v1#bib.bib67), [68](https://arxiv.org/html/2602.15474v1#bib.bib68), [69](https://arxiv.org/html/2602.15474v1#bib.bib69)].

## VI Results

We now analyze the efficiency of QRC and classical methods when solving the problems of statistical inference explained in Sec. [II](https://arxiv.org/html/2602.15474v1#S2 "II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). The reservoir dynamics correspond to those of our superconducting system in Fig. [1](https://arxiv.org/html/2602.15474v1#S1.F1 "Figure 1 â€£ I Introduction â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), which, as we derived previously, is described by the Bose-Hubbard model Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). We fix the system parameters to Ï‰1=10â€‹GHz\omega\_{1}=10\,\mathrm{GHz}, Ï‰2=9â€‹GHz\omega\_{2}=9\,\mathrm{GHz}, g12=400â€‹MHzg\_{12}=400\,\mathrm{MHz}, and U=600â€‹MHzU=600\,\mathrm{MHz}. The value of Îµ0\varepsilon\_{0} varies slightly across tasks and will be reported in each of them.

In each of the problems tackled we characterize the performance of the prediction in terms of a quantity XX, and fit the results to laws of the form Xâ€‹(T)X(T), where TT is the number of data points fed to the algorithm. When displaying the results, the reported markers correspond to the mean performance over independent test realizations, while error bars denote Â±1â€‹Ïƒ\pm 1\sigma (one standard deviation) around the mean. Fitting the scaling laws Xâ€‹(T)X(T) allows for a qualitative understanding of the performance of QRC compared with classical methods. A detailed explanation of the fitting procedure that we have followed can be found in the Supplementary Material.

For the two classification tasks (Normal vs. Laplace and GARCH-band assignment), we use the accuracy of the prediction X=AX=A as a performance characterization. This accuracy AA is defined as the percentage of successful predictions when solving many different problems with equal-length TT data inputs. We then fit the accuracy of the predictions as a function of TT to obtain a scaling law. We consider two main forms for this scaling law

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Aâ€‹(T)\displaystyle A(T) | =Aâˆžâˆ’câ€‹eâˆ’kâ€‹Tp,\displaystyle=A\_{\infty}-c\,e^{-kT^{p}}, |  | (19) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Aâ€‹(T)\displaystyle A(T) | =Aâˆžâˆ’câ€‹Tâˆ’p.\displaystyle=A\_{\infty}-c\,T^{-p}. |  | (20) |

For the Student-t regression task we use the prediction error X=RMSEX=\mathrm{RMSE}, see Eq. [14](https://arxiv.org/html/2602.15474v1#S4.E14 "Equation 14 â€£ IV Quantum Reservoir Computing â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), on the target 1/Î½1/\nu . Specifically, we test which of the following scaling laws fit our data better:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | RMSEâ€‹(T)\displaystyle\mathrm{RMSE}(T) | =câ€‹Tâˆ’p,\displaystyle=c\,T^{-p}, |  | (21) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | RMSEâ€‹(T)\displaystyle\mathrm{RMSE}(T) | =câ€‹(lnâ¡T)âˆ’p(T>1),\displaystyle=c\,(\ln T)^{-p}\qquad(T>1), |  | (22) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | RMSEâ€‹(T)\displaystyle\mathrm{RMSE}(T) | =râˆž+câ€‹eâˆ’kâ€‹Tp,\displaystyle=r\_{\infty}+c\,e^{-kT^{p}}, |  | (23) |

where TT is the number of data points fed into the algorithm, as before.

![Refer to caption](Figures/NvsL_9neur.png)(a)(a)

![Refer to caption](Figures/NvsL_fit.png)(b)(b)

Figure 2: Normal vs. Laplace discrimination. (a) Prediction accuracy of QRC and a generalized likelihood ratio test versus the number of data points per sample TT. (b) Accuracy scaling of QRC with input length TT fitted by stretched-exponential laws Aâ€‹(T)=Aâˆžâˆ’câ€‹eâˆ’kâ€‹TpA(T)=A\_{\infty}-c\,e^{-kT^{p}}, together with the corresponding linearized representation (inset: classical case).
For this task, the driving amplitude is fixed to Ïµ0=3.8â€‹GHz\epsilon\_{0}=3.8\,\mathrm{GHz}.



![Refer to caption](Figures/Tstudent_9neur.png)(a)(a)

![Refer to caption](Figures/t-student_fit.png)(b)(b)

Figure 3: Student-t degrees-of-freedom prediction. (a) Test-set RMSE of the 1/Î½1/\nu estimator versus sequence length TT, comparing the QRC readout with a classical maximum-likelihood estimator. Both methods improve monotonically with TT, with QRC achieving lower RMSE and the gap narrowing at large TT. (b) Scaling analysis of data in panel (a), which are fitted to power-law decays Râ€‹Mâ€‹Sâ€‹Eâ€‹(T)=câ€‹Tâˆ’pRMSE(T)=c\,T^{-p}, together with the corresponding linearized representation (inset: classical case).
For this task, the driving amplitude is fixed to Ïµ0=1â€‹GHz\epsilon\_{0}=1\,\mathrm{GHz}.

### VI.1 Normal vs. Laplace Classification

The first task probes whether the reservoir can identify distributional *shape* under random translations and re-scalings. The QRC and GLRT accuracies for this task versus the length of the data sequence TT are shown in Fig. [2](https://arxiv.org/html/2602.15474v1#S6.F2 "Figure 2 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")(a). We observe that QRC is competitive against the generalized likelihood ratio test (GLRT) across the explored range of sample sizes, and it is particularly strong in the small-TT regime. That is, QRC attains a significantly higher accuracy than GLRT in the case of short data sequences, with a separation comparable to (or larger than) the displayed uncertainty. As TT increases, the two methods rapidly converge. At the largest sample sizes, GLRT seems to perform better. However, the confidence intervals for both cases still overlap substantially for most points. The scaling analysis in Fig. [2](https://arxiv.org/html/2602.15474v1#S6.F2 "Figure 2 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")(b) indicates that both datasets are best summarized by stretched-exponential approaches to an asymptote, see Eq. [19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). The best-fit parameters are Aâˆž,c=1.000Â±0.005A\_{\infty,c}=1.000\pm 0.005 with (cc,kc,pc)=(0.58Â±0.02,0.086Â±0.008,0.72Â±0.03)(c\_{c},k\_{c},p\_{c})=(0.58\pm 0.02,0.086\pm 0.008,0.72\pm 0.03) for GLRT, and Aâˆž,q=0.943Â±0.007A\_{\infty,q}=0.943\pm 0.007 with (cq,kq,pq)=(0.37Â±0.02,0.016Â±0.005,1.14Â±0.08)(c\_{q},k\_{q},p\_{q})=(0.37\pm 0.02,0.016\pm 0.005,1.14\pm 0.08) for QRC, with Ï‡red2=2.85\chi^{2}\_{\rm red}=2.85 (classical) and Ï‡red2=0.17\chi^{2}\_{\rm red}=0.17 (quantum). These fits are consistent with the qualitative behaviour observed in Fig. [2](https://arxiv.org/html/2602.15474v1#S6.F2 "Figure 2 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")(a): both approaches improve quickly with TT, and the classical method outperforms QRC at large T,T, as indicated by Aâˆž,c>Aâˆž,q.A\_{\infty,c}>A\_{\infty,q}.

### VI.2 Prediction of Student-t Degrees of Freedom

We next consider a regression setting in which the target is the inverse of the degrees of freedom of a Student-t distribution, 1/Î½.1/\nu. As we have previously commented, we use this quantity to enhance sensitivity to tail heaviness. Figure [3](https://arxiv.org/html/2602.15474v1#S6.F3 "Figure 3 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") contains the RMSE of the prediction as a function of the sequence length TT for the quantum and classical cases. In contrast to the previous task, QRC shows a systematic advantage over the likelihood-based protocol across a broad interval of T.T. From short to intermediate series lengths, the QRC curve lies below the classical one, and the separation is most pronounced around the intermediate-TT range, where the error bars do not overlap. For the longest series lengths, both methods approach a similar error floor and the difference becomes comparable to the error bars. The scaling fits shown in Fig. [3](https://arxiv.org/html/2602.15474v1#S6.F3 "Figure 3 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")(b) select a power-law decay given by Eq. [21](https://arxiv.org/html/2602.15474v1#S6.E21 "Equation 21 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") for both approaches, with exponents pc=0.483Â±0.005p\_{c}=0.483\pm 0.005 and pq=0.451Â±0.008p\_{q}=0.451\pm 0.008 and prefactors cc=0.93Â±0.02c\_{c}=0.93\pm 0.02 and cq=0.76Â±0.03c\_{q}=0.76\pm 0.03 (with Ï‡red2=1.07\chi^{2}\_{\rm red}=1.07 and 0.850.85, respectively). The similar exponents indicate comparable asymptotic decay rates with TT, whereas the smaller prefactor obtained for QRC compactly captures the lower RMSE observed throughout most of the explored range. Furthermore, we obtain an exponent close to p=0.5.p=0.5. This is the exponent expected when taking into account the Central Limit Theorem. Indeed, for any regular estimator built from TT effectively independent samples, that theorem implies Tâ€‹(Î¸^âˆ’Î¸)â‡’ð’©â€‹(0,ÏƒÎ¸2)\sqrt{T}\,(\hat{\theta}-\theta)\Rightarrow\mathcal{N}(0,\sigma\_{\theta}^{2}), and hence RMSEâ€‹(Î¸^)âˆ¼ÏƒÎ¸/T\mathrm{RMSE}(\hat{\theta})\sim\sigma\_{\theta}/\sqrt{T}, i.e. a Tâˆ’1/2T^{-1/2} decay.

![Refer to caption](Figures/GARCH_9neur.png)(a)(a)

![Refer to caption](Figures/GARCH_fit.png)(b)(b)

Figure 4: GARCH(1,1) volatility-regime classification. (a) Test accuracy versus input length TT for QRC and a classical feature-based classifier. (b) Scaling analysis of the accuracy versus TT using the fitted scaling laws for Aâ€‹(T).A(T).
The classical method is best described by a stretched-exponential approach to a plateau, A^câ€‹(T)=Aâˆž,câˆ’ccâ€‹eâˆ’kcâ€‹Tpc\hat{A}\_{c}(T)=A\_{\infty,c}-c\_{c}e^{-k\_{c}T^{p\_{c}}}, whereas the QRC data favor a power-law approach, A^qâ€‹(T)=Aâˆž,qâˆ’cqâ€‹Tâˆ’pq\hat{A}\_{q}(T)=A\_{\infty,q}-c\_{q}T^{-p\_{q}}.
For this task, the driving amplitude is fixed to Ïµ0=1.9â€‹GHz\epsilon\_{0}=1.9\,\mathrm{GHz}.

### VI.3 GARCH Band Classification

Finally, we address the correlated setting of GARCHâ€‹(1,1)\mathrm{GARCH}(1,1) sequences, where the goal is to assign each time series to one of three persistence bands. Figure [4](https://arxiv.org/html/2602.15474v1#S6.F4 "Figure 4 â€£ VI.2 Prediction of Student-t Degrees of Freedom â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") shows that QRC provides a benefit for short and moderately short time series: in the low-TT regime, QRC achieves higher accuracy than the feature-based classical classifier trained directly on the raw xtx\_{t}, and the improvement is larger than (or comparable to) the corresponding confidence intervals. As TT increases, the two approaches become nearly indistinguishable within uncertainty, and at the largest TT values the classical curve can slightly exceed QRC, albeit with overlapping error bars.

| Task | Selected law | Aâˆž/râˆžA\_{\infty}/r\_{\infty} (Â±Ïƒ\pm\sigma) | cc (Â±Ïƒ\pm\sigma) | kk (Â±Ïƒ\pm\sigma) | pp (Â±Ïƒ\pm\sigma) | Ï‡red2\chi^{2}\_{\rm red} |
| --- | --- | --- | --- | --- | --- | --- |
| GARCH classic | ([19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | 1.0000Â±0.00131.0000\pm 0.0013 | 2.47Â±0.082.47\pm 0.08 | 0.926Â±0.0140.926\pm 0.014 | 0.136Â±0.0080.136\pm 0.008 | 1.40 |
| GARCH quantum | ([20](https://arxiv.org/html/2602.15474v1#S6.E20 "Equation 20 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | 1.00Â±0.131.00\pm 0.13 | 1.01Â±0.061.01\pm 0.06 | â€“ | 0.21Â±0.080.21\pm 0.08 | 0.56 |
| Normal vs Laplace classic | ([19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | 1.000Â±0.0051.000\pm 0.005 | 0.58Â±0.020.58\pm 0.02 | 0.086Â±0.0080.086\pm 0.008 | 0.72Â±0.030.72\pm 0.03 | 2.85 |
| Normal vs Laplace quantum | ([19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | 0.943Â±0.0070.943\pm 0.007 | 0.37Â±0.020.37\pm 0.02 | 0.016Â±0.0050.016\pm 0.005 | 1.14Â±0.081.14\pm 0.08 | 0.17 |
| tt-Student Î½\nu classic | ([21](https://arxiv.org/html/2602.15474v1#S6.E21 "Equation 21 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | â€“ | 0.93Â±0.020.93\pm 0.02 | â€“ | 0.483Â±0.0050.483\pm 0.005 | 1.07 |
| tt-Student Î½\nu quantum | ([21](https://arxiv.org/html/2602.15474v1#S6.E21 "Equation 21 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) | â€“ | 0.76Â±0.030.76\pm 0.03 | â€“ | 0.451Â±0.0080.451\pm 0.008 | 0.85 |

Table 1: Summary of the selected scaling laws and the corresponding fitted parameters for each task.
The second column contains the selected law, the one with the closest to one Ï‡r2,\chi^{2}\_{r}, from the ansatzs Eqs. ([19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"))-([23](https://arxiv.org/html/2602.15474v1#S6.E23 "Equation 23 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")). The other columns indicate the estimation of parameters Â±1â€‹Ïƒ\pm 1\sigma uncertainties, together with the reduced chi-squared of the fit in the last column, Ï‡red2.\chi^{2}\_{\rm red}.

The scaling fits in Fig. [4](https://arxiv.org/html/2602.15474v1#S6.F4 "Figure 4 â€£ VI.2 Prediction of Student-t Degrees of Freedom â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") favor different effective laws for the two approaches. For the classical baseline, the best description is given by Eq. ([19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")) with Aâˆž,c=1.0000Â±0.0013A\_{\infty,c}=1.0000\pm 0.0013, (cc,kc,pc)=(2.47Â±0.08,0.926Â±0.014,â€‰0.136Â±0.008)(c\_{c},k\_{c},p\_{c})=(2.47\pm 0.08,0.926\pm 0.014,\,0.136\pm 0.008) and Ï‡red2=1.40\chi^{2}\_{\rm red}=1.40, while for QRC the preferred ansatz is Eq. ([20](https://arxiv.org/html/2602.15474v1#S6.E20 "Equation 20 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")), with Aâˆž,q=1.00Â±0.13A\_{\infty,q}=1.00\pm 0.13, pq=0.21Â±0.08p\_{q}=0.21\pm 0.08, cq=1.01Â±0.06c\_{q}=1.01\pm 0.06 and Ï‡red2=0.56\chi^{2}\_{\rm red}=0.56. At the phenomenological level, these fits reflect the same qualitative message as the raw curves: QRC extracts useful regime information already from relatively short correlated sequences, whereas for longer time series the classical method exhibits better accuracy in its predictions. We further observe a peculiar swing of the quantum data points around the theoretical fitted law in Fig. [4](https://arxiv.org/html/2602.15474v1#S6.F4 "Figure 4 â€£ VI.2 Prediction of Student-t Degrees of Freedom â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")(b), which does not occur in the other problem treated above. This correlation in the accuracy of the prediction for different time series may be caused by the
intrinsic time-correlations exhibited by GARCH models.

### VI.4 Performance overview

Table [1](https://arxiv.org/html/2602.15474v1#S6.T1 "Table 1 â€£ VI.3 GARCH Band Classification â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") summarizes the scaling-law fits obtained for each task. We report there the selected functional form from the non-linear analysis together with the associated parameter estimates and complementary goodness-of-fit diagnostics. In particular, we provide the asymptotic performance level (AâˆžA\_{\infty} for accuracies, or râˆžr\_{\infty} for RMSE when applicable) together with its uncertainty, the fitted coefficients (c,k,p)(c,k,p), and the reduced chi-squared values computed from the non-linear weighted least-squares fits, see Supplementary Material.

We have seen that QRC improves over classical algorithms at short T,T, where decisions must be made with limited data. In contrast, classical methods marginally outperform QRC when the amount of data is large. This is reflected in the parameters of the fitted laws. Notice that the parameters that control the efficiency as Tâ†’âˆžT\rightarrow\infty are consistent with asymptotic accuracies close to unity in most cases (not in the Normal/Laplace discrimination). This is not trivial, as there is no general theoretical guarantee that QRC should saturate to unit accuracy in the infinite-data limit. This is the case at least in the GARCH problem, as time correlations must be taken into account for correct parameter estimation. The good performance of QRC in the GARCH problem is likely to be caused by time correlation being smaller than the noise-induced decay of the quantum state. As if it were the opposite, decoherence would produce a loss of memory likely to be incompatible with a full GARCH parameter estimation at infinite time.

Once we have seen that the efficiency of QRC can be as good as desired by increasing the sequence length, we can focus on the parameters that control the finite-time prediction results. There are two main parameters that control the efficiency in this regime. The ones that set the long time scaling are those denoted by pp, while those responsible for the short-TT limit are denoted by cc in Eqs. [19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") to [23](https://arxiv.org/html/2602.15474v1#S6.E23 "Equation 23 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"). Our parameter estimates systematically indicate that, in all the problems treated, QRC beats classical methods at short TT while having lower efficiency in the long-TT limit.

## VII Conclusions

Our results indicate that QRC with Bose-Hubbard-type dynamics can be more efficient than classical algorithms solving problems in statistical inference in the regime of limited data. From the problems we analyzed, the GARCH problemâ€”explained in Sec. [II.3](https://arxiv.org/html/2602.15474v1#S2.SS3 "II.3 GARCH volatility estimation â€£ II Computational Problems â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")â€”is the most relevant one for financial forecasting. At the same time, it is the most difficult problem to solve due to data correlations and heavy tails. For this specific computational task, we obtained the clearest advantage of QRC with respect to its classical counterpart in the regime of limited information. This regime, where QRC outperforms the classical method, is particularly relevant. Indeed, one would like to have clear information about the GARCH volatility regime as soon as possible in order to optimize portfolio investments. We have obtained similar results for the other statistical inference tasks analyzed here, distribution discrimination and Student-t parameter estimation, for which QRC provided a quantum advantage in the limit of scarce information.

The above advantages have been obtained using artificially constrained reservoir dynamics. Indeed, our numerical computations have been performed using a cutoff in the bosonic occupancies in order to make the numerical simulation feasible. Taking into account the rather good efficiency of our *cut-off* QRC-based learning, we strongly believe that it is worth implementing the same algorithm on real superconducting hardware. Running our numerical algorithm on real quantum hardware will make it possible to access reservoirs with a much larger number of neurons. Shuch an increase in the number of neurons will likely to induce a change in the underlying reservoir dynamic. Indeed, we have discussed how the Bose-Hubbard model Eq. [11](https://arxiv.org/html/2602.15474v1#S3.E11 "Equation 11 â€£ III Architecture â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") may not capture the stronger non-linear evolution in the case of large bosonic cut-offs, as a full rotor model is likely to be needed.

In summary, we have laid the foundations for constructing analog superconducting circuits that can be used to implement QRC for statistical inference. This avenue of research offers many ingredients that can be added to our basic algorithm and to the experimental setup, potentially leading to improvements in QRC performance. As discussed in the previous paragraph, a larger Hilbert space would likely benefit QRC. On top of that, one could envision adding more nonlinearities to the reservoir dynamics, either by operating the Josephson junctions in a different regime or by incorporating a few additional superconducting islands with all-to-all couplings. Notice that all-to-all coupling naturally occurs in systems of capacitively connected superconducting islands due to the long-range character of the Coulomb interaction. All these directions are within the reach of experimentally available superconducting systems, which makes this an interesting topic to explore further.

## VIII Acknowledges

This work is part of the European Union NextGeneration EU/PRTR project ConsolidaciÃ³n Investigadora CNS2022-136025. M. P. acknowledges further support through grant no. PID2024-156340NB-I00 funded by Ministerio de Ciencia, InnovaciÃ³n y Universidades/Agencia Estatal de InvestigaciÃ³n (MICIU/AEI/10.13039/501100011033) and the European Regional Development Fund (ERDF). We gratefully acknowledge funding by the University of Warwickâ€™s International Partnership Fund 2024. The numerical computations were performed in the facilities of SupercomputaciÃ³n Castilla y LeÃ³n (SCAYLE).

## References

* [1]

  Paul Benioff.
  The computer as a physical system: A microscopic quantum mechanical hamiltonian model of computers as represented by turing machines.
  Journal of statistical physics, 22(5):563â€“591, 1980.
* [2]

  Richard P Feynman.
  Simulating physics with computers.
  In Feynman and computation, pages 133â€“153. cRc Press, 2018.
* [3]

  David P DiVincenzo.
  The physical implementation of quantum computation.
  Fortschritte der Physik: Progress of Physics, 48(9-11):771â€“783, 2000.
* [4]

  John Preskill.
  Quantum computing in the nisq era and beyond.
  Quantum, 2:79, 2018.
* [5]

  Peter W Shor.
  Algorithms for quantum computation: discrete logarithms and factoring.
  In Proceedings 35th annual symposium on foundations of computer science, pages 124â€“134. Ieee, 1994.
* [6]

  Lov K Grover.
  A fast quantum mechanical algorithm for database search.
  In Proceedings of the twenty-eighth annual ACM symposium on Theory of computing, pages 212â€“219, 1996.
* [7]

  A Yu Kitaev.
  Quantum measurements and the abelian stabilizer problem.
  arXiv preprint quant-ph/9511026, 1995.
* [8]

  Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J Love, AlÃ¡n Aspuru-Guzik, and Jeremy L Oâ€™brien.
  A variational eigenvalue solver on a photonic quantum processor.
  Nature communications, 5(1):4213, 2014.
* [9]

  Quantum error correction below the surface code threshold.
  Nature, 638(8052):920â€“926, 2025.
* [10]

  Tan He, Weiping Lin, Rui Wang, Yuan Li, Jiahao Bei, Jianbin Cai, Sirui Cao, Danning Chen, Kefu Chen, Xiawei Chen, et al.
  Experimental quantum error correction below the surface code threshold via all-microwave leakage suppression.
  Physical Review Letters, 135(26):260601, 2025.
* [11]

  Alec Eickbusch, Matt McEwen, Volodymyr Sivak, Alexandre Bourassa, Juan Atalaya, Jahan Claes, Dvir Kafri, Craig Gidney, Christopher W Warren, Jonathan Gross, et al.
  Demonstration of dynamic surface codes.
  Nature Physics, pages 1â€“8, 2025.
* [12]

  Joschka Roffe.
  Quantum error correction: an introductory guide.
  Contemporary Physics, 60(3):226â€“245, 2019.
* [13]

  Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio Boixo, Fernando GSL Brandao, David A Buell, et al.
  Quantum supremacy using a programmable superconducting processor.
  Nature, 574(7779):505â€“510, 2019.
* [14]

  Han-Sen Zhong, Hui Wang, Yu-Hao Deng, Ming-Cheng Chen, Li-Chao Peng, Yi-Han Luo, Jian Qin, Dian Wu, Xing Ding, Yi Hu, et al.
  Quantum computational advantage using photons.
  Science, 370(6523):1460â€“1463, 2020.
* [15]

  Feng Pan, Keyang Chen, and Pan Zhang.
  Solving the sampling problem of the sycamore quantum circuits.
  Physical Review Letters, 129(9):090502, 2022.
* [16]

  Andrew M Childs and Wim Van Dam.
  Quantum algorithms for algebraic problems.
  Reviews of Modern Physics, 82(1):1â€“52, 2010.
* [17]

  Keisuke Fujii and Kohei Nakajima.
  Harnessing disordered-ensemble quantum dynamics for machine learning.
  Physical Review Applied, 8(2):024030, 2017.
* [18]

  Keisuke Fujii and Kohei Nakajima.
  Quantum reservoir computing: a reservoir approach toward quantum machine learning on near-term quantum devices.
  In Reservoir Computing: Theory, Physical Implementations, and Applications, pages 423â€“450. Springer, 2021.
* [19]

  Pere Mujal, Rodrigo MartÃ­nezâ€PeÃ±a, Johannes Nokkala, Jorge GarcÃ­aâ€Beni, Gian Luca Giorgi, Miguel C. Soriano, and Roberta Zambrini.
  Opportunities in quantum reservoir computing and extreme learning machines.
  Advanced Quantum Technologies, 4(8), June 2021.
* [20]

  Ana Palacios, Rodrigo Mart\Ìmathrm{i}nez-PeÃ±a, Miguel C Soriano, Gian Luca Giorgi, and Roberta Zambrini.
  Role of coherence in many-body quantum reservoir computing.
  Communications Physics, 7(1):369, 2024.
* [21]

  Jorge Garc\Ìmathrm{i}a-Beni, Gian Luca Giorgi, Miguel C Soriano, and Roberta Zambrini.
  Scalable photonic platform for real-time quantum reservoir computing.
  Physical Review Applied, 20(1):014051, 2023.
* [22]

  Guillem LlodrÃ , Pere Mujal, Roberta Zambrini, and Gian Luca Giorgi.
  Quantum reservoir computing in atomic lattices.
  Chaos, Solitons & Fractals, 195:116289, 2025.
* [23]

  Kevin Kirby.
  Context dynamics in neural sequential learning.
  In Proc. Florida AI Research Symposium (FLAIRS), volume 66, 1991.
* [24]

  Herbert Jaeger.
  The â€œecho stateâ€ approach to analysing and training recurrent neural networks-with an erratum note.
  Bonn, Germany: German national research center for information technology gmd technical report, 148(34):13, 2001.
* [25]

  Wolfgang Maass, Thomas NatschlÃ¤ger, and Henry Markram.
  Real-time computing without stable states: A new framework for neural computation based on perturbations.
  Neural computation, 14(11):2531â€“2560, 2002.
* [26]

  Jeffrey L Elman.
  Finding structure in time.
  Cognitive science, 14(2):179â€“211, 1990.
* [27]

  Sepp Hochreiter and JÃ¼rgen Schmidhuber.
  Long short-term memory.
  Neural computation, 9(8):1735â€“1780, 1997.
* [28]

  L. Domingo, G. Carlo, and F. Borondo.
  Taking advantage of noise in quantum reservoir computing.
  Scientific Reports, 13(1):8790, 2023.
* [29]

  Antonio Sannia, Rodrigo MartÃ­nez-PeÃ±a, Miguel C. Soriano, Gian Luca Giorgi, and Roberta Zambrini.
  Dissipation as a resource for Quantum Reservoir Computing.
  Quantum, 8:1291, March 2024.
* [30]

  Daniel Fry, Amol Deshmukh, Samuel Yen-Chi Chen, Vladimir Rastunkov, and Vanio Markov.
  Optimizing quantum noise-induced reservoir computing for nonlinear and chaotic time series prediction.
  Scientific Reports, 13(1):19326, 2023.
* [31]

  Johannes Nokkala.
  Online quantum time series processing with random oscillator networks.
  Scientific Reports, 13(1):7694, 2023.
* [32]

  Yudai Suzuki, Qi Gao, Ken C Pradel, Kenji Yasuoka, and Naoki Yamamoto.
  Natural quantum reservoir computing for temporal information processing.
  Scientific reports, 12(1):1353, 2022.
* [33]

  Wissal Hamhoum, Soumaya Cherkaoui, Jean-Frederic Laprade, Ola Ahmed, and Shengrui Wang.
  Multivariate time series forecasting with gate-based quantum reservoir computing on nisq hardware.
  arXiv preprint arXiv:2510.13634, 2025.
* [34]

  Pere Mujal, Rodrigo Mart\Ìmathrm{i}nez-PeÃ±a, Gian Luca Giorgi, Miguel C Soriano, and Roberta Zambrini.
  Time-series quantum reservoir computing with weak and projective measurements.
  npj Quantum Information, 9(1):16, 2023.
* [35]

  Aki Kutvonen, Keisuke Fujii, and Takahiro Sagawa.
  Optimizing a quantum reservoir computer for time series prediction.
  Scientific reports, 10(1):14687, 2020.
* [36]

  Qingyu Li, Chiranjib Mukhopadhyay, Abolfazl Bayat, and Ali Habibnia.
  Quantum reservoir computing for realized volatility forecasting.
  arXiv preprint arXiv:2505.13933, 2025.
* [37]

  Juan JosÃ© Garc\Ìmathrm{i}a Ripoll.
  Quantum information and quantum optics with superconducting circuits.
  Cambridge University Press, 2022.
* [38]

  Michel H Devoret and Robert J Schoelkopf.
  Superconducting circuits for quantum information: an outlook.
  Science, 339(6124):1169â€“1174, 2013.
* [39]

  Philip Krantz, Morten Kjaergaard, Fei Yan, Terry P Orlando, Simon Gustavsson, and William D Oliver.
  A quantum engineerâ€™s guide to superconducting qubits.
  Applied physics reviews, 6(2), 2019.
* [40]

  M. Pino, A. M. Tsvelik, and L. B. Ioffe.
  Unpaired majorana modes in josephson-junction arrays with gapless bulk excitations.
  Phys. Rev. Lett., 115:197001, Nov 2015.
* [41]

  Mark W Johnson, Mohammad HS Amin, Suzanne Gildert, Trevor Lanting, Firas Hamze, Neil Dickson, Richard Harris, Andrew J Berkley, Jan Johansson, Paul Bunyk, et al.
  Quantum annealing with manufactured spins.
  Nature, 473(7346):194â€“198, 2011.
* [42]

  Richard Harris, Yuki Sato, Andrew J Berkley, M Reis, Fabio Altomare, MH Amin, Kelly Boothby, P Bunyk, C Deng, Colin Enderud, et al.
  Phase transitions in a programmable quantum spin glass simulator.
  Science, 361(6398):162â€“165, 2018.
* [43]

  Andrew A Houck, Hakan E TÃ¼reci, and Jens Koch.
  On-chip quantum simulation with superconducting circuits.
  Nature Physics, 8(4):292â€“299, 2012.
* [44]

  Iulia M Georgescu, Sahel Ashhab, and Franco Nori.
  Quantum simulation.
  Reviews of Modern Physics, 86(1):153â€“185, 2014.
* [45]

  Omjyoti Dutta, Mariusz Gajda, Philipp Hauke, Maciej Lewenstein, Dirk-SÃ¶ren LÃ¼hmann, Boris A Malomed, Tomasz SowiÅ„ski, and Jakub Zakrzewski.
  Non-standard hubbard models in optical lattices: a review.
  Reports on Progress in Physics, 78(6):066001, 2015.
* [46]

  M Pino, J Prior, and SR Clark.
  Capturing the re-entrant behavior of one-dimensional boseâ€“hubbard model.
  physica status solidi (b), 250(1):51â€“58, 2013.
* [47]

  Rama Cont.
  Empirical properties of asset returns: stylized facts and statistical issues.
  Quantitative finance, 1(2):223, 2001.
* [48]

  Benoit Mandelbrot et al.
  The variation of certain speculative prices.
  Journal of business, 36(4):394, 1963.
* [49]

  Robert F Engle.
  Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation.
  Econometrica: Journal of the econometric society, pages 987â€“1007, 1982.
* [50]

  Tim Bollerslev.
  Generalized autoregressive conditional heteroskedasticity.
  Journal of econometrics, 31(3):307â€“327, 1986.
* [51]

  Ruey S Tsay.
  Analysis of financial time series.
  John wiley & sons, 2005.
* [52]

  Mar\Ìmathrm{i}a Hita-PÃ©rez, Gabriel JaumÃ , Manuel Pino, and Juan JosÃ© Garc\Ìmathrm{i}a-Ripoll.
  Ultrastrong capacitive coupling of flux qubits.
  Physical Review Applied, 17(1):014028, 2022.
* [53]

  Andrew A Houck, Jens Koch, Michel H Devoret, Steven M Girvin, and Robert J Schoelkopf.
  Life after charge noise: recent results with transmon qubits.
  Quantum Information Processing, 8(2):105â€“115, 2009.
* [54]

  Alexander PM Place, Lila VH Rodgers, Pranav Mundada, Basil M Smitham, Mattias Fitzpatrick, Zhaoqi Leng, Anjali Premkumar, Jacob Bryon, Andrei Vrajitoarea, Sara Sussman, et al.
  New material platform for superconducting transmon qubits with coherence times exceeding 0.3 milliseconds.
  Nature communications, 12(1):1779, 2021.
* [55]

  Marlan O Scully and M Suhail Zubairy.
  Quantum optics.
  Cambridge university press, 1997.
* [56]

  Manuel Pino, Lev B Ioffe, and Boris L Altshuler.
  Nonergodic metallic and insulating phases of josephson junction chains.
  Proceedings of the National Academy of Sciences, 113(3):536â€“541, 2016.
* [57]

  Oliver Morsch and Markus Oberthaler.
  Dynamics of bose-einstein condensates in optical lattices.
  Rev. Mod. Phys., 78:179â€“215, Feb 2006.
* [58]

  Julien Dudas, Baptiste Carles, Erwan Plouet, Frank Alice Mizrahi, Julie Grollier, and Danijela MarkoviÄ‡.
  Quantum reservoir computing implementation on coherently coupled quantum oscillators.
  npj Quantum Information, 9(1):64, 2023.
* [59]

  Julien Dudas, Julie Grollier, and Danijela MarkoviÄ‡.
  Coherently coupled quantum oscillators for quantum reservoir computing.
  In 2022 IEEE 22nd International Conference on Nanotechnology (NANO), pages 397â€“400. IEEE, 2022.
* [60]

  Lennert Appeltant, Miguel Cornelles Soriano, Guy Van der Sande, Jan Danckaert, Serge Massar, Joni Dambre, Benjamin Schrauwen, Claudio R Mirasso, and Ingo Fischer.
  Information processing using a single dynamical node as complex system.
  Nature communications, 2(1):468, 2011.
* [61]

  Daniel Brunner, Miguel C Soriano, Claudio R Mirasso, and Ingo Fischer.
  Parallel photonic information processing at gigabyte per second data rates using transient states.
  Nature communications, 4(1):1364, 2013.
* [62]

  Neill Lambert, Eric Giguâ€˜ere, Paul Menczel, Boxi Li, Patrick Hopf, Gerardo Suâ€™arez, Marc Gali, Jake Lishman, Rushiraj Gadhvi, Rochisha Agarwal, Asier Galicia, Nathan Shammah, Paul Nation, J. R. Johansson, Shahnawaz Ahmed, Simon Cross, Alexander Pitchford, and Franco Nori.
  Qutip 5: The quantum toolbox in Python.
  Physics Reports, 1153:1â€“62, 2026.
* [63]

  Soeren Ihssen, Simon Geisert, Gabriel Jauma, Patrick Winkel, Martin Spiecker, Nicolas Zapata, Nicolas Gosling, Patrick Paluch, Manuel Pino, Thomas Reisinger, et al.
  Low crosstalk modular flip-chip architecture for coupled superconducting qubits.
  Applied Physics Letters, 126(13), 2025.
* [64]

  Steven M Kay.
  Fundamentals of statistical signal processing: estimation theory.
  Prentice-Hall, Inc., 1993.
* [65]

  Erich Leo Lehmann and Joseph P Romano.
  Testing statistical hypotheses.
  Springer, 2005.
* [66]

  Tim Bollerslev.
  Generalized autoregressive conditional heteroskedasticity.
  Journal of Econometrics, 31(3):307â€“327, 1986.
* [67]

  Tim Bollerslev and Jeffrey M Wooldridge.
  Quasi-maximum likelihood estimation and inference in dynamic models with time-varying covariances.
  Econometric reviews, 11(2):143â€“172, 1992.
* [68]

  Ruey S. Tsay.
  Analysis of Financial Time Series.
  Wiley, 2010.
* [69]

  Chris Brooks.
  Introductory Econometrics for Finance.
  Cambridge University Press, 2019.
* [70]

  Rene Andrae, Tim Schulze-Hartung, and Peter Melchior.
  Dos and donâ€™ts of reduced chi-squared, 2010.

Supplemental Material for: Quantum Reservoir Computing for Statistical inference in a analog superconducting circuit

## S1 Fitting procedure

We explain the procedure used to fit data to the theoretical laws in each of the tasks described in the main body of the manuscript. The fits are performed in a weighted manner, using one-standard-deviation uncertainties to normalize the residuals. In practice, we followed two complementary procedures. First, we carried out a fit of the data to each of the candidate laws described above, Eqs. [19](https://arxiv.org/html/2602.15474v1#S6.E19 "Equation 19 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit"), [20](https://arxiv.org/html/2602.15474v1#S6.E20 "Equation 20 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") for classification tasks and Eqs. [21](https://arxiv.org/html/2602.15474v1#S6.E21 "Equation 21 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit")-[23](https://arxiv.org/html/2602.15474v1#S6.E23 "Equation 23 â€£ VI Results â€£ Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit") for parameter estimation. We then select the candidate whose reduced chi-squared Ï‡red2\chi^{2}\_{\rm red} is closest to unity. Second, to place the Ï‡red2\chi^{2}\_{\rm red}-based comparison on firmer statistical footing, we repeated the analysis using linearized weighted regressions. Note that the reduced chi-squared diagnostic is strictly justified for (weighted) linear least-squares models [[70](https://arxiv.org/html/2602.15474v1#bib.bib70)]. Both procedures led to consistent model and parameter estimates.

Let us explain in more depth the procedure for the linearized approach. We used a grid of values for a subset of the parameters. For each point of the grid, we performed a linear fit to extract the values of the other parameters and the Ï‡red2\chi\_{\rm red}^{2} of the fit. We then select the point of the grid that yields a Ï‡red2\chi\_{\rm red}^{2} closest to unity and report the value of the scanned parameters together with the uncertainties determined from the grid resolution. For instance, for the power law Aâ€‹(T)=Aâˆžâˆ’câ€‹Tâˆ’pA(T)=A\_{\infty}-c\,T^{-p}, we scan AâˆžA\_{\infty} and fit lnâ¡(Aâˆžâˆ’A)\ln(A\_{\infty}-A) versus lnâ¡T\ln T to extract (lnâ¡c,p)(\ln c,p) by weighted linear regression. For the stretched-exponential form Aâ€‹(T)=Aâˆžâˆ’câ€‹eâˆ’kâ€‹TpA(T)=A\_{\infty}-c\,e^{-kT^{p}}, we scan (Aâˆž,p)(A\_{\infty},p) and fit lnâ¡(Aâˆžâˆ’A)\ln(A\_{\infty}-A) versus TpT^{p} to extract (lnâ¡c,k)(\ln c,k). For the Student-t regression task, we fit the error curve RMSEâ€‹(T)\mathrm{RMSE}(T) for the target 1/Î½1/\nu. The power and log-power candidates are handled via weighted linear regression after taking logarithms, i.e. lnâ¡RMSE\ln\mathrm{RMSE} versus lnâ¡T\ln T and lnâ¡RMSE\ln\mathrm{RMSE} versus lnâ¡lnâ¡T\ln\ln T, respectively (yielding (lnâ¡c,p)(\ln c,p)), whereas the exponential-with-floor candidate RMSEâ€‹(T)=râˆž+câ€‹eâˆ’kâ€‹Tp\mathrm{RMSE}(T)=r\_{\infty}+c\,e^{-kT^{p}} is evaluated by scanning (râˆž,p)(r\_{\infty},p) and fitting lnâ¡(RMSEâˆ’râˆž)\ln(\mathrm{RMSE}-r\_{\infty}) versus TpT^{p} to obtain (lnâ¡c,k)(\ln c,k).

When fitting scaling laws to performance curves in the non-linear approach, we estimate parameters by weighted non-linear least squares (WLS), using residuals normalized by the reported Ïƒ\sigma uncertainties of each data point. Specifically, for observations yiy\_{i} at TiT\_{i} with error bars Ïƒi\sigma\_{i}, we minimize

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï‡2â€‹(ðœ½)=âˆ‘i[yiâˆ’fâ€‹(Ti;ðœ½)Ïƒi]2,\chi^{2}(\boldsymbol{\theta})=\sum\_{i}\left[\frac{y\_{i}-f(T\_{i};\boldsymbol{\theta})}{\sigma\_{i}}\right]^{2}, |  | (24) |

and report parameter uncertainties as Â±1â€‹Ïƒ\pm 1\sigma from the Gaussâ€“Newton (local linearization) approximation to the covariance at the optimum ðœ½^\hat{\boldsymbol{\theta}},

|  |  |  |  |
| --- | --- | --- | --- |
|  | Cov^â€‹(ðœ½^)â‰ˆÏ‡red2â€‹(JâŠ¤â€‹J)âˆ’1,\widehat{\mathrm{Cov}}(\hat{\boldsymbol{\theta}})\;\approx\;\chi^{2}\_{\rm red}\,\big(J^{\top}J\big)^{-1}, |  | (25) |

where JJ is the Jacobian of the normalized residual vector with respect to ðœ½\boldsymbol{\theta} evaluated at ðœ½^\hat{\boldsymbol{\theta}} and Ï‡red2=Ï‡2/dof\chi^{2}\_{\rm red}=\chi^{2}/{\rm dof}.
We report the results of these non-linear fits, as they are consistent with those obtained from the linearized approach described in the previous paragraph.