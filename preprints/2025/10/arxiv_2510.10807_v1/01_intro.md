---
authors:
- Ali Atiah Alzahrani
doc_id: arxiv:2510.10807v1
family_id: arxiv:2510.10807
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation
url_abs: http://arxiv.org/abs/2510.10807v1
url_html: https://arxiv.org/html/2510.10807v1
venue: arXiv q-fin
version: 1
year: 2025
---


Ali Atiah Alzahraniâˆ—
  
Public Investment Fund (PIF)â€ 

###### Abstract

We study whether regime-conditioned generative scenarios, coupled with a convex CVaR allocator, improve portfolio decisions under regime shifts. We introduce *Multi-Agent Regime-Conditioned Diffusion (MARCD)*, which (i) infers latent regimes via a Gaussian HMM, (ii) trains a diffusion model with a *tail-weighted* objective and a *regime-specialized MoE denoiser* to enrich crisis co-movements, and (iii) feeds the generated scenarios into a turnover-aware *CVaR epigraph QP* with explicit governance. In strict walk-forward tests on liquid multi-asset ETFs (2005â€“2025), MARCD outperforms standard allocators and improves calibration relative to popular generators. Over 2020â€“2025 out-of-sample (monthly; 10â€‰bps), MARCD attains *Sharpe* 1.23 (BL 1.02) and *MaxDD* 9.3% (BL 14.1%), a 34% reduction, at comparable turnover; stationary block-bootstrap intervals indicate the Sharpe uplift is significant at 5%. We provide theory linking tail-weighted diffusion to *spectral-risk control* of the decision-relevant CVaR gap, *oracle/consistency* results for the regime-MoE denoiser, and *Lipschitz/Regret* guarantees for the allocator. Together, MARCD offers a reproducible bridge from *tail-faithful scenario modeling* to *governed portfolio decisions* with materially improved drawdown control.

â€ â€ footnotetext: 
âˆ—Corresponding author: alialzahrani@pif.gov.sa
  
â€ The views expressed are those of the author and do not necessarily reflect the views
of the Public Investment Fund. This material is for research purposes only and
does not constitute investment advice.


Market data
(prices, factors)

Regime inference
(HMM / filters)

Regime-conditioned
diffusion generator
Tail-weighted loss (q,Î·)(q,\eta); Regime-MoE (gate gtg\_{t})

Signal extraction
(risk/alpha features)
Blend Î»\lambda: (Î¼^t,Î£^t)(\hat{\mu}\_{t},\hat{\Sigma}\_{t}); shrinkage

Allocation
(CVaR-QP, Î±=0.95\alpha{=}0.95)
box & turnover cap Ï„\tau;â€„ optional +Îºâ€‹â€–Î”â€‹wâ€–1+\kappa\|\Delta w\|\_{1}

Backtest
metrics
NN scenarios(Î¼^t,Î£^t)(\hat{\mu}\_{t},\hat{\Sigma}\_{t})trades, P&Lregime posteriors ğ…t\boldsymbol{\pi}\_{t}ScenarioSignalAllocation

Figure 1: Multi-Agent Regime-Conditioned Diffusion (MARCD).

## 1 Introduction

Financial returns are non-stationary, with abrupt regime changes (e.g., 2008, 2020, 2022) that challenge meanâ€“variance optimization (MVO) (Markowitz, [1952](https://arxiv.org/html/2510.10807v1#bib.bib15)) and Blackâ€“Litterman (BL) (Black and Litterman, [1992](https://arxiv.org/html/2510.10807v1#bib.bib3)). Modern generative modelsâ€”GANs (Yoon etÂ al., [2019](https://arxiv.org/html/2510.10807v1#bib.bib20)), diffusion (Rasul etÂ al., [2021](https://arxiv.org/html/2510.10807v1#bib.bib16)), transformers (Zhou etÂ al., [2023](https://arxiv.org/html/2510.10807v1#bib.bib21))â€”produce realistic sequences but are often unconditioned and decoupled from decisions. Large peak-to-trough losses are driven by left-tail co-movements that standard diffusion training (MSE) tends to underweight, and a single denoiser blurred across regimes can dilute crisis dynamics.

We refer to our method as *Multi-Agent Regime-Conditioned Diffusion (MARCD)* and use MARCD thereafter. MARCD aligns a diffusion generator to HMM posteriors while explicitly improving tail fidelity and crisis behavior: we employ a *tail-weighted* diffusion objective to emphasize adverse outcomes that govern realized drawdowns, and we augment the denoiser with a lightweight *regime expert* (mixture-of-experts) whose gate increases with the crisis posterior, enriching co-crash structure without degrading calm-regime fit. Generated scenarios feed a CVaR-focused, turnover-aware allocator within an auditable, walk-forward protocol.

Contributions. We integrate regime modeling, tail-aware generation, and robust allocation: (i) regime-conditioned diffusion aligned to HMM posteriors with a tail-weighted training objective that improves left-tail dependence; (ii) a regime-aware expert denoiser (MoE) that specializes to high-volatility states via learned gating; (iii) a multi-agent pipeline translating samples to decisions; and (iv) a CVaR-focused allocation with turnover control and explicit governance (walk-forward, constraints).

## 2 Related Work

Regimes. HMMs capture structural breaks and state dependence (Hamilton, [1989](https://arxiv.org/html/2510.10807v1#bib.bib7); Kim and Nelson, [1994](https://arxiv.org/html/2510.10807v1#bib.bib10); Ang and Timmermann, [2012](https://arxiv.org/html/2510.10807v1#bib.bib1)); we use their posteriors as conditioning signals for both generation and allocation. Generative time series. GAN- and VAE-based generators (e.g., TimeGAN and TimeVAE) and diffusion models improve realism and calibration (Yoon etÂ al., [2019](https://arxiv.org/html/2510.10807v1#bib.bib20); Desai etÂ al., [2021](https://arxiv.org/html/2510.10807v1#bib.bib5); Rasul etÂ al., [2021](https://arxiv.org/html/2510.10807v1#bib.bib16); Tashiro etÂ al., [2021](https://arxiv.org/html/2510.10807v1#bib.bib19)), yet are often unconditioned and loosely coupled to portfolio decisions; recent TS diffusions (*TSDiff*, *mr-Diff*) and a finance simulator (*CTS-GAN*) are complementary to our regime-conditioned, decision-tied approach (Kollovieh etÂ al., [2023](https://arxiv.org/html/2510.10807v1#bib.bib11); Shen etÂ al., [2024](https://arxiv.org/html/2510.10807v1#bib.bib18); Istiaque etÂ al., [2024](https://arxiv.org/html/2510.10807v1#bib.bib9)). Robust portfolios. Distributionally robust and CVaR formulations address fat tails (Delage and Ye, [2010](https://arxiv.org/html/2510.10807v1#bib.bib4); Rockafellar and Uryasev, [2000](https://arxiv.org/html/2510.10807v1#bib.bib17)) but hinge on scenario quality; we feed a regime-conditioned set into a convex allocator. Multi-agent. Building on coordination frameworks (Lowe etÂ al., [2017](https://arxiv.org/html/2510.10807v1#bib.bib14)), we orchestrate Scenarioâ†’\toSignalâ†’\toAllocation with light, role-based agents. Sequence models. LSTMs (Hochreiter and Schmidhuber, [1997](https://arxiv.org/html/2510.10807v1#bib.bib8); Fischer and Krauss, [2018](https://arxiv.org/html/2510.10807v1#bib.bib6)), TCNs (Bai etÂ al., [2018](https://arxiv.org/html/2510.10807v1#bib.bib2)), and Transformers (Lim etÂ al., [2021](https://arxiv.org/html/2510.10807v1#bib.bib13)) remain standard forecasters; we treat point-forecast models as standard baselines, focusing instead on regime-conditioned *distributional* generation wired to a convex CVaR allocator under strict walk-forward evaluation.

## 3 Methodology

Setup.
At rebalancing date tt, let ğ‘tâˆˆâ„d\mathbf{R}\_{t}\in\mathbb{R}^{d} denote the observed return vector and ğ°tâˆˆâ„d\mathbf{w}\_{t}\in\mathbb{R}^{d} the portfolio weights, which satisfy

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğŸâŠ¤â€‹ğ°t=1,â„“â‰¤ğ°tâ‰¤ğ’–.\mathbf{1}^{\top}\mathbf{w}\_{t}=1,\qquad\boldsymbol{\ell}\leq\mathbf{w}\_{t}\leq\boldsymbol{u}. |  | (1) |

Market regimes are modeled by a KK-state Gaussian HMM with latent state StS\_{t} and posterior vector ğ…t\boldsymbol{\pi}\_{t}, where Ï€t,k=Pâ€‹(St=kâˆ£ğ‘1:t)\pi\_{t,k}=P(S\_{t}{=}k\mid\mathbf{R}\_{1:t}). The generator produces NN next-period scenarios {ğ«t+1(i)}i=1N\{\mathbf{r}^{(i)}\_{t+1}\}\_{i=1}^{N}. Turnover is Ï„t=â€–ğ°tâˆ’ğ°tâˆ’1â€–1\tau\_{t}=\|\mathbf{w}\_{t}-\mathbf{w}\_{t-1}\|\_{1}. To avoid notation overload, we reserve Î±s\alpha\_{s} for the diffusion schedule and Î±\alpha for the allocatorâ€™s CVaR level, use Î»\lambda for scenario blending, and Î»Î¼\lambda\_{\mu} for the expected-return weight in the allocator.

### 3.1 Method Overview and Rationale

Our objective is to reduce pathwise drawdowns while preserving risk-adjusted return under strict walk-forward governance. We posit that returns exhibit regime-dependent higher-order dependence and that left-tail comovements matter more for realized drawdowns than central calibration. Accordingly, we bias generation toward adverse outcomes, make the generator responsive to regime signals, and align the allocator with tail-focused yet convex objectives that remain auditable and turnover-aware. Concretely, this yields a tail-weighted diffusion objective to improve co-crash fidelity, a regime-aware denoiser that specializes to high-volatility episodes, and a spectral CVaR allocator with a simple regime-adaptive risk throttle.

Core training setup.
UNet (8 stages, base ch.=64), cosine noise schedule, Ïµ\epsilon-prediction, EMA=0.999=0.999;
AdamW 1â€‹eâˆ’41\mathrm{e}{-4}; batch 256256; 250250k steps; seed 20202020.

### 3.2 Regime Detection (strict walk-forward)

We fit/update a KK-state Gaussian HMM on {ğ‘s}sâ‰¤t\{\mathbf{R}\_{s}\}\_{s\leq t} and extract posteriors Ï€t,k=Pâ€‹(St=kâˆ£ğ‘1:t)\pi\_{t,k}=P(S\_{t}{=}k\mid\mathbf{R}\_{1:t}).
Conditioning features ğ’›t\boldsymbol{z}\_{t} encode regime context (e.g., argâ¡maxkâ¡Ï€t,k\arg\max\_{k}\pi\_{t,k} and recent statistics). All estimation is strict walk-forward: only data up to tt is used; HMM parameters refresh on a rolling window.

### 3.3 Regime-Conditioned Diffusion

We train a variance-preserving diffusion model to denoise ğ±s\mathbf{x}\_{s} with regime context ğ’›t\boldsymbol{z}\_{t}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | qâ€‹(ğ±sâˆ£ğ±0)=ğ’©â€‹(Î±sâ€‹ğ±0,(1âˆ’Î±s)â€‹ğˆ),â„’diff=ğ”¼â€‹â€–Ïµâˆ’ÏµÎ¸â€‹(Î±sâ€‹ğ±0+1âˆ’Î±sâ€‹Ïµ,s,ğ’›t)â€–2.\displaystyle q(\mathbf{x}\_{s}\mid\mathbf{x}\_{0})=\mathcal{N}\!\big(\sqrt{\alpha\_{s}}\mathbf{x}\_{0},(1{-}\alpha\_{s})\mathbf{I}\big),\quad\mathcal{L}\_{\text{diff}}=\mathbb{E}\big\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}\_{\theta}(\sqrt{\alpha\_{s}}\mathbf{x}\_{0}+\sqrt{1{-}\alpha\_{s}}\boldsymbol{\epsilon},s,\boldsymbol{z}\_{t})\big\|^{2}. |  | (2) |

*Implementation.* We use a conditional DDPM with a UNet-style denoiser (4 down/4 up blocks), a cosine noise schedule, exponential moving average (EMA) of weights, and â‰ˆ\approx1â€“2M parameters; conditioning is via the regime embedding ğ’›t\boldsymbol{z}\_{t} injected at each block.

At deployment time tt we sample NN returns {ğ«t+1(i)}\{\mathbf{r}^{(i)}\_{t+1}\} conditioned on ğ’›t\boldsymbol{z}\_{t}. The Signal Agent forms blended moments

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ^t=Î»â€‹ğsynth+(1âˆ’Î»)â€‹ğhist,ğšº^t=Î»â€‹ğšºsynth+(1âˆ’Î»)â€‹ğšºhist.\displaystyle\hat{\boldsymbol{\mu}}\_{t}=\lambda\,\boldsymbol{\mu}\_{\text{synth}}+(1{-}\lambda)\boldsymbol{\mu}\_{\text{hist}},\qquad\hat{\boldsymbol{\Sigma}}\_{t}=\lambda\,\boldsymbol{\Sigma}\_{\text{synth}}+(1{-}\lambda)\boldsymbol{\Sigma}\_{\text{hist}}. |  | (3) |

### 3.4 Allocation Agent: CVaR Epigraph Program and Properties

Define per-scenario loss â„“i=âˆ’ğ°âŠ¤â€‹ğ«t+1(i)\ell\_{i}=-\,\mathbf{w}^{\top}\mathbf{r}^{(i)}\_{t+1}. We solve the convex program

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | minğ°,Î¶,{si}\displaystyle\min\_{\mathbf{w},\,\zeta,\,\{s\_{i}\}}\; | âˆ’Î»Î¼â€‹ğ^tâŠ¤â€‹ğ°+Î³â€‹ğ°âŠ¤â€‹ğšº^tâ€‹ğ°+Î¶+1(1âˆ’Î±)â€‹Nâ€‹âˆ‘i=1Nsi\displaystyle-\lambda\_{\mu}\,\hat{\boldsymbol{\mu}}\_{t}^{\top}\mathbf{w}+\gamma\,\mathbf{w}^{\top}\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w}+\zeta+\frac{1}{(1-\alpha)N}\sum\_{i=1}^{N}s\_{i} |  | (4) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | s.t. | siâ‰¥0,siâ‰¥â„“iâˆ’Î¶,i=1,â€¦,N,\displaystyle s\_{i}\geq 0,\;s\_{i}\geq\ell\_{i}-\zeta,\;i=1,\dots,N, |  | (5) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | ğŸâŠ¤â€‹ğ°=1,â„“â‰¤ğ°â‰¤ğ®box,â€–ğ°âˆ’ğ°tâˆ’1â€–1â‰¤Ï„.\displaystyle\mathbf{1}^{\top}\mathbf{w}=1,\;\;\boldsymbol{\ell}\leq\mathbf{w}\leq\mathbf{u}^{\text{box}},\;\;\|\mathbf{w}-\mathbf{w}\_{t-1}\|\_{1}\leq\tau. |  | (6) |

When used, we add a turnover penalty +Îºâ€‹â€–ğ°âˆ’ğ°tâˆ’1â€–1+\kappa\|\mathbf{w}-\mathbf{w}\_{t-1}\|\_{1}.

Convexity/complexity. The objective combines a quadratic term ğ°âŠ¤â€‹ğšº^tâ€‹ğ°\mathbf{w}^{\top}\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w} with the convex CVaR epigraph; constraints are affine, yielding a QP with Oâ€‹(N)O(N) linear epigraph constraints. For d=10d{=}10 and N=1024N{=}1024, interior-point methods scale as Oâ€‹(d3+Nâ€‹d2)O(d^{3}+Nd^{2}) and run fast on commodity CPUs. Unless stated otherwise, the CVaR level is Î±=0.95\alpha{=}0.95. We shrink ğšº^t\hat{\boldsymbol{\Sigma}}\_{t} toward the identity to obtain a well-conditioned covariance matrix (Ledoit and Wolf, [2004](https://arxiv.org/html/2510.10807v1#bib.bib12)).

#### Note.

We use the standard Rockafellarâ€“Uryasev CVaR at level Î±\alpha in all experiments; spectral risk measures are left to future work.

> Governance & Auditability.
> The allocatorâ€™s KKT system (App.Â A.3) logs active constraints, tail weights,
> and duals at each rebalance. This yields solver-side audit trails linking regime
> posteriors and tail emphasis to realized tradesâ€”important for model risk and compliance.

Algorithm 1  Walk-forward regime-conditioned decision pipeline

0:â€„â€Šassets dd, states KK, scenarios NN, CVaR level Î±\alpha, bounds (â„“,ğ’–)(\boldsymbol{\ell},\boldsymbol{u}), turnover cap Ï„\tau, blend Î»\lambda, regs (Î³,Î»Î¼)(\gamma,\lambda\_{\mu})

1:â€„â€ŠInitialize ğ°t0\mathbf{w}\_{t\_{0}} (e.g., equal-weight)

2:â€„â€Šfor t=t0,â€¦,tendt=t\_{0},\dots,t\_{\text{end}} do

3:â€ƒâ€„â€ŠRegime update: fit/update HMM on {ğ‘s}sâ‰¤t\{\mathbf{R}\_{s}\}\_{s\leq t}; compute Ï€t,â‹…\pi\_{t,\cdot} and ğ’›t\boldsymbol{z}\_{t}

4:â€ƒâ€„â€ŠScenario gen: draw {ğ«t+1(i)}i=1Nâˆ¼pÎ¸(â‹…âˆ£ğ’›t)\{\mathbf{r}^{(i)}\_{t+1}\}\_{i=1}^{N}\sim p\_{\theta}(\cdot\mid\boldsymbol{z}\_{t})

5:â€ƒâ€„â€ŠSignals: form (ğ^t,ğšº^t)(\hat{\boldsymbol{\mu}}\_{t},\hat{\boldsymbol{\Sigma}}\_{t}) via blending with weight Î»\lambda

6:â€ƒâ€„â€ŠAllocation: solve (4) for ğ°t\mathbf{w}\_{t} with (â„“,ğ’–,Ï„)(\boldsymbol{\ell},\boldsymbol{u},\tau); optionally include cost penalty Îºâ€‹â€–ğ°tâˆ’ğ°tâˆ’1â€–1\kappa\|\mathbf{w}\_{t}{-}\mathbf{w}\_{t-1}\|\_{1}

7:â€ƒâ€„â€ŠTrade from ğ°tâˆ’1\mathbf{w}\_{t-1} to ğ°t\mathbf{w}\_{t}; record turnover; log diagnostics for auditability

8:â€„â€Šend for

### 3.5 Tail-Weighted Diffusion Loss

We avoid target leakage by using a *portfolio-free* proxy for adverse outcomes during training. Define the worst single-asset one-step loss
â„“~=âˆ’minjâ¡rj\tilde{\ell}=-\min\_{j}r\_{j} and reweight errors when â„“~\tilde{\ell} falls in its lower qq-quantile:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„’tail=ğ”¼â€‹[(1+Î·â€‹â€‰1â€‹{â„“~â‰¤Qqâ€‹(â„“~)})â€‹â€–ğœºâˆ’ğœºÎ¸â€‹(â‹…)â€–22],qâˆˆ[0.05,0.10],Î·âˆˆ[1,3].\mathcal{L}\_{\text{tail}}=\mathbb{E}\!\left[\bigl(1+\eta\,\mathbf{1}\{\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\}\bigr)\,\|\boldsymbol{\varepsilon}-\boldsymbol{\varepsilon}\_{\theta}(\cdot)\|\_{2}^{2}\right],\qquad q\!\in\![0.05,0.10],~\eta\!\in\![1,3]. |  | (7) |

At deployment (allocation), portfolio losses use â„“=âˆ’ğ°âŠ¤â€‹ğ«\ell=-\mathbf{w}^{\top}\mathbf{r} only for evaluation/diagnostics.

### 3.6 Regime-MoE Denoiser

We instantiate a two-expert denoiser with a crisis head specialized to high-volatility regimes.
A gate gt=Ïƒâ€‹(MLPâ€‹(ğ³t))g\_{t}=\sigma(\mathrm{MLP}(\mathbf{z}\_{t})) mixes experts:
Ïµ^Î¸=(1âˆ’gt)â€‹Ïµ^Î¸base+gtâ€‹Ïµ^Î¸crisis\hat{\epsilon}\_{\theta}=(1-g\_{t})\,\hat{\epsilon}^{\text{base}}\_{\theta}+g\_{t}\,\hat{\epsilon}^{\text{crisis}}\_{\theta}.
At sampling, gtg\_{t} increases with the HMM crisis posterior, enriching co-crash structure.

### 3.7 Theory Highlights

Takeaways (statements; proofs in App.Â A).

###### Theorem 1 (Spectral CVaR Control by Tail-Weighted Diffusion; App.Â A.11).

Minimizing LtailL\_{\text{tail}} in Eq.Â (7) controls a spectral-risk upper bound on the
*decision-relevant* CVaR generalization gap for any feasible portfolio ww,
scaling with (1âˆ’Î±)âˆ’1(1-\alpha)^{-1} and the denoising error on the lower-qq tail.

###### Theorem 2 (MoE Oracle, Consistency & Stability; App.Â A.13).

With a gate monotone in the HMM crisis posterior (Sec.Â 3.6),
the regime-MoE enjoys an oracle excess-risk bound, gate-consistency under a calibrated
surrogate, and Lipschitz stability of the DDPM reverse dynamics.

###### Theorem 3 (Allocator Lipschitzness & Regret; App.Â A.14).

The CVaR epigraph QP (Sec.Â 3.4) has a Lipschitz solution map in (Î¼,Î£)(\mu,\Sigma) and
admits a decision-regret bound under moment and CVaR perturbations; the CVaR error
term shrinks with LtailL\_{\text{tail}}.

## 4 Experimental setup

Assets & horizon. Ten liquid ETFs; daily 2005â€“2025; splits: 2005â€“2018 train, 2019 val, 2020â€“2025 test.
Data. Daily total returns computed from Yahoo Finance *Adjusted Close* (dividends included).
Baselines. EW, RP, BL; monthly rebal.; 10â€‰bps costs (identical across methods). Allocator parity.
All strategies (EW, RP, BL, MARCD) rebalance monthly on the last trading day, incur identical transaction costs of 10â€‰bps per trade, and are subject to the same turnover controls
(an â„“1\ell\_{1} cap â€–ğ°tâˆ’ğ°tâˆ’1â€–1â‰¤0.20\|\mathbf{w}\_{t}{-}\mathbf{w}\_{t-1}\|\_{1}\!\leq\!0.20; no penalty, Îº=0\kappa{=}0, unless stated otherwise),
as well as the same box and leverage constraints. Baselines form their *unconstrained* targets (EW, RP equal risk contributions, BL no-views prior anchored to a cap-weighted market proxy with standard Ï„\tau (confidence) and ğ›€\boldsymbol{\Omega} (uncertainty) settings) and then apply the *same partial-rebalance projection* toward target under the â„“1\ell\_{1} cap.
Diagnostics. KS, ES, VS; LB pâ€‹(|r|)p(|r|); VaR0.95 unconditional coverage (Kupiec UC) pp; CVaR0.95 error (â€‰bps). KS is averaged across assets; ES/VS are multivariate; CVaR error is an absolute calibration error reported in basis points. We also include a stationary block bootstrap (SBB) generator as a nonparametric baseline for scenario diagnostics.
Metrics. Return=CAGR; rf=0; 252-day annualization; Sortino uses downside dev. to 0%; Calmar=Return/|MaxDD||\mathrm{MaxDD}|.
Protocol. Strict walk-forward; HMM 3y rolling; scenarios conditioned on ğ’›t\boldsymbol{z}\_{t}; CVaR-QP allocation.

## 5 Results and discussion

Diagnosticsâ€” All results use *monthly* rebalancing on the last trading day, 10â€‰bps trading cost, and the metric conventions above. Under strict walk-forward (2020â€“2025), MARCD shows stronger scenario calibration (â†“KS/ES/VS; LB/UC pp competitive, slightly below TimeVAE). See TableÂ [1](https://arxiv.org/html/2510.10807v1#S5.T1 "Table 1 â€£ 5 Results and discussion â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation").

Performanceâ€” MARCD attains higher risk-adjusted performance (Sharpe 1.23 vs. 1.02 for BL) with materially smaller drawdowns. Summary metrics are reported in TableÂ [2](https://arxiv.org/html/2510.10807v1#S5.T2 "Table 2 â€£ 5 Results and discussion â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation"), and trajectories are visualized in FigureÂ [2](https://arxiv.org/html/2510.10807v1#S5.F2 "Figure 2 â€£ 5 Results and discussion â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation"). Over 2020â€“2025 OOS, MaxDD is 9.3% for MARCD vs BL 14.1% and EW 21.2% (34%/56% lower; absolute 4.8%/11.9%). Consistent with this, Calmar improves to 1.11 (BL 0.70; EW 0.38). A stationary block bootstrap (B=1000B{=}1000, block =20=20) indicates MARCDâ€™s Sharpe exceeds BL/EW (two-sided p<0.05p{<}0.05); CVaR0.95\mathrm{CVaR}\_{0.95} and MaxDD also improve at similar turnover. In stress windowsâ€”COVID-19 (Febâ€“Apr 2020) and the 2022 inflation shock (Junâ€“Oct 2022)â€”MARCDâ€™s drawdowns are smaller than BL/EW. Removing regime conditioning lowers crisis Sharpe and weakens VaR coverage; dropping the CVaR term raises 95%-CVaR and MaxDD, indicating complementary benefits.

Table 1: OOS scenario diagnostics. Lower is better (â†“) except pp (â†‘); LB on |r||r|. Abbrev.: SBB=Stationary block bootstrap; TGAN=TimeGAN.

| Model | KSâ†“\downarrow | ESâ†“\downarrow | VSâ†“\downarrow | LB pâ€‹(|r|)â†‘p(|r|)\uparrow | VaR0.95 UC pâ†‘p\uparrow | CVaR0.95 err (bps)â†“\downarrow |
| --- | --- | --- | --- | --- | --- | --- |
| SBB | 0.196 | 0.358 | 0.329 | 0.22 | 0.11 | 39 |
| TGAN | 0.182 | 0.341 | 0.312 | 0.28 | 0.16 | 33 |
| TimeVAE | 0.159 | 0.305 | 0.268 | 0.52 | 0.63 | 17 |
| MARCD | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 | 15 |

![Refer to caption](pic.png)


Figure 2: OOS cumulative NAV, drawdown, and HMM regime posteriors (K=3K{=}3).

Sensitivity & robustnessâ€” Results are stable across blend weights Î»âˆˆ[0.3,0.7]\lambda\!\in\![0.3,0.7] and CVaR trade-off Î³âˆˆ[0.5,1.5]\gamma\!\in\![0.5,1.5]; MARCD maintains Sharpe above BL and lower MaxDD at similar turnover. Performance remains robust under modest transaction-cost stress (e.g., doubled â€‰bps) and when the turnover cap is varied within a reasonable band, indicating the gains are not due to a narrow hyperparameter choice.

Table 2: Out-of-sample performance (2020â€“2025; monthly rebal.; annualized; net of 10â€‰bps). Higher is better (â†‘) except Vol and MaxDD (â†“). MaxDD is reported as a positive magnitude.

| Strategy | Return %â†‘\uparrow | Vol %â†“\downarrow | Sharpeâ†‘\uparrow | Sortinoâ†‘\uparrow | MaxDD %â†“\downarrow | Calmarâ†‘\uparrow |
| --- | --- | --- | --- | --- | --- | --- |
| EW | 8.1 | 11.2 | 0.72 | 1.09 | 21.2 | 0.38 |
| RP | 7.6 | 8.6 | 0.88 | 1.37 | 14.9 | 0.51 |
| BL | 9.9 | 9.7 | 1.02 | 1.50 | 14.1 | 0.70 |
| MARCD | 10.3 | 8.4 | 1.23 | 1.69 | 9.3 | 1.11 |

## 6 Ablations and Component Analyses

Summary. Removing either *regime conditioning* or the *CVaR term* weakens tail control and calibration, and pushing the blend to the extremes (Î»=0\lambda{=}0 or 11) underperforms the base mix. Concretely, TableÂ [3](https://arxiv.org/html/2510.10807v1#S6.T3 "Table 3 â€£ 6 Ablations and Component Analyses â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation") shows Sharpe falling from 1.23 (base) to 1.12\mathbf{1.12}â€“1.13\mathbf{1.13} for all ablations, while MaxDD rises from 9.3% to 11.3% (uncond. diffusion), 14.6% (no CVaR), 12.1% (Î»=0\lambda{=}0), and 12.8% (Î»=1\lambda{=}1)â€”i.e., +2.0%â€“5.3% absolute (+21â€“57% relative). Calibration also degrades: the VaR0.95 UC pp drops from 0.58 to 0.490.49, 0.460.46, 0.520.52, and 0.480.48, and the CVaR0.95\mathrm{CVaR}\_{0.95} error increases from 15 to 2222, 2727, 2121, and 2424, respectively. Volatility rises (8.4â†’\rightarrow8.6â€“9.1) and returns slip (10.3â†’\rightarrow9.7â€“10.1), while turnover remains similar (15.3â€“15.9%). Overall, MARCD (base) is strongest across risk/return and tail-calibration columns; FigureÂ [3](https://arxiv.org/html/2510.10807v1#S6.F3 "Figure 3 â€£ 6 Ablations and Component Analyses â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation") visualizes these degradations in both performance and diagnostics.

Table 3: Ablations (OOS 2020â€“2025; annualized; net 10â€‰bps). Higher is better except Vol, MaxDD.

Variant
Return %â†‘
Vol %â†“
Sharpeâ†‘
MaxDD %â†“
VaR0.95 UC ppâ†‘
CVaR0.95 errâ†“
Turnover %


MARCD (base)
10.3
8.4
1.23
9.3
0.58
15
15.8

Uncond. diffusion
9.8
8.7
1.13
11.3
0.49
22
15.4

No CVaR term
10.1
9.1
1.12
14.6
0.46
27
15.6

Î»=0.0\lambda{=}0.0
9.7
8.6
1.13
12.1
0.52
21
15.3

Î»=1.0\lambda{=}1.0
9.9
8.8
1.12
12.8
0.48
24
15.9

![Refer to caption](ablations.png)


Figure 3: Ablationsâ€”performance and diagnostic metrics across variants (OOS 2020â€“2025).

## 7 Sensitivity Studies

Summary. One-parameter sweeps over K,Î±,Î»,Ï„K,\alpha,\lambda,\tau show stable realism (KS/ES/VS) and calibration (pp-values â‰ˆ0.5\approx 0.5â€“0.60.6), with K=3K{=}3 and Î±=0.95\alpha{=}0.95 typically strongest. Diagnostics remain tight across settings in TableÂ [4](https://arxiv.org/html/2510.10807v1#S7.T4 "Table 4 â€£ 7 Sensitivity Studies â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation"), while predictable riskâ€“return trade-offs appear in TableÂ [5](https://arxiv.org/html/2510.10807v1#S7.T5 "Table 5 â€£ 7 Sensitivity Studies â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation") (e.g., higher Î±\alpha lowers Vol/MaxDD with modest Sharpe changes; turnover responds primarily to Ï„\tau). The base setting sits near the Pareto front for both realism and performance.

Table 4: Diagnostics under parameter sweeps (OOS 2020â€“2025). Lower is better (â†“) except pp (â†‘).

| Parameter | Value | KSâ†“ | ESâ†“ | VSâ†“ | LB pâ€‹(|r|)p(|r|)â†‘ | VaR0.95 UC ppâ†‘ |
| --- | --- | --- | --- | --- | --- | --- |
| Base | â€“ | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 |
| KK | 2 | 0.156 | 0.295 | 0.251 | 0.46 | 0.54 |
| KK | 3 | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 |
| KK | 4 | 0.160 | 0.292 | 0.249 | 0.49 | 0.59 |
| Î±\alpha | 0.90 | 0.157 | 0.293 | 0.251 | 0.48 | 0.55 |
| Î±\alpha | 0.95 | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 |
| Î±\alpha | 0.99 | 0.159 | 0.292 | 0.248 | 0.51 | 0.61 |
| Î»\lambda | 0.30 | 0.156 | 0.291 | 0.248 | 0.49 | 0.57 |
| Î»\lambda | 0.50 | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 |
| Î»\lambda | 0.70 | 0.155 | 0.289 | 0.248 | 0.49 | 0.58 |
| Ï„\tau | 0.10 | 0.156 | 0.290 | 0.248 | 0.50 | 0.58 |
| Ï„\tau | 0.20 | 0.154 | 0.289 | 0.247 | 0.50 | 0.58 |




Table 5: Performance under parameter sweeps (annualized; net 10â€‰bps).

| Parameter | Value | Return %â†‘ | Vol %â†“ | Sharpeâ†‘ | MaxDD %â†“ | Turnover % |
| --- | --- | --- | --- | --- | --- | --- |
| Base | â€“ | 10.3 | 8.4 | 1.23 | 9.3 | 15.8 |
| KK | 2 | 9.9 | 8.6 | 1.15 | 11.8 | 9.3 |
| KK | 4 | 10.1 | 8.5 | 1.19 | 11.2 | 11.2 |
| Î±\alpha | 0.90 | 10.6 | 9.2 | 1.15 | 11.4 | 16.0 |
| Î±\alpha | 0.99 | 9.7 | 7.8 | 1.19 | 10.0 | 15.2 |
| Î»\lambda | 0.30 | 10.1 | 8.5 | 1.19 | 11.3 | 15.4 |
| Î»\lambda | 0.70 | 10.2 | 8.6 | 1.18 | 11.5 | 16.1 |
| Ï„\tau | 0.10 | 10.0 | 8.3 | 1.20 | 11.1 | 10.2 |
| Ï„\tau | 0.30 | 10.5 | 8.6 | 1.22 | 11.0 | 21.7 |

## 8 Model Selection and Significance

Summary. Rolling BIC favors K=3K{=}3 and this choice attains the best OOS Sharpe with competitive MaxDD and VaR coverage. TableÂ [6](https://arxiv.org/html/2510.10807v1#S8.T6 "Table 6 â€£ 8 Model Selection and Significance â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation") reports the BIC deltas alongside OOS outcomes across Kâˆˆ{2,3,4}K\in\{2,3,4\}. Stationary block-bootstrap intervals (TableÂ [7](https://arxiv.org/html/2510.10807v1#S8.T7 "Table 7 â€£ 8 Model Selection and Significance â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) indicate MARCDâ€™s Sharpe uplift versus EW/BL/RP is significant at the 5% level.

Table 6: HMM selection (rolling BIC) and OOS outcomes (2020â€“2025).

| KK | Î”\DeltaBIC (vs. 3) | Sharpeâ†‘ | MaxDD %â†“ | VaR0.95 UC ppâ†‘ |
| --- | --- | --- | --- | --- |
| 2 | +18+18 | 1.15 | 11.8 | 0.54 |
| 3 | 0 | 1.23 | 9.3 | 0.58 |
| 4 | +9+9 | 1.19 | 11.2 | 0.59 |




Table 7: Sharpe uplift Î”\Delta (MARCD âˆ’- baseline), 95% CIs (OOS 2020â€“2025).

| Baseline | Î”\Delta | 95% CI |
| --- | --- | --- |
| EW | 0.510.51 | [0.31,â€„0.71][0.31,\;0.71] |
| BL | 0.210.21 | [0.07,â€„0.35][0.07,\;0.35] |
| RP | 0.350.35 | [0.18,â€„0.51][0.18,\;0.51] |

## 9 Application Profiles (overview)

Summary. The five profiles trace clear riskâ€“return trade-offs: Conservative minimizes Vol and maximizes Calmar; Crisis-Focused achieves the lowest MaxDD; Aggressive maximizes return; Balanced and Momentum sit between, with diagnostics remaining competitive. FigureÂ [4](https://arxiv.org/html/2510.10807v1#S9.F4 "Figure 4 â€£ 9 Application Profiles (overview) â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation") summarizes profile-level performance and diagnostics to facilitate side-by-side comparison.

![Refer to caption](profiles.png)


Figure 4: Profilesâ€”performance and diagnostics summary (OOS 2020â€“2025).

## 10 Conclusion

We presented MARCD, a regime-conditioned generative-to-decision pipeline that couples an HMM-aligned diffusion generator with a CVaR-focused, turnover-aware allocator under strict walk-forward governance. Two additionsâ€”a *tail-weighted* diffusion objective and a *regime expert* (MoE) denoiserâ€”improve left-tail co-movements and crisis fidelity in the scenarios. Empirically (OOS 2020â€“2025; monthly; net 10â€‰bps), these changes *reduce MaxDD by 34.1% at comparable Sharpe and turnover*, and deliver a higher Calmar ratio, indicating more robust peak-to-trough behavior.

*Limitations.* Our study uses 10 liquid ETFs, a single OOS window, and monthly rebalancing with a simplified execution model (fixed 10â€‰bps; turnover cap). Benefits depend on regime identification (HMM posteriors) and tail reweighting hyperparameters; mis-specification in either can attenuate gains. Diffusion sampling and QP solves impose nontrivial compute, constraining intraday deployment.

*Future work.* (i) Decision-aware training (end-to-end) that differentiates through spectral CVaR, turnover, and holdings penalties; (ii) short multi-step scenario generation with a convex *pathwise drawdown CVaR* objective; (iii) distributional robustness (e.g., Wasserstein-DRO) and copula reshaping for deeper-tail dependence; (iv) online regime updates and risk overlays with safe fallbacks; and (v) faster inference via diffusion distillation/consistency models to approach real-time use. Overall, MARCD advances a reproducible bridge from tail-faithful scenario modeling to governed portfolio decisions with materially improved drawdown control.

## References

* Ang and Timmermann [2012]

  Andrew Ang and Allan Timmermann.
  Regime shifts in financial markets.
  In *Handbook of Financial Econometrics*, pages 287â€“339. Elsevier, 2012.
* Bai etÂ al. [2018]

  Shaojie Bai, J.Â Zico Kolter, and Vladlen Koltun.
  An empirical evaluation of generic convolutional and recurrent networks for sequence modeling.
  *arXiv preprint arXiv:1803.01271*, 2018.
* Black and Litterman [1992]

  Fischer Black and Robert Litterman.
  Global portfolio optimization.
  *Financial Analysts Journal*, 48(5):28â€“43, 1992.
* Delage and Ye [2010]

  Erick Delage and Yinyu Ye.
  Distributionally robust optimization under moment uncertainty with application to data-driven problems.
  *Operations Research*, 58(3):595â€“612, 2010.
* Desai etÂ al. [2021]

  Abhyuday Desai, Cynthia Freeman, Zuhui Wang, and Ian Beaver.
  Timevae: A variational auto-encoder for multivariate time series generation.
  *arXiv preprint arXiv:2111.08095*, 2021.
  URL <https://arxiv.org/abs/2111.08095>.
* Fischer and Krauss [2018]

  Thomas Fischer and Christopher Krauss.
  Deep learning with long short-term memory networks for financial market predictions.
  *European Journal of Operational Research*, 270(2):654â€“669, 2018.
* Hamilton [1989]

  JamesÂ D Hamilton.
  A new approach to the economic analysis of nonstationary time series and the business cycle.
  *Econometrica*, 57(2):357â€“384, 1989.
* Hochreiter and Schmidhuber [1997]

  Sepp Hochreiter and JÃ¼rgen Schmidhuber.
  Long short-term memory.
  *Neural Computation*, 9(8):1735â€“1780, 1997.
  doi: 10.1162/neco.1997.9.8.1735.
* Istiaque etÂ al. [2024]

  RiasatÂ Ali Istiaque, ChiÂ Seng Pun, and Yuli Song.
  Simulating asset prices using conditional time-series gan.
  In *Proceedings of the 5th ACM International Conference on AI in Finance (ICAIF â€™24)*. ACM, 2024.
  doi: 10.1145/3677052.3698638.
* Kim and Nelson [1994]

  Chang-Jin Kim and CharlesÂ R Nelson.
  Dynamic linear models with markov-switching.
  *Journal of Econometrics*, 60(1-2):1â€“22, 1994.
* Kollovieh etÂ al. [2023]

  Marcel Kollovieh, AbdulÂ Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, and Yuyang Wang.
  Predict, refine, synthesize: Self-guiding diffusion models for probabilistic time series.
  In *Advances in Neural Information Processing Systems*, 2023.
* Ledoit and Wolf [2004]

  Olivier Ledoit and Michael Wolf.
  A well-conditioned estimator for large-dimensional covariance matrices.
  *Journal of Multivariate Analysis*, 88(2):365â€“411, 2004.
* Lim etÂ al. [2021]

  Bryan Lim, SercanÂ Ã–. Arik, Nicolas Loeff, and Tomas Pfister.
  Temporal fusion transformers for interpretable multi-horizon time series forecasting.
  *International Journal of Forecasting*, 37(4):1748â€“1764, 2021.
  doi: 10.1016/j.ijforecast.2021.03.012.
* Lowe etÂ al. [2017]

  Ryan Lowe, YiÂ Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch.
  Multi-agent actor-critic for mixed cooperative-competitive environments.
  In *Advances in Neural Information Processing Systems*, 2017.
* Markowitz [1952]

  Harry Markowitz.
  Portfolio selection.
  *Journal of Finance*, 7(1):77â€“91, 1952.
* Rasul etÂ al. [2021]

  Kashif Rasul, Abdul-Saboor Sheikh, Ingo Schuster, Urs Bergmann, and Roland Vollgraf.
  Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting.
  In *International Conference on Machine Learning*, 2021.
* Rockafellar and Uryasev [2000]

  RÂ Tyrrell Rockafellar and Stanislav Uryasev.
  Optimization of conditional value-at-risk.
  *Journal of Risk*, 2(3):21â€“41, 2000.
* Shen etÂ al. [2024]

  Lifeng Shen, Weiyu Chen, and JamesÂ T. Kwok.
  Multi-resolution diffusion models for time series forecasting.
  In *International Conference on Learning Representations (ICLR)*, 2024.
* Tashiro etÂ al. [2021]

  Yusuke Tashiro, Yang Song, Jiaming Song, and Stefano Ermon.
  Csdi: Conditional score-based diffusion models for probabilistic time series imputation.
  In *Advances in Neural Information Processing Systems*, 2021.
* Yoon etÂ al. [2019]

  Jinsung Yoon, Daniel Jarrett, and Mihaela vanÂ der Schaar.
  Time-series generative adversarial networks.
  In *Advances in Neural Information Processing Systems*, 2019.
* Zhou etÂ al. [2023]

  Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianmin Li, Hui Xiong, and Wancai Zhang.
  Informer: Beyond efficient transformer for long sequence time-series forecasting.
  In *AAAI Conference on Artificial Intelligence*, 2023.

## Appendix

## Appendix A Additional Methodology Details and Proof Sketches

#### Notation & Assumptions (Summary).

Rtâˆˆâ„dR\_{t}\in\mathbb{R}^{d} returns; wâˆˆâ„dw\in\mathbb{R}^{d} portfolio with 1âŠ¤â€‹w=11^{\top}w=1, box & turnover caps
(Sec.Â 3.4). HMM posteriors Ï€t\pi\_{t} and context ztz\_{t} (Sec.Â 3.2); diffusion schedule Î±s\alpha\_{s}; CVaR
level Î±\alpha. Tail quantile Qqâ€‹(â„“~)Q\_{q}(\tilde{\ell}) with â„“~=âˆ’minjâ¡rj\tilde{\ell}=-\min\_{j}r\_{j}. Blended moments
(Î¼^t,Î£^t)(\hat{\mu}\_{t},\hat{\Sigma}\_{t}) per Eq.Â (3). Loss Lâ€‹(w,r)=âˆ’wâŠ¤â€‹rL(w,r)=-w^{\top}r. Denoiser Îµ^Î¸\hat{\varepsilon}\_{\theta}
with MoE gate gt=Ïƒâ€‹(MLPâ€‹(zt))g\_{t}=\sigma(\mathrm{MLP}(z\_{t})) (Sec.Â 3.6).

### A.1 Comprehensive MARCD Objective (stochastic â†’\to sample-average)

At rebalance time tt with regime context ğ’›t\boldsymbol{z}\_{t} (from a KK-state HMM), the conditional generator defines
pÎ¸â€‹(ğ«âˆ£ğ’›t)p\_{\theta}(\mathbf{r}\mid\boldsymbol{z}\_{t}) for next-period returns ğ«âˆˆâ„d\mathbf{r}\in\mathbb{R}^{d}.
Let historical moments on a rolling window be (ğhist,ğšºhist)(\boldsymbol{\mu}\_{\text{hist}},\boldsymbol{\Sigma}\_{\text{hist}}) and
generator-implied moments be (ğsynth,ğšºsynth)(\boldsymbol{\mu}\_{\text{synth}},\boldsymbol{\Sigma}\_{\text{synth}}) where
ğsynth=ğ”¼pÎ¸â€‹[ğ«âˆ£ğ’›t]\boldsymbol{\mu}\_{\text{synth}}=\mathbb{E}\_{p\_{\theta}}[\mathbf{r}\mid\boldsymbol{z}\_{t}] and
ğšºsynth=CovpÎ¸â€‹[ğ«âˆ£ğ’›t]\boldsymbol{\Sigma}\_{\text{synth}}=\mathrm{Cov}\_{p\_{\theta}}[\mathbf{r}\mid\boldsymbol{z}\_{t}].
Blend

|  |  |  |
| --- | --- | --- |
|  | ğ^t=Î»â€‹ğsynth+(1âˆ’Î»)â€‹ğhist,ğšº^t=Î»â€‹ğšºsynth+(1âˆ’Î»)â€‹ğšºhist,\hat{\boldsymbol{\mu}}\_{t}=\lambda\,\boldsymbol{\mu}\_{\text{synth}}+(1{-}\lambda)\boldsymbol{\mu}\_{\text{hist}},\qquad\hat{\boldsymbol{\Sigma}}\_{t}=\lambda\,\boldsymbol{\Sigma}\_{\text{synth}}+(1{-}\lambda)\boldsymbol{\Sigma}\_{\text{hist}}, |  |

and (optionally) apply Ledoitâ€“Wolf shrinkage ğšº^tÎ´=(1âˆ’Î´)â€‹ğšº^t+Î´â€‹Î·â€‹ğˆâ‰»0\hat{\boldsymbol{\Sigma}}\_{t}^{\delta}=(1{-}\delta)\hat{\boldsymbol{\Sigma}}\_{t}+\delta\,\eta\mathbf{I}\succ 0.

Define portfolio loss Lâ€‹(ğ°,ğ«)â‰”âˆ’ğ°âŠ¤â€‹ğ«L(\mathbf{w},\mathbf{r})\coloneqq-\mathbf{w}^{\top}\mathbf{r} with ğ°âˆˆâ„d\mathbf{w}\in\mathbb{R}^{d}.
The decision-aware stochastic program is

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | minğ°âˆˆğ’²\displaystyle\min\_{\mathbf{w}\in\mathcal{W}}~ | âˆ’Î»Î¼â€‹ğ^tâŠ¤â€‹ğ°+Î³â€‹ğ°âŠ¤â€‹ğšº^tâ€‹ğ°âŸmeanâ€“variance regularizer+CVaRÎ±â€‹(Lâ€‹(ğ°,ğ«))âŸtail risk underÂ pÎ¸(â‹…âˆ£ğ’›t)\displaystyle\underbrace{-\lambda\_{\mu}\,\hat{\boldsymbol{\mu}}\_{t}^{\top}\mathbf{w}+\gamma\,\mathbf{w}^{\top}\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w}}\_{\text{mean--variance regularizer}}~+~\underbrace{\mathrm{CVaR}\_{\alpha}\!\big(L(\mathbf{w},\mathbf{r})\big)}\_{\text{tail risk under }p\_{\theta}(\cdot\mid\boldsymbol{z}\_{t})} |  | (8) |

subject to the feasible set
ğ’²={ğ°:ğŸâŠ¤â€‹ğ°=1,â„“â‰¤ğ°â‰¤ğ’–,â€–ğ°âˆ’ğ°tâˆ’1â€–1â‰¤Ï„}\mathcal{W}\!=\!\{\mathbf{w}:\mathbf{1}^{\top}\mathbf{w}=1,~\boldsymbol{\ell}\leq\mathbf{w}\leq\boldsymbol{u},~\|\mathbf{w}-\mathbf{w}\_{t-1}\|\_{1}\leq\tau\}.
Using the Rockafellarâ€“Uryasev representation,
CVaRÎ±â€‹(L)=infÎ¶âˆˆâ„{Î¶+11âˆ’Î±â€‹ğ”¼â€‹(Lâˆ’Î¶)+}\mathrm{CVaR}\_{\alpha}(L)=\inf\_{\zeta\in\mathbb{R}}\big\{\zeta+\tfrac{1}{1-\alpha}\,\mathbb{E}(L-\zeta)\_{+}\big\}.
Approximating the expectation with NN i.i.d. scenarios ğ«(i)âˆ¼pÎ¸(â‹…âˆ£ğ’›t)\mathbf{r}^{(i)}\!\sim p\_{\theta}(\cdot\mid\boldsymbol{z}\_{t}) yields the SAA:

|  |  |  |  |
| --- | --- | --- | --- |
|  | minğ°,Î¶âˆ’Î»Î¼â€‹ğ^tâŠ¤â€‹ğ°+Î³â€‹ğ°âŠ¤â€‹ğšº^tâ€‹ğ°+Î¶+1(1âˆ’Î±)â€‹Nâ€‹âˆ‘i=1N(Lâ€‹(ğ°,ğ«(i))âˆ’Î¶)+.\displaystyle\min\_{\mathbf{w},\zeta}~-\lambda\_{\mu}\,\hat{\boldsymbol{\mu}}\_{t}^{\top}\mathbf{w}+\gamma\,\mathbf{w}^{\top}\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w}+\zeta+\frac{1}{(1-\alpha)N}\sum\_{i=1}^{N}\big(L(\mathbf{w},\mathbf{r}^{(i)})-\zeta\big)\_{+}. |  | (9) |

### A.2 Epigraph QP, Turnover Linearization, and Dual Weights

Introduce uiâ‰¥0u\_{i}\geq 0 with uiâ‰¥Lâ€‹(ğ°,ğ«(i))âˆ’Î¶u\_{i}\geq L(\mathbf{w},\mathbf{r}^{(i)})-\zeta to obtain the convex QP

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | minğ°,Î¶,{ui}â‰¥0\displaystyle\min\_{\mathbf{w},\zeta,\{u\_{i}\}\geq 0}~ | âˆ’Î»Î¼â€‹ğ^tâŠ¤â€‹ğ°+Î³â€‹ğ°âŠ¤â€‹ğšº^tâ€‹ğ°+Î¶+1(1âˆ’Î±)â€‹Nâ€‹âˆ‘i=1Nui\displaystyle-\lambda\_{\mu}\,\hat{\boldsymbol{\mu}}\_{t}^{\top}\mathbf{w}+\gamma\,\mathbf{w}^{\top}\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w}+\zeta+\frac{1}{(1-\alpha)N}\sum\_{i=1}^{N}u\_{i} |  | (10) |
|  |  |  |  |
| --- | --- | --- | --- |
|  | s.t. | ğŸâŠ¤â€‹ğ°=1,â„“â‰¤ğ°â‰¤ğ’–,â€–ğ°âˆ’ğ°tâˆ’1â€–1â‰¤Ï„,uiâ‰¥âˆ’ğ°âŠ¤â€‹ğ«(i)âˆ’Î¶.\displaystyle\mathbf{1}^{\top}\mathbf{w}=1,\qquad\boldsymbol{\ell}\leq\mathbf{w}\leq\boldsymbol{u},\qquad\|\mathbf{w}-\mathbf{w}\_{t-1}\|\_{1}\leq\tau,\qquad u\_{i}\geq-\mathbf{w}^{\top}\mathbf{r}^{(i)}-\zeta. |  |

Turnover is enforced linearly by split variables ğ¬+,ğ¬âˆ’â‰¥0\mathbf{s}^{+},\mathbf{s}^{-}\!\geq 0 with ğ°âˆ’ğ°tâˆ’1=ğ¬+âˆ’ğ¬âˆ’\mathbf{w}-\mathbf{w}\_{t-1}=\mathbf{s}^{+}-\mathbf{s}^{-} and
âˆ‘j(sj++sjâˆ’)â‰¤Ï„\sum\_{j}(s^{+}\_{j}+s^{-}\_{j})\leq\tau (and, if penalized, add Îºâ€‹âˆ‘j(sj++sjâˆ’)\kappa\sum\_{j}(s^{+}\_{j}+s^{-}\_{j}) to the objective).
For fixed ğ°\mathbf{w}, the inner epigraph minimization has the well-known dual

|  |  |  |
| --- | --- | --- |
|  | maxpâˆˆâ„Nâ¡1Nâ€‹âˆ‘i=1Npiâ€‹Lâ€‹(ğ°,ğ«(i))â€‹s.t.â€‹âˆ‘ipi=1,0â‰¤piâ‰¤1(1âˆ’Î±)â€‹N,\max\_{p\in\mathbb{R}^{N}}~\frac{1}{N}\sum\_{i=1}^{N}p\_{i}\,L(\mathbf{w},\mathbf{r}^{(i)})\quad\text{s.t.}\quad\sum\_{i}p\_{i}=1,\quad 0\leq p\_{i}\leq\frac{1}{(1-\alpha)N}, |  |

so the CVaR term can be viewed as a worst-case tail-weighted average within a capped simplex.

#### Convexity and complexity.

With ğšº^tâª°0\hat{\boldsymbol{\Sigma}}\_{t}\succeq 0 and linear constraints, ([10](https://arxiv.org/html/2510.10807v1#A1.E10 "In A.2 Epigraph QP, Turnover Linearization, and Dual Weights â€£ Appendix A Additional Methodology Details and Proof Sketches â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) is a convex QP.
Interior-point methods scale as ğ’ªâ€‹(d3+Nâ€‹d2)\mathcal{O}(d^{3}+Nd^{2}) per rebalance (here d=10d{=}10, N=1024N{=}1024).

### A.3 KKT Sketch for the Allocator (useful for auditability)

Let Î½\nu be the multiplier for ğŸâŠ¤â€‹ğ°=1\mathbf{1}^{\top}\mathbf{w}=1, (Î±âˆ’,Î±+)â‰¥0(\alpha^{-},\alpha^{+})\!\geq\!0 for box constraints,
Ïâ‰¥0\rho\!\geq\!0 for turnover cap (via (ğ¬+,ğ¬âˆ’)(\mathbf{s}^{+},\mathbf{s}^{-})), and (Î²i,Î³i)â‰¥0(\beta\_{i},\gamma\_{i})\!\geq\!0 for uiâ‰¥0u\_{i}\!\geq\!0 and
uiâ‰¥âˆ’ğ°âŠ¤â€‹ğ«(i)âˆ’zâ€‹eâ€‹tâ€‹au\_{i}\!\geq\!-\mathbf{w}^{\top}\mathbf{r}^{(i)}-\\
zeta. Stationarity gives

|  |  |  |
| --- | --- | --- |
|  | âˆ’Î»Î¼â€‹ğ^t+2â€‹Î³â€‹ğšº^tâ€‹ğ°âˆ’âˆ‘i=1NÎ³i(1âˆ’Î±)â€‹Nâ€‹ğ«(i)+Î½â€‹â€‰1+(Î±+âˆ’Î±âˆ’)+turnover terms=0,1âˆ’âˆ‘i=1NÎ³i(1âˆ’Î±)â€‹N=0,-\,\lambda\_{\mu}\,\hat{\boldsymbol{\mu}}\_{t}+2\gamma\,\hat{\boldsymbol{\Sigma}}\_{t}\mathbf{w}-\sum\_{i=1}^{N}\frac{\gamma\_{i}}{(1-\alpha)N}\,\mathbf{r}^{(i)}+\nu\,\mathbf{1}+(\alpha^{+}-\alpha^{-})+\text{turnover terms}=0,\quad 1-\sum\_{i=1}^{N}\frac{\gamma\_{i}}{(1-\alpha)N}=0, |  |

plus primal feasibility and complementary slackness.
These KKT quantities (including active box/turnover constraints and tail weights Î³i\gamma\_{i}) are
useful for *model-risk audit logs*.

### A.4 Decision-aware extension (sketch): bilevel objective and gradients

We sketch an end-to-end variant that trains generator parameters Î¸\theta for decision quality, not just sample fidelity.
Let ğ’™=(ğ°,Î¶,{ui},ğ¬+,ğ¬âˆ’)\boldsymbol{x}\!=\!(\mathbf{w},\zeta,\{u\_{i}\},\mathbf{s}^{+},\mathbf{s}^{-}) collect allocator variables and write the QP fromÂ (6) compactly as

|  |  |  |
| --- | --- | --- |
|  | Vâ€‹(Î¸;ğ’›t)â‰”minğ’™âˆˆğ’³â€‹(Î¸;ğ’›t)â¡Fâ€‹(ğ’™;Î¸,ğ’›t),V(\theta;\boldsymbol{z}\_{t})\;\coloneqq\;\min\_{\boldsymbol{x}\in\mathcal{X}(\theta;\boldsymbol{z}\_{t})}\;F(\boldsymbol{x};\theta,\boldsymbol{z}\_{t}), |  |

where FF is the CVaR-epigraph objective (incl. MV term and optional turnover penalty) and ğ’³\mathcal{X} encodes the linear constraints.
The decision-aware training objective is the bilevel program

|  |  |  |  |
| --- | --- | --- | --- |
|  | minÎ¸â¡ğ”¼tâ€‹[â„’diffâ€‹(Î¸;ğ’›t)+Î·â€‹Vâ€‹(Î¸;ğ’›t)],\displaystyle\min\_{\theta}\;\;\mathbb{E}\_{t}\Big[\,\mathcal{L}\_{\text{diff}}(\theta;\boldsymbol{z}\_{t})\;+\;\eta\,V(\theta;\boldsymbol{z}\_{t})\,\Big], |  | (11) |

with scenarios ğ«(i)=gÎ¸â€‹(ğœºi,ğ’›t)\mathbf{r}^{(i)}\!=\!g\_{\theta}(\boldsymbol{\varepsilon}\_{i},\boldsymbol{z}\_{t}) (reparameterized draws; ğœºiâˆ¼ğ’©â€‹(0,ğˆ)\boldsymbol{\varepsilon}\_{i}\!\sim\!\mathcal{N}(0,\mathbf{I})).

#### Hypergradient (constraint-dependent envelope).

Let gâ€‹(ğ’™;Î¸,ğ’›t)â‰¤0g(\boldsymbol{x};\theta,\boldsymbol{z}\_{t})\leq 0 and hâ€‹(ğ’™;Î¸,ğ’›t)=0h(\boldsymbol{x};\theta,\boldsymbol{z}\_{t})=0 denote the inequality/equality stacks forÂ ğ’³\mathcal{X}, and (Î»â‹†,Î½â‹†)(\lambda^{\star},\nu^{\star}) the optimal duals at the inner solution ğ’™â‹†â€‹(Î¸;ğ’›t)\boldsymbol{x}^{\star}(\theta;\boldsymbol{z}\_{t}).
Under standard regularity (convexity, LICQ, strict complementarity),

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‡Î¸Vâ€‹(Î¸;ğ’›t)=âˆ‚Î¸Fâ€‹(ğ’™â‹†;Î¸,ğ’›t)âŸpathwise termâˆ’Î»â‹†âŠ¤â€‹âˆ‚Î¸gâ€‹(ğ’™â‹†;Î¸,ğ’›t)+Î½â‹†âŠ¤â€‹âˆ‚Î¸hâ€‹(ğ’™â‹†;Î¸,ğ’›t)âŸconstraint dependence via scenarios/moments.\displaystyle\nabla\_{\theta}V(\theta;\boldsymbol{z}\_{t})\;=\;\underbrace{\partial\_{\theta}F(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t})}\_{\text{pathwise term}}\;-\;\underbrace{\lambda^{\star\top}\partial\_{\theta}g(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t})\;+\;\nu^{\star\top}\partial\_{\theta}h(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t})}\_{\text{constraint dependence via scenarios/moments}}. |  | (12) |

The full hypergradient ofÂ ([11](https://arxiv.org/html/2510.10807v1#A1.E11 "In A.4 Decision-aware extension (sketch): bilevel objective and gradients â€£ Appendix A Additional Methodology Details and Proof Sketches â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) is then
âˆ‡Î¸ğ”¼tâ€‹[â„’diff]+Î·â€‹ğ”¼tâ€‹[âˆ‡Î¸V]\nabla\_{\theta}\mathbb{E}\_{t}[\,\mathcal{L}\_{\text{diff}}\,]\;+\;\eta\,\mathbb{E}\_{t}[\nabla\_{\theta}V],
where âˆ‚Î¸F\partial\_{\theta}F accounts for ğ^tâ€‹(Î¸),ğšº^tâ€‹(Î¸)\hat{\boldsymbol{\mu}}\_{t}(\theta),\hat{\boldsymbol{\Sigma}}\_{t}(\theta) and the scenario-dependent hinge terms via ğ«(i)=gÎ¸â€‹(ğœºi,ğ’›t)\mathbf{r}^{(i)}\!=\!g\_{\theta}(\boldsymbol{\varepsilon}\_{i},\boldsymbol{z}\_{t}).

#### Implicit differentiation (QP sensitivity).

Equivalently, one may differentiate the KKT system forÂ ğ’™â‹†\boldsymbol{x}^{\star}.
Let KK be the KKT Jacobian (block matrix of âˆ‡xâ€‹x2â„’\nabla^{2}\_{xx}\mathcal{L}, constraint Jacobians, and complementarity terms).
Solving the linear system

|  |  |  |
| --- | --- | --- |
|  | Kâ€‹ddâ€‹Î¸â€‹[ğ’™â‹†Î»â‹†Î½â‹†]=âˆ’[âˆ‚Î¸(âˆ‡xâ„’â€‹(ğ’™â‹†,Î»â‹†,Î½â‹†;Î¸))âˆ‚Î¸gâ€‹(ğ’™â‹†;Î¸,ğ’›t)âˆ‚Î¸hâ€‹(ğ’™â‹†;Î¸,ğ’›t)]K\;\frac{\mathrm{d}}{\mathrm{d}\theta}\!\begin{bmatrix}\boldsymbol{x}^{\star}\\ \lambda^{\star}\\ \nu^{\star}\end{bmatrix}\;=\;-\begin{bmatrix}\partial\_{\theta}\big(\nabla\_{x}\mathcal{L}(\boldsymbol{x}^{\star},\lambda^{\star},\nu^{\star};\theta)\big)\\[2.0pt] \partial\_{\theta}g(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t})\\[2.0pt] \partial\_{\theta}h(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t})\end{bmatrix} |  |

yields dâ€‹ğ’™â‹†dâ€‹Î¸\tfrac{\mathrm{d}\boldsymbol{x}^{\star}}{\mathrm{d}\theta}; one then applies the chain rule to Fâ€‹(ğ’™â‹†;Î¸,ğ’›t)F(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t}).
In practice,Â ([12](https://arxiv.org/html/2510.10807v1#A1.E12 "In Hypergradient (constraint-dependent envelope). â€£ A.4 Decision-aware extension (sketch): bilevel objective and gradients â€£ Appendix A Additional Methodology Details and Proof Sketches â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) avoids forming dâ€‹ğ’™â‹†dâ€‹Î¸\tfrac{\mathrm{d}\boldsymbol{x}^{\star}}{\mathrm{d}\theta} explicitly because the duals (Î»â‹†,Î½â‹†)(\lambda^{\star},\nu^{\star}) are returned by the QP solver and can be logged (cf. auditability).

#### Smooth surrogate for stable training.

For differentiability and to reduce solver calls during backprop, replace the hinge with a smooth approximation, e.g.
(x)+â‰ˆ1Î²â€‹logâ¡(1+eÎ²â€‹x)(x)\_{+}\approx\tfrac{1}{\beta}\log(1+\mathrm{e}^{\beta x}) (large Î²\beta), and/or use a small quadratic penalty on turnover so the constraint set is Î¸\theta-independent.
Then the envelope simplifies to âˆ‡Î¸Vâ‰ˆâˆ‚Î¸Fâ€‹(ğ’™â‹†;Î¸,ğ’›t)\nabla\_{\theta}V\approx\partial\_{\theta}F(\boldsymbol{x}^{\star};\theta,\boldsymbol{z}\_{t}) (constraints do not depend on Î¸\theta), while preserving the allocatorâ€™s behavior.

#### Practical recipe.

(i) Reparameterize scenarios: ğ«(i)=gÎ¸â€‹(ğœºi,ğ’›t)\mathbf{r}^{(i)}\!=\!g\_{\theta}(\boldsymbol{\varepsilon}\_{i},\boldsymbol{z}\_{t});
(ii) compute ğ^t,ğšº^t\hat{\boldsymbol{\mu}}\_{t},\hat{\boldsymbol{\Sigma}}\_{t} and solve the QP for ğ’™â‹†\boldsymbol{x}^{\star} (store duals);
(iii) backpropagate throughÂ ([11](https://arxiv.org/html/2510.10807v1#A1.E11 "In A.4 Decision-aware extension (sketch): bilevel objective and gradients â€£ Appendix A Additional Methodology Details and Proof Sketches â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) using either the envelope formÂ ([12](https://arxiv.org/html/2510.10807v1#A1.E12 "In Hypergradient (constraint-dependent envelope). â€£ A.4 Decision-aware extension (sketch): bilevel objective and gradients â€£ Appendix A Additional Methodology Details and Proof Sketches â€£ Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation")) or an implicit-diff QP layer;
(iv) use a small Î·\eta warm-up and gradient clipping;
(v) keep walk-forward protocol (no look-ahead).
Compute overhead is one QP solve per step plus either one adjoint KKT solve or the envelope evaluation; asymptotically the same order as inference (ğ’ªâ€‹(d3+Nâ€‹d2)\mathcal{O}(d^{3}{+}Nd^{2})).

### A.5 Tail-Weighted Diffusion as a Spectral-Risk Surrogate

Recall the tail-weighted diffusion loss from (7),
Ltail=ğ”¼â€‹[(1+Î·â€‹â€‰1â€‹{â„“~â‰¤Qqâ€‹(â„“~)})â€‹â€–Îµâˆ’ÎµÎ¸â€‹(â‹…)â€–22]L\_{\text{tail}}=\mathbb{E}\big[\big(1+\eta\,\mathbf{1}\{\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\}\big)\,\|\varepsilon-\varepsilon\_{\theta}(\cdot)\|\_{2}^{2}\big], where â„“~=âˆ’minjâ¡rj\tilde{\ell}=-\min\_{j}r\_{j} and qâˆˆ[0.05,0.10]q\in[0.05,0.10],
Î·âˆˆ[1,3]\eta\in[1,3] [, Â§3.5], and the regime-MoE gate is defined in Â§3.6.

###### Assumption 1 (Tail-Lipschitz Decoder).

There exists L>0L>0 such that the denoising error maps to return error with
â€–râˆ’r^â€–â‰¤Lâ€‹â€–Îµâˆ’ÎµÎ¸â€–\|r-\hat{r}\|\leq L\,\|\varepsilon-\varepsilon\_{\theta}\| on the lower-qq tail set {â„“~â‰¤Qqâ€‹(â„“~)}\{\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\}.

###### Proposition 1 (Spectral risk proxy for portfolio tail functionals).

Let wâˆˆâ„dw\in\mathbb{R}^{d} be any feasible portfolio (budget/box/turnover constraints as in (4)â€“(6)).
Under the Tail-Lipschitz Decoder, the portfolio CVaR error admits

|  |  |  |
| --- | --- | --- |
|  | |CVaRÎ±â€‹(âˆ’wâŠ¤â€‹r)âˆ’CVaRÎ±â€‹(âˆ’wâŠ¤â€‹r^)|â‰¤Lâ€‹â€–wâ€–21âˆ’Î±â€‹ğ”¼â€‹[(1+Î·â€‹â€‰1â€‹{â„“~â‰¤Qqâ€‹(â„“~)})â€‹â€–Îµâˆ’ÎµÎ¸â€‹(â‹…)â€–22].\Big|\mathrm{CVaR}\_{\alpha}(-w^{\top}r)-\mathrm{CVaR}\_{\alpha}(-w^{\top}\hat{r})\Big|\;\leq\;\frac{L\,\|w\|\_{2}}{1-\alpha}\,\sqrt{\mathbb{E}\!\left[\big(1+\eta\,\mathbf{1}\{\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\}\big)\,\|\varepsilon-\varepsilon\_{\theta}(\cdot)\|\_{2}^{2}\right]}. |  |

###### Sketch.

Write the CVaR difference as a tail average of linear losses and apply Cauchyâ€“Schwarz on the
tail region. The Lipschitz link transfers denoising error into return error; the (1âˆ’Î±)âˆ’1(1-\alpha)^{-1}
factor comes from the Rockafellarâ€“Uryasev representation. Tail reweighting magnifies the
integrand over the lower-qq region, producing a spectral-risk-like weight on squared error.
âˆ

###### Remark 1 (Decision relevance).

Since allocation solves the convex CVaR epigraph QP (4)â€“(6), controlling the bound above
reduces the decision-relevant generalization gap seen by the allocator.

### A.6 Finite-Sample Statistics of Tail Reweighting

Define weights wi=1+Î·â€‹â€‰1â€‹{â„“~iâ‰¤Qqâ€‹(â„“~)}w\_{i}=1+\eta\,\mathbf{1}\{\tilde{\ell}\_{i}\leq Q\_{q}(\tilde{\ell})\}.
With q=â„™â€‹(â„“~â‰¤Qqâ€‹(â„“~))q=\mathbb{P}(\tilde{\ell}\leq Q\_{q}(\tilde{\ell})), the normalized weights are
wÂ¯i=wi/((1âˆ’q)+qâ€‹(1+Î·))\bar{w}\_{i}=w\_{i}/\big((1-q)+q(1+\eta)\big).

###### Proposition 2 (Closed-form effective sample size (ESS)).

Let NN be the batch size. Then the ESS of (wÂ¯i)i=1N(\bar{w}\_{i})\_{i=1}^{N} is

|  |  |  |
| --- | --- | --- |
|  | ESSâ€‹(q,Î·)=Nâ€‹(1+Î·â€‹q)21+2â€‹Î·â€‹q+Î·2â€‹q=Nâ€‹1+2â€‹Î·â€‹q+Î·2â€‹q21+2â€‹Î·â€‹q+Î·2â€‹q.\mathrm{ESS}(q,\eta)=N\,\frac{\big(1+\eta q\big)^{2}}{1+2\eta q+\eta^{2}q}\;=\;N\,\frac{1+2\eta q+\eta^{2}q^{2}}{1+2\eta q+\eta^{2}q}. |  |

###### Proof.

Compute ESS=(âˆ‘iwÂ¯i)2/âˆ‘iwÂ¯i2\mathrm{ESS}=(\sum\_{i}\bar{w}\_{i})^{2}/\sum\_{i}\bar{w}\_{i}^{2} by partitioning into tail vs non-tail
fractions (q,1âˆ’q)(q,1-q) and substituting w={1,1+Î·}w=\{1,1+\eta\}.
âˆ

###### Remark 2 (Choosing (q,Î·)(q,\eta)).

Moderate (q,Î·)(q,\eta) keeps ESS\mathrm{ESS} large while emphasizing the adverse region that drives
CVaRÎ±\mathrm{CVaR}\_{\alpha}. In practice, your ranges qâˆˆ[0.05,0.10],Î·âˆˆ[1,3]q\in[0.05,0.10],\;\eta\in[1,3] preserve stability.

### A.7 Regime-MoE Denoiser: Oracle Inequality and Crisis Specialization

Let ZZ be the regime context with gate gâ€‹(Z)âˆˆ[0,1]g(Z)\in[0,1] and experts
ÎµÎ¸,base,ÎµÎ¸,crisis\varepsilon\_{\theta,\mathrm{base}},\varepsilon\_{\theta,\mathrm{crisis}}.
The denoiser is Îµ^Î¸=(1âˆ’g)â€‹ÎµÎ¸,base+gâ€‹ÎµÎ¸,crisis\hat{\varepsilon}\_{\theta}=(1-g)\varepsilon\_{\theta,\mathrm{base}}+g\,\varepsilon\_{\theta,\mathrm{crisis}}
[, Â§3.6].

###### Assumption 2 (Well-specified conditional regressors).

For each regime label Câˆˆ{base,crisis}C\in\{\mathrm{base},\mathrm{crisis}\},
the Bayes denoiser equals the conditional mean:
ÎµCâ‹†â€‹(x,s,Z)=ğ”¼â€‹[Îµ|x,s,Z,C]\varepsilon^{\star}\_{C}(x,s,Z)=\mathbb{E}[\varepsilon\,|\,x,s,Z,C].

###### Theorem 4 (MoE oracle risk decomposition).

Let gâ‹†â€‹(Z)=â„™â€‹(C=crisis|Z)g^{\star}(Z)=\mathbb{P}(C=\mathrm{crisis}\,|\,Z).
Then for squared loss,

|  |  |  |
| --- | --- | --- |
|  | â„›â€‹(Îµ^Î¸)âˆ’â„›â€‹(Îµ^â‹†)â‰¤c1â€‹ğ”¼â€‹[(gâ€‹(Z)âˆ’gâ‹†â€‹(Z))2]+c2â€‹âˆ‘CApproxErrC,\mathcal{R}(\hat{\varepsilon}\_{\theta})-\mathcal{R}(\hat{\varepsilon}^{\star})\;\leq\;c\_{1}\,\mathbb{E}\!\left[(g(Z)-g^{\star}(Z))^{2}\right]+c\_{2}\,\sum\_{C}\mathrm{ApproxErr}\_{C}, |  |

where Îµ^â‹†=(1âˆ’gâ‹†)â€‹Îµbaseâ‹†+gâ‹†â€‹Îµcrisisâ‹†\hat{\varepsilon}^{\star}=(1-g^{\star})\varepsilon^{\star}\_{\mathrm{base}}+g^{\star}\,\varepsilon^{\star}\_{\mathrm{crisis}},
and ApproxErrC\mathrm{ApproxErr}\_{C} is the approximation error of each expert class.

###### Sketch.

Expand the regression risk via law of total expectation and project onto the MoE span.
The first term arises from gating misclassification; the second from function-class limits.
âˆ

###### Corollary 1 (Crisis improvement under informative gating).

If gg is monotone in the HMM crisis posterior (as in Â§3.6) and the crisis expert reduces tail MSE,
then MoE strictly improves tail-region risk whenever
ğ”¼â€‹[(gâˆ’gâ‹†)2]\mathbb{E}[(g-g^{\star})^{2}] is below a regime-dependent threshold.

### A.8 Stability of Gated Denoising and DDPM Sampling

###### Assumption 3 (Lipschitz experts and gate).

Each expert is LÎµL\_{\varepsilon}-Lipschitz in (x,s)(x,s) and the gate gâ€‹(Z)g(Z) is LgL\_{g}-Lipschitz in its inputs.

###### Proposition 3 (Lipschitz constant of the MoE drift).

The MoE denoiser inherits Lipschitz constant
LMoEâ‰¤(1+â€–gâ€–âˆ)â€‹LÎµ+Lgâ€‹Î”ÎµL\_{\mathrm{MoE}}\leq(1+\|g\|\_{\infty})L\_{\varepsilon}+L\_{g}\,\Delta\_{\varepsilon},
where Î”Îµ=supâ€–Îµcrisisâˆ’Îµbaseâ€–\Delta\_{\varepsilon}=\sup\|\,\varepsilon\_{\mathrm{crisis}}-\varepsilon\_{\mathrm{base}}\,\|.
Hence the DDPM reverse SDE/ODE remains contractive whenever
LMoEL\_{\mathrm{MoE}} satisfies the usual step-size criteria.

###### Remark 3.

This implies stability of sampling trajectories when the gate smoothly tracks regime posteriors
(our HMM-derived gt=Ïƒâ€‹(MLPâ€‹(zt))g\_{t}=\sigma(\mathrm{MLP}(z\_{t}))).

### A.9 Decision-Relevant Regret Bound for the CVaR Allocator

Let wâ‹†w^{\star} solve the true-distribution QP (4)â€“(6) and w^\hat{w} the QP using
blended/shrunk (Î¼^t,Î£^t)(\hat{\mu}\_{t},\hat{\Sigma}\_{t}) and sample CVaR under pÎ¸(â‹…|zt)p\_{\theta}(\cdot|z\_{t}).

###### Assumption 4 (Modeling error budgets).

There exist Î´Î¼,Î´Î£,Î´CVaRâ‰¥0\delta\_{\mu},\delta\_{\Sigma},\delta\_{\mathrm{CVaR}}\geq 0 such that
â€–Î¼^tâˆ’Î¼â‹†â€–2â‰¤Î´Î¼\|\hat{\mu}\_{t}-\mu^{\star}\|\_{2}\leq\delta\_{\mu}, â€–Î£^tâˆ’Î£â‹†â€–opâ‰¤Î´Î£\|\hat{\Sigma}\_{t}-\Sigma^{\star}\|\_{\mathrm{op}}\leq\delta\_{\Sigma},
and the CVaR term differs from truth by at most Î´CVaR\delta\_{\mathrm{CVaR}} uniformly over feasible ww.

###### Theorem 5 (Regret bound).

Let Î“\Gamma be the strong convexity modulus of the QP objective in ww induced by Î£^t\hat{\Sigma}\_{t}.
Then

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(w^)âˆ’Fâ€‹(wâ‹†)â‰¤12â€‹Î“â€‹(Î»Î¼â€‹Î´Î¼+ÎºÎ£â€‹Î´Î£+Î´CVaR)2,F(\hat{w})-F(w^{\star})\;\leq\;\frac{1}{2\Gamma}\Big(\lambda\_{\mu}\,\delta\_{\mu}+\kappa\_{\Sigma}\,\delta\_{\Sigma}+\delta\_{\mathrm{CVaR}}\Big)^{2}, |  |

for suitable Î»Î¼,ÎºÎ£\lambda\_{\mu},\kappa\_{\Sigma} depending on budget/box/turnover radii.
Moreover, if LtailL\_{\text{tail}} is small, then Î´CVaR\delta\_{\mathrm{CVaR}} is small by Proposition in A.5.

###### Sketch.

Apply standard stability of strongly convex programs under objective perturbations, bounding
the mean/variance terms by norm inequalities and the CVaR gap via A.5.
âˆ

### A.10 Quantile-Threshold Asymptotics for Qqâ€‹(â„“~)Q\_{q}(\tilde{\ell})

Let Q^q\hat{Q}\_{q} be the empirical qq-quantile of â„“~\tilde{\ell} used in LtailL\_{\text{tail}}.
Under standard regularity (continuous density fâ„“~f\_{\tilde{\ell}} at QqQ\_{q}),

|  |  |  |
| --- | --- | --- |
|  | Nâ€‹(Q^qâˆ’Qq)â‡’ğ’©â€‹(0,qâ€‹(1âˆ’q)/fâ„“~â€‹(Qq)2).\sqrt{N}\,(\hat{Q}\_{q}-Q\_{q})\;\Rightarrow\;\mathcal{N}\big(0,\,q(1-q)/f\_{\tilde{\ell}}(Q\_{q})^{2}\big). |  |

Thus the randomness introduced by thresholding is Oâ„™â€‹(Nâˆ’1/2)O\_{\mathbb{P}}(N^{-1/2}) and absorbed by
the ESS of A.6 for moderate (q,Î·)(q,\eta).

###### Remark 4.

In practice, we use a running estimate of QqQ\_{q} with exponential smoothing, which further
stabilizes the gate into the weighted region while keeping the training unbiased on average.

### A.11 Tail-Weighted Diffusion as a Spectral Risk Upper-Bound

Recall LtailL\_{\text{tail}} in (7). Define a spectral weight Ï•â€‹(u)=1+Î·â€‹â€‰1â€‹{uâ‰¤q}\phi(u)=1+\eta\,\mathbf{1}\{u\leq q\} on uâˆˆ[0,1]u\in[0,1],
normalized by Ï•Â¯=âˆ«01Ï•â€‹(u)â€‹ğ‘‘u=1+Î·â€‹q\bar{\phi}=\int\_{0}^{1}\phi(u)\,du=1+\eta q, and its probability measure
dâ€‹Î¦â€‹(u)=Ï•â€‹(u)â€‹dâ€‹u/Ï•Â¯d\Phi(u)=\phi(u)\,du/\bar{\phi}. Let â„›Î¦â€‹(L)\mathcal{R}\_{\Phi}(L) be the spectral risk of a loss LL under Î¦\Phi.

###### Assumption 5 (Tail-Lipschitz Decoder on tail set).

There exists Ldec>0L\_{\mathrm{dec}}>0 s.t. on {â„“~â‰¤Qqâ€‹(â„“~)}\{\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\} we have
â€–râˆ’r^â€–â‰¤Ldecâ€‹â€–Îµâˆ’ÎµÎ¸â€–\|r-\hat{r}\|\leq L\_{\mathrm{dec}}\,\|\varepsilon-\varepsilon\_{\theta}\|.

###### Theorem 6 (Spectral CVaR control by LtailL\_{\text{tail}}).

For any feasible ww,

|  |  |  |
| --- | --- | --- |
|  | |CVaRÎ±â€‹(âˆ’wâŠ¤â€‹r)âˆ’CVaRÎ±â€‹(âˆ’wâŠ¤â€‹r^)|â‰¤Ldecâ€‹â€–wâ€–21âˆ’Î±â€‹Ï•Â¯â€‹ğ”¼â€‹[Ï•â€‹(U)â€‹â€–Îµâˆ’ÎµÎ¸â€–22],\Big|\mathrm{CVaR}\_{\alpha}(-w^{\top}r)-\mathrm{CVaR}\_{\alpha}(-w^{\top}\hat{r})\Big|\;\leq\;\frac{L\_{\mathrm{dec}}\,\|w\|\_{2}}{1-\alpha}\;\sqrt{\bar{\phi}\;\mathbb{E}\big[\phi(U)\,\|\varepsilon-\varepsilon\_{\theta}\|\_{2}^{2}\big]}, |  |

where UU is the PIT of â„“~\tilde{\ell}. Hence minimizing LtailL\_{\text{tail}} reduces a spectral upper-bound
on the *decision-relevant* CVaR generalization gap.

###### Sketch.

Express CVaR via Rockafellarâ€“Uryasevâ€™s tail average. Cauchyâ€“Schwarz with tail reweighting
Ï•\phi yields the inequality; the decoder Lipschitz links denoising and return errors.
âˆ

###### Remark 5.

Because allocation solves the convex CVaR epigraph QP in (4)â€“(6), decreasing this gap
directly lowers the allocatorâ€™s risk mis-specification at decision time.

### A.12 Finite-Sample Efficiency of Tail Reweighting

Let wi=1+Î·â€‹â€‰1â€‹{â„“~iâ‰¤Qqâ€‹(â„“~)}w\_{i}=1+\eta\,\mathbf{1}\{\tilde{\ell}\_{i}\leq Q\_{q}(\tilde{\ell})\} and normalized wÂ¯i=wi/ğ”¼â€‹[wi]\bar{w}\_{i}=w\_{i}/\mathbb{E}[w\_{i}].

###### Proposition 4 (Effective sample size).

ESS=Nâ€‹(1+Î·â€‹q)2(1âˆ’q)+qâ€‹(1+Î·)2=Nâ€‹1+2â€‹Î·â€‹q+Î·2â€‹q21+2â€‹Î·â€‹q+Î·2â€‹q\mathrm{ESS}=N\frac{(1+\eta q)^{2}}{(1-q)+q(1+\eta)^{2}}=N\frac{1+2\eta q+\eta^{2}q^{2}}{1+2\eta q+\eta^{2}q}.

###### Remark 6.

Moderate (q,Î·)(q,\eta) (e.g., qâˆˆ[0.05,0.10],Î·âˆˆ[1,3]q\in[0.05,0.10],\,\eta\in[1,3]) retains high ESS while emphasizing
the adverse set that drives CVaRÎ±\mathrm{CVaR}\_{\alpha}.

### A.13 Regime-MoE: Oracle Inequality, Consistency, and Stability

Let Îµ^Î¸=(1âˆ’g)â€‹ÎµÎ¸,base+gâ€‹ÎµÎ¸,crisis\hat{\varepsilon}\_{\theta}=(1-g)\varepsilon\_{\theta,\mathrm{base}}+g\,\varepsilon\_{\theta,\mathrm{crisis}} with g=gâ€‹(Z)âˆˆ[0,1]g=g(Z)\in[0,1].

###### Assumption 6 (Bayes experts + margin).

For Câˆˆ{base,crisis}C\in\{\mathrm{base},\mathrm{crisis}\}, the Bayes denoiser ÎµCâ‹†\varepsilon^{\star}\_{C} lies in the closure of the
expert class and there exists a margin Î³m>0\gamma\_{m}>0 such that
â„™â€‹(|gâ‹†â€‹(Z)âˆ’1/2|â‰¤Î³m)â‰¤Îºm\mathbb{P}(|g^{\star}(Z)-1/2|\leq\gamma\_{m})\leq\kappa\_{m} for some Îºm<1\kappa\_{m}<1.

###### Theorem 7 (Oracle excess risk for MoE).

For squared loss,

|  |  |  |
| --- | --- | --- |
|  | â„›â€‹(Îµ^Î¸)âˆ’â„›â€‹(Îµ^â‹†)â‰¤c1â€‹ğ”¼â€‹[(gâˆ’gâ‹†)2]+c2â€‹âˆ‘Câˆˆ{base,crisis}ApproxErrC+c3â€‹Îºm,\mathcal{R}(\hat{\varepsilon}\_{\theta})-\mathcal{R}(\hat{\varepsilon}^{\star})\;\leq\;c\_{1}\,\mathbb{E}\!\left[(g-g^{\star})^{2}\right]+c\_{2}\!\!\sum\_{C\in\{\mathrm{base,crisis}\}}\!\!\!\!\mathrm{ApproxErr}\_{C}+c\_{3}\,\kappa\_{m}, |  |

where Îµ^â‹†=(1âˆ’gâ‹†)â€‹Îµbaseâ‹†+gâ‹†â€‹Îµcrisisâ‹†\hat{\varepsilon}^{\star}=(1-g^{\star})\varepsilon^{\star}\_{\mathrm{base}}+g^{\star}\varepsilon^{\star}\_{\mathrm{crisis}}.

###### Proposition 5 (Gate consistency).

If gg is trained with a calibrated surrogate (e.g., logistic) on HMM posteriors and the feature
class has finite Rademacher complexity â„œn\mathfrak{R}\_{n}, then
ğ”¼â€‹[(gâˆ’gâ‹†)2]=Oâ€‹(â„œn)+onâ€‹(1)\mathbb{E}[(g-g^{\star})^{2}]\!=\!O(\mathfrak{R}\_{n})+o\_{n}(1).

###### Proposition 6 (Lipschitz MoE drift).

If experts are LÎµL\_{\varepsilon}-Lipschitz in (x,s)(x,s) and gg is LgL\_{g}-Lipschitz in ZZ,
then the MoE drift is LMoEâ‰¤(1+â€–gâ€–âˆ)â€‹LÎµ+Lgâ€‹Î”ÎµL\_{\mathrm{MoE}}\!\leq\!(1+\|g\|\_{\infty})L\_{\varepsilon}+L\_{g}\,\Delta\_{\varepsilon},
Î”Îµ=supâ€–Îµcrisisâˆ’Îµbaseâ€–\Delta\_{\varepsilon}=\sup\|\varepsilon\_{\mathrm{crisis}}-\varepsilon\_{\mathrm{base}}\|, ensuring stable DDPM steps.

### A.14 Allocation Mapping: Strong Convexity, Lipschitzness, and Regret

Let w^â€‹(Î¼^,Î£^)\hat{w}(\hat{\mu},\hat{\Sigma}) solve the CVaR-QP (4)â€“(6) and assume Î£^âª°Î»minâ€‹I\hat{\Sigma}\succeq\lambda\_{\min}I.

###### Theorem 8 (Lipschitz solution map).

There exist constants (cÎ¼,cÎ£)(c\_{\mu},c\_{\Sigma}) such that for feasible perturbations
(Î´â€‹Î¼,Î´â€‹Î£)(\delta\mu,\delta\Sigma) with fixed constraints,

|  |  |  |
| --- | --- | --- |
|  | â€–w^â€‹(Î¼^+Î´â€‹Î¼,Î£^+Î´â€‹Î£)âˆ’w^â€‹(Î¼^,Î£^)â€–2â‰¤cÎ¼â€‹â€–Î´â€‹Î¼â€–2+cÎ£â€‹â€–Î´â€‹Î£â€–opÎ»min.\|\hat{w}(\hat{\mu}+\delta\mu,\hat{\Sigma}+\delta\Sigma)-\hat{w}(\hat{\mu},\hat{\Sigma})\|\_{2}\;\leq\;\frac{c\_{\mu}\|\delta\mu\|\_{2}+c\_{\Sigma}\|\delta\Sigma\|\_{\mathrm{op}}}{\lambda\_{\min}}. |  |

###### Corollary 2 (Decision regret under moment & CVaR errors).

Let Î´CVaR\delta\_{\mathrm{CVaR}} bound the CVaR term perturbation uniformly over feasible ww.
If the objective is Î“\Gamma-strongly convex in ww, then

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(w^)âˆ’Fâ€‹(wâ‹†)â‰¤12â€‹Î“â€‹(Î»Î¼â€‹â€–Î´â€‹Î¼â€–2+ÎºÎ£â€‹â€–Î´â€‹Î£â€–op+Î´CVaR)2.F(\hat{w})-F(w^{\star})\;\leq\;\frac{1}{2\Gamma}\Big(\lambda\_{\mu}\|\delta\mu\|\_{2}+\kappa\_{\Sigma}\|\delta\Sigma\|\_{\mathrm{op}}+\delta\_{\mathrm{CVaR}}\Big)^{2}. |  |

###### Remark 7.

By A.11, Î´CVaR\delta\_{\mathrm{CVaR}} shrinks with LtailL\_{\text{tail}}; thus tail-weighted training tightens the
end-to-end decision regret.

### A.15 Distribution Shift View: CVaR Sensitivity under Wasserstein-W1W\_{1}

Let losses be KK-Lipschitz in rr. For distributions P,QP,Q with W1â€‹(P,Q)â‰¤ÏW\_{1}(P,Q)\leq\rho,

###### Proposition 7 (CVaR Lipschitz continuity).

|CVaRÎ±Pâ€‹(L)âˆ’CVaRÎ±Qâ€‹(L)|â‰¤K1âˆ’Î±â€‹Ï.|\mathrm{CVaR}\_{\alpha}^{P}(L)-\mathrm{CVaR}\_{\alpha}^{Q}(L)|\leq\frac{K}{1-\alpha}\,\rho.

###### Sketch.

Use the tail-average representation of CVaR and Kantorovichâ€“Rubinstein duality, noting the
1/(1âˆ’Î±)1/(1-\alpha) amplification of tail averages.
âˆ

###### Remark 8 (Interpretation).

Tail-aware generation (small LtailL\_{\text{tail}}) + bounded shift Ï\rho jointly ensure limited CVaR drift,
explaining empirical robustness under modest market shifts.

### A.16 Convex Pathwise Drawdown-CVaR Surrogate

For a horizon {t+1,â€¦,t+H}\{t+1,\dots,t+H\} with scenarios rt+1:t+H(i)r^{(i)}\_{t+1:t+H}, introduce auxiliary peaks
ph(i)p^{(i)}\_{h} and drawdowns dh(i)d^{(i)}\_{h}:

|  |  |  |
| --- | --- | --- |
|  | ph(i)â‰¥phâˆ’1(i)+wâŠ¤â€‹rt+h(i),dh(i)â‰¥ph(i)âˆ’(pt(i)+âˆ‘u=1hwâŠ¤â€‹rt+u(i)),MDD(i)â‰¥dh(i).p^{(i)}\_{h}\geq p^{(i)}\_{h-1}+w^{\top}r^{(i)}\_{t+h},\quad d^{(i)}\_{h}\geq p^{(i)}\_{h}-\big(p^{(i)}\_{t}+\textstyle\sum\_{u=1}^{h}w^{\top}r^{(i)}\_{t+u}\big),\quad\operatorname{MDD}^{(i)}\geq d^{(i)}\_{h}. |  |

Then the convex surrogate program

|  |  |  |
| --- | --- | --- |
|  | minw,Î¶,{MDD(i)},â€¦â¡Î¶+1(1âˆ’Î±)â€‹Nâ€‹âˆ‘i(MDD(i)âˆ’Î¶)++Â MV terms\min\_{w,\zeta,\{\operatorname{MDD}^{(i)}\},\ldots}\;\;\zeta+\frac{1}{(1-\alpha)N}\sum\_{i}(\operatorname{MDD}^{(i)}-\zeta)\_{+}\;+\;\text{ MV terms} |  |

with budget/box/turnover constraints yields a CVaR-over-drawdown relaxation that stays QP-like
after linearization, enabling direct drawdown control in multi-step allocation.

### A.17 Envelope for Decision-Aware Training

Consider Vâ€‹(Î¸;zt)=minxâˆˆXâ¡Fâ€‹(x;Î¸,zt)V(\theta;z\_{t})=\min\_{x\in X}\,F(x;\theta,z\_{t}) where x=(w,Î¶,{ui},s+,sâˆ’)x=(w,\zeta,\{u\_{i}\},s^{+},s^{-})
and XX fixes budget/box/turnover constraints (Î¸\theta-independent). Then

###### Theorem 9 (Constraint-Independent Envelope).

If Fâ€‹(â‹…;Î¸,zt)F(\cdot;\theta,z\_{t}) is continuously differentiable in Î¸\theta and XX does not depend on Î¸\theta,
then at any optimum xâ‹†â€‹(Î¸;zt)x^{\star}(\theta;z\_{t}),

|  |  |  |
| --- | --- | --- |
|  | âˆ‡Î¸Vâ€‹(Î¸;zt)=âˆ‚Î¸Fâ€‹(xâ‹†â€‹(Î¸;zt);Î¸,zt).\nabla\_{\theta}V(\theta;z\_{t})\;=\;\partial\_{\theta}F\big(x^{\star}(\theta;z\_{t});\theta,z\_{t}\big). |  |

###### Sketch.

Direct envelope theorem: no constraint Jacobians in Î¸\theta; dual terms vanish from the gradient.
âˆ

###### Corollary 3 (Smooth hinge surrogate for CVaR).

Replacing (x)+(x)\_{+} by a smooth (1/Î²)â€‹logâ¡(1+eÎ²â€‹x)(1/\beta)\log(1+e^{\beta x}) yields
âˆ‡Î¸ğ”¼â€‹[Vâ€‹(Î¸;zt)]=ğ”¼â€‹[âˆ‚Î¸Fâ€‹(xâ‹†;Î¸,zt)]\nabla\_{\theta}\mathbb{E}[V(\theta;z\_{t})]=\mathbb{E}[\partial\_{\theta}F(x^{\star};\theta,z\_{t})],
facilitating end-to-end training with a single QP solve per step.

### A.18 CVaR Estimation with Tail Reweighting

Let CVaR^Î±\widehat{\mathrm{CVaR}}\_{\alpha} be the empirical epigraph estimator using NN scenarios.

###### Assumption 7 (Tail regularity).

The loss distribution has continuous density near VaRÎ±\mathrm{VaR}\_{\alpha} and finite second moment
on the lower tail.

###### Theorem 10 (Rate with tail emphasis).

For weights wi=1+Î·â€‹â€‰1â€‹{â„“~iâ‰¤Qqâ€‹(â„“~)}w\_{i}=1+\eta\,\mathbf{1}\{\tilde{\ell}\_{i}\leq Q\_{q}(\tilde{\ell})\} normalized to wÂ¯i\bar{w}\_{i},

|  |  |  |
| --- | --- | --- |
|  | |CVaR^Î±âˆ’CVaRÎ±|=Oâ„™â€‹(1ESSâ€‹(q,Î·)),\big|\widehat{\mathrm{CVaR}}\_{\alpha}-\mathrm{CVaR}\_{\alpha}\big|=O\_{\mathbb{P}}\!\left(\sqrt{\frac{1}{\mathrm{ESS}(q,\eta)}}\right), |  |

with ESSâ€‹(q,Î·)\mathrm{ESS}(q,\eta) from App.Â A.12. Moderate (q,Î·)(q,\eta) balances bias/variance:
higher tail mass can reduce variance of the tail average while keeping ESS large.

### A.19 Gate Monotonicity â‡’\Rightarrow Tail-Region Risk Drop

Let gâ‹†â€‹(Z)=â„™â€‹(C=crisisâˆ£Z)g^{\star}(Z)=\mathbb{P}(C=\mathrm{crisis}\mid Z) and suppose the crisis expert dominates on the
tail region: ğ”¼â€‹[â€–Îµâˆ’Îµcrisisâ‹†â€–2|â„“~â‰¤Qqâ€‹(â„“~)]â‰¤ğ”¼â€‹[â€–Îµâˆ’Îµbaseâ‹†â€–2|â„“~â‰¤Qqâ€‹(â„“~)]\mathbb{E}\big[\|\varepsilon-\varepsilon\_{\mathrm{crisis}}^{\star}\|^{2}\,\big|\,\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\big]\leq\mathbb{E}\big[\|\varepsilon-\varepsilon\_{\mathrm{base}}^{\star}\|^{2}\,\big|\,\tilde{\ell}\leq Q\_{q}(\tilde{\ell})\big].

###### Proposition 8 (Tail-risk improvement under monotone gate).

If gâ€‹(Z)g(Z) is non-decreasing in the HMM crisis posterior (Sec.Â 3.6), then for sufficiently small
ğ”¼â€‹[(gâˆ’gâ‹†)2]\mathbb{E}[(g-g^{\star})^{2}], the MoE denoiser strictly reduces tail-region MSE versus either single expert.

###### Sketch.

Risk decomposition from the MoE oracle inequality (App.Â A.13) and the dominance assumption on the tail set.
âˆ

### A.20 End-to-End Decision Gap under Distribution Shift

Let PP (train) and QQ (test) satisfy W1â€‹(P,Q)â‰¤ÏW\_{1}(P,Q)\leq\rho for scenario distributions.
Assume per-scenario loss Lâ€‹(w,r)L(w,r) is KK-Lipschitz in rr for feasible ww.

###### Theorem 11 (Shift-aware decision bound).

Let w^\hat{w} be the optimizer under PÎ¸P\_{\theta} and wQâ‹†w\_{Q}^{\star} under QQ.
Then for the CVaR objective,

|  |  |  |
| --- | --- | --- |
|  | FQâ€‹(w^)âˆ’FQâ€‹(wQâ‹†)â‰¤c1â€‹Ltail1/2âŸtrain gen. gap+c2â€‹Ï/(1âˆ’Î±)âŸshift gap+c3â€‹â€–Î¼^âˆ’Î¼Qâ€–2+c4â€‹â€–Î£^âˆ’Î£Qâ€–opâŸmoment error,F\_{Q}(\hat{w})-F\_{Q}(w\_{Q}^{\star})\;\leq\;\underbrace{c\_{1}\,L\_{\text{tail}}^{1/2}}\_{\text{train gen. gap}}\;+\;\underbrace{c\_{2}\,\rho/(1-\alpha)}\_{\text{shift gap}}\;+\;\underbrace{c\_{3}\,\|\hat{\mu}-\mu\_{Q}\|\_{2}+c\_{4}\,\|\hat{\Sigma}-\Sigma\_{Q}\|\_{\rm op}}\_{\text{moment error}}, |  |

for constants (ci)(c\_{i}) depending on feasible-set radii and strong convexity.

###### Sketch.

Combine App.Â A.11 (spectral control), App.Â A.15 (CVaR W1W\_{1} continuity), and App.Â A.14 (allocator Lipschitz).
âˆ