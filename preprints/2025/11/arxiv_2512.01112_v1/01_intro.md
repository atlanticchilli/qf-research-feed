---
authors:
- Tarun Chitra
doc_id: arxiv:2512.01112v1
family_id: arxiv:2512.01112
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: 'Autodeleveraging: Impossibilities and Optimization'
url_abs: http://arxiv.org/abs/2512.01112v1
url_html: https://arxiv.org/html/2512.01112v1
venue: arXiv q-fin
version: 1
year: 2025
---


Tarun Chitra
  
Gauntlet
  
tarun@gauntlet.xyz

(November 30, 2025)

###### Abstract

Autodeleveraging (ADL) is a last-resort loss socialization mechanism for perpetual futures venues.
It is triggered when solvency-preserving liquidations fail.
Despite the dominance of perpetual futures in the crypto derivatives market, with over $60 trillion of volume in 2024, there has been no formal study of ADL.
In this paper, we provide the first rigorous model of ADL.
We prove that ADL mechanisms face a fundamental *trilemma*: no policy can simultaneously satisfy exchange *solvency*, *revenue*, and *fairness* to traders.
This impossibility theorem implies that as participation scales, a novel form of *moral hazard* grows asymptotically, rendering â€˜zero-lossâ€™ socialization impossible.
On the positive side, we show that three classes of ADL mechanisms can optimally navigate this trilemma to provide fairness, robustness to price shocks, and maximal exchange revenue.
We analyze these mechanisms on the Hyperliquid dataset from October 10, 2025, when ADL was used repeatedly to close $2.1 billion of positions in 12 minutes.
By comparing our ADL mechanisms to the one used in practice on Hyperliquid and Binance, we demonstrate empirically that Hyperliquidâ€™s production queue overutilized ADL by â‰ˆ8Ã—\approx 8\times relative to our optimal policy, imposing roughly $630 million of unnecessary haircuts on winning traders.
This comparison also suggests that Binance overutilized ADL far more than Hyperliquid.
Our results both theoretically and empirically demonstrate that optimized ADL mechanisms can dramatically reduce losses of trader profitability while maintaining exchange solvency.

## 1 Introduction

Perpetual futures (or simply, perpetuals) are by far the most popular crypto derivatives contract.
These contracts allow for duration-independent hedging of cryptocurrencies, such as Bitcoin, Ethereum or Solana.
That is, unlike traditional future contracts, perpetuals are not subject to a fixed expiration date.
Instead, perpetuals are similar to *contracts for difference*, where market participants repeatedly send each other payments depending on how the spot price trades relative to the futures price.
For instance, if the spot price is higher than the futures price, then traders with short futures positions pay the traders with long futures until the prices are equalized.
We note that while Robert Shillerâ€™s 1993 proposal for perpetual futures provides the genesis of this idea, the BitMEX exchangeâ€™s 2016 launch of the XBTUSD perpetual swap became the first live implementationÂ [shiller1993measuring, Soska2021BitMEX, Hayes2025AdaptOrDie].

Perpetual futures have a higher notional trading volume than spot cryptocurrency volume.
This is akin to index futures for US stocks, where there is far more volume traded in the futures contracts than the underlying spot assets, with the S&P 500 futures index future trading roughly ten times more volume than the spot assetÂ [CMEGroup2024EqualWeight].
In 2024, centralized crypto exchanges such as Binance and Bybit processed nearly $58.5 trillion (notional) in perpetuals tradesÂ [CoinGecko2025Perps].
On the other hand, centralized exchanges processed nearly $17.4 trillion of spot cryptocurrency tradesÂ [CoinGecko2025Q1], which is a 3.3x ratio of perpetuals to spot volume.

The main reason for the elevated usage of perpetual futures, much like their index futures cousins, is due to the high level of leverage they offer.
In particular, the capital requirements for trading perpetual futures are much lower than spot trading.
Moreover, the continuous nature of perpetual futures allows for easier margin management than duration-based futures.
This is illustrated via the large gap between the maximum leverage offered by perpetuals exchanges (up to 125xÂ [Binance2025CollateralLeverageUpdate]) versus the index futures on the Chicago Mercantile Exchange (around 10-15x leverage for index futuresÂ [CMEGroup2025SP500Margins]).

##### Centralized vs. Decentralized Exchanges.

Historically, the majority of perpetuals trading volume has been concentrated on centralized exchanges (CEXes).
These venues, which include Binance, Bybit, and Coinbase, require users to deposit collateral that is custodied by the exchange.
The exchange is responsible for ensuring that usersâ€™ positions are solvent and that their collateral is not used to cover losses from other traders.
In practice, this involves traders having to trust the exchange to not use their collateral for other purposes.
In 2022, centralized exchange FTX was found to have utilized customer collateral for other purposes, leading to multi-billion-dollar lossesÂ [FTXDebtors2023Report].

In response, there has been an increasing trend in the usage of decentralized exchanges (DEXes) for trading perpetual futures.
These exchanges provide far more transparency and auditability into the mechanics of the exchange.
In particular, userâ€™s can always verify what their collateral is being used for and what positions it is collateralizing.
Moreover, these exchanges are permissionless and pseudonymous, meaning anyone can trade on these exchanges without explicitly revealing their identity.

The transparent nature of decentralized exchanges does have, however, a downside.
Most positions in decentralized exchanges need to be fully overcollateralized, which generally means traders can take less leverage than they would on a centralized exchange.
Generally speaking, this is because the exchange doesnâ€™t know the identity of a trader and can only enforce global collateral invariants (e.g.Â assets > liabilities) by forcing users to post more collateral than if the exchange knew their identity.
Early decentralized perpetuals exchanges, such as perpetual protocol, were unable to offer much more than 5x leverage.

However, in recent years, hybrid models of decentralized exchanges where withdrawals and deposits are permissionless, but certain exchange operations are centralized, have become popular.
The most popular exchange of this form is Hyperliquid, which has helped increase the market share of perpetuals volume on DEXs from roughly 1% in 2024 to over 8% in 2025.
These hybrid models allow for the exchange to use cryptographic commitments to enforce collateral rights while also allowing for oracles, markets, and solvency to be controlled by a smaller set of participants.
This allows the exchange to avoid issues that fully open decentralized exchanges have, where weak collateral can be added to an exchange that cannot be sold or liquidated successfully during a market crash to ensure solvency.

More concretely, there have been recent incidents on perpetual DEXs that highlight how novel market structures can be exploited or stressed in practice.
These include but are not limited to: Hyperliquidâ€™s XPL pre-market price spike and the JellyJelly attackÂ [CryptoTimesXPL2025, ODailyXPL2025, OakResearchJELLY].
These episodes led to emergency safeguards and community post-mortems, underscoring the need for robust oracle design, listing policies, and circuit breakers to mitigate manipulation.
Such emergency responses would have been nearly impossible in the fully decentralized setting, demonstrating the value of hybrid models of decentralization in perpetual futures.

##### Liquidations.

Despite the empirical prominence of perpetuals markets, there has been little formal study of the stability and robustness of these markets relative to the large body of research into spot cryptocurrency trading.
For instance, the main price stability mechanism used for perpetuals is the *funding rate*, a continuous payment stream between the long and short positions.
There has been some study of how to replicate funding rates via other financial instrumentsÂ [AngerisChitra2023PerpsSIAM, he2022fundamentals, ackerer2024perpetual], but little to no empirical study of how well such approximations work.
Even more surprising is the lack of formal study of how robust perpetual exchanges are under high leverage conditions, despite their usage being driven by high leverage traders.

A crucial component to ensuring the stability of perpetual futures markets with high leverage isÂ *liquidation*.
This is the process of closing a userâ€™s position that is worth less than the cash collateral they have posted to the exchange.
Perpetuals exchanges rely on liquidation mechanisms to ensure that they stay solvent â€” that is, the assets they hold are greater than the liabilities they owe to traders.
To the authorâ€™s knowledge, there has been no formal study of liquidations in perpetuals exchanges, despite there being a large body of work studying liquidations in overcollateralized cryptocurrency lending (e.g.Â [perez2021liquidations, kao2020analysis, sun2022liquidity, qin2021empirical]).

Liquidations are executed by taking the collateral of a trader and selling it in a manner that minimizes losses that the exchange realizes.
In centralized exchanges, liquidations are usually executed by the exchange itself in its own spot markets.
For instance, suppose that a user uses $1,000 worth of collateral to open a long position with 10x leverage.
This implies that if the price falls from the initial price when the contract was opened, p0p\_{0}, by roughly 10%, then the userâ€™s position will have a value of -$1,000, so that userâ€™s net position is $0.
If the price decreases beyond this point, then the userâ€™s position will have a negative value, implying that the user owes the exchange (and hence, other traders) capital.
We say that a traderâ€™s position is *insolvent* if such a negative net position is realized.

Exchanges utilize liquidations to remove trader positions before they are insolvent.
For instance, in our example, an exchange might deem a traderâ€™s position to be liquidatable if the price falls by 9%, such that the traderâ€™s position is closed before insolvency.
Provided that the exchange can execute this position (inclusive of transaction fees and market impact costs) at a price in between 0.91â€‹p00.91p\_{0} and 0.9â€‹p00.9p\_{0}, the position can be closed profitably.
This profit is usually distributed to other traders in the exchange, added to an insurance fund for future losses, or realized as a profit for the exchange.

Centralized exchanges usually execute liquidations in their own spot markets.
This is because they can effectively guarantee atomicity of liquidations, ensuring that the liquidation transaction does not get front run and have a worse execution price than expected.
In decentralized exchanges, liquidiations are usually executed by third-party actors known as liquidators.
Liquidators can be viewed as traders who have the ability to warehouse the inventory of a collateral position and exit profitably.
From an economic perspective, liquidations need to be profitable for either the exchange or the liquidator in order to help with exchange solvency.

##### Autodeleveraging.

In severe market dislocations, it is sometimes possible for liquidations to be so deeply unprofitable that they are unable to be executed by any party.
When this happens, the exchange can reach a state of insolvency, where the assets held are less than the liabilities owed to its traders.
This excess in liabilities is known as the *shortfall*.
In such scenarios, a natural strategy to reduce the risk of total insolvency is to socialize losses by haircutting profitable (or *winning*) traders.
In the worst case, a winning userâ€™s position is completely closed to zero, leaving them with a potentially large opportunity cost.
This process is known as *autodeleveraging* (ADL) and is a last-resort measure used by exchanges.

Autodeleveraging is unique in that it algorithmically socializes losses on winners based on a public rule or mechanism that an exchange posts.
This means that all of the position closures and implicit liquidations of insolvent positions are performed in an irreversible and atomic manner.
The closest analogue to autodeleveraging in traditional finance is a central counterparty (CCP) such as a derivatives clearing house.
In traditional finance, CCPs employ default waterfalls and loss mutualization (including variation-margin gains haircutting (VMGH)) that share the same core idea of allocating residual losses across non-defaulting membersÂ [DuffieZhu2011, Pirrong2011, CPMI\_IOSCO\_2014, ContGhamamiSITG, KubitzaWinnersLosers, Turing2019MagicRelighting].
CCPs generally have manual, non-algorithmic socialization and disbursement of insurance funds during such events with disputes reconciled via the legal system.
We note, furthermore, that only clearing members bare the losses in CCPs, which leads to a different principal-agent dynamic than perpetuals markets as smaller traders need not bare the final losses.

Autodeleveraging, to the best of the authorâ€™s knowledge, was first introduced by the crypto exchange Huobi in 2015Â [HuobiADL].
Prior to the implementation of ADL, exchanges would manually socialize losses, with the exchange serving as the sole CCP.
By 2016, the BitMEX exchange implemented ADL via a formula that ranked trader positions for ADL by their profit times their leverageÂ [BitMEXADL].
This formula persists to today on virtually every centralized exchange (including Binance, who implemented the formula in 2019Â [BinanceADL]) and on the decentralized exchange HyperliquidÂ [HyperliquidDocsLiquidations].
We note that there are some decentralized exchanges such as DriftÂ [DriftADLCode] and ParadexÂ [ParadexADLBlog] that use a different ADL mechanism (the *pro-rata* mechanism defined inÂ Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
However, well over 95% of perpetuals trading volume is on exchanges that utilize the BitMEX ranking model.

In practice, ADL is reserved for extreme tail events where routine liquidation mechanisms are insufficient to maintain venue solvency.
There are two primary scenarios that can trigger ADL activation.
First, a sudden and large price movement can push positions far beyond their liquidation thresholds before the exchangeâ€™s liquidation system can execute the necessary trades.
Second, a temporary but severe loss of executable liquidity in the order book can prevent the exchange from closing positions at prices near their liquidation triggers, even when the price movement itself is not extreme.

To illustrate how such scenarios can lead to insolvency, consider a concrete example.
Suppose that a trader posts $1,000 of collateral to take a 10x leveraged long position with a notional value of $10,000, where the position becomes liquidatable when the price declines by 9% from its initial value p0p\_{0}.
Under normal market conditions, the exchange would execute a liquidation when the price reaches 0.91â€‹p00.91\,p\_{0}, closing the position and recovering the collateral.
However, if an abrupt 12% price drop occurs between price updates or during a period of low liquidity, the position may be closed at a significantly worse execution price, such as 0.88â€‹p00.88\,p\_{0} rather than the intended 0.91â€‹p00.91\,p\_{0}.
In this scenario, the accountâ€™s equity becomes negative, representing approximately 2% of its initial collateral value.
When many traders simultaneously experience such execution slippage and the exchangeâ€™s insurance fund reserves cannot absorb the aggregate resulting losses, the venue triggers ADL.
Under the exchangeâ€™s predefined ADL rules, the system algorithmically reduces or closes profitable opposing positions until the shortfall is covered and solvency is restored.

Inherently, ADL creates *moral hazard* â€” that is, losing traders have an incentive to take on more risk in anticipation of being socialized by winning traders.
The goal of an exchange is to balance the risk of insolvency against haircutting winning trader profits.
Moral hazard is measured by this trade-off â€” if it is possible to reduce the risk of insolvency to zero without haircutting winning traders, then the system has no moral hazard.
On the other hand, if it is not possible to reduce the risk of insolvency by any appreciable amount without severely haircutting winning trades, the system has excessive moral hazard.
The job of an exchange operator is to choose an ADL mechanism that tries to induce a low level of moral hazard under most tail event scenarios.
This connects to principalâ€“agent models of moral hazard and linear/robust contracting [Holmstrom1982, Carroll2015RobustLinearContracts, DuttingEtAl2023MultiAgentContracts], with key differences: many agents act simultaneously, externalities operate through a common solvency constraint, and tail-risk mitigation substitutes for standard effort observability.

Despite the rarity of ADL, it is certainly not hypothetical: there have been dozens of instances of ADL activations on major venues since 2018Â [BinanceADL, BitMEXADL, AevoADL, CoinglassADL].
The largest episode of ADL usage was on October 10-11, 2025 (UTC), when outsized liquidations exhausted insurance funds and multiple venues simultaneously invoked ADLÂ [CoinDesk2025LargestLiquidations].
However, other famous incidents such as the March 2020 â€œBlack Thursdayâ€ and May 19, 2021 deleveraging event were other prominent days involving ADL usage.
Most of these usages of ADL often involved controversies, in that highly profitable but lower risk (e.g.Â lower leverage) traders found their positions closed out by ADL mechanisms.
These traders have often threatened to sue exchanges for unfair treatment, with rumors and public speculation surfacing during Oct. 10â€“11, 2025 (subsequently denied by Wintermute)Â [CointelegraphWintermute2025, TheBlockWintermute2025]111See also prior complaints during May 2020 on Binance futures when profitable shorts were closed via ADLÂ [CointelegraphBinanceADL2020].

This incidents demonstrate a natural trade-off that perpetuals exchanges have to make: they can either aggressively socialize losses to their winners and (potentially) lose the future revenue of these users while preserving solvency or hold the losses due to the insolvency on their balance sheet.
In the former case, the exchange effectively chooses to prioritize short term solvency and potential liquidation profits over long term value and fees generated by users.
The latter case, effectively creates a long term risk for the exchangeâ€™s balance sheet, especially if it does not have sufficient funds to cover insolvencies.
This strongly suggests that one can view the choice of how an exchange implements ADL as a trade-off between solvency, moral hazard, and long term revenue for an exchange.

We note that open interest post October 10, 2025 that suggests that Hyperliquid has nearly 50% of open interest, whereas competitors such as Lighter and even Binance have recovered to pre-event levels.222Source: DeFiLlama perpetuals dashboard, <https://defillama.com/perps>, accessed Nov. 30, 2025.
Open interest is generally more expensive to manipulate than trading volume and can serve as a coarse measurement of expected future revenue for an exchange.
Numerous parties have argued that this open interest loss for Hyperliquid is due to their overly aggressive ADL policy.333See, e.g.Â , public commentary from @fiddybps1, @0xReaz, @Eugene\_Bulltime, and @0xLouisT on X (Nov. 2025): <https://x.com/fiddybps1/status/1978750722901762321>, <https://x.com/0xReaz/status/1986486213101166599>, <https://x.com/Eugene_Bulltime/status/1994380900067582182>, <https://x.com/0xLouisT/status/1990815109787058654>.

##### This Paper.

In this paper, we provide (to the authorâ€™s best knowledge) the first formal mathematical model of autodeleveraging.
The main model of the paper is venue-agnostic: it abstracts away pricing (e.g.Â order book versus automated market maker microstructure) and focuses on how positions are opened and closed.
As a warning to the reader: this paper is more verbose than necessary.
The author aims to provide a self-contained, pedagogical introduction to perpetual futures and liquidations, as the current literature and open source documentary does not cover liquidations and ADL in any manner comprehensive enough for formal study.
Throughout the paper, there will be numerous simple numerical examples to illustrate the basic concepts and mechanics of perpetual futures.

The first section of the paper (Â§[2](https://arxiv.org/html/2512.01112v1#S2 "2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) provides definitions and examples of the basic objects â€” *positions* â€” and basic operations that one can perform on them.
In the process of defining the set of operations on positions, we will naturally need to define the economics of positions using funding rates and arbitrage.
These definitions will hopefully provide answers to the questions of why one opens a position, how much one has to spend on keeping a position open, and how positions on different exchanges achieve price synchronization.
From these economic properties, we will naturally define solvency for both individual traders and of the exchange itself.

Liquidations and ADL then naturally follow as operations that exist to try to use economic means to enforce solvency constraints with high probability.
We will define the set of ADL mechanisms in a sufficiently broad manner to allow for venue-specific ADL, this allowing us to compare Binance, Hyperliquid, Drift, and other exchanges.
Our decomposition of the ADL strategy space intoÂ *severity* (i.e.,Â dollar amount impacted by ADL) and *haircuts* (i.e.,Â per-trader percentage liquidated) allows us to separate exchange solvency and trader profitability into two separate optimization problems.
This will be key to simplifying our results and constructing practical algorithms.

Given a perpetuals exchange, defined in the combinatorial manner ofÂ Â§[2](https://arxiv.org/html/2512.01112v1#S2 "2 Background â€£ Autodeleveraging: Impossibilities and Optimization"), we next focus on notions of risk that are endemic to perpetuals exchanges inÂ Â§[3](https://arxiv.org/html/2512.01112v1#S3 "3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization").
We construct a set of risk measurements that, while specific to perpetuals exchanges, are connected to classical risk metrics such as Value-at-Risk.
Subsequently, we describe four facets of perpetuals exchange risk that we will analyze: extreme value analysis, Schur ordering, fairness, and moral hazard.

Extreme value analysis is the classical actuarial estimation of tail probabilities and rare events.
We provide a simple primer to make the text self-contained and our notation consistent.
The Schur ordering provides a way of partially ordering risk measurements, even if they are not fully comparable.
This allows us to compare ADL mechanisms across venues, despite the fact that the outcomes might not have explicitly comparable risks in every situation.
Algorithmic fairness measures (axiomatic and optimization-based) are subsequently introduced to concretely answer the question of whether ADL is more fair to certain traders than others.
Finally, we describe the general moral hazard problem and specialize it to the perpetuals exchange setting.
In this setting, it corresponds to whether the exchange operator has an incentive to take on more risk than necessary because they can socialize worst-case losses on their best traders.

With these risk tools in tow, we are now prepared to describe the main results of the paper.
We have five classes of results in this paper:

1. 1.

   *Negative*: Moral hazard is strictly increasing in the size of the exchange.
2. 2.

   *Fairness*: The Pro-Rata ADL mechanism is the most fair mechanism
3. 3.

   *Robustness*: Given a risk model gg for historical user behavior, there is a unique ADL mechanism maximally robust to price shocks
4. 4.

   *ADL as Stackelberg Game*: Multiple price shocks causing ADL to be used repeatedly are a Stackelberg game that can be studied rigorously.
5. 5.

   *Empirical*: Using Hyperliquidâ€™s data from October 10, 2025, where ADL was used over 40 times in a 10 minute period, we evaluate the performance of difference ADL mechanisms

##### Negative Results.

Our negative results focus on quantifying limits to how much ADL can actually reduce insolvency without inuring traders with disproportionate losses.
We explicitly ask the question of how the loss of profit due to ADL to the trader with the highest PNL scales as the number of positions nn grows.
We quantify this by looking at ratios of the maximum winnerâ€™s profit to the total shortfall (over all traders) and to the worst traderâ€™s shortfall.
These ratios can be viewed as analogues of the Value-at-Risk and Expected Shortfall metrics in traditional risk modeling, as we show in AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").
The main difference is that while Value-at-Risk and Expected Shortfall measure the total expected loss (over all traders) in tail events, our metrics only measure the expected loss to the most winning trader.
Moreover, AppendixÂ [B.5](https://arxiv.org/html/2512.01112v1#A2.SS5 "B.5 Relationship to Classical Risk Measures â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") shows that classical VaR/ES rankings echo the same conclusion: queue-based ADL always delivers the lowest top-winner survival even under these traditional risk lenses.

When these ratios, as constructed, are bounded below by a constant, then the winner can expect to always retain at least a constant fraction of their earnings after an ADL event.
However, if these ratios decay to zero, then the winner has no guarantee of retaining any of their profits after an ADL event.
We show that under some mild technical assumptions, these ratios decay as Oâ€‹(bnn)O(\frac{b\_{n}}{n}), where bnb\_{n} is the *extreme value scale* (EV scale) of profits (seeÂ Â§[3](https://arxiv.org/html/2512.01112v1#S3 "3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization")).
For most well-behaved probability distributions over the set of profits, bn=oâ€‹(n)b\_{n}=o(n), so the ratios decay to zero.
This result establishes a fundamental limit of these markets: moral hazard scales with participation.
It suggests that as crypto exchanges grow, ADL must become either more frequent or more severe for top traders; they cannot â€œgrow outâ€ of the problem.

##### Fairness Results.

As the negative results show that no ADL mechanism can scale to preserve winnerâ€™s profit, a natural follow-up question is, what is the most fair way of socializing profitable users?
We consider two notions of fairness inÂ Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"): axiomatic and optimization-based.
They are both common in the algorithmic fairness literature within machine learningÂ [KleinbergEtAl2018FairnessImpossibility, BarocasHardtNarayanan2019FairnessBook, Mehrabi2021SurveyFairness, DworkEtAl2012FairnessAwareness, Agarwal2018ReductionsFairness, HardtPriceSrebro2016EqualityOfOpportunity].
We demonstrate that the pro-rata ADL rule (used by DriftÂ [DriftADLCode] and ParadexÂ [ParadexADLBlog]) is the unique fair ADL rule in *both* the axiomatic and optimization sensesÂ [johnson2023concave].

Axiomatic fairness involves defining rules or invariants that a particular ADL mechanism must satisfy to be deemed fair.
The rules we analyze for fairness are monotonicity, scale invariance and Sybil resistance.
Roughly speaking, monotonicity says that if you were the kkth highest winner (ranked by PNL) before ADL, then you will be the kkth highest winner after ADL.
Scale invariance states that if everyone scaled up their positions by an equal factor, their loss due to ADL does not change.
And finally, Sybil resistance states that splitting a position into multiple positions does not change the loss due to ADL.
We show that under mild smoothness conditions, the pro-rata ADL rule is the unique rule to satisfy these axioms.
In stark contrast, we show that the queue-based mechanisms used by Binance and Hyperliquid are effectively â€œanti-fairâ€: in our model and data they produce extremely low Profit-to-Solvency Ratios (PTSR), imposing disproportionately large losses on the top winner.
This finding contradicts the common intuition that queues are orderly; instead, they concentrate losses on the most successful traders.

Optimization-based fairness involves showing that for a large class of individual trader utility functions, a particular mechanism maximizes social welfare (i.e.,Â the total profit).
This is more of a system-wide fairness notion, as it shows that the system as a whole is fair, even though there might be individuals who were punished more by an ADL mechanism.
Unlike the axiomatic rules, which have to hold for every trader exactly, the optimization-based fairness rules can be thought of as â€˜fuzzierâ€™ and allowing for more slack.
Despite this, we still show that the pro-rata ADL rule is the unique rule to maximize social welfare for a large class of concave utility functions.

##### Robustness Results.

A natural question, beyond fairness, is whether an ADL rule is *robust* to subsequent price shocks.
The main question here is whether the choices of severities (e.g.Â total amount to socialize) and haircuts (e.g.Â per-account socialization) increases the chance of insolvency should another price shock occur.
InÂ Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization"), we consider a new threat model where an ADL mechanism is graded based on how well it reduces to total shortfall from two price shocks.
The model involves a price shock occurring that triggers ADL, an ADL policy being executed, and then another price shock occurring.

We show that a natural way to model total shortfall is via a *risk model* gg that maps a userâ€™s amount of leverage used to a risk score.
A higher risk score implies that a traderâ€™s leverage level places a higher burden on the rest of the exchangeâ€™s solvency, especially in the repeated price shock scenario.
We first show that the risk model is effectively a way to quantify the total shortfall.
Given a stochastic process for price shocks, one can construct an optimal risk model (using convex duality) gâˆ—g^{\*} that maximizes the total solvency gained per dollar of winner position that is haircut by an ADL policy.
With the optimal risk model in hand, we construct a linear-time algorithm to choose haircuts for each trader that are weighted by this model.
We then show that the resulting ADL policy derived from these weights has lowest expected total shortfall and is the optimal ADL policy (in the Schur ordering sense).

##### ADL as a Stackelberg Game.

A direct extension of the robustness threat model is to consider a sequential ADL problem, where for multiple rounds, a price shock is received, the exchange chooses an ADL policy, and then losses are realized.
This model might at first glance seem to only have theoretical value since ADL is itself a rare event.
However, on October 10, 2025 there were multiple ADL events that occurred over a short time window on both Hyperliquid and Binance.
While the account-level data for Binanceâ€™s usage of ADL is not public, we do have this data for Hyperliquid.
Starting at 10:21:00 UTC, there were at least 40 recorded ADL events on Hyperliquid in a 10 minute period.
This strongly suggests that there is clustering or cascading of ADL events, making the multiple round model necessary to study.

Unlike in the single round models (used for fairness and robustness), the exchange is allowed to adjust their ADL policy after each ADL shock.
One can view this as a sequential game and we argue that it is a *Stackelberg game*.
Stackelberg games have a well-known follower-leader decompsoition, where one user (the leader) plays a strategy first.
Then the follower conditions their strategy on the leaderâ€™s action, before playing their own move.
In the ADL setting, the exchange is the leader and the traders are the followers.

We first show that viewing ADL as a dynamic, multiple round Stackelberg game leads to sharply different equilibria.
We prove a crucial â€œprincipal-agentâ€ tension: any strategy an exchange executes that minimizes the time to recover solvency (i.e.,Â number of rounds) necessarily maximizes the loss of exchange long-term revenue.
This trade-off is the economic heart of the paper: the exchange wants to be solvent in few rounds, but doing so destroys the best customers (e.g.Â the whales).
Intuitively, this occurs because any strategy that quickly recovers solvency autodeleverages the largest winners more aggressively.
These winners, however, are also often the most profitable users and generate high long-term fees for the exchange.
By liquidating them aggressively, youâ€™re removing the capital that they would use to later create positions and generate fees.
We note that threats to sue exchanges for ADL losses in profit after October 10, 2025 provide indirect empirical evidence to support this theoretical resultÂ [CointelegraphWintermute2025, TheBlockWintermute2025].

This implies that any optimal ADL policy over multiple ronds also has to include incentive compatibility constraints that balance future exchange revenue, current exchange solvency, and current trader profits.
We construct an explicit algorithm for optimizing a revenue and solvency based objective and show that a simple mirror descent algorithm achieves vanishing regret for this objective.
We conclude with a simple example demonstrating that no static policy that dominate the dynamic policy, especially when exchange long-term revenue is a consideration.

##### Empirical Results: The $630 Million Inefficiency.

We conclude by analyzing the October 10, 2025 ADL events on Hyperliquid.
Unlike centralized exchanges like Binance and Bybit, Hyperliquid publicly shares all position data, including position leverage, collateral, PNL, and ADL status.
Using this data, we evaluate the efficiency of Hyperliquidâ€™s ADL mechanism (which is a slight modification of the original 2015 Huobi queueing mechanism).
We show that Hyperliquid autodeleveraged roughly Â $705m of winning trader PNL during the 12 minute cascade on October 10, 2025.
Over the same period, there were at least 40 ADL events which accumulated a total of Â $304m of negative equity positions.444Hyperliquidâ€™s on-chain fill log for 10 Oct. 2025 records 34,983 individual ADL executions across 19,337 distinct wallets and 162 tickers. We analyze the per-fill data but aggregate those executions into the 40 queue waves discussed in the text.
Measured shock-by-shock, this implies the production queue generated about Â $630m of overshootâ€”haircuts beyond the deficits that actually materialized.
This result highlights a massive capital inefficiency in current queue-based mechanisms: they are not just unfair; they destroy hundreds of millions of dollars of trader value unnecessarily.

We then compare the pro-rata, risk-weighted pro-rata, and dynamic mechanisms to the live queueing mechanism used.
We utilize these methods with different severity optimization algorithms and show that all of these algorithms were able to learn to autodeleverage substantially less than what Hyperliquid did in practice.
Utilizing these algorithms on the historical data, we find that nearly 98% of the over autodeleveraging used by Hyperliquid could have been removed by a smarter ADL policy.

##### Notation.

* â€¢

  For a vector xâˆˆRnx\in{\mbox{\bf R}}^{n}, we define (x)+=maxâ¡(x,0)(x)\_{+}=\max(x,0), where this is done coordinate-wise and (x)âˆ’=minâ¡(x,0)(x)\_{-}=\min(x,0) (also coordinate-wise).
  Using our convention, we have (x)+=âˆ’(âˆ’x)âˆ’(x)\_{+}=-(-x)\_{-}
* â€¢

  We denote the set of integers {1,â€¦,n}\{1,\ldots,n\} by [n][n].
* â€¢

  For a sequence x1,x2,â€¦x\_{1},x\_{2},\ldots, we denote the subsequence from ss to tt as xs:t=(xs,xs+1,â€¦,xt)x\_{s:t}=(x\_{s},x\_{s+1},\ldots,x\_{t}).
* â€¢

  We use ğŸE\mathbf{1}\_{E} or ğŸâ€‹{E}\mathbf{1}\{E\} to denote the indicator function of an event EE, which is 11 if EE is true and 0 otherwise.
* â€¢

  We use the notation fâ€‹(n)â‰gâ€‹(n)f(n)\asymp g(n) to denote that fâ€‹(n)=Î˜â€‹(gâ€‹(n))f(n)=\Theta(g(n)), i.e.,Â there exist constants c,C>0c,C>0 such that câ€‹|gâ€‹(n)|â‰¤|fâ€‹(n)|â‰¤Câ€‹|gâ€‹(n)|c|g(n)|\leq|f(n)|\leq C|g(n)| for sufficiently large nn.
* â€¢

  We write Xnâ‰pYnX\_{n}\asymp\_{p}Y\_{n} for random variables Xn,YnX\_{n},Y\_{n} if there exist constants c,C>0c,C>0 such that câ€‹|Yn|â‰¤|Xn|â‰¤Câ€‹|Yn|c|Y\_{n}|\leq|X\_{n}|\leq C|Y\_{n}| with high probability as nâ†’âˆn\to\infty.
* â€¢

  For vectors x,yâˆˆRnx,y\in{\mbox{\bf R}}^{n}, we write xâ‰ºyx\prec y if xx is majorized by yy (see Â§[3.2](https://arxiv.org/html/2512.01112v1#S3.SS2.SSS0.Px1 "Schur-Convexity and Submajorization. â€£ 3.2 Fairness and Distributional Comparisons â€£ 3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization") for details).

## 2 Background

We will first introduce a mathematical model for solvency risks in a perpetuals exchange.
Using this model, we define the key components for measuring the solvency of perpetuals exchanges: trader equity, exchange deficits, and autodeleveraging (ADL) policies.
These components will allow us to formalize the notion of moral hazard in perpetuals exchanges and sets the notation up for our main results inÂ Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization"),Â Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"),Â Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization"), andÂ Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization").

### 2.1 Perpetuals Exchanges.

A *perpetuals futures exchange* (or perpetuals exchange) is a derivatives trading venue that allows traders to use leverage to speculate on the prices of cryptocurrency assets.
The main asset traded is a perpetual future, which is a continuous, expiryless futures contract.
Traders speculate on the contract in either the long (buy) or short (sell) direction.
Traders are allowed to make leveraged bets up to a maximum leverage cap â„“max\ell^{\max}.
As is often common with levered positions, the trader has to post collateral, known as *margin*, to keep their positions *solvent*.
We define a precise notion of solvency in this section, but for now think of solvency conditions as meaning that a traderâ€™s assets are greater than their liabilities.

The exchange incentivizes futures prices to approximately match spot prices by having long and short traders pay each other a continuous rate, known as the *funding rate*.
The funding rate is determined by the spot price of the asset and the relative imbalance of long and short futures positions.
Arbitrageurs keep the price of the futures contract in line with the spot price by opening futures positions that push the contract price towards the spot price.
For simplicity, we assume that trades occur in discrete time tâˆˆNt\in{\mbox{\bf N}}, but note that our results can easily be extended to continuous time tâˆˆR+t\in{\mbox{\bf R}}\_{+}.

##### Spot Price Oracle.

Perpetual futures exchanges require a spot price oracle that provides a spot price of the asset from a spot trading venue.
Price oracles are assumed to be expensive or difficult to manipulate, which is dependent on the liquidity of the spot market.
Most perpetuals exchanges utilize oracles that aggregate price reporting over multiple venues to increase the overall liquidity represented in the price and hence, the manipulation cost.
We assume that there is a non-manipulable spot price p^t\hat{p}\_{t} for an asset at all times tâˆˆR+t\in{\mbox{\bf R}}\_{+}.
Furthermore, we denote the futures price quoted by the exchange as ptp\_{t} and similarly assume that it exists for all tâˆˆR+t\in{\mbox{\bf R}}\_{+}.

##### Positions.

Given a spot price oracle and futures price, a perpetuals exchange is able to open and close *positions* created by its traders.
A position consists of collateral deposited by the trader, a leverage amount, and a direction (e.g.Â buy or sell).
A traderâ€™s position is updated as the spot price changes, realizing a gain or a loss for the trader.
The accumulation of gains and losses over the lifetime of the position is the traderâ€™s PNL (profit-and-loss).
We define a perpetuals exchange with nn traders as the set

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’«n={(qi,ci,ti,bi)âˆˆR+3Ã—{âˆ’1,1}:iâˆˆ[n]}\mathcal{P}\_{n}=\{(q\_{i},c\_{i},t\_{i},b\_{i})\in{\mbox{\bf R}}\_{+}^{3}\times\{-1,1\}:i\in[n]\} |  | (1) |

where qiâ‰¥0q\_{i}\geq 0 is the notional quantity of futures held by the trader, ciâ‰¥0c\_{i}\geq 0 is the traderâ€™s collateral (cash) position (also known as the *initial margin*), tiâˆˆNt\_{i}\in{\mbox{\bf N}} is the timestamp that the position was created, and bib\_{i} is their side (âˆ’1-1 is sell, 11 is buy).
We denote each position ğ”­i=(qi,ci,ti,bi)\mathfrak{p}\_{i}=(q\_{i},c\_{i},t\_{i},b\_{i}) and assume that without the loss of generality that there is a fixed, strictly increasing ordering of these orders such that we can refer to ğ”­i\mathfrak{p}\_{i} unambiguously.

For each position ğ”­\mathfrak{p}, we define the *notional exposure* at time tt is the gross dollar size

|  |  |  |
| --- | --- | --- |
|  | ni,t=ptâ€‹qi.n\_{i,t}\ =\ p\_{t}\,q\_{i}\,. |  |

The notional exposure is the gross dollar size of the traderâ€™s position and is used to define leverage.

##### Example.

In this section, we fix a canonical running example that we will reuse across definitions to illustrate each exchange function.
Our simple test perpetuals exchange will have five positions, ğ’«5\mathcal{P}\_{5}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’«5={\displaystyle\mathcal{P}\_{5}=\Big\{ | ğ”­A=(qA,cA,tA,bA)=(1,â€‰2,â€‰0,+1),\displaystyle\mathfrak{p}\_{A}=(q\_{A},c\_{A},t\_{A},b\_{A})=\big(1,\,2,\,0,\,+1\big), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | ğ”­B=(qB,cB,tB,bB)=(1,23,â€‰0,+1),\displaystyle\mathfrak{p}\_{B}=(q\_{B},c\_{B},t\_{B},b\_{B})=\big(1,\,\tfrac{2}{3},\,0,\,+1\big), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | ğ”­C=(qC,cC,tC,bC)=(4,83,â€‰0,âˆ’1),\displaystyle\mathfrak{p}\_{C}=(q\_{C},c\_{C},t\_{C},b\_{C})=\big(4,\,\tfrac{8}{3},\,0,\,-1\big), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | ğ”­D=(qD,cD,tD,bD)=(1,219,â€‰0,+1),\displaystyle\mathfrak{p}\_{D}=(q\_{D},c\_{D},t\_{D},b\_{D})=\big(1,\,\tfrac{2}{19},\,0,\,+1\big), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | ğ”­E=(qE,cE,tE,bE)=(1,1099,â€‰0,âˆ’1)}.\displaystyle\mathfrak{p}\_{E}=(q\_{E},c\_{E},t\_{E},b\_{E})=\big(1,\,\tfrac{10}{99},\,0,\,-1\big)\Big\}. |  |

Moreover, if at t=0t=0 we have p0=1p\_{0}=1 for ğ’«5\mathcal{P}\_{5}, then the notional exposure are:

|  |  |  |
| --- | --- | --- |
|  | nA,0=1â‹…1=1,nB,0=1â‹…1=1,nC,0=1â‹…4=4,nD,0=1â‹…1=1,nE,0=1â‹…1=1.n\_{A,0}=1\cdot 1=1,\quad n\_{B,0}=1\cdot 1=1,\quad n\_{C,0}=1\cdot 4=4,\quad n\_{D,0}=1\cdot 1=1,\quad n\_{E,0}=1\cdot 1=1. |  |

Note this toy example is net short by 2 contracts: âˆ‘ibiâ€‹qi=âˆ’2\sum\_{i}b\_{i}q\_{i}=-2.
For AMM-style venues, the pool holds the offsetting inventory qV=2q\_{V}=2 with bV=+1b\_{V}=+1, so across traders plus venue âˆ‘ibiâ€‹qi+bVâ€‹qV=0\sum\_{i}b\_{i}q\_{i}+b\_{V}q\_{V}=0.
For order-book venues, interpret ğ’«5\mathcal{P}\_{5} as a subset of accounts.
The complementary matched positions are omitted but implied.555We note that in centralized exchanges, the exchange itself creates the complementary positions whereas in decentralized exchanges with order books (like Hyperliquid and Lighter), a liquidity provider like HLP or LLP owns the position; see Hyperliquidâ€™s HLP documentationÂ [HyperliquidHLPVaults] and the Lighter whitepaperÂ [LighterWhitepaper].
All zero-sum statements (e.g.,Â funding rates, which will be defined shortly) are taken over traders plus the venue inventory.

##### Position Creation.

When an exchange opens a new position, it performs two tasks:

1. 1.

   Selecting a price ptp\_{t} for the position and constructing ğ”­=(q,c,t,b)\mathfrak{p}=(q,c,t,b).
2. 2.

   Construction of an equal but opposite position, ğ”­Â¯=(q,c,t,âˆ’b)\overline{\mathfrak{p}}=(q,c,t,-b) is created

The latter condition is needed because the perpetuals exchange is meant to be a neutral matching layer for traders.
This means that the exchange should not have a net exposure to the spot asset, as it increases the risk of default for traders.
Specifically, the position ğ”­Â¯\overline{\mathfrak{p}} is created to ensure that the total notional exposure of the exchange to the spot asset is zero.666In centralized venues such as Binance Futures, the matching engine and clearing layer are designed to operate a matched book over user positions, as reflected in their open interest endpoints for USD$- and COIN-margined futuresÂ [BinanceFuturesOpenInterest]. In decentralized order-book venues like Hyperliquid, the protocol core similarly avoids taking directional exposure. Offsetting inventory is held in separate HLP vaults on behalf of liquidity providersÂ [HyperliquidHLPVaults].
We define

|  |  |  |
| --- | --- | --- |
|  | ğ’«Â¯n=ğ’«nâˆª{ğ”­Â¯:ğ”­âˆˆğ’«n}\overline{\mathcal{P}}\_{n}=\mathcal{P}\_{n}\cup\{\overline{\mathfrak{p}}:\mathfrak{p}\in\mathcal{P}\_{n}\} |  |

as the full set of positions held by the exchange (including matching, complementary positions).

While all venues construct ğ”­Â¯\overline{\mathfrak{p}} in the same manner, the price ptp\_{t} is chosen in a venue-specific manner.
Each venue has a *liquidity model* for determining how prices ptp\_{t} are chosen.
The two most popular liquidity models are order books and automated market makers (AMMs).

Order book venues maintain a limit order book of bids and asks for perpetual futures contracts at discrete price levels, and have been extensively studied in the market microstructure literatureÂ [Kyle1985, AlmgrenChriss2001, Gatheral2010, BouchaudImpact2010].
Traders may submit limit orders, which rest in the book until they are matched, or market orders, which execute immediately against resting liquidity.
When a trader opens a new position as a taker, the execution price ptp\_{t} is the volume-weighted average of the resting orders they consume, i.e.,Â the price they would obtain by submitting a market order of size qq into the book at time tt.
The largest order book venues in the perpetual futures market include centralized exchanges such as Binance and Bybit and decentralized exchanges such as Hyperliquid and Lighter.777From a risk-warehousing perspective, Hyperliquidâ€™s HLP vaults cause the protocol to function as a hybrid between a pure order-book venue and an inventory-taking pool: user orders are matched via an order book, but directional exposure is warehoused collectively in HLP vaults on behalf of liquidity providersÂ [HyperliquidHLPVaults, OakResearchJELLY, CoinDesk2025LargestLiquidations].

Automated market maker (AMM) venues maintain a pool of collateral and inventory for the perpetual, and quote prices according to a deterministic pricing rule or bonding curve that depends on the pool state, typically implemented via constant-function market makersÂ [AngerisChitra2020ImprovedOracles, Angeris2023GeometryCFMM].
Traders interact with the pool via swap-like trades: submitting an order of size qq moves the pool along its pricing curve, and the execution price ptp\_{t} is the average price paid over this path.
When a trader opens a new position against the AMM, the pool itself holds the offsetting inventory ğ”­Â¯\overline{\mathfrak{p}}, so that the traderâ€™s exposure is matched by an equal and opposite position in the pool, as in inventory-taking perpetual venues such as GMX, Drift, and Perpetual Protocol v2Â [GMXDocs, DriftADLCode, PerpV2Docs].

In the remainder of this paper, we will ignore the liquidity model of a perpetuals exchange.
This is because the default conditions that we will study for autodeleveraging only depend on the positions ğ’«n\mathcal{P}\_{n} and not the process by which they were created.

##### Example.

Consider an order-book venue at time tt with three resting sell (ask) limit orders

|  |  |  |
| --- | --- | --- |
|  | (p1,q1)=(1.0,1),(p2,q2)=(1.1,3),(p3,q3)=(1.2,10).(p^{1},q^{1})=(1.0,1),\quad(p^{2},q^{2})=(1.1,3),\quad(p^{3},q^{3})=(1.2,10). |  |

A trader submits a market buy order for quantity q=5q=5. The exchange matches this order against the resting asks in priceâ€“time priority: it first consumes q1=1q\_{1}=1 at p1=1.0p\_{1}=1.0, then q2=3q\_{2}=3 at p2=1.1p\_{2}=1.1, and finally 11 unit from the third order at p3=1.2p\_{3}=1.2.
The total notional paid is 1â‹…1.0+3â‹…1.1+1â‹…1.2=5.51\cdot 1.0+3\cdot 1.1+1\cdot 1.2=5.5, so the execution price is the volume-weighted average pt=5.55=1.1p\_{t}=\frac{5.5}{5}=1.1.
Ignoring fees, the taker acquires a new long position ğ”­=(q,c,t,b)=(5,c,t,+1)\mathfrak{p}=(q,c,t,b)=(5,c,t,+1) with notional exposure qâ€‹pt=5.5q\,p\_{t}=5.5.
Aggregating across the three maker accounts, the exchange simultaneously creates an equal and opposite short position ğ”­Â¯\overline{\mathfrak{p}} of size 55, so that total long and short contract quantities (over all accounts) remain matched.

##### Open Interest.

Note that the notion of leverage is encoded into the quantity qiq\_{i} of a position, as a user who can buy ptiâ€‹qp\_{t\_{i}}q units of spot assets with cic\_{i} units of collteral can open a position with qiâ‰¤â„“maxâ€‹qq\_{i}\leq\ell\_{\max}q.
This implies that the correct notion of the notional trades outstanding, known as *interest*, on a pereptuals exchange is simply the sum of price-weighted quantities.
We divide the exchange ğ’«n\mathcal{P}\_{n} into long and short positions:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„’â€‹(ğ’«n)\displaystyle\mathcal{L}(\mathcal{P}\_{n}) | ={(qi,ci,ti,bi)âˆˆğ’«n:bi=1}\displaystyle=\{(q\_{i},c\_{i},t\_{i},b\_{i})\in\mathcal{P}\_{n}:b\_{i}=1\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’®â€‹(ğ’«n)\displaystyle\mathcal{S}(\mathcal{P}\_{n}) | ={(qi,ci,ti,bi)âˆˆğ’«n:bi=âˆ’1}\displaystyle=\{(q\_{i},c\_{i},t\_{i},b\_{i})\in\mathcal{P}\_{n}:b\_{i}=-1\} |  |

We define the total set of long and short positions as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„’Â¯â€‹(ğ’«n)\displaystyle\overline{\mathcal{L}}(\mathcal{P}\_{n}) | =â„’â€‹(ğ’«n)âˆª{ğ”­Â¯:ğ”­âˆˆâ„’â€‹(ğ’«n)}\displaystyle=\mathcal{L}(\mathcal{P}\_{n})\cup\{\overline{\mathfrak{p}}:\mathfrak{p}\in\mathcal{L}(\mathcal{P}\_{n})\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’®Â¯â€‹(ğ’«n)\displaystyle\overline{\mathcal{S}}(\mathcal{P}\_{n}) | =ğ’®â€‹(ğ’«n)âˆª{ğ”­Â¯:ğ”­âˆˆğ’®â€‹(ğ’«n)}\displaystyle=\mathcal{S}(\mathcal{P}\_{n})\cup\{\overline{\mathfrak{p}}:\mathfrak{p}\in\mathcal{S}(\mathcal{P}\_{n})\} |  |

This is the set of all long and short positions, including matching positions.

Futures exchanges define the *open interest* of the exchange as the total outstanding notional value of the positions held by the exchange.
Given the futures price ptp\_{t}, the long open interest Lâ€‹(ğ’«n,pt)L(\mathcal{P}\_{n},p\_{t}) and short open interest Sâ€‹(ğ’«n,pt)S(\mathcal{P}\_{n},p\_{t}) are defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Lâ€‹(ğ’«n,pt)\displaystyle L(\mathcal{P}\_{n},p\_{t}) | =âˆ‘(qi,ci,ti,bi)âˆˆâ„’â€‹(ğ’«n)qiâ€‹pt\displaystyle=\sum\_{(q\_{i},c\_{i},t\_{i},b\_{i})\in\mathcal{L}(\mathcal{P}\_{n})}q\_{i}p\_{t} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Sâ€‹(ğ’«n,pt)\displaystyle S(\mathcal{P}\_{n},p\_{t}) | =âˆ‘(qi,ci,ti,bi)âˆˆğ’®â€‹(ğ’«n)qiâ€‹pt\displaystyle=\sum\_{(q\_{i},c\_{i},t\_{i},b\_{i})\in\mathcal{S}(\mathcal{P}\_{n})}q\_{i}p\_{t} |  |

Given the long and short open interest, we define the exchangeâ€™s open interest simply as the sum, Oâ€‹Iâ€‹(ğ’«n,pt)=Lâ€‹(ğ’«n,pt)+Sâ€‹(ğ’«n,pt)OI(\mathcal{P}\_{n},p\_{t})=L(\mathcal{P}\_{n},p\_{t})+S(\mathcal{P}\_{n},p\_{t})
888We note that exchangeâ€™s will report open interest over ğ’«Â¯n\overline{\mathcal{P}}\_{n}, which would be twice the open interest reported here. Since we assume that ğ’«n\mathcal{P}\_{n} is the set of unmatched trader positions, one can view our definition of open interest (which differs from Binanceâ€™s definition by a factor of two) as â€˜trader open interestâ€™ vs. â€˜exchange open interestâ€™.
To lighten notation, we will write Lt=Lâ€‹(ğ’«n,pt),St=Sâ€‹(ğ’«n,pt),Oâ€‹It=Oâ€‹Iâ€‹(ğ’«n,pt)L\_{t}=L(\mathcal{P}\_{n},p\_{t}),S\_{t}=S(\mathcal{P}\_{n},p\_{t}),OI\_{t}=OI(\mathcal{P}\_{n},p\_{t}) when the exchange ğ’«n\mathcal{P}\_{n} is already defined.

##### Example.

For ğ’«5\mathcal{P}\_{5} at t=0t=0 with p0=1p\_{0}=1, longs are {A,B,D}\{A,B,D\} and shorts are {C,E}\{C,E\}, so

|  |  |  |
| --- | --- | --- |
|  | L0=âˆ‘bi=+1qiâ€‹p0=(1+1+1)â‹…1=3,S0=âˆ‘bi=âˆ’1qiâ€‹p0=(4+1)â‹…1=5,Oâ€‹I0=8.L\_{0}=\sum\_{b\_{i}=+1}q\_{i}p\_{0}=(1+1+1)\cdot 1=3,\quad S\_{0}=\sum\_{b\_{i}=-1}q\_{i}p\_{0}=(4+1)\cdot 1=5,\quad OI\_{0}=8. |  |

At t=1t=1 with p1=1.4p\_{1}=1.4 (same quantities), L1=3â‹…1.4=4.2L\_{1}=3\cdot 1.4=4.2, S1=5â‹…1.4=7.0S\_{1}=5\cdot 1.4=7.0, Oâ€‹I1=11.2OI\_{1}=11.2 .

##### Leverage and Margin.

The *leverage* of a position is the ratio of the notional exposure to the collateral value.
If the leverage is greater than 1, it means that the user has effectively borrowed money from the exchange to have an exposure higher than their cash balance.
When the leverage is less than 1, the userâ€™s position is *overcollateralized*.

As the price of the asset changes, the leverage of the position naturally changes due to its dependence on notional exposure.
When a position is opened, there is an *initial leverage* ratio that the position is created with.
We define the initial leverage of a position as

|  |  |  |
| --- | --- | --- |
|  | â„“i=â„“â€‹(ğ”­i)=ni,tic=ptiâ€‹qici\ell\_{i}=\ell(\mathfrak{p}\_{i})=\frac{n\_{i,t\_{i}}}{c}=\frac{p\_{t\_{i}}q\_{i}}{c\_{i}} |  |

The larger the initial leverage, the most exposure the trader has to the asset and implicitly, the more risk the exchange is taking on lending to the user.

For risk management purposes, exchanges define leverage limits in terms of initial and maintenanceÂ *margins*.
Margins are bounds on the ratio of notional exposure to collateral that the exchange enforces as an invariant.
The *initial margin ratio*, mIâˆˆ(0,1)m\_{I}\in(0,1) is defined such that for any valid position, we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | mIâ€‹ptiâ€‹qiâ‰¤cim\_{I}p\_{t\_{i}}q\_{i}\leq c\_{i} |  | (2) |

This invariant implies that the maximum leverage that a position can have, â„“max\ell^{\max} is â„“max=1mI\ell^{\max}=\frac{1}{m\_{I}}.

In order to continually satisfyÂ ([2](https://arxiv.org/html/2512.01112v1#S2.E2 "Equation 2 â€£ Leverage and Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) as spot and future prices change, a trader often needs to â€˜top upâ€™ or add more collateral their position.
The amount of collateral needed is related to the exchangeâ€™s *maintenance margin ratio* mÎ¼m\_{\mu}, which will be defined in the sequel.
As the user adjusts their collateral position dynamically, we let ci,tc\_{i,t} be the total quantity of collateral (margin) placed by the user at time tt.
This also means that the state of position is dynamic, ğ”­i,t=(qi,ci,t,ti,bi)\mathfrak{p}\_{i,t}=(q\_{i},c\_{i,t},t\_{i},b\_{i}).
We define the *leverage at time tt* as â„“i,t=ğŸtâ‰¥tiâ€‹ptâ€‹qici,t\ell\_{i,t}=\mathbf{1}\_{t\geq t\_{i}}\frac{p\_{t}q\_{i}}{c\_{i,t}}

##### Example.

These five examples of ğ’«5\mathcal{P}\_{5} represent one highly overcollateralized and under leveraged position (ğ”­A\mathfrak{p}\_{A}), two somewhat leveraged positions with medium leverage (ğ”­B,ğ”­C\mathfrak{p}\_{B},\mathfrak{p}\_{C}) and two highly leveraged positions (ğ”­D,ğ”­E\mathfrak{p}\_{D},\mathfrak{p}\_{E}).
We will initialize the example with p0=1p\_{0}=1 and take a maximum leverage â„“max=10\ell^{\max}=10 (e.g.,Â mI=0.10m\_{I}=0.10).
This gives the following opening leverages:

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | â„“A,0\displaystyle\ell\_{A,0} | =1â‹…12=0.5,\displaystyle=\tfrac{1\cdot 1}{2}=0.5, | â„“B,0\displaystyle\ell\_{B,0} | =1â‹…12/3=1.5,\displaystyle=\tfrac{1\cdot 1}{2/3}=1.5, | â„“C,0\displaystyle\ell\_{C,0} | =1â‹…48/3=1.5,\displaystyle=\tfrac{1\cdot 4}{8/3}=1.5, |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | â„“D,0\displaystyle\ell\_{D,0} | =1â‹…12/19=9.5,\displaystyle=\tfrac{1\cdot 1}{2/19}=9.5, | â„“E,0\displaystyle\ell\_{E,0} | =1â‹…110/99=9.9.\displaystyle=\tfrac{1\cdot 1}{10/99}=9.9. |  | | |

If the mark moves to p1=1.4p\_{1}=1.4 and cash is unchanged (ci,1=cic\_{i,1}=c\_{i}), then time-11 leverages are

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | â„“A,1\displaystyle\ell\_{A,1} | =1.4â‹…12=0.7,\displaystyle=\tfrac{1.4\cdot 1}{2}=0.7, | â„“B,1\displaystyle\ell\_{B,1} | =1.4â‹…12/3=2.1,\displaystyle=\tfrac{1.4\cdot 1}{2/3}=2.1, | â„“C,1\displaystyle\ell\_{C,1} | =1.4â‹…48/3=2.1,\displaystyle=\tfrac{1.4\cdot 4}{8/3}=2.1, |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | â„“D,1\displaystyle\ell\_{D,1} | =1.4â‹…12/19=13.3,\displaystyle=\tfrac{1.4\cdot 1}{2/19}=13.3, | â„“E,1\displaystyle\ell\_{E,1} | =1.4â‹…110/99=13.86.\displaystyle=\tfrac{1.4\cdot 1}{10/99}=13.86. |  | | |

In practice, if â„“i,1>â„“max\ell\_{i,1}>\ell^{\max} (e.g.,Â ğ”­D\mathfrak{p}\_{D} and ğ”­E\mathfrak{p}\_{E}), then the venue requires collateral additions from the trader to restore the constraint â„“i,1â‰¤â„“mâ€‹aâ€‹x\ell\_{i,1}\leq\ell^{max}.

##### Funding Rate.

A perpetual future is only useful as a hedging instrument if the futures price ptp\_{t} and spot price p^t\hat{p}\_{t} are sufficiently â€œclose.â€
To incentivize this, the majority of perpetuals futures markets use a continuous payment stream between the long and short positions called a *funding rate*.
If the price of the future is lower than spot, pt<p^tp\_{t}<\hat{p}\_{t}, traders holding short futures positions pay a payment to traders holding long futures positions.
This encourages traders who want to earn these payments to open long positions, which will decrease the over all rate.
Conversely, if pt>p^tp\_{t}>\hat{p}\_{t}, traders holding long positions pay those holding short positions.

Most funding rates are simple linear functions of the relative imbalance between the long and short positions.
A common funding rateÂ [Chitra2025PDLP] formula takes the form:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î³â€‹(ğ’«n,pt,p^t)=Îºâ€‹(Lâ€‹(ğ’«n,pt)Sâ€‹(ğ’«n,pt)âˆ’ptp^t)\gamma(\mathcal{P}\_{n},p\_{t},\hat{p}\_{t})=\kappa\left(\frac{L(\mathcal{P}\_{n},p\_{t})}{S(\mathcal{P}\_{n},p\_{t})}-\frac{p\_{t}}{\hat{p}\_{t}}\right) |  | (3) |

for a constant Îº>0\kappa>0.
For brevity, write Î³t=Î³â€‹(ğ’«n,pt,p^t)\gamma\_{t}=\gamma(\mathcal{P}\_{n},p\_{t},\hat{p}\_{t}).
Note that we have defined Î³t\gamma\_{t} such that if Î³t>0\gamma\_{t}>0, then short traders pay long traders Î³t\gamma\_{t}% of their holdings.
This convention is opposite to what many exchanges use (i.e.,Â Î³t<0\gamma\_{t}<0 represents a payment from the short side to the long side).
However, our convention leads to needing to check fewer negative signs in our formulas, as we will illustrate with our examples.

Given funding rates Î³t\gamma\_{t} for tâ‰¥0t\geq 0, a position ğ”­=(q,c,t,b)\mathfrak{p}=(q,c,t,b) linearly accumulates funding positions between time tt and the current time TT, if the position is solvent.
That is, if the position is solvent at time TT, the user receives a payments of the form

|  |  |  |
| --- | --- | --- |
|  | Î“â€‹((q,c,t,b),t,T)=âˆ‘s=t+1T(bâ€‹q)â€‹Î³sâ€‹ps\Gamma((q,c,t,b),t,T)=\sum\_{s=t+1}^{T}(bq)\gamma\_{s}p\_{s} |  |

If Î“>0\Gamma>0, then over the interval [t,T][t,T], the user receives a payment from the exchange whereas if Î“<0\Gamma<0, the user pays the exchange.
When the user pays the exchange, their profits are distributed by the exchange to the other side of the market.
For brevity, we use the notation Î“i,t,T=Î“â€‹(ğ”­i,t,T)\Gamma\_{i,t,T}=\Gamma(\mathfrak{p}\_{i},t,T).

We also note that the funding rate, by construction, is zero-sum when one considers entire set of exchange positions ğ’«Â¯n\overline{\mathcal{P}}\_{n}.
To see, this note the following:

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘ğ”­âˆˆğ’«Â¯nÎ³tâ€‹ptâ€‹(bâ€‹q)=âˆ‘ğ”­âˆˆâ„’Â¯â€‹(ğ’«n)Î³tâ€‹ptâ€‹(q)âˆ’âˆ‘ğ”­âˆˆğ’®Â¯â€‹(ğ’«n)Î³tâ€‹ptâ€‹(q)=0\sum\_{\mathfrak{p}\in\overline{\mathcal{P}}\_{n}}\gamma\_{t}p\_{t}\,(bq)=\sum\_{\mathfrak{p}\in\overline{\mathcal{L}}(\mathcal{P}\_{n})}\gamma\_{t}p\_{t}\,(q)-\sum\_{\mathfrak{p}\in\overline{\mathcal{S}}(\mathcal{P}\_{n})}\gamma\_{t}p\_{t}\,(q)=0 |  | (4) |

where the last equality follows from the fact that ğ”­âˆˆâ„’Â¯â€‹(ğ’«n)â‡”ğ”­Â¯âˆˆğ’®Â¯â€‹(ğ’«n)\mathfrak{p}\in\overline{\mathcal{L}}(\mathcal{P}\_{n})\iff\overline{\mathfrak{p}}\in\overline{\mathcal{S}}(\mathcal{P}\_{n}).

##### Example.

To make the linear funding rule concrete, take Îº=1\kappa=1 and suppose the oracle and mark follow
(p^0,p0)=(1,1)(\hat{p}\_{0},p\_{0})=(1,1), (p^1,p1)=(1.5,1.4)(\hat{p}\_{1},p\_{1})=(1.5,1.4), (p^2,p2)=(1.25,1.3)(\hat{p}\_{2},p\_{2})=(1.25,1.3), with quantities unchanged (so LS=35\tfrac{L}{S}=\tfrac{3}{5}).
Then with Îº=1\kappa=1, Î³1=LSâˆ’p1p^1=0.6âˆ’1.41.5â‰ˆâˆ’0.3333\gamma\_{1}=\tfrac{L}{S}-\tfrac{p\_{1}}{\hat{p}\_{1}}=0.6-\tfrac{1.4}{1.5}\approx-0.3333 and Î³2=0.6âˆ’1.31.25=âˆ’0.44\gamma\_{2}=0.6-\tfrac{1.3}{1.25}=-0.44 (longs pay shorts at both steps).
Per-step funding cash to each position is Î³tâ€‹ptâ€‹(biâ€‹qi)\gamma\_{t}p\_{t}\,(b\_{i}q\_{i}) (positive means received, negative means paid):

|  |  |  |
| --- | --- | --- |
|  | tğ”­Ağ”­Bğ”­Cğ”­Dğ”­E00.00000.00000.00000.00000.00001âˆ’0.4667âˆ’0.4667+1.8667âˆ’0.4667+0.46672âˆ’0.5720âˆ’0.5720+2.2880âˆ’0.5720+0.5720\begin{array}[]{c|ccccc}t&\mathfrak{p}\_{A}&\mathfrak{p}\_{B}&\mathfrak{p}\_{C}&\mathfrak{p}\_{D}&\mathfrak{p}\_{E}\\ \hline\cr 0&0.0000&0.0000&0.0000&0.0000&0.0000\\ 1&-0.4667&-0.4667&+1.8667&-0.4667&+0.4667\\ 2&-0.5720&-0.5720&+2.2880&-0.5720&+0.5720\\ \end{array} |  |

Values follow Eq.Â ([3](https://arxiv.org/html/2512.01112v1#S2.E3 "Equation 3 â€£ Funding Rate. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) using (p^t,pt)(\hat{p}\_{t},p\_{t}) above.

##### Profit and Loss.

Given funding rates, one can write the explicit profit and/or loss that a trader faces during the lifetime of their position.
We define the profit-and-loss (PNL) of duration T>0T>0, ğ–¯ğ–­ğ–«s:T:(R+4Ã—{âˆ’1,1})Ã—R+TÃ—R+Tâ†’R\mathsf{PNL}\_{s:T}:({\mbox{\bf R}}\_{+}^{4}\times\{-1,1\})\times{\mbox{\bf R}}\_{+}^{T}\times{\mbox{\bf R}}\_{+}^{T}\rightarrow{\mbox{\bf R}} as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«s:Tâ€‹((q,c,â„“,t,b),p1:T,p^1:T)=ğŸsâ‰¤t<Tâ€‹(bâ€‹qâ€‹(pT^âˆ’pt)+Î“â€‹((q,c,t,b),t,T^))\mathsf{PNL}\_{s:T}((q,c,\ell,t,b),p\_{1:T},\hat{p}\_{1:T})=\mathbf{1}\_{s\leq t<T}\left(bq(p\_{\hat{T}}-p\_{t})+\Gamma((q,c,t,b),t,\hat{T})\right) |  | (5) |

where T^=minâ¡(T,Ï„)\hat{T}=\min(T,\tau) is the last time the position is solvent.
We will use the shorthand ğ–¯ğ–­ğ–«T=ğ–¯ğ–­ğ–«0:T\mathsf{PNL}\_{T}=\mathsf{PNL}\_{0:T}.
We will formally define the quantity Ï„\tau shortly when we discuss liquidations, but for now think of it as a martingale stopping time for position solvency.
This condition states that the total position of the user is their collateral plus the net change from funding costs.
A natural consequence of the zero-sum nature of funding is that the total PNL is also zero-sum:

|  |  |  |
| --- | --- | --- |
|  | âˆ‘ğ”­âˆˆğ’«Â¯nğ–¯ğ–­ğ–«Tâ€‹(ğ”­,p1:T,p^1:T)=âˆ‘ğ”­âˆˆğ’«Â¯nbâ€‹qâ€‹(pT^âˆ’p0)+Î“â€‹(ğ”­,t,T^)=0\sum\_{\mathfrak{p}\in\overline{\mathcal{P}}\_{n}}\mathsf{PNL}\_{T}(\mathfrak{p},p\_{1:T},\hat{p}\_{1:T})=\sum\_{\mathfrak{p}\in\overline{\mathcal{P}}\_{n}}bq(p\_{\hat{T}}-p\_{0})+\Gamma(\mathfrak{p},t,\hat{T})=0 |  |

The first term sums to zero, because there will be offsetting positions with b=âˆ’1,b=1b=-1,b=1 and the second term is zero viaÂ ([4](https://arxiv.org/html/2512.01112v1#S2.E4 "Equation 4 â€£ Funding Rate. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).

##### Example.

Under the additive funding convention in Eq.Â ([5](https://arxiv.org/html/2512.01112v1#S2.E5 "Equation 5 â€£ Profit and Loss. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) with the prices, open interest, and funding above, PNL over [0,1][0,1] and [0,2][0,2] is:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«0:1â€‹(ğ”­A)\displaystyle\mathsf{PNL}\_{0:1}(\mathfrak{p}\_{A}) | =âˆ’0.0667,\displaystyle=-0.0667, | ğ–¯ğ–­ğ–«0:2â€‹(ğ”­A)\displaystyle\quad\mathsf{PNL}\_{0:2}(\mathfrak{p}\_{A}) | =âˆ’0.7387,\displaystyle=-0.7387, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«0:1â€‹(ğ”­B)\displaystyle\mathsf{PNL}\_{0:1}(\mathfrak{p}\_{B}) | =âˆ’0.0667,\displaystyle=-0.0667, | ğ–¯ğ–­ğ–«0:2â€‹(ğ”­B)\displaystyle\quad\mathsf{PNL}\_{0:2}(\mathfrak{p}\_{B}) | =âˆ’0.7387,\displaystyle=-0.7387, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«0:1â€‹(ğ”­C)\displaystyle\mathsf{PNL}\_{0:1}(\mathfrak{p}\_{C}) | =+0.2667,\displaystyle=+0.2667, | ğ–¯ğ–­ğ–«0:2â€‹(ğ”­C)\displaystyle\quad\mathsf{PNL}\_{0:2}(\mathfrak{p}\_{C}) | =+2.9547,\displaystyle=+2.9547, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«0:1â€‹(ğ”­D)\displaystyle\mathsf{PNL}\_{0:1}(\mathfrak{p}\_{D}) | =âˆ’0.0667,\displaystyle=-0.0667, | ğ–¯ğ–­ğ–«0:2â€‹(ğ”­D)\displaystyle\quad\mathsf{PNL}\_{0:2}(\mathfrak{p}\_{D}) | =âˆ’0.7387,\displaystyle=-0.7387, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¯ğ–­ğ–«0:1â€‹(ğ”­E)\displaystyle\mathsf{PNL}\_{0:1}(\mathfrak{p}\_{E}) | =+0.0667,\displaystyle=+0.0667, | ğ–¯ğ–­ğ–«0:2â€‹(ğ”­E)\displaystyle\quad\mathsf{PNL}\_{0:2}(\mathfrak{p}\_{E}) | =+0.7387.\displaystyle=+0.7387. |  |

##### Equity.

For each position ğ”­i,t\mathfrak{p}\_{i,t}, one can view the assets of the position as ci,tc\_{i,t} (e.g.Â the margin posted by the user) and the liabilities of the users as âˆ’ğ–¯ğ–­ğ–«Tâ€‹(ğ”­i,t,p1:T,p^1:T)-\mathsf{PNL}\_{T}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T}).
The liabilities are the negative of PNL because if the user has a loss, then they have positive liabilities to the exchange (e.g.Â they owe the exchange money).
On the other hand, if the user has a gain, then the exchange owes the user money (and is a negative liability).
The *equity* of a position ğ”­i,t\mathfrak{p}\_{i,t}, eâ€‹(ğ”­i,t)e(\mathfrak{p}\_{i,t}) is simply the assets of the position minus the liabilities:

|  |  |  |  |
| --- | --- | --- | --- |
|  | eâ€‹(ğ”­i,t,p1,T,p^1,T)=ci,t+ğ–¯ğ–­ğ–«Tâ€‹(ğ”­i,t,p1:T,p^1:T)e(\mathfrak{p}\_{i,t},p\_{1,T},\hat{p}\_{1,T})=c\_{i,t}+\mathsf{PNL}\_{T}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T}) |  | (6) |

For notational convenience, we will write the terminal equity shorthand

|  |  |  |
| --- | --- | --- |
|  | eTâ€‹(ğ”­i,t)=eâ€‹(ğ”­i,t,p1:T,p^1:T).e\_{T}(\mathfrak{p}\_{i,t})=e(\mathfrak{p}\_{i,t},\ p\_{1:T},\ \hat{p}\_{1:T}). |  |

A position is said to be *totally insolvent* if eTâ€‹(ğ”­i,t)<0e\_{T}(\mathfrak{p}\_{i,t})<0.
Traders can update their collateral ci,tc\_{i,t} or close positions to avoid fully insolvency.
We define the random variable Ï„â€‹(ğ”­i,t,p1:t)\tau(\mathfrak{p}\_{i,t},p\_{1:t}) as the first time that a position is insolvent, i.e.,

|  |  |  |
| --- | --- | --- |
|  | Ï„â€‹(ğ”­i,t,p1:t)=minâ¡{sâ‰¤t:eâ€‹(ğ”­i,s,p1:s)â‰¤Î¼â€‹psâ€‹qi}\tau(\mathfrak{p}\_{i,t},p\_{1:t})=\min\{s\leq t:e(\mathfrak{p}\_{i,s},p\_{1:s})\leq\mu p\_{s}q\_{i}\} |  |

For any time index tt, we will refer to the *winner* and *loser* index sets as

|  |  |  |
| --- | --- | --- |
|  | ğ’²t={i:eâ€‹(ğ”­i,t)>0},â„’t={i:eâ€‹(ğ”­i,t)<0}.\mathcal{W}\_{t}\ =\ \{\,i:\ e(\mathfrak{p}\_{i,t})>0\,\},\qquad\mathcal{L}\_{t}\ =\ \{\,i:\ e(\mathfrak{p}\_{i,t})<0\,\}. |  |

Write their sizes as kt=|ğ’²t|k\_{t}=|\mathcal{W}\_{t}| and mt=|â„’t|m\_{t}=|\mathcal{L}\_{t}|. We will use ğ’²T,â„’T\mathcal{W}\_{T},\mathcal{L}\_{T} for the terminal sets at horizon TT.

##### Example.

To illustrate the maintenance test, let Î¼=0.10\mu=0.10 and reuse the [0,1][0,1] price and funding path above. Equities at t=1t=1 (using ci,1=cic\_{i,1}=c\_{i}) are

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | eâ€‹(ğ”­A)\displaystyle e(\mathfrak{p}\_{A}) | =2âˆ’0.0667â‰ˆ1.9333,\displaystyle=2-0.0667\approx 1.9333, | eâ€‹(ğ”­B)\displaystyle e(\mathfrak{p}\_{B}) | =23âˆ’0.0667â‰ˆ0.6000,\displaystyle=\tfrac{2}{3}-0.0667\approx 0.6000, | eâ€‹(ğ”­C)\displaystyle e(\mathfrak{p}\_{C}) | =83+0.2667â‰ˆ2.9334,\displaystyle=\tfrac{8}{3}+0.2667\approx 2.9334, |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | eâ€‹(ğ”­D)\displaystyle e(\mathfrak{p}\_{D}) | =219âˆ’0.0667â‰ˆ0.0386,\displaystyle=\tfrac{2}{19}-0.0667\approx 0.0386, | eâ€‹(ğ”­E)\displaystyle e(\mathfrak{p}\_{E}) | =1099+0.0667â‰ˆ0.1677.\displaystyle=\tfrac{10}{99}+0.0667\approx 0.1677. |  | | |

At t=2t=2 (using the same path and ci,2=cic\_{i,2}=c\_{i}), equities are

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | eâ€‹(ğ”­A)\displaystyle e(\mathfrak{p}\_{A}) | â‰ˆ1.2613,\displaystyle\approx 1.2613, | eâ€‹(ğ”­B)\displaystyle e(\mathfrak{p}\_{B}) | â‰ˆâˆ’0.0720,\displaystyle\approx-0.0720, | eâ€‹(ğ”­C)\displaystyle e(\mathfrak{p}\_{C}) | â‰ˆ5.6214,\displaystyle\approx 5.6214, |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | eâ€‹(ğ”­D)\displaystyle e(\mathfrak{p}\_{D}) | â‰ˆâˆ’0.6334,\displaystyle\approx-0.6334, | eâ€‹(ğ”­E)\displaystyle e(\mathfrak{p}\_{E}) | â‰ˆ0.8397.\displaystyle\approx 0.8397. |  | | |

Note that under this price move, there are now negative equity positions that are liquidatable.

##### Maintenance Margin.

As spot and future prices change, an exchange needs to enforce dynamic collateral requirements to avoid insolvencies.
The *maintenance margin ratio*, mÎ¼m\_{\mu}, represents the ratio of collateral to notional exposure that a trader must maintain under adverse price moves.
With mÎ¼âˆˆ(0,1)m\_{\mu}\in(0,1) and equity from eq.Â ([6](https://arxiv.org/html/2512.01112v1#S2.E6 "Equation 6 â€£ Equity. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")), a position is maintenance-insolvent (and liquidatable) when

|  |  |  |  |
| --- | --- | --- | --- |
|  | eâ€‹(ğ”­i,t)â‰¤mÎ¼â€‹ptâ€‹|qi|.e(\mathfrak{p}\_{i,t})\ \leq\ m\_{\mu}\,p\_{t}\,|q\_{i}|. |  | (7) |

Note that maintenance margin depends on the equity of a position (e.g.Â includes the positionâ€™s PNL) whereas initial margin only depends on the initial cash position.
If a user violatesÂ ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) due to a price move, they can add collateral within a specified time interval to keep their position open.
Otherwise, the venue liquidates the position.

##### Example.

Take mÎ¼=0.10m\_{\mu}=0.10 and reuse the [0,1][0,1] path above with p1=1.4p\_{1}=1.4 and the computed equities

|  |  |  |
| --- | --- | --- |
|  | eâ€‹(ğ”­A)â‰ˆ1.9333,eâ€‹(ğ”­B)â‰ˆ0.6000,eâ€‹(ğ”­C)â‰ˆ2.9334,eâ€‹(ğ”­D)â‰ˆ0.0386,eâ€‹(ğ”­E)â‰ˆ0.1677.e(\mathfrak{p}\_{A})\approx 1.9333,\quad e(\mathfrak{p}\_{B})\approx 0.6000,\quad e(\mathfrak{p}\_{C})\approx 2.9334,\quad e(\mathfrak{p}\_{D})\approx 0.0386,\quad e(\mathfrak{p}\_{E})\approx 0.1677. |  |

The maintenance thresholds are mÎ¼â€‹p1â€‹|q|=(0.14, 0.14, 0.56, 0.14, 0.14)m\_{\mu}p\_{1}|q|=(0.14,\ 0.14,\ 0.56,\ 0.14,\ 0.14) for (A,B,C,D,E)(A,B,C,D,E). Here eâ€‹(ğ”­D)â‰¤mÎ¼â€‹p1â€‹|q|e(\mathfrak{p}\_{D})\leq m\_{\mu}p\_{1}|q| while others remain above the threshold.
Position DD is maintenance-insolvent and would need to add collateral or be liquidated.

##### Leverage Mass.

The final quantity we will define aims to measure how much leverage the winning (positive equity) and losing (negative equity) sides have on the exchange.
This will serve as a coarse measure of an exchangeâ€™s risk exposure and will be used inÂ Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization").
We define a natural aggregate leverage quantity for both the winning and losing sides that normalizes leverage by equity, allowing us to compare traders with very different margin ratios on a common â€œtrue asset compositionâ€ scale.
For iâˆˆğ’²ti\in\mathcal{W}\_{t} define the *winner effective leverage* Î»i,t+=ni,teâ€‹(ğ”­i,t)\lambda^{+}\_{i,t}=\frac{n\_{i,t}}{e(\mathfrak{p}\_{i,t})}, and for iâˆˆâ„’ti\in\mathcal{L}\_{t} the *loser effective leverage* Î»i,tâˆ’=ni,t|eâ€‹(ğ”­i,t)|\lambda^{-}\_{i,t}=\frac{n\_{i,t}}{|e(\mathfrak{p}\_{i,t})|}. The *winner* and *loser leverage masses* are

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„“t+=âˆ‘iâˆˆğ’²tÎ»i,t+,â„“tâˆ’=âˆ‘iâˆˆâ„’tÎ»i,tâˆ’,â„“Â¯tÂ±=â„“tÂ±nâ€‹(perâ€“trader).\ell^{+}\_{t}\ =\ \sum\_{i\in\mathcal{W}\_{t}}\lambda^{+}\_{i,t},\qquad\ell^{-}\_{t}\ =\ \sum\_{i\in\mathcal{L}\_{t}}\lambda^{-}\_{i,t},\qquad\bar{\ell}^{\pm}\_{t}\ =\ \frac{\ell^{\pm}\_{t}}{n}\ (\text{per--trader}). |  | (8) |

Note that unlike the leverage â„“i,t\ell\_{i,t}, we divide by the equity (which can be larger or smaller than leverage, depending on the traderâ€™s PNL).

##### Example.

Consider t=1t=1 with p1=1.40p\_{1}=1.40. Then ni,1=p1â€‹qi=1.4n\_{i,1}=p\_{1}q\_{i}=1.4 for iâˆˆ{A,B,D,E}i\in\{A,B,D,E\} and 5.65.6 for CC.
Using the equities at t=1t=1 above, all five are winners and

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | Î»A,1+\displaystyle\lambda^{+}\_{A,1} | =1.41.9333â‰ˆ0.7246,\displaystyle=\tfrac{1.4}{1.9333}\approx 0.7246, | Î»B,1+\displaystyle\lambda^{+}\_{B,1} | =1.40.6000=2.3333,\displaystyle=\tfrac{1.4}{0.6000}=2.3333, | Î»C,1+\displaystyle\lambda^{+}\_{C,1} | =5.62.9334â‰ˆ1.9090,\displaystyle=\tfrac{5.6}{2.9334}\approx 1.9090, |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | Î»D,1+\displaystyle\lambda^{+}\_{D,1} | =1.40.0386â‰ˆ36.269,\displaystyle=\tfrac{1.4}{0.0386}\approx 36.269, | Î»E,1+\displaystyle\lambda^{+}\_{E,1} | =1.40.1677â‰ˆ8.353.\displaystyle=\tfrac{1.4}{0.1677}\approx 8.353. |  | | |

Hence â„“1+â‰ˆ49.59\ell^{+}\_{1}\approx 49.59; the large Î»D,1+\lambda^{+}\_{D,1} reflects DDâ€™s very small equity at t=1t=1.
Recall DDâ€™s opening leverage was only â„“D,0â‰ˆ9.5\ell\_{D,0}\approx 9.5, so effective leverage can greatly exceed raw leverage when equity has been eroded by losses.
At t=2t=2 with p2=1.30p\_{2}=1.30, ni,2=p2â€‹|qi|n\_{i,2}=p\_{2}|q\_{i}| equals 1.31.3 for iâˆˆ{A,B,D,E}i\in\{A,B,D,E\} and 5.25.2 for CC.
From the equity example above, the winner/loser sets are ğ’²2={A,C,E}\mathcal{W}\_{2}=\{A,C,E\} with eAâ‰ˆ1.2613e\_{A}\approx 1.2613, eCâ‰ˆ5.6214e\_{C}\approx 5.6214, eEâ‰ˆ0.8397e\_{E}\approx 0.8397 and â„’2={B,D}\mathcal{L}\_{2}=\{B,D\} with eBâ‰ˆâˆ’0.0720e\_{B}\approx-0.0720, eDâ‰ˆâˆ’0.6334e\_{D}\approx-0.6334.
Winner effective leverages are

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | Î»A,2+\displaystyle\lambda^{+}\_{A,2} | =1.31.2613â‰ˆ1.031,\displaystyle=\tfrac{1.3}{1.2613}\approx 1.031, | Î»C,2+\displaystyle\lambda^{+}\_{C,2} | =5.25.6214â‰ˆ0.925,\displaystyle=\tfrac{5.2}{5.6214}\approx 0.925, | Î»E,2+\displaystyle\lambda^{+}\_{E,2} | =1.30.8397â‰ˆ1.548,\displaystyle=\tfrac{1.3}{0.8397}\approx 1.548, |  |

so â„“2+â‰ˆ3.504\ell^{+}\_{2}\approx 3.504.
Loser effective leverages are

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Î»B,2âˆ’\displaystyle\lambda^{-}\_{B,2} | =1.3|âˆ’0.0720|â‰ˆ18.05,\displaystyle=\tfrac{1.3}{|{-}0.0720|}\approx 18.05, | Î»D,2âˆ’\displaystyle\lambda^{-}\_{D,2} | =1.3|âˆ’0.6334|â‰ˆ2.052,\displaystyle=\tfrac{1.3}{|{-}0.6334|}\approx 2.052, |  |

so â„“2âˆ’â‰ˆ20.102\ell^{-}\_{2}\approx 20.102.
The ratio of leverage masses â„“2âˆ’/â„“2+â‰ˆ5.7\ell^{-}\_{2}/\ell^{+}\_{2}\approx 5.7 shows that, at this horizon, most effective leverage sits on the losing side of the book.
Here BB and DD have the same notional ni,2n\_{i,2} but very different effective leverages, illustrating how Î»i,tÂ±\lambda^{\pm}\_{i,t} can diverge from the raw leverage â„“i,t\ell\_{i,t} when equities differ.

### 2.2 Liquidations

When a userâ€™s position is insolvent,Â i.e.,Â ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) holds, the exchange must *liquidate* the position â€” that is, remove some or all of the position from ğ’«n\mathcal{P}\_{n}.
Liquidations are used to ensure that the exchange itself remains solvent, which ensures that traders can withdraw their funds and profits as expected.
The process of liquidating a position is probabilistic, however, and can fail in a number of ways.
We will illustrate the high-level process of liquidation using bankruptcy and liquidation prices.
Then we will describe how exchanges can lose solvency when liquidations fail, leading to the usage of autodeleveraging mechanisms.
Our description of liquidations is minimal, avoiding formal mathematical description unless needed, as we are concerned with liquidations failure versus liquidation mechanics.
We refer the interested reader toÂ [Soska2021BitMEX, perez2021liquidations, qin2021empirical, AngerisChitra2023PerpsSIAM] for detailed accounts of liquidation mechanisms and modeling on centralized and decentralized venues.

#### 2.2.1 Liquidation Prices

Before defining how liquidations work, we need to define the criteria for when a position is eligible for liquidation.
These criteria depend on when certain prices are reached where a trader position has low or negative equity.
We focus on defining three prices: bankruptcy price (zero equity), liquidation price (low equity), and execution price (actual realized price of a liquidation).
In practice, liquidation mechanisms often use more price-based variables to decide on execution.
However, all mechanisms define these three prices, allowing us to abstract liquidations to mechanisms involving these prices.

##### Bankruptcy Price.

The *bankruptcy price* of a position ğ”­i,t\mathfrak{p}\_{i,t}, pbâ€‹kâ€‹(ğ”­i,t)p^{bk}(\mathfrak{p}\_{i,t}), is the highest price at which the position is totally insolvent.
The threshold condition for a position to be totally insolvent is eTâ€‹(ğ”­i,t)=0e\_{T}(\mathfrak{p}\_{i,t})=0:

|  |  |  |
| --- | --- | --- |
|  | 0=eTâ€‹(ğ”­i,t)=ci,t+ğ–¯ğ–­ğ–«Tâ€‹(ğ”­i,t,p1:T,p^1:T)=ci,t+biâ€‹qiâ€‹(pbâ€‹kâ€‹(ğ”­i,t)âˆ’pt)+Î“â€‹(ğ”­i,t,t,T^)0=e\_{T}(\mathfrak{p}\_{i,t})=c\_{i,t}+\mathsf{PNL}\_{T}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T})=c\_{i,t}+b\_{i}q\_{i}(p^{bk}(\mathfrak{p}\_{i,t})-p\_{t})+\Gamma(\mathfrak{p}\_{i,t},t,\hat{T}) |  |

Rearranging this gives:

|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­i,t)=maxâ¡(ptâˆ’ci,t+Î“â€‹(ğ”­i,t,t,T^)biâ€‹qi,0)p^{bk}(\mathfrak{p}\_{i,t})=\max\left(p\_{t}-\frac{c\_{i,t}+\Gamma(\mathfrak{p}\_{i,t},t,\hat{T})}{b\_{i}q\_{i}},0\right) |  | (9) |

One can view the bankruptcy price as the worst-case liquidation price, in the sense that if the position is liquidated at any p<pbâ€‹kâ€‹(ğ”­i,t)p<p^{bk}(\mathfrak{p}\_{i,t}), then other traders of the exchange will realize a loss.
Such a loss, which is either bourne by the exchange or by other traders, is known as *bad debt* (seeÂ Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).

The bankruptcy price also constrains the maximum leverage that a position can have.
Suppose that the funding is zero, e.g.Â Î“â€‹(ğ”­i,t,t,T^)=0\Gamma(\mathfrak{p}\_{i,t},t,\hat{T})=0.
The bankruptcy price then simplifies to:

|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­i,t)=maxâ¡(ptâˆ’ci,tbiâ€‹qi,0)=maxâ¡(ptâˆ’biâ„“i,tâ€‹pt,0)=ptâ€‹maxâ¡(1âˆ’biâ„“i,t,0)p^{bk}(\mathfrak{p}\_{i,t})=\max\left(p\_{t}-\frac{c\_{i,t}}{b\_{i}q\_{i}},0\right)=\max\left(p\_{t}-\frac{b\_{i}}{\ell\_{i,t}}\,p\_{t},0\right)=p\_{t}\max\left(1-\frac{b\_{i}}{\ell\_{i,t}},0\right) |  | (10) |

This formula represents the common maxim that a perpetuals position with â„“iâ‰¥1\ell\_{i}\geq 1 times leverage will be liquidated when the price moves by 1â„“i\frac{1}{\ell\_{i}}% in the direction opposite to bib\_{i}; see, for example,Â [Binance2025CollateralLeverageUpdate, he2022fundamentals].
For instance, a maximal 10x leveraged position will be liquidated when the price moves by 10% from the initial price.
Detailed numerical examples of bankruptcy prices are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

##### Liquidation Price.

To avoid bad debt, an exchange defines a *liquidation price* p^lâ€‹iâ€‹qâ€‹(ğ”­i,t)â‰¥pbâ€‹kâ€‹(ğ”­i,t)\hat{p}^{liq}(\mathfrak{p}\_{i,t})\geq p^{bk}(\mathfrak{p}\_{i,t}), when the position is liquidatable at time tt.
Generally, the liquidation price is a spot price derived from the oracle versus a futures price quoted by the exchange.
This makes market manipulation â€” creating and executing non-economically rational orders to force a liquidation â€” costly to perform.
When the maintenance margin conditionÂ ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) is satisfied, the exchange attempts to partially liquidate the position.
The Î¼\mu-liquidation price, plâ€‹iâ€‹qâ€‹(ğ”­i,t,Î¼)p^{liq}(\mathfrak{p}\_{i,t},\mu) is defined as the maximal price whereÂ ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) holds. To avoid ambiguity about the base price used in pbâ€‹kp^{bk}, we write p^lâ€‹iâ€‹q\hat{p}^{liq} directly in terms of the entry price ptip\_{t\_{i}} (independent of bankruptcy):

|  |  |  |
| --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­i,t,Î¼)={maxâ¡(ptiâˆ’(ci,t+Î“â€‹(ğ”­i,t,t,T^))/qi1âˆ’Î¼, 0),bi=+1,pti+(ci,t+Î“â€‹(ğ”­i,t,t,T^))/|qi|1+Î¼,bi=âˆ’1.\hat{p}^{liq}(\mathfrak{p}\_{i,t},\mu)=\begin{cases}\displaystyle\max\!\left(\frac{\,p\_{t\_{i}}-(c\_{i,t}+\Gamma(\mathfrak{p}\_{i,t},t,\hat{T}))/q\_{i}\,}{1-\mu},\ 0\right),&b\_{i}=+1,\\[10.0pt] \displaystyle\frac{\,p\_{t\_{i}}+(c\_{i,t}+\Gamma(\mathfrak{p}\_{i,t},t,\hat{T}))/|q\_{i}|\,}{1+\mu},&b\_{i}=-1.\end{cases} |  |

Detailed numerical examples of liquidation prices are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

##### Execution Price.

When p^t<plâ€‹iâ€‹qâ€‹(ğ”­i,t,Î¼)\hat{p}\_{t}<p^{liq}(\mathfrak{p}\_{i,t},\mu) a position is liquidatable. The venue then sells (if bi=+1b\_{i}=+1) or buys (if bi=âˆ’1b\_{i}=-1) a slice of size Î”â€‹q\Delta q, realizing an execution price peâ€‹xâ€‹eâ€‹câ€‹(ğ”­i,t,Î¼,Î”â€‹q)p^{exec}(\mathfrak{p}\_{i,t},\mu,\Delta q).
Whether a liquidation creates bad debt depends on the location of peâ€‹xâ€‹eâ€‹cp^{exec} relative to the bankruptcy price pbâ€‹kp^{bk}:

* â€¢

  *Long* (bi=+1b\_{i}=+1): no shortfall if peâ€‹xâ€‹eâ€‹câ‰¥pbâ€‹kp^{exec}\geq p^{bk}; otherwise the realized shortfall is Dt=(pbâ€‹kâˆ’peâ€‹xâ€‹eâ€‹c)â€‹Î”â€‹qD\_{t}=(p^{bk}-p^{exec})\,\Delta q.
* â€¢

  *Short* (bi=âˆ’1b\_{i}=-1): no shortfall if peâ€‹xâ€‹eâ€‹câ‰¤pbâ€‹kp^{exec}\leq p^{bk}; otherwise the realized shortfall is Dt=(peâ€‹xâ€‹eâ€‹câˆ’pbâ€‹k)â€‹Î”â€‹qD\_{t}=(p^{exec}-p^{bk})\,\Delta q.

Shortfalls are first absorbed by the insurance fund (Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) up to its balance.
Any residual shortfall not covered by the insurance fund is socialized via ADL (Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
The choice of liquidation size Î”â€‹q\Delta q and impact parameter Î±\alpha together determines whether thin-equity positions can typically be closed without realizing bad debt.
Detailed numerical examples of execution prices and shortfalls are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

#### 2.2.2 Liquidation Mechanics

Given liquidation prices, a natural question is how liquidations are mechanically executed.
At a high level, the exchange seizes a low equity positionâ€™s cash and collateral and sells it to the market.
Such a sale can realize a profit or a loss for the exchange and is best thought of as a trading strategy itself.
We will provide a high-level description of liquidation mechanisms as trading strategies, with the caveat that there are many idiosyncrasies in practical implementations (see, e.g., [BinanceADL, HyperliquidDocsLiquidations, BitMEXADL] for venue documentation and differences between auctions, order-book liquidations, and RFQ-style closures).

##### Liquidation Costs.

Most exchanges charge penalties to users who are liquidated as a means of disincentivizing liquidations and moral hazard.
These fees come in three flavors: fixed charges, insurance fund fees, and liquidation incentives.
The fixed fees correspond to reimbursement for gas and/or operational costs that an exchange realizes for performing a liquidation.
The insurance fund fees are proportional to the liquidation price and allow for the exchange to cover bad debt.
Finally, the liquidation incentives are used to encourage third-party actors known as liquidators to hold the risk of buying the position of size Î”â€‹q\Delta q from the exchange and exiting it profitably.

In decentralized exchanges, liquidators are usually any market participant with enough capital who can connect to the exchange.
On the other hand, in centralized exchanges, liquidators are usually whitelisted parties approved by the exchange to perform liquidations
We denote the set of liquidation costs for a liquidation of size Î”â€‹q\Delta q at time tt as Ï„tâ€‹(Î”â€‹q)âˆˆR+\tau\_{t}(\Delta q)\in{\mbox{\bf R}}\_{+}, which represents the cash cost paid by the user upon liquidation.
Detailed numerical examples of liquidation costs are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

##### Liquidation Strategies.

The policy by which an exchange chooses the liquidation quantity Î”â€‹q\Delta q is known as the *liquidation strategy*, L:ğ’«nÃ—R+TÃ—R+Tâ†’RL:\mathcal{P}\_{n}\times{\mbox{\bf R}}^{T}\_{+}\times{\mbox{\bf R}}^{T}\_{+}\rightarrow{\mbox{\bf R}}.
The strategy Lâ€‹(ğ”­i,t,p1:T,p^1:T)L(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T}) outputs a quantity Î”â€‹q\Delta q to liquidate.
Generally speaking, the strategy has some model of the environment (e.g.Â the price impact function of the spot and futures exchanges) and utilizes that to pick the quantity.
Most exchanges utilize a simple a greedy liquidation strategy that chooses the minimal Î”â€‹q\Delta q to ensure that the equity does not satisfyÂ ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
Such strategies choose Î”â€‹q\Delta q such that an equality of the form

|  |  |  |  |
| --- | --- | --- | --- |
|  | eTâ€‹(ğ”­i,t)+bâ€‹Î”â€‹qâ€‹(pteâ€‹xâ€‹eâ€‹câˆ’pt)âˆ’Ï„tâ€‹(Î”â€‹q)=Î¼â€‹ptâ€‹(qâˆ’Î”â€‹q)e\_{T}(\mathfrak{p}\_{i,t})+b\,\Delta q\,(p^{exec}\_{t}-p\_{t})-\tau\_{t}(\Delta q)=\mu p\_{t}(q-\Delta q) |  | (11) |

approximately holds.
For notational simplicity, we assume that Lâ€‹(ğ”­i,t,p1:T,p^1:T)=0L(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T})=0 if the position ğ”­i,t\mathfrak{p}\_{i,t} is not liquidatable.

As an explicit example, suppose that we have linear price impact, i.e.,Â peâ€‹xâ€‹eâ€‹c=ptâˆ“Î±2â€‹Î”â€‹qp^{exec}=p\_{t}\mp\tfrac{\alpha}{2}\,\Delta q.
We receive a quadratic equation in Î”â€‹q\Delta q:

|  |  |  |
| --- | --- | --- |
|  | Î±2â€‹Î”â€‹q2âˆ’Î¼â€‹ptâ€‹Î”â€‹q+(Î¼â€‹ptâ€‹qâˆ’eT+Ï„)=â€„0,\tfrac{\alpha}{2}\,\Delta q^{2}\;-\;\mu p\_{t}\,\Delta q\;+\;(\mu p\_{t}q-e\_{T}+\tau)\;=\;0, |  |

The greedy liquidation strategy simply takes the smallest feasible root of this quadratic and uses it as the liquidation quantity Î”â€‹q\Delta q.
We refer the reader to AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization") for detailed numerical examples of this strategy and related liquidation procedures.

##### Bad Debt.

A liquidation for position ğ”­i,t\mathfrak{p}\_{i,t} generates *bad debt* if the post-liquidation equity (including execution price and fees) is non-positive.
Formally, we define an adjusted terminal equity e~Tâ€‹(ğ”­i,t,p1:T,p^1:T,Î”â€‹q)\tilde{e}\_{T}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T},\Delta q) that incorporates liquidation costs:

|  |  |  |  |
| --- | --- | --- | --- |
|  | e~T=eT+bâ€‹Î”â€‹qâ€‹(peâ€‹xâ€‹eâ€‹câˆ’pt)âˆ’Ï„tâ€‹(Î”â€‹q)\tilde{e}\_{T}\;=\;e\_{T}\;+\;b\,\Delta q\,\big(p^{exec}-p\_{t}\big)\;-\;\tau\_{t}(\Delta q) |  | (12) |

Intuitively, relative to marking the entire position at ptp\_{t}, realizing a slice Î”â€‹q\Delta q at peâ€‹xâ€‹eâ€‹cp^{exec} changes equity by the slippage term bâ€‹Î”â€‹qâ€‹(peâ€‹xâ€‹eâ€‹câˆ’pt)b\,\Delta q\,(p^{exec}-p\_{t}), and fees reduce equity via Ï„tâ€‹(Î”â€‹q)\tau\_{t}(\Delta q).
We say that a liquidation creates bad debt if e~Tâ€‹(ğ”­i,t,p1:T,p^1:T,Î”â€‹q)<0\tilde{e}\_{T}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T},\Delta q)<0, i.e.,Â the liquidation leaves a residual liability for the venue.

Note that in practice, a liquidation strategy might retry or reattempt to liquidate the position repeatedly.
We elide formulating the details of such a liquidation strategy here for simplicity, but note that our model can be easily extended to account for this.
We define the *total bad debt* or *shortfall* of an exchange, DtD\_{t} given a liquidation strategy LL is,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Dtâ€‹(L)=âˆ‘ğ”­âˆˆğ’«nmaxâ¡(0,âˆ’e~â€‹(ğ”­i,t,p1:T,p^1:T,Î”â€‹qi))=âˆ‘ğ”­âˆˆğ’«nâˆ’e~â€‹(ğ”­i,t,p1:T,p^1:T,Î”â€‹qi)âˆ’D\_{t}(L)=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}\max(0,-\tilde{e}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T},\Delta q\_{i}))=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}-\tilde{e}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T},\Delta q\_{i})\_{-} |  | (13) |

where Î”â€‹qi=Lâ€‹(ğ”­i,t,p1:T,p^1:T)\Delta q\_{i}=L(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T}).
This represents the shortfall that the exchange must cover to be solvent (Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
Detailed numerical examples of bad debt are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

eT,ie\_{T,i}equity ranking (kâ†’1k\rightarrow 1)10%10\% liquidation thresholdbankruptcykkkâˆ’1k-1kâˆ’2k-2â‹¯\cdots2211liquidatablept=0.88â€‹p0p\_{t}=0.88\,p\_{0}p^t=0.80â€‹p0\hat{p}\_{t}=0.80\,p\_{0}eT,k<0e\_{T,k}<0


(a) Baseline 10% liquidation buffer: mark price pt=0.88â€‹p0p\_{t}=0.88p\_{0} is 10% above bankruptcy p^t=0.80â€‹p0\hat{p}\_{t}=0.80p\_{0}.

eT,ie\_{T,i}equity ranking (kâ†’1k\rightarrow 1)10%10\% liquidation thresholdbankruptcykkkâˆ’1k-1kâˆ’2k-2â‹¯\cdots2211pt+Î”=0.94â€‹p0p\_{t+\Delta}=0.94\,p\_{0}p^t+Î”=0.93â€‹p0\hat{p}\_{t+\Delta}=0.93\,p\_{0}all positions solvent


(b) Price recovery: increasing the mark price by Î”â€‹pt=+0.06â€‹p0\Delta p\_{t}=+0.06p\_{0} and the bankruptcy level by Î”â€‹p^t=+0.13â€‹p0\Delta\hat{p}\_{t}=+0.13p\_{0} moves them to pt+Î”=0.94â€‹p0p\_{t+\Delta}=0.94p\_{0} and p^t+Î”=0.93â€‹p0\hat{p}\_{t+\Delta}=0.93p\_{0}, leaving every account with positive equity and a residual markâ€“bankruptcy buffer of about 1%1\%.

eT,ie\_{T,i}ranking (kâ†’1k\rightarrow 1)bankruptcykkkâˆ’1k-1kâˆ’2k-2â‹¯\cdots2211pt=0.88â€‹p0p\_{t}=0.88\,p\_{0}p^t=0.80â€‹p0\hat{p}\_{t}=0.80\,p\_{0}negative equity (insolvent)


(c) Example of a negative-equity account inside the sorted stack.

Figure 1: Sorted equity profiles for stylized liquidation examples. Negative positions (red) appear on the left, positive positions (green) on the right. Dashed lines highlight the bankruptcy level and liquidation triggers.

##### Anatomy of a Liquidation.

Given the bankruptcy, liquidation, and execution prices, we can now describe the high-level algorithm that liquidations follow (see AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization")).
We note that many live liquidation systems will have much more complex liquidation algorithms.
These complexities deal with the coordination costs of coordinating many parties (e.g.Â oracle provider, liquidators, spot order book liquidity) and precise models that exchanges use for their liquidation strategy.
However, we effectively lump all of these complexities into the definition of the liquidation strategy.
A detailed algorithmic description of the liquidation loop and a step-by-step example are provided in AppendixÂ [A](https://arxiv.org/html/2512.01112v1#A1 "Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").

### 2.3 Exchange Solvency

In the previous section, we focused on liquidations as a means to remove individual trader solvencies.
However, there is also a â€˜macroscopicâ€™ notion of solvency at the exchange level.
The goal of the exchange is to make sure that traders can realize their full profits and losses given the cash collateral held at the exchange.
In rare cases, an exchange might not be able to successfully execute a liquidation strategy, leading to the exchange being unable to pay unrealized but earned profits to some users.

In this section, we define solvency for exchanges and how exchanges use *insurance funds* to try to ensure solvency.
An exchangeâ€™s insurance fund is the first line of defense against insolvency.
However, if the insurance fund has insufficient balance, the exchange will need to utilize a autodeleveraging mechanism to socialize losses.
In this section, we will define solvency for exchanges and how insurance funds are constructed.

##### Exchange Solvency.

The *solvency* of an exchange is simply the total equity of all positions:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)=âˆ‘ğ”­âˆˆğ’«neTâ€‹(ğ”­)=âˆ‘ğ”­âˆˆğ’«ncğ”­+ğ–¯ğ–­ğ–«Tâ€‹(ğ”­,p1:T,p^1:T)\mathsf{Solv}\_{T}(\mathcal{P}\_{n})=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}e\_{T}(\mathfrak{p})=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}c\_{\mathfrak{p}}+\mathsf{PNL}\_{T}(\mathfrak{p},p\_{1:T},\hat{p}\_{1:T}) |  | (14) |

An exchange is said to be *insolvent* if the following condition holds ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)â‰¤0\mathsf{Solv}\_{T}(\mathcal{P}\_{n})\leq 0.
The insolvency condition corresponds to when the total cash held by the exchange on behalf of users is less than the total accrued profits.
This mean that if this insolvency condition is hit, the exchange will not be about to payout all profitable traders when they withdraw from the exchange.
Note that this is a global condition on ğ’«n\mathcal{P}\_{n} as opposed to a per user constraint.

Most exchanges have a solvency threshold, Î´>0\delta>0, such that if it takes a global loss of Î´\delta units of equity to become truly insolvent, then the exchange is deemed approximately insolvent.
This notion of approximate insolvency is useful in practice, as it allows an exchange to have a risk parameter for tuning how aggressively it enters the ADL regime.
Formally, we define an exchange to be Î´\delta-insolvent if the following condition holds ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)â‰¤Î´\mathsf{Solv}\_{T}(\mathcal{P}\_{n})\leq\delta.

##### Comparison to overcollateralized lending.

In overcollateralized lending, where a user uses one crypto asset as collateral to borrow another crypto asset, there is a similar notion of a userâ€™s equity position.
However, in overcollateralized lending, the userâ€™s equity position is not global, but rather is local to the user.
The goal of a lending protocol is to ensure that the equity elâ€‹eâ€‹nâ€‹dâ€‹(p)â‰¥0e\_{lend}(p)\geq 0 for *every* userâ€™s position pp.
Ensuring per account solvency condition inherently forces overcollateralized lending protocols to offer far lower leverage than perpetuals exchanges.
From a mathematical standpoint, perpetual solvency is easier to satisfy, allowing for higher leverage â€” there is only one global constraint that has to hold versus Oâ€‹(n)O(n) local constraints for nn users.
However, in perpetuals exchanges, users who are solvent can face losses from users who are insolvent which cannot happen in isolated overcollateralized lending markets like Morpho.

##### Insurance Funds.

Many exchanges maintain an insurance fund to cover bad debt that arises from failed liquidations.
When a positive shortfall Dt>0D\_{t}>0 is realized, the insurance fund is used to reduce DtD\_{t} to as close to zero as possible.
The insurance fund is typically funded using a portion of the exchangeâ€™s revenue from transaction, liquidation, and funding fees.

Insurance reserves in crypto funds were first popularized alongside perpetual futures in the mid-2010s (notably on BitMEX)Â [Soska2021BitMEX].
A majority of perpetuals venues (centralized and on-chain) maintain such reserves (e.g.Â BitMEXÂ [BitMEXADL], BinanceÂ [BinanceFuturesInsuranceFund], DriftÂ [DriftADLCode], BybitÂ [BybitInsuranceFund]).
To illustrate the size of these funds, we note that mid-2025 estimates place OKX and Bybit insurance funds at roughly $300M and $150M, respectivelyÂ [OKXBybitInsuranceComparison].

We will first provide a simple model for how the insurance fund evolves over time.
Let ğ–¨ğ–¥tâ‰¥0\mathsf{IF}\_{t}\geq 0 denote the insurancefund balance at time tt.
Furthermore, let ğ’¯t\mathcal{T}\_{t} be the multiset of liquidations at time tt with sizes {Î”â€‹qj}jâˆˆğ’¯t\{\Delta q\_{j}\}\_{j\in\mathcal{T}\_{t}} and execution costs Ï„tâ€‹(Î”â€‹qj)âˆˆR+\tau\_{t}(\Delta q\_{j})\in{\mbox{\bf R}}\_{+} (cf.Â eq.Â ([12](https://arxiv.org/html/2512.01112v1#S2.E12 "Equation 12 â€£ Bad Debt. â€£ 2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))).
Let Vtâ‰¥0V\_{t}\geq 0 denote the gross traded volume (absolute quantity) in the contract at time tt.
We introduce three parameters to model insurance fund growth: Î±,Î²,Î·âˆˆ[0,1]\alpha,\beta,\eta\in[0,1].
The Î±,Î²,Î·\alpha,\beta,\eta parameters controls how much of liquidation, funding, and trading fee revenue is added ğ–¨ğ–¥t\mathsf{IF}\_{t}, respectively.

Given these parameters, the time evolution of the insurance fund is given by:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ–¨ğ–¥t+1=ğ–¨ğ–¥t+Î±â€‹âˆ‘jâˆˆğ’¯tÏ„tâ€‹(Î”â€‹qj)+Î·â€‹ptâ€‹Vt+Î²â€‹âˆ‘i=1n|Î³t|â€‹ptâ€‹qiâˆ’minâ¡{ğ–¨ğ–¥t,Dt}\mathsf{IF}\_{t+1}=\mathsf{IF}\_{t}+\alpha\sum\_{j\in\mathcal{T}\_{t}}\tau\_{t}(\Delta q\_{j})+\eta\,p\_{t}V\_{t}+\beta\sum\_{i=1}^{n}|\gamma\_{t}|\,p\_{t}\,q\_{i}-\min\{\mathsf{IF}\_{t},\,D\_{t}\} |  | (15) |

Note that the positive contributions represent the revenue sharing terms whereas the negative contribution represents the cover of a shortfall using the insurance fund.

The main quantity of interest, given ğ–¨ğ–¥t\mathsf{IF}\_{t}, is the *residual shortfall*.
This represents the amount of bad debt that cannot be covered by the insurance fund and needs to be socialized via ADL (Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
Formally, we define the residual shortfall as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Rt=Dtâˆ’minâ¡{ğ–¨ğ–¥t,Dt}=(Dtâˆ’ğ–¨ğ–¥t)+R\_{t}=D\_{t}-\min\{\mathsf{IF}\_{t},\,D\_{t}\}=(D\_{t}-\mathsf{IF}\_{t})\_{+} |  | (16) |

We note that when Rt>0R\_{t}>0, an ADL mechanism is triggered.

##### Example.

Continuing from the previous liquidation example, the bad debt realized at t=4t=4 by ğ”­E\mathfrak{p}\_{E} is

|  |  |  |
| --- | --- | --- |
|  | D4=(pEeâ€‹xâ€‹eâ€‹câˆ’pbâ€‹kâ€‹(ğ”­E,4))â€‹Î”â€‹qEâ‰ˆâ€„0.399.D\_{4}\;=\;(p^{exec}\_{E}-p^{bk}(\mathfrak{p}\_{E,4}))\,\Delta q\_{E}\;\approx\;0.399. |  |

Let ğ–¨ğ–¥4\mathsf{IF}\_{4} denote the pre-coverage fund balance. The coverage is minâ¡{ğ–¨ğ–¥4,D4}\min\{\mathsf{IF}\_{4},D\_{4}\} and the ADL residual is R4=(D4âˆ’ğ–¨ğ–¥4)+R\_{4}=(D\_{4}-\mathsf{IF}\_{4})\_{+}.
We assume that the fund evolves via eq.Â ([15](https://arxiv.org/html/2512.01112v1#S2.E15 "Equation 15 â€£ Insurance Funds. â€£ 2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) and model liquidation fees as affine in notional size:

|  |  |  |
| --- | --- | --- |
|  | Ï„tâ€‹(Î”â€‹q)=Ï„fâ€‹iâ€‹x+Ï•mâ€‹aâ€‹râ€‹kâ€‹ptâ€‹Î”â€‹q+Ï•eâ€‹xâ€‹eâ€‹câ€‹pteâ€‹xâ€‹eâ€‹câ€‹Î”â€‹q,\tau\_{t}(\Delta q)=\tau^{fix}+\phi^{mark}\,p\_{t}\,\Delta q+\phi^{exec}\,p^{exec}\_{t}\,\Delta q, |  |

where Ï„fâ€‹iâ€‹x\tau^{fix} is a fixed fee and Ï•mâ€‹aâ€‹râ€‹k,Ï•eâ€‹xâ€‹eâ€‹c\phi^{mark},\phi^{exec} are proportional rates on mark and execution price, respectively.
Using the Hyperliquid fee schedule (Ï„fâ€‹iâ€‹x,Ï•mâ€‹aâ€‹râ€‹k,Ï•eâ€‹xâ€‹eâ€‹c)=(0,20â€‹bps,10â€‹bps)(\tau^{fix},\phi^{mark},\phi^{exec})=(0,20\,\mathrm{bps},10\,\mathrm{bps}) (see Â§[2.2.2](https://arxiv.org/html/2512.01112v1#S2.SS2.SSS2 "2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")), the fees are

|  |  |  |
| --- | --- | --- |
|  | Ï„4â€‹(Î”â€‹qE)=0+20â‹…10âˆ’4â‹…p4â€‹Î”â€‹qE+10â‹…10âˆ’4â‹…pEeâ€‹xâ€‹eâ€‹câ€‹Î”â€‹qEâ‰ˆ0.00365.\tau\_{4}(\Delta q\_{E})=0+20\cdot 10^{-4}\cdot p\_{4}\,\Delta q\_{E}+10\cdot 10^{-4}\cdot p^{exec}\_{E}\,\Delta q\_{E}\approx 0.00365. |  |

Assuming Î³4=0\gamma\_{4}=0 and neglecting trading volume V4V\_{4} for simplicity:

* â€¢

  *Sufficiently sized fund (R4=0R\_{4}=0).* If ğ–¨ğ–¥4â‰¥D4\mathsf{IF}\_{4}\geq D\_{4}, the debt is fully covered. No ADL occurs. The balance updates to

  |  |  |  |
  | --- | --- | --- |
  |  | ğ–¨ğ–¥5=ğ–¨ğ–¥4+Î±â€‹Ï„4â€‹(Î”â€‹qE)âˆ’D4.\mathsf{IF}\_{5}=\mathsf{IF}\_{4}+\alpha\,\tau\_{4}(\Delta q\_{E})-D\_{4}. |  |
* â€¢

  *Insufficiently sized fund (R4>0R\_{4}>0).* If ğ–¨ğ–¥4<D4\mathsf{IF}\_{4}<D\_{4}, the fund is depleted to zero and pays ğ–¨ğ–¥4\mathsf{IF}\_{4}. The residual R4=D4âˆ’ğ–¨ğ–¥4R\_{4}=D\_{4}-\mathsf{IF}\_{4} is socialized via ADL (Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")). The new balance is simply the inflows:

  |  |  |  |
  | --- | --- | --- |
  |  | ğ–¨ğ–¥5=Î±â€‹Ï„4â€‹(Î”â€‹qE).\mathsf{IF}\_{5}=\alpha\,\tau\_{4}(\Delta q\_{E}). |  |

Increasing Î±\alpha, Î²\beta, or Î·\eta builds ğ–¨ğ–¥t\mathsf{IF}\_{t} faster, reducing the probability of Rt>0R\_{t}>0.

##### Optimal Insurance Fund Size.

A natural question to ask is, what is the optimal size for an insurance fund?
While this question is nuanced in practice, we provide a simple mean-field model that provide some intuition.
In particular, we determine the optimal fund size Kâˆ—K^{\*} by minimizing a total cost function that balances the opportunity cost of capital against the expected franchise damage from ADL events.
Let r>0r>0 denote the opportunity cost of holding capital (e.g., the risk-free rate) and Îº>0\kappa>0 denote the reputation cost per unit of socialized loss (reflecting lost future volume).
The exchange minimizes

|  |  |  |
| --- | --- | --- |
|  | minKâ‰¥0â¡râ€‹K+Îºâ€‹ğ„[(DTâˆ’K)+].\min\_{K\geq 0}\;rK+\kappa\,\mathop{\bf E{}}[(D\_{T}-K)\_{+}]. |  |

This is a classic newsvendor-type problemÂ [ArrowHarrisMarschak1951].
Classical result show that the optimal size is the Value-at-Risk of the deficit distribution at quantile 1âˆ’r/Îº1-r/\kappa:

|  |  |  |
| --- | --- | --- |
|  | Kâˆ—=VaR1âˆ’r/Îºâ€‹(DT)=inf{x:ğğ«ğ¨ğ›(DTâ‰¤x)â‰¥1âˆ’r/Îº}.K^{\*}\;=\;\text{VaR}\_{1-r/\kappa}(D\_{T})\;=\;\inf\{x:\mathop{\bf Prob}(D\_{T}\leq x)\geq 1-r/\kappa\}. |  |

For completeness, we provide a derivation in AppendixÂ [A.8](https://arxiv.org/html/2512.01112v1#A1.SS8 "A.8 Optimal Capital Structure Derivation â€£ Appendix A Liquidations, Autodeleveraging, and Insurance Funds â€£ Autodeleveraging: Impossibilities and Optimization").
Intuitively, as the reputation cost Îº\kappa increases relative to the cost of capital rr, the exchange holds a larger buffer to push ADL events further into the tail.

### 2.4 Autodeleveraging

Any mechanism for reducing or closing profitable user positions to reduce an exchangeâ€™s insolvency is termed *autodeleveraging* (ADL).
Mathematically, ADL mechanisms attempt to liquidating positions in order to reduce the residual RtR\_{t}.
This inherently means that users with positive equity (e.g.Â are profitable) will be forced to close their positions and not realize their full profit.

We first note that ADL mechanisms are not deterministic and foolproof.
For example, if an exchange is already insolvent, ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)â‰¤0\mathsf{Solv}\_{T}(\mathcal{P}\_{n})\leq 0, then no deterministic ADL mechanism can return solvency.
To see this, we define four key quantifies, the total shortfall DTâ€‹(ğ’«n)D\_{T}(\mathcal{P}\_{n}), the maximum shortfall Î”Tâ€‹(ğ’«n)\Delta\_{T}(\mathcal{P}\_{n}), the total winnerâ€™s equity WTâ€‹(ğ’«n)W\_{T}(\mathcal{P}\_{n}), and the max-winner Ï‰Tâ€‹(ğ’«n)\omega\_{T}(\mathcal{P}\_{n}):

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | DTâ€‹(ğ’«n)\displaystyle D\_{T}(\mathcal{P}\_{n}) | =âˆ‘ğ”­âˆˆğ’«n(âˆ’eTâ€‹(ğ”­))+â‰¥0\displaystyle=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}\big(-e\_{T}(\mathfrak{p})\big)\_{+}\geq 0 | Î”Tâ€‹(ğ’«n)\displaystyle\Delta\_{T}(\mathcal{P}\_{n}) | =maxğ”­âˆˆğ’«nâ¡(âˆ’eTâ€‹(ğ”­)âˆ’)â‰¥0\displaystyle=\max\_{\mathfrak{p}\in\mathcal{P}\_{n}}\big(-e\_{T}(\mathfrak{p})\_{-}\big)\geq 0 |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | WTâ€‹(ğ’«n)\displaystyle W\_{T}(\mathcal{P}\_{n}) | =âˆ‘ğ”­âˆˆğ’«neTâ€‹(ğ”­)+â‰¥0\displaystyle=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}e\_{T}(\mathfrak{p})\_{+}\geq 0 | Ï‰Tâ€‹(ğ’«n)\displaystyle\omega\_{T}(\mathcal{P}\_{n}) | =maxğ”­âˆˆğ’«nâ¡eTâ€‹(ğ”­)+â‰¥0\displaystyle=\max\_{\mathfrak{p}\in\mathcal{P}\_{n}}e\_{T}(\mathfrak{p})\_{+}\geq 0 |  |

For notational simplicity, we will use Roman letters for total quantities and Greek letters for maximum or extreme value quantities.
The shortfall represents the total amount of negative equity whereas the winnersâ€™ equity represents the total amount of positive equity.
By definition, ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)=WTâ€‹(ğ’«n)âˆ’DTâ€‹(ğ’«n)\mathsf{Solv}\_{T}(\mathcal{P}\_{n})=W\_{T}(\mathcal{P}\_{n})-D\_{T}(\mathcal{P}\_{n}), so if ğ–²ğ—ˆğ—…ğ—Tâ€‹(ğ’«n)â‰¤0\mathsf{Solv}\_{T}(\mathcal{P}\_{n})\leq 0, then DTâ€‹(ğ’«n)â‰¥WTâ€‹(ğ’«n)D\_{T}(\mathcal{P}\_{n})\geq W\_{T}(\mathcal{P}\_{n}), i.e.,Â no amount of forced liquidations of positive equity can cover the shortfall.

Instead, ADL mechanisms attempt to liquidate a fraction of the shortfall, then allow the market to react for some time (e.g.Â for users to close positions or post more margin and spot prices to update), before attempting a future deleveraging (if needed).
This means that the ADL process should be viewed probabilistically, as a sequence of decisions that are dynamically adjusted based on market conditions.
We will demonstrate that from this perspective, ADL can be formulated as a standard reinforcement learning problem.

##### ADL Policies.

The fundamental object of reinforcement learning is the policy, which maps states of the world to actions.
For ADL, the positions ğ’«n\mathcal{P}\_{n} serve as the state space, whereas the actions are the fraction of shortfall to socialize and which positions are socialized.
While the majority of exchanges (e.g.Â Binance and Hyperliquid) use queue-based policies that greedily rank positions by PNL and leverage, we will define a formalism over a larger class of potential ADL policies.
This larger class will enable us to find more efficient and fair ADL policies than queue-based models and includes pro-rata ADL policies used by smaller exchanges such as Drift and Paradex.

An *ADL policy* Ï€â€‹(ğ’«n)\pi(\mathcal{P}\_{n}) maps a perpetuals exchange to a fraction of shortfall to socialize, Î¸âˆˆ[0,1]\theta\in[0,1], and a set of haircuts to apply to positions, hâˆˆ[0,1]nh\in[0,1]^{n}.
We term the fraction Î¸\theta the *severity* of the ADL policy.
For notational convenience we define Î¸Ï€,hÏ€\theta\_{\pi},h\_{\pi} as the severity and haircuts induced by an ADL policy Ï€\pi.
We say an ADL policy Ï€\pi if *valid* if the following three constraints always hold:

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘ğ”­âˆˆğ’«nhÏ€,iâ€‹eTâ€‹(ğ”­)+=Î¸Ï€â€‹DTâ€‹(ğ’«n)=âˆ’âˆ‘ğ”­âˆˆğ’«nhÏ€,iâ€‹eTâ€‹(ğ”­)âˆ’.\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}h\_{\pi,i}e\_{T}(\mathfrak{p})\_{+}=\theta\_{\pi}D\_{T}(\mathcal{P}\_{n})=-\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}h\_{\pi,i}e\_{T}(\mathfrak{p})\_{-}. |  | (17) |

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î¸Ï€â€‹DTâ€‹(ğ’«n)â‰¤WTâ€‹(ğ’«n).\theta\_{\pi}D\_{T}(\mathcal{P}\_{n})\leq W\_{T}(\mathcal{P}\_{n}). |  | (18) |

where pip\_{i} is the iith traderâ€™s position.
The first two conditionsÂ ([17](https://arxiv.org/html/2512.01112v1#S2.E17 "Equation 17 â€£ ADL Policies. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) ensure that when an ADL policy is executed, only a Î¸\theta% of the deficit is socialized from the winners to the losers (i.e.,Â a budget balance constraint).
The third conditionÂ ([18](https://arxiv.org/html/2512.01112v1#S2.E18 "Equation 18 â€£ ADL Policies. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) ensures that Î¸Ï€\theta\_{\pi} is chosen such that one does not need to haircut more equity than what the winners have (i.e.,Â a feasibility constraint).
We define the post-policy deficit DTÏ€D^{\pi}\_{T}, winners WTÏ€W^{\pi}\_{T}, and max-winner MTÏ€M^{\pi}\_{T} as

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | DTÏ€\displaystyle D^{\pi}\_{T} | =Î¸Ï€â€‹DTâ€‹(ğ’«n)\displaystyle=\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}) | Î”TÏ€\displaystyle\Delta^{\pi}\_{T} | =Î¸Ï€â€‹Î”Tâ€‹(ğ’«n)\displaystyle=\theta\_{\pi}\Delta\_{T}(\mathcal{P}\_{n}) |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | WTÏ€\displaystyle W^{\pi}\_{T} | =âˆ‘ğ”­âˆˆğ’«n(1âˆ’hÏ€,i)â€‹(eTâ€‹(ğ”­))+\displaystyle=\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}(1-h\_{\pi,i})(e\_{T}(\mathfrak{p}))\_{+} | Ï‰TÏ€\displaystyle\omega^{\pi}\_{T} | =maxğ”­âˆˆğ’«nâ¡(1âˆ’hÏ€,i)â€‹(eTâ€‹(ğ”­))+\displaystyle=\max\_{\mathfrak{p}\in\mathcal{P}\_{n}}(1-h\_{\pi,i})(e\_{T}(\mathfrak{p}))\_{+} |  |

Our goal is to construct policies that minimize an objective function that balances individual user profits with global exchange solvency.

Given an ADL policy outputting (Î¸Ï€,hÏ€)(\theta\_{\pi},h\_{\pi}), the positive equity positions ğ’²T={i:eTâ€‹(ğ”­i)>0}\mathcal{W}\_{T}=\{i:e\_{T}(\mathfrak{p}\_{i})>0\} are haircut by hÏ€,ih\_{\pi,i}, leading to equities eTâ€‹(ğ”­i)â†(1âˆ’hÏ€,i)â€‹eTâ€‹(ğ”­i)e\_{T}(\mathfrak{p}\_{i})\leftarrow(1-h\_{\pi,i})e\_{T}(\mathfrak{p}\_{i}) for iâˆˆğ’²Ti\in\mathcal{W}\_{T}.
For instance, if we have equities eT=(10,5,âˆ’5)e\_{T}=(10,5,-5) and the ADL policy outputs haircuts (0.5,0,âˆ’1)(0.5,0,-1), then the post-ADL equities are eT=(5,5,0)e\_{T}=(5,5,0).
On the other hand, if the ADL policy outputs haircuts h=(0.25,0.5,âˆ’1)h=(0.25,0.5,-1), then the final equities after execution of the policy are eT=(7.5,2.5,0)e\_{T}=(7.5,2.5,0).

##### Examples of ADL Policies.

We will first provide two canonical examples: queueing (or *leverage ranking*) and pro-rata.
These examples represent the solvency policies of virtually all live perpetuals exchanges as of November 2025.
For both of these policies, the choice of Î¸Ï€\theta\_{\pi} is independent of the choice of hÏ€h\_{\pi}.

##### PNL and Leverage Ranking.

The policy that the largest centralized exchange, Binance, and the largest decentralized exchange, Hyperliquid, use is the PNL-leverage ranking (which we also refer to as a *queueing* method).
We will denote this strategy as Ï€Pâ€‹L\pi\_{PL} and define it via the algorithm that implements it.
Given a haircut budget B=Î¸Ï€Pâ€‹Lâ€‹DTâ€‹(ğ’«n)B=\theta\_{\pi\_{PL}}D\_{T}(\mathcal{P}\_{n}), the algorithm to choose hih\_{i} works as follows:

1. 1.

   For each position ğ”­=(q,c,â„“,t,b)âˆˆğ’«n\mathfrak{p}=(q,c,\ell,t,b)\in\mathcal{P}\_{n}, define the score999We note that technically, many exchanges define the leverage used in the score differently (i.e.,Â instead of the score being linear in â„“\ell, some exchanges multiply by â„“â€‹pâ€‹qpâ€‹q+c)\frac{\ell pq}{pq+c}). This does not change our main results and mainly adds technical complications to the example. sTâ€‹(ğ”­,prâ€‹eâ€‹f)=â„“â€‹p^Tprâ€‹eâ€‹fs\_{T}(\mathfrak{p},p^{ref})=\ell\,\frac{\hat{p}\_{T}}{p^{ref}}.
2. 2.

   Let Ïƒâˆˆğ–¯ğ–¾ğ—‹ğ—†â€‹(ğ’«n)\sigma\in\mathsf{Perm}(\mathcal{P}\_{n}) be any permutation of the positions ranked by decreasing score sTâ€‹(ğ”­,prâ€‹eâ€‹f)s\_{T}(\mathfrak{p},p^{ref})
3. 3.

   For iâˆˆ[n]i\in[n], define Ai=(Bâˆ’âˆ‘j=1ieTâ€‹(ğ”­Ïƒâ€‹(j))+)+A\_{i}=(B-\sum\_{j=1}^{i}e\_{T}(\mathfrak{p}\_{\sigma(j)})\_{+})\_{+}, where eTâ€‹(ğ”­Ïƒâ€‹(j))e\_{T}(\mathfrak{p}\_{\sigma(j)}) is the equity of the jjth largest position under the ranking Ïƒ\sigma
4. 4.

   Define hâˆˆ[0,1]nh\in[0,1]^{n} as

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | hÏ€Pâ€‹L,Ïƒâ€‹(i)={1ifÂ â€‹Aiâˆ’1âˆ’Ai=eTâ€‹(ğ”­Ïƒâ€‹(i))+,Ai>0Aiâˆ’1eTâ€‹(ğ”­Ïƒâ€‹(i))ifÂ â€‹Ai=0,Aiâˆ’1>00otherwiseh\_{\pi\_{PL},\sigma(i)}=\begin{cases}1&\text{if }A\_{i-1}-A\_{i}=e\_{T}(\mathfrak{p}\_{\sigma(i)})\_{+},\;A\_{i}>0\\ \frac{A\_{i-1}}{e\_{T}(\mathfrak{p}\_{\sigma}(i))}&\text{if }A\_{i}=0,A\_{i-1}>0\\ 0&\text{otherwise}\end{cases} |  | (19) |

Note this definition of hÏ€Pâ€‹Lh\_{\pi\_{PL}} ensures that âˆ‘i=1nhÏ€Pâ€‹L,iâ€‹eTâ€‹(ğ”­i)=B\sum\_{i=1}^{n}h\_{\pi\_{PL},i}e\_{T}(\mathfrak{p}\_{i})=B, satisfyingÂ ([17](https://arxiv.org/html/2512.01112v1#S2.E17 "Equation 17 â€£ ADL Policies. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
On the other hand, since we only subtract positive equity positions (e.g.Â jj such that eTâ€‹(ğ”­Ïƒâ€‹(j))+>0e\_{T}(\mathfrak{p}\_{\sigma(j)})\_{+}>0), we satisfyÂ ([18](https://arxiv.org/html/2512.01112v1#S2.E18 "Equation 18 â€£ ADL Policies. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) by construction.

There is one remaining question to address: how should we interpret the score sTâ€‹(ğ”­,prâ€‹eâ€‹f)s\_{T}(\mathfrak{p},p^{ref})?
Most exchanges justify this form for the score by arguing that it can represent the risk a single position holds, so that the exchange ranks positions to ADL by risk-level.
Winning, positive equity positions that are autodeleveraged first will tend to be higher risk positions (i.e.,Â used more leverage for their winnings).
The price terms in the numerator, pT^p\_{\hat{T}}, represents the last mark price of the position whereas the parameter prâ€‹eâ€‹fp^{ref} represents the initial or opening price of the user.

Binance chooses the scoring parameter prâ€‹eâ€‹f=pbâ€‹kp^{ref}=p^{bk} of the position,Â i.e.,sTBinanceâ€‹(ğ”­)=â„“â€‹pT^â€‹(ğ”­)pbâ€‹kâ€‹(ğ”­)s^{\text{Binance}}\_{T}(\mathfrak{p})=\ell\frac{p\_{\hat{T}}(\mathfrak{p})}{p^{bk}(\mathfrak{p})}.
Hyperliquid, on the other hand, chooses the parameter prâ€‹eâ€‹fp^{ref} to simply be the last mark price, prâ€‹eâ€‹f=p^tp^{ref}=\hat{p}\_{t}.
In other words, Binanceâ€™s choice effectively ranks a position based on the maximum possible PNL that a user could realize whereas Hyperliquid simply chooses the current PNL.

##### Pro-Rata Rules.

This haircut strategy is even simpler than the PNL-Leverage ranking and has some benefits in terms of fairness, as we will show inÂ Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization").
Given a valid feasible shortfall Î¸Ï€â€‹DTâ€‹(ğ’«nâ‰¤WTâ€‹(ğ’«n))\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}\leq W\_{T}(\mathcal{P}\_{n})), the pro-rata haircut policy is defined as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | hÏ€Pâ€‹Râ€‹(ğ”­)=Î¸Ï€â€‹DTâ€‹(ğ’«n)WTâ€‹(ğ’«n)â€‹(eTâ€‹(ğ”­))+h\_{\pi\_{PR}}(\mathfrak{p})=\frac{\theta\_{\pi}D\_{T}(\mathcal{P}\_{n})}{W\_{T}(\mathcal{P}\_{n})}(e\_{T}(\mathfrak{p}))\_{+} |  | (20) |

This ranking simply says that the positive equity positions are socialized proportional to their size.
Some exchanges slightly modify this formula to include leverage (e.g., Binanceâ€™s ADL Priority Index includes leverage and unrealized PNL [BinanceADL]; Aevo documentation discusses leverage-weighted priority [AevoADL]), which penalizes higher leverage positions much like the PNL-leverage ranking:

|  |  |  |  |
| --- | --- | --- | --- |
|  | hÏ€Lâ€‹Pâ€‹Râ€‹(ğ”­)=(â„“â€‹eTâ€‹(ğ”­)+âˆ‘ğ”­âˆˆğ’«nâ„“â€‹eTâ€‹(ğ”­)+)â€‹hÏ€Pâ€‹Râ€‹(ğ’«n)h\_{\pi\_{LPR}}(\mathfrak{p})=\left(\frac{\ell e\_{T}(\mathfrak{p})\_{+}}{\sum\_{\mathfrak{p}\in\mathcal{P}\_{n}}\ell e\_{T}(\mathfrak{p})\_{+}}\right)h\_{\pi\_{PR}}(\mathcal{P}\_{n}) |  | (21) |

eT,ie\_{T,i}ranking (kâ†’1k\rightarrow 1)kkkâˆ’1k-1kâˆ’2k-2â‹¯\cdots2211deficithaircutqueuehaircutseverity Î¸=0.50\theta=0.50

(a) Queue ADL:
  
all haircuts fall on the highest-ranked winner.

eT,ie\_{T,i}ranking (kâ†’1k\rightarrow 1)kkkâˆ’1k-1kâˆ’2k-2â‹¯\cdots2211deficithaircutpro-rata haircutsseverity Î¸=0.50\theta=0.50

(b) Pro-rata ADL:
  
haircuts are shared across the surviving winners.

Figure 2: ADL severity example comparing queue and pro-rata coloring. Purple shading equals the negative equity mass (deficit) while blue shading shows the haircut mass allocated to winning traders. The queue panelâ€™s dashed blue block at rankÂ 2 highlights residual equity when the queue method allows partial closures; exchanges that close winners fully (e.g., Hyperliquid) would shave this bar completely. Haircut mass matches deficit mass in each panel, illustrating severity Î¸=0.50\theta=0.50.

##### Per-account constraints.

Suppose that one wants to enforce some per-account constraints on the amount haircut.
For instance, suppose that we guarantee that for user ii, their haircut hih\_{i} always satisfies

|  |  |  |  |
| --- | --- | --- | --- |
|  | hiâ‰¤hÂ¯ih\_{i}\leq\overline{h}\_{i} |  | (22) |

This corresponds to an exchange guaranteeing that a user will never lose more than hÂ¯i\overline{h}\_{i}% of their position in a single ADL round.
Moreover, an exchange might also offer an absolute guarantee to users: if your equity is positive and sufficiently large, you will never be have your equity cut to below some threshold eÂ¯i\underline{e}\_{i}.
This can be represented by the constraint

|  |  |  |  |
| --- | --- | --- | --- |
|  | (1âˆ’hÏ€,i)â€‹eTâ€‹(ğ”­i)â‰¥eÂ¯i(1-h\_{\pi,i})e\_{T}(\mathfrak{p}\_{i})\geq\underline{e}\_{i} |  | (23) |

Numerous exchanges offer one or both of these guarantees on a per-ADL-round basis, including Hyperliquid, BitMEX, and AevoÂ [HyperliquidDocsLiquidations, BitMEXADL, AevoADL].

##### Numerical example.

Consider five accounts with equities eT=(10,5,1,âˆ’3,âˆ’12)e\_{T}=(10,5,1,-3,-12) and queue order Ïƒ=(2,1,3,5,4)\sigma=(2,1,3,5,4) induced by the PNL-leverage scores.
Let the queue policy choose severity Î¸Ï€Pâ€‹L=12\theta\_{\pi\_{PL}}=\tfrac{1}{2}, so the haircut budget is B=Î¸Ï€Pâ€‹Lâ€‹DTâ€‹(ğ’«n)=7.5B=\theta\_{\pi\_{PL}}D\_{T}(\mathcal{P}\_{n})=7.5.
The construction inÂ ([19](https://arxiv.org/html/2512.01112v1#S2.E19 "Equation 19 â€£ Item 4 â€£ PNL and Leverage Ranking. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) yields A=(2.5,0,0,0,0)A=(2.5,0,0,0,0) and haircuts h=(0.25,1,0,0,0)h=(0.25,1,0,0,0): the top winner is cut from 1010 to 7.57.5, the second winner is fully wiped out, and the remaining accounts are unchanged, giving eT=(7.5,0,1,âˆ’3,âˆ’4.5)e\_{T}=(7.5,0,1,-3,-4.5).
If, before the next ADL decision, only the losing accounts partially recover to eT=(7.5,0,1,âˆ’1.5,âˆ’2.25)e\_{T}=(7.5,0,1,-1.5,-2.25), then a second round at the same severity Î¸Ï€Pâ€‹L=12\theta\_{\pi\_{PL}}=\tfrac{1}{2} autodeleverages all negative-equity accounts against the largest winner, yielding final equities eT=(3.75,0,1,0,0)e\_{T}=(3.75,0,1,0,0).
Under the pro-rata ruleÂ ([20](https://arxiv.org/html/2512.01112v1#S2.E20 "Equation 20 â€£ Pro-Rata Rules. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) with the same severity Î¸Ï€Pâ€‹R=12\theta\_{\pi\_{PR}}=\tfrac{1}{2}, we have DT=15D\_{T}=15 and WT=16W\_{T}=16, so the uniform haircut factor is Î±=Î¸Ï€Pâ€‹Râ€‹DT/WT=15/32\alpha=\theta\_{\pi\_{PR}}D\_{T}/W\_{T}=15/32 and each winning accountâ€™s equity is scaled by (1âˆ’Î±)=17/32(1-\alpha)=17/32, giving eT=(170/32,85/32,17/32,âˆ’3,âˆ’12)e\_{T}=(170/32,85/32,17/32,-3,-12).
In particular, the ranking of positive-equity accounts is preserved under pro-rata, since all winners are multiplied by the same constant factor, illustrating its rank-preservation property.

### 2.5 ADL Trilemma

The preceding subsections defined trader equity, exchange solvency, insurance funds, and autodeleveraging (ADL) policies.
In this subsection we introduce a highâ€“level design principle that organizes the rest of the paper: an *ADL trilemma*.
Informally, a perpetuals venue cannot simultaneously (i) keep insolvency and ADL breach events rare, (ii) protect solvent winners from large socialized losses, and (iii) extract maximal longâ€“run exchange revenue from trading and funding activity.
Any ADL design must pick (at most) two of these three goals.

##### Exchange revenue.

To define the trilemma, we have to first formally describe what constitutes exchange revenue.
Recall fromÂ Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization") that, given parameters Î±,Î²,Î·âˆˆ[0,1]\alpha,\beta,\eta\in[0,1], the insurance fund Iâ€‹FtIF\_{t}
evolves by

|  |  |  |
| --- | --- | --- |
|  | Iâ€‹Ft+1=Iâ€‹Ft+Î±â€‹âˆ‘jâˆˆTtÏ„tâ€‹(Î”â€‹qj)+Î·â€‹ptâ€‹Vt+Î²â€‹âˆ‘i=1n|Î³t|â€‹ptâ€‹|qi|âˆ’minâ¡{Iâ€‹Ft,Dt},IF\_{t+1}=IF\_{t}+\alpha\sum\_{j\in T\_{t}}\tau\_{t}(\Delta q\_{j})+\eta\,p\_{t}V\_{t}+\beta\sum\_{i=1}^{n}|\gamma\_{t}|\,p\_{t}|q\_{i}|-\min\{IF\_{t},D\_{t}\}, |  |

where TtT\_{t} is the multiset of liquidations at tt, VtV\_{t} is traded volume, Î³t\gamma\_{t} is the funding rate, and DtD\_{t} is the period bad debt.
For notational convenience, define the perâ€“period gross fee flows

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ–¥ğ–¾ğ–¾tliq\displaystyle\mathsf{Fee}^{\text{liq}}\_{t} | =âˆ‘jâˆˆTtÏ„tâ€‹(Î”â€‹qj)\displaystyle=\sum\_{j\in T\_{t}}\tau\_{t}(\Delta q\_{j}) | ğ–¥ğ–¾ğ–¾ttrade=ptâ€‹Vt\displaystyle\mathsf{Fee}^{\text{trade}}\_{t}=p\_{t}V\_{t} | ğ–¥ğ–¾ğ–¾tfund=âˆ‘i=1n|Î³t|â€‹ptâ€‹|qi|.\displaystyle\mathsf{Fee}^{\text{fund}}\_{t}=\sum\_{i=1}^{n}|\gamma\_{t}|\,p\_{t}|q\_{i}|. |  |

Most exchanges fully collect liquidation and trading fees and potentially collect fees on funding rates.101010In particular, we note that HLP-like systems where fees are charged on quoting offsetting positions can be viewed as a form of exchange revenueÂ [HyperliquidHLPVaults]. Moreover, a number of perpetuals AMM DEXs collect protocol revenue from funding flowsÂ [GMXDocs, PerpV2Docs].

Let Î¶â‰¤(1âˆ’Î²)\zeta\leq(1-\beta) be the expected fraction of funding rates that the exchange keeps as revenue.
Then the exchangeâ€™s *gross revenue* at time tt is

|  |  |  |
| --- | --- | --- |
|  | ğ–±ğ–¾ğ—ğ–¾ğ—‡ğ—ğ–¾tgross=ğ–¥ğ–¾ğ–¾tliq+ğ–¥ğ–¾ğ–¾ttrade+Î¶â€‹ğ–¥ğ–¾ğ–¾tfund.\mathsf{Revenue}^{\text{gross}}\_{t}=\mathsf{Fee}^{\text{liq}}\_{t}+\mathsf{Fee}^{\text{trade}}\_{t}+\zeta\mathsf{Fee}^{\text{fund}}\_{t}. |  |

By construction, the fractions Î±,Î·,Î²\alpha,\eta,\beta of these fee flows are diverted into the
insurance fund. The remaining share accrues as *net exchange revenue*

|  |  |  |
| --- | --- | --- |
|  | ğ–±ğ–¾ğ—ğ–¾ğ—‡ğ—ğ–¾t:=(1âˆ’Î±)ğ–¥ğ–¾ğ–¾tliq+(1âˆ’Î·)ğ–¥ğ–¾ğ–¾ttrade+(1âˆ’Î²âˆ’Î¶)ğ–¥ğ–¾ğ–¾tfund.\mathsf{Revenue}\_{t}:=(1-\alpha)\,\mathsf{Fee}^{\text{liq}}\_{t}+(1-\eta)\,\mathsf{Fee}^{\text{trade}}\_{t}+(1-\beta-\zeta)\,\mathsf{Fee}^{\text{fund}}\_{t}. |  |

We note that inÂ Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization") that we refine this notion of revenue to a discounted *exchange longâ€“term value* (LTV).
The LTV accounts for future expected fee flows and traders leaving the exchange as a function of the realized ADL haircuts.

##### Three competing desiderata.

There are three main goals that an ADL policy aims to enforce for traders and exchanges: revenue, solvency, and fairness.
We formalize these notions in the sequel:

* â€¢

  *Solvency.* (Â§[4](https://arxiv.org/html/2512.01112v1#S4 "4 Severity Optimization â€£ Autodeleveraging: Impossibilities and Optimization"), Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization")) The exchange aims to ensure that Rt=0R\_{t}=0 for most times tt and that the total shortfall âˆ‘tRt\sum\_{t}R\_{t} is small relative to the expected insurance fund size.
  This desideratum is beneficial to both the exchange and traders.
* â€¢

  *Fairness and moral hazard.* (Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"), Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization"))
  Traders want to know that if they face socialization, they will not be asked to absorb a portion of RtR\_{t} that is too large relative to their notional exposure on the exchange.
  This desideratum is mainly beneficial to traders.
* â€¢

  *Exchange revenue and participation.* (Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization"))
  Heavy ADL on highâ€“value winners can trigger traders exiting the exchange permanently, shrinking future fee flows.
  This desideratum is mainly beneficial to the exchange.

It is clear that Î±,Î²,Î·\alpha,\beta,\eta and the ADL policy Ï€\pi jointly control these three dimensions.
But a natural question is what the trade-offs are between these three desiderata at different values of Î±,Î²,Î·\alpha,\beta,\eta and parametrizations of Ï€\pi.
Raising Î±,Î²,Î·\alpha,\beta,\eta builds the reserve faster and decreases breaches (i.e.,Â times with Rt>0R\_{t}>0), but diverts exchange revenue into the fund.
Increasing ADL severity (or concentrating haircuts) makes breaches rarer and accelerates solvency, but worsens fairness and drives away the highestâ€“value winning traders.
Keeping severities (i.e.,Â total solvency resolved by ADL) small preserves fairness and participation, but leaves the exchange exposed to repeated shortfalls.
The goal of this paper is to formalize these three statements via a trilemma:

###### Proposition 2.1 (Trilemma, Informal).

Fix a sequence of perpetuals exchanges ğ’«n\mathcal{P}\_{n} and static ADL policies Ï€n\pi\_{n} with insurance parameters (Î±,Î²,Î·)(\alpha,\beta,\eta).
Under the heavy-tailed shortfall assumptions of Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization"), no policy family (Ï€n)(\pi\_{n}) can simultaneously satisfy the following uniformly in nn:

1. (S)

   Solvency: Residual risk is controlled, i.e.,, âˆ‘tRtâ€‹(Ï€n)=Opâ€‹(1)\sum\_{t}R\_{t}(\pi\_{n})=O\_{p}(1) and â„™â€‹[Rtâ€‹(Ï€n)>0]=Oâ€‹(1)\mathbb{P}[R\_{t}(\pi\_{n})>0]=O(1).
2. (F)

   Fairness: Moral hazard is bounded, i.e.,, Ï‰TÏ€/DTÏ€=Î˜â€‹(1)\omega^{\pi}\_{T}/D^{\pi}\_{T}=\Theta(1) and Ï‰TÏ€/Î”TÏ€=Î˜â€‹(1)\omega^{\pi}\_{T}/\Delta^{\pi}\_{T}=\Theta(1).
3. (R)

   Revenue: Exchange revenue is preserved relative to a benchmark, i.e.,, LTVâ€‹(Ï€n)â‰LTVbenchmark\text{LTV}(\pi\_{n})\asymp\text{LTV}\_{\text{benchmark}}.

Enforcing (S) requires sacrificing (F) (via concentrated haircuts) or (R) (via excessive insurance diversion). Conversely, preserving (F) and (R) necessitates frequent solvency breaches.

A formal statement with precise definitions and a complete proof of the proposition appears in AppendixÂ [I](https://arxiv.org/html/2512.01112v1#A9 "Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization").

##### Proof sketch and roadmap.

The remainder of the paper establishes the Trilemma by analyzing each desideratum in turn:

* â€¢

  *Solvency Ratios (Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization"), AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization")).*
  We analyze the ratio Ï‰TÏ€/DTÏ€\omega^{\pi}\_{T}/D^{\pi}\_{T} under heavy-tailed assumptions.
  TheoremÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem3 "Theorem B.3 (PTSR scaling). â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") proves that for any budget-balanced static ADL with severity Î¸n\theta\_{n}, the ratio scales as bn/(Î¸nâ€‹n)b\_{n}/(\theta\_{n}n).
  Consequently, enforcing rare breaches (large Î¸n\theta\_{n}) drives the ratio to zero, violating (F).
* â€¢

  *Fairness Models (Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")â€“Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization"), AppendicesÂ [C](https://arxiv.org/html/2512.01112v1#A3 "Appendix C Theoretical Properties of Capped Pro-Rata â€£ Autodeleveraging: Impossibilities and Optimization")â€“[E.2](https://arxiv.org/html/2512.01112v1#A5.SS2 "E.2 RAP Optimality and Convex Dominance â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization")).*
  We formalize fairness in two regimes.
  First, for a single round (Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")), we show that capped pro-rata is the unique policy satisfying Sybil resistance and monotonicity.
  Second, under external shocks (Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization")), we prove that leverage-weighted rules (RAP) minimize future shortfall but sacrifice the most systemically important winners, highlighting the tension between short-term robustness and long-term participation.
* â€¢

  *Revenue and Price of Anarchy (Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization"), AppendixÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.SS3 "F.3 Stackelberg vs. Nash in a Two-Round ADL Game â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")).*
  We model the revenue-solvency tradeoff as a Stackelberg game between the exchange and traders.
  We show that static severities yield an unbounded Price of Anarchy (Jnâ€‹(Ï€)âˆ¼Î¸nâ€‹n/bnJ\_{n}(\pi)\sim\theta\_{n}n/b\_{n}) compared to dynamic policies.
  This confirms that achieving (R) and (S) simultaneously requires dynamic intervention, as static rules cannot balance the trilemma asymptotically.

## 3 Risk and Fairness Preliminaries

To analyze how different ADL policies balance solvency and winner survival, we require metrics that capture both the *magnitude* of losses (risk) and their *distribution* across traders (fairness).
Classical risk measures like Value-at-Risk (VaR) and Expected Shortfall (ES) quantify aggregate solvency but ignore how the burden is shared.
To address this, we introduce fairness-aware metrics and distributional orderings that allow us to rank policies based on how they concentrate or spread losses among winners.
We then provide with an brief presentation of extreme-value scaling that we use in the sequel, before concluding with a brief introduction to algorithmic fairness.
The preliminaries in this section are meant to be incomplete and we refer the reader to the literature cited for more details.

### 3.1 Risk Metrics

#### 3.1.1 Traditional Risk Metrics

We briefly review standard metrics used in finance and regulationÂ [Boyd2017MultiPeriodTrading, BCBS2019FRTB].
For a loss Xâ‰¥0X\geq 0 and confidence level Î±âˆˆ(0,1)\alpha\in(0,1):

* â€¢

  *Value-at-Risk (VaR):* The quantile VaRÎ±â€‹(X)=inf{x:ğğ«ğ¨ğ›(X>x)â‰¤Î±}\mathrm{VaR}\_{\alpha}(X)=\inf\{x:\mathop{\bf Prob}(X>x)\leq\alpha\}.
* â€¢

  *Expected Shortfall (ES):* The average loss in the worst Î±\alpha-fraction of cases, ESÎ±â€‹(X)=ğ„[Xâˆ£Xâ‰¥VaRÎ±â€‹(X)]\mathrm{ES}\_{\alpha}(X)=\mathop{\bf E{}}[X\mid X\geq\mathrm{VaR}\_{\alpha}(X)].

In ADL, we apply these to the residual shortfall RtR\_{t} to measure solvency risk.

#### 3.1.2 ADL-Specific Efficiency Metrics

To capture the trade-off between solvency and trader welfare, we define two ratios that normalize winner survival by the scale of the default:

* â€¢

  *Profitability-to-Total-Solvency Ratio (PTSR):*

  |  |  |  |
  | --- | --- | --- |
  |  | ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Ï€)=ğ„[Ï‰TÏ€DTÏ€].\mathsf{PTSR}\_{T}(\pi)=\mathop{\bf E{}}\left[\frac{\omega^{\pi}\_{T}}{D^{\pi}\_{T}}\right]. |  |

  This measures the survival of the top winner relative to the total socialized loss. A low PTSR indicates that the most profitable trader is being disproportionately cannibalized to cover deficits.
* â€¢

  *Profitability-to-Maximum Solvency Ratio (PMR):*

  |  |  |  |
  | --- | --- | --- |
  |  | ğ–¯ğ–¬ğ–±Tâ€‹(Ï€)=ğ„[Ï‰TÏ€Î”TÏ€].\mathsf{PMR}\_{T}(\pi)=\mathop{\bf E{}}\left[\frac{\omega^{\pi}\_{T}}{\Delta^{\pi}\_{T}}\right]. |  |

  This compares the top winnerâ€™s equity to the largest single loserâ€™s shortfall, capturing the concentration of risk on both sides of the trade.

These ratios mirror the VaR/ES distinction: PTSR captures aggregate efficiency, while PMR captures tail concentration.
We formalize this connection and derive exact relationships in AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").

### 3.2 Fairness and Distributional Comparisons

While scalar metrics like PTSR provide summary statistics, they cannot fully capture the fairness of a policy across the entire population of winners.
Two policies might achieve similar solvency but distribute the pain very differentlyâ€”one by wiping out a few large winners (Queue), another by shaving everyone slightly (Pro-Rata).
To rank policies robustly, we use tools from majorization theoryÂ [MarshallOlkinArnold2011].

##### Schur-Convexity and Submajorization.

We compare haircut vectors hâˆˆRnh\in{\mbox{\bf R}}^{n} using *submajorization* (â‰ºw\prec\_{w}).
We say a policy Ï€A\pi\_{A} is *more fair* (or less concentrated) than Ï€B\pi\_{B} if its haircut vector is submajorized by Ï€B\pi\_{B}â€™s, i.e., hâ€‹(Ï€A)â‰ºwhâ€‹(Ï€B)h(\pi\_{A})\prec\_{w}h(\pi\_{B}).
This implies that for *any* convex cost function Ï•\phi (representing trader disutility), the aggregate distress is lower under Ï€A\pi\_{A}:

|  |  |  |
| --- | --- | --- |
|  | hâ€‹(Ï€A)â‰ºwhâ€‹(Ï€B)âŸ¹âˆ‘Ï•â€‹(hiâ€‹(Ï€A))â‰¤âˆ‘Ï•â€‹(hiâ€‹(Ï€B)).h(\pi\_{A})\prec\_{w}h(\pi\_{B})\implies\sum\phi(h\_{i}(\pi\_{A}))\leq\sum\phi(h\_{i}(\pi\_{B})). |  |

This gives us a powerful, parameter-free way to claim that Pro-Rata is â€œfairerâ€ than Queue: it minimizes the collective pain for all convex risk attitudes.
We provide a detailed treatment of these orderings and their application to ADL in AppendixÂ [E.2](https://arxiv.org/html/2512.01112v1#A5.SS2.SSS0.Px2 "RAP realizes Schur-convex dominance. â€£ E.2 RAP Optimality and Convex Dominance â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization").

##### Comonotonicity.

In our worst-case analysis, we often consider *comonotonic* couplings, where winnersâ€™ profits and losersâ€™ deficits are perfectly correlated (move in lockstep).
This represents the most dangerous regime for ADL, as large deficits coincide with large winner profits, testing the policyâ€™s ability to extract liquidity without destroying the best traders.
Our negative results in Â§[5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") exploit this structure to derive tight bounds on the Trilemma.
See AppendixÂ [E.2](https://arxiv.org/html/2512.01112v1#A5.SS2.SSS0.Px2 "RAP realizes Schur-convex dominance. â€£ E.2 RAP Optimality and Convex Dominance â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") for further details on comonotonic risk bounds.

### 3.3 Extremeâ€“value scaling

Our asymptotic analysis relies on *extremeâ€“value scales*: deterministic sequences that characterize the typical magnitude of the largest winner equity and the largest loser shortfall in the limit of a large market.
Recall the winner and loser index sets ğ’²T\mathcal{W}\_{T} and â„’T\mathcal{L}\_{T} with cardinalities knk\_{n} and mnm\_{n}, respectively.
Under mild mixing we assume the aggregate winner and loser masses concentrate at linear scales:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (WTâ€‹(ğ’«n)n,DTâ€‹(ğ’«n)n)â†’ğ‘(Î¼+,Î¼âˆ’).\left(\frac{W\_{T}(\mathcal{P}\_{n})}{n},\,\frac{D\_{T}(\mathcal{P}\_{n})}{n}\right)\xrightarrow{p}(\mu\_{+},\mu\_{-}). |  | (24) |

Here Î¼+,Î¼âˆ’>0\mu\_{+},\mu\_{-}>0 summarize the average winner and loser magnitudes.
We define the respective maxima as

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Ï‰T,Î”T)=(maxiâˆˆğ’²T(eT(ğ”­i,T))+,maxiâˆˆâ„’T(âˆ’eT(ğ”­i,T))+).\big(\omega\_{T},\,\Delta\_{T}\big)=\left(\max\_{i\in\mathcal{W}\_{T}}\big(e\_{T}(\mathfrak{p}\_{i,T})\big)\_{+},\,\max\_{i\in\mathcal{L}\_{T}}\big(-e\_{T}(\mathfrak{p}\_{i,T})\big)\_{+}\right). |  | (25) |

A pair of deterministic, increasing sequences {bk+}kâ‰¥1\{b^{+}\_{k}\}\_{k\geq 1} and {bmâˆ’}mâ‰¥1\{b^{-}\_{m}\}\_{m\geq 1} constitute *extremeâ€“value scales* if there exist constants c+,câˆ’âˆˆ(0,âˆ)c\_{+},c\_{-}\in(0,\infty) such that, as nâ†’âˆn\to\infty,

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Ï‰Tbkn+,Î”Tbmnâˆ’)â†’ğ‘(c+,câˆ’).\left(\frac{\omega\_{T}}{b^{+}\_{k\_{n}}},\,\frac{\Delta\_{T}}{b^{-}\_{m\_{n}}}\right)\xrightarrow{p}(c\_{+},c\_{-}). |  | (26) |

We abbreviate bn=bkn+b\_{n}=b^{+}\_{k\_{n}} when the context (winner side) is unambiguous.
A canonical choice, consistent with classical extremeâ€“value theory, is the set of *upperâ€“quantile normalizers*:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (bk+,bmâˆ’)=(F+âˆ’1â€‹(1âˆ’1k),Fâˆ’âˆ’1â€‹(1âˆ’1m)).\big(b^{+}\_{k},\,b^{-}\_{m}\big)=\left(F\_{+}^{-1}\!\left(1-\frac{1}{k}\right),\,F\_{-}^{-1}\!\left(1-\frac{1}{m}\right)\right). |  | (27) |

where F+F\_{+} and Fâˆ’F\_{-} denote the distribution functions of winner-side positive equities and loser-side shortfalls, respectively.

##### Examples.

Two prototypical cases appear throughout our analysis:

* â€¢

  *Light tails (subâ€“Gaussian).* For distributions with subâ€“Gaussian scales Ïƒ+,Ïƒâˆ’\sigma\_{+},\sigma\_{-},

  |  |  |  |
  | --- | --- | --- |
  |  | bk+â‰Ïƒ+â€‹2â€‹logâ¡k,bmâˆ’â‰Ïƒâˆ’â€‹2â€‹logâ¡m.b^{+}\_{k}\ \asymp\ \sigma\_{+}\sqrt{2\log k},\qquad b^{-}\_{m}\ \asymp\ \sigma\_{-}\sqrt{2\log m}. |  |
* â€¢

  *Powerâ€“law tails (Pareto/FrÃ©chet).* For distributions satisfying ğğ«ğ¨ğ›{(eT)+>x}âˆ¼C+â€‹xâˆ’Î±+\mathop{\bf Prob}\{(e\_{T})\_{+}>x\}\sim C\_{+}x^{-\alpha\_{+}} and ğğ«ğ¨ğ›{(âˆ’(eT))+>x}âˆ¼Câˆ’â€‹xâˆ’Î±âˆ’\mathop{\bf Prob}\{(-(e\_{T}))\_{+}>x\}\sim C\_{-}x^{-\alpha\_{-}} with Î±Â±>0\alpha\_{\pm}>0,

  |  |  |  |
  | --- | --- | --- |
  |  | bk+â‰(C+â€‹k)1/Î±+,bmâˆ’â‰(Câˆ’â€‹m)1/Î±âˆ’.b^{+}\_{k}\ \asymp\ (C\_{+}k)^{1/\alpha\_{+}},\qquad b^{-}\_{m}\ \asymp\ (C\_{-}m)^{1/\alpha\_{-}}. |  |

##### Extremeâ€“value severity scales.

We refer to Î¸n=Î˜â€‹(bn/n)\theta\_{n}=\Theta(b\_{n}/n) as the *extremeâ€“value severity scale*.
This choice aligns the haircut magnitude with the typical largest winner equity bn=bkn+b\_{n}=b^{+}\_{k\_{n}} in a large market where kn=Î˜â€‹(n)k\_{n}=\Theta(n).
TheoremÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem3 "Theorem B.3 (PTSR scaling). â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") (AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization")) demonstrates that this scale is canonical: for any budget-balanced ADL with total severity H=Î¸nâ€‹DTH=\theta\_{n}D\_{T}, the PTSR scales asymptotically as bkn+/(Î¸nâ€‹n)b^{+}\_{k\_{n}}/(\theta\_{n}n).
Consequently, parameter choices on the extremeâ€“value scale preserve non-degenerate efficiency limits, whereas aggressive severities Î¸nâ‰«bkn+/n\theta\_{n}\gg b^{+}\_{k\_{n}}/n drive the PTSR to zero.

### 3.4 Fairness

##### Algorithmic Fairness in ADL.

Algorithmic fairness literature distinguishes between *axiomatic* approaches, which posit structural invariants (often yielding impossibility resultsÂ [Arrow1951, KleinbergEtAl2018FairnessImpossibility]), and *optimization* approaches, which minimize disparate impact via convex programsÂ [DworkEtAl2012FairnessAwareness].
ADL spans both: queue-based policies resemble discrete ranking mechanisms subject to Arrow-style impossibilities, while pro-rata policies admit continuous convex formulations.
We adopt an axiomatic perspective to characterize â€œidealâ€ fairness, then relax it to optimize for robustness.

##### Axiomatic Properties.

We formalize three operational desiderata for fair ADL policies:

* â€¢

  *Sybil Resistance:* Splitting an account into multiple smaller positions (or merging them) should not alter the aggregate haircut. This ensures outcomes depend on total exposure, not identity or fragmentation. Queue-based rules violate this, as splitting a large winner can push parts of its equity lower in the priority stack.
* â€¢

  *Monotonicity (Stable Ordering):* The policy should preserve the relative ordering of winners. If trader AA has more equity than trader BB pre-ADL, AA should also have more equity post-ADL. This prevents arbitrary re-ranking of survivors.
* â€¢

  *Scale Invariance:* If all deficits and equities scale by Î»>0\lambda>0, the relative haircuts should remain unchanged. This ensures the mechanism responds to *leverage* and *risk distribution*, not nominal sizes.

In Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"), we prove that *capped pro-rata* is the unique policy satisfying all three properties, whereas standard queueing fails Sybil resistance and monotonicity.

### 3.5 Moral hazard

Moral hazard is a generic incentive problem that arises when one party (the *agent*) can take actions that affect risk or payoffs, but those actions are not perfectly observable, verifiable, or contractible by the party bearing some of the downside (the *principal*); see, e.g.Â Holmstrom1982, LaffontMartimort2002.
Classic examples include workers choosing effort under wage contracts, managers taking portfolio risk on behalf of investors, or insurers providing coverage to policyholders whose behavior may change once insured.
Because the agentâ€™s action is hidden, the principal cannot simultaneously provide full insurance (so that the agentâ€™s payoff is insulated from shocks) and preserve strong incentives for the agent to take socially desirable actions: risk sharing necessarily distorts effort incentives.
The central goal of the moral-hazard literature is therefore to characterize *second-best* contracts (typically linear or otherwise simple sharing rules) that optimally trade off incentive provision against insurance under information constraintsÂ [DuttingEtAl2023MultiAgentContracts, Carroll2015RobustLinearContracts].

In modern treatments, moral hazard also interacts with robustness and model uncertainty: the principal designs contracts that must perform well across a range of environments, counterparty types, or effort technologies, which further limits how close one can get to the idealized first-best benchmark [DuttingEtAl2023MultiAgentContracts].
In financial systems, these issues appear whenever risk is mutualized or losses are socialized across participants: for example, in insurance pools and in centrally cleared derivatives, where default funds and loss-sharing rules can weaken incentives for individual risk management.
Our ADL setting can be viewed as an instance of this general template, with winners and losers in the market acting as principals who provide mutual insurance and the exchange acting as an agent choosing risk and loss-sharing policies; the negative results in SectionÂ [5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") make this second-best trade-off precise in our model.

## 4 Severity Optimization

We decompose the ADL problem into two orthogonal components: *severity* (how much to socialize) and *haircuts* (who pays).
Solvency is driven almost entirely by the scalar severity sequence (Î¸t)(\theta\_{t}), while fairness and revenue depend on the haircut distribution hth\_{t}.
Since Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")â€“Â§[7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") cover haircut design, here we focus on optimizing Î¸t\theta\_{t} to balance solvency against the risk of driving away traders.

##### Severity Policies.

A *causal severity policy* maps available information â„±t\mathcal{F}\_{t} (deficits, funding rates, risk limits) to a severity fraction Î¸tâˆˆ[0,1]\theta\_{t}\in[0,1].
We contrast three approaches:

1. 1.

   *Static Interpolation:* Î¸t\theta\_{t} is fixed or linearly interpolates between deficit-matching and full queue liquidation. This is simple but rigid.
2. 2.

   *Exponential Backoff:* Î¸t=Î¸0â€‹Î±kt\theta\_{t}=\theta\_{0}\alpha^{k\_{t}} decays as the number of recent shocks ktk\_{t} increases. This prevents cascading failures from wiping out the entire book during prolonged stress.
3. 3.

   *Online Control (Mirror Descent):* We treat severity selection as an online convex optimization problem. The controller adjusts Î¸t\theta\_{t} to minimize a regret bound combining solvency costs (RtR\_{t}) and revenue loss (excessive haircuts). This approach adapts to non-stationary market conditions and respects caps Î˜t\Theta\_{t} derived from the Price of Anarchy analysis in Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization").

##### Separation Principle.

Under the budget-balance constraintÂ ([17](https://arxiv.org/html/2512.01112v1#S2.E17 "Equation 17 â€£ ADL Policies. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")), any one-round ADL policy Ï€\pi with severity Î¸Ï€\theta\_{\pi} and haircuts hÏ€h\_{\pi} satisfies

|  |  |  |
| --- | --- | --- |
|  | Hâ€‹(Ï€)=âˆ‘ihÏ€,iâ€‹eTâ€‹(ğ”­i)+=Î¸Ï€â€‹DTâ€‹(ğ’«n),H(\pi)\;=\;\sum\_{i}h\_{\pi,i}\,e\_{T}(\mathfrak{p}\_{i})\_{+}\;=\;\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}), |  |

so the post-ADL deficit is

|  |  |  |
| --- | --- | --- |
|  | RTâ€‹(Ï€)=(DTâ€‹(ğ’«n)âˆ’Hâ€‹(Ï€))+=(1âˆ’Î¸Ï€)+â€‹DTâ€‹(ğ’«n),R\_{T}(\pi)\;=\;(D\_{T}(\mathcal{P}\_{n})-H(\pi))\_{+}\;=\;(1-\theta\_{\pi})\_{+}D\_{T}(\mathcal{P}\_{n}), |  |

which depends only on Î¸Ï€\theta\_{\pi} and DTâ€‹(ğ’«n)D\_{T}(\mathcal{P}\_{n}), not on how Hâ€‹(Ï€)H(\pi) is distributed across winners.
Thus, any solvency functional that depends on Ï€\pi only via {Rtâ€‹(Ï€)}t\{R\_{t}(\pi)\}\_{t} (e.g., breach frequencies, VaR/ES of âˆ‘tRt\sum\_{t}R\_{t}) can be optimized over the scalar sequence (Î¸t)(\theta\_{t}), holding the haircut rule fixed.
Conversely, fairness and revenue functionals depend on the winner-side post-ADL equities {(1âˆ’hÏ€,i)â€‹eTâ€‹(ğ”­i)+}i\{(1-h\_{\pi,i})e\_{T}(\mathfrak{p}\_{i})\_{+}\}\_{i} and are invariant to the choice of Î¸t\theta\_{t} once the total budget HtH\_{t} is fixed.
We exploit this separability in our numerics (Â§[9](https://arxiv.org/html/2512.01112v1#S9 "9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization")) by tuning Î¸t\theta\_{t} (severity control) and hth\_{t} independently.

## 5 Negative Results

We begin with two structural limits for ADL.
They formalize a moral-hazard trade-off between solvency and winner payoffs that cannot be removed by better policy design.
The tension is instantaneous and zero-sum at the shock: covering aggregate deficit DTD\_{T} eventually requires shaving the profits of the best winner.
We first argue that this tension can be viewed as a form of moral hazard, in the sense used in principal-agent contracts.

An exchange that earns fees from trading volume has an incentive to let very risky, highly leveraged users accumulate large positions.
When these users default, their negative equity shows up as a large deficit DTD\_{T}, which is then socialized onto the winners via ADL haircuts.
In our model this is the basic moral-hazard question: the exchange enjoys fee revenue from risky losers, while the cost of their tail losses is borne by solvent winners.
The results below quantify how this wedge scales as the market thickens, showing that the severity needed for solvency grows with the number of positions and with the leverage imbalance between losers and winners.

### 5.1 Impossibility of Avoiding Moral Hazard as nâ†’âˆn\to\infty

We first show that the tension between solvency and winner survival scales unfavorably with market size, creating an unavoidable moral hazard wedge.
Viewing traders as principals and the exchange as an agent, preserving the agentâ€™s utility (solvency) asymptotically destroys the principalsâ€™ utility (winner profits) unless severity vanishes.

##### Example.

Consider a book of size nn where loser positions are i.i.d. with mean loss Î¼>0\mu>0, so aggregate deficit scales as DTâ‰ˆÎ¼â€‹nD\_{T}\approx\mu n.
Suppose the top winnerâ€™s equity scales sub-linearly, e.g., bnâˆ¼câ€‹logâ¡nb\_{n}\sim c\log n (light tails).
If the exchange commits to a fixed severity Î¸Â¯>0\bar{\theta}>0 to maintain solvency, the total haircut budget is Hnâ‰ˆÎ¸Â¯â€‹Î¼â€‹nH\_{n}\approx\bar{\theta}\mu n.
As nâ†’âˆn\to\infty, this linear haircut cost overwhelms the logarithmic winner equity:

|  |  |  |
| --- | --- | --- |
|  | enpostâ‰ˆ(câ€‹logâ¡nâˆ’Î¸Â¯â€‹Î¼â€‹n)+â†’0.e\_{n}^{\text{post}}\approx(c\log n-\bar{\theta}\mu n)\_{+}\to 0. |  |

Thus, to preserve any winner profit, severity must vanish at the rate Î¸n=Oâ€‹(bn/n)\theta\_{n}=O(b\_{n}/n).
Constant severity policies therefore represent a form of growing moral hazard: they transfer an increasingly large share of tail risk from the exchange to the most profitable traders.
We formalize this scaling in AppendixÂ [B.6](https://arxiv.org/html/2512.01112v1#A2.SS6 "B.6 Randomized constructions for moral-hazard examples â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").

##### Main Result.

In our model, socialization is instantaneously zero-sum: every dollar of deficit DTD\_{T} covered by ADL must come from the winnersâ€™ equity.
If ADL usage does not vanish as the market grows larger (nâ†’âˆn\rightarrow\infty), then one cannot simultaneously keep deficits small (solvency, low DTD\_{T}) and preserve winner payoffs (high Ï‰T\omega\_{T}).
The proposition below quantifies this tradeoff in terms of extreme-value scales and can be read as a moral-hazard impossibility result in the principalâ€“agent sense.

###### Proposition 5.1 (Informal).

Suppose that the extreme value scale of the winning traderâ€™s equity, Ï‰TÏ€â€‹(ğ’«n)\omega\_{T}^{\pi}(\mathcal{P}\_{n}), is bnb\_{n}.
Then,

|  |  |  |
| --- | --- | --- |
|  | ğ–¯ğ–³ğ–²ğ–±Tâ€‹(ğ’«n,Ï€)=ğ„Ï€[Ï‰TÏ€â€‹(ğ’«n)DTÏ€â€‹(ğ’«n)]â‰bnÎ¸nâ€‹n\mathsf{PTSR}\_{T}(\mathcal{P}\_{n},\pi)=\mathop{\bf E{}}\_{\pi}\left[\frac{\omega^{\pi}\_{T}(\mathcal{P}\_{n})}{D^{\pi}\_{T}(\mathcal{P}\_{n})}\right]\asymp\frac{b\_{n}}{\theta\_{n}\,n} |  |

In particular, the example above shows the order bn/nb\_{n}/n is tight: unless the severity vanishes at the extremeâ€“value scale, Î¸n=Î˜â€‹(bn/n)\theta\_{n}=\Theta(b\_{n}/n), one cannot preserve the best traderâ€™s profits as nâ†’âˆn\to\infty.
See Â§[3](https://arxiv.org/html/2512.01112v1#S3 "3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization") for the formal definition of extreme-value scales.

##### Example.

The bound bn/nb\_{n}/n dictates the maximal safe severity for different distributions:

* â€¢

  *Gaussian Winners (Light Tails):* For eiâˆ¼ğ’©â€‹(0,1)e\_{i}\sim\mathcal{N}(0,1), the maximum scales as bnâˆ¼2â€‹logâ¡nb\_{n}\sim\sqrt{2\log n}.
  Thus, severity must vanish rapidly, Î¸nâ‰²2â€‹logâ¡n/n\theta\_{n}\lesssim\sqrt{2\log n}/n, to avoid autodeleveraging the top winner.
  This implies that the shortfall that can be covered goes to zero as nâ†’âˆn\rightarrow\infty.
* â€¢

  *Pareto Winners (Heavy Tails):* For eiâˆ¼Paretoâ€‹(Î±)e\_{i}\sim\text{Pareto}(\alpha) with Î±>1\alpha>1, the maximum scales as bnâˆ¼n1/Î±b\_{n}\sim n^{1/\alpha}.
  Here, the constraint is looser but still vanishing as nâ†’âˆn\rightarrow\infty: Î¸nâ‰²nâˆ’(1âˆ’1/Î±)\theta\_{n}\lesssim n^{-(1-1/\alpha)}.

Even in the heavy-tailed case (infinite variance, Î±<2\alpha<2), budget balance implies that a constant fraction severity Î¸\theta wipes out the top winner almost surely as nâ†’âˆn\to\infty.

### 5.2 Excessive leverage guarantees large maximal trader loss

Another natural form of moral hazard, one that quantifies the role of the exchange as an agent, is the ratio of leverage held by the winning and losing sides.
If losers generally have much more leverage than winners, then the exchange is giving winning traders a higher likelihood of paying socialized losses.
We quantify this deficiency in risk management by the exchange by providing a more quantitative extreme value result: we show that the ratio of winner to loser leverages is a multiplicative term in how fast the winning traderâ€™s position is likely to be autodeleveraged.

##### Example.

Consider a regime where loser leverage mass â„“âˆ’\ell^{-} dominates winner leverage mass â„“+\ell^{+}.
Aggregate shortfall scales with loser liability, DTâ‰ˆâ„“âˆ’â€‹bnâˆ’D\_{T}\approx\ell^{-}b\_{n}^{-}, while the top winnerâ€™s equity scales as Ï‰Tâ‰ˆâ„“+â€‹bn+\omega\_{T}\approx\ell^{+}b\_{n}^{+}.
If severity Î¸n\theta\_{n} is fixed, the haircut budget Hn=Î¸nâ€‹DTâ‰ˆÎ¸nâ€‹â„“âˆ’â€‹bnâˆ’H\_{n}=\theta\_{n}D\_{T}\approx\theta\_{n}\ell^{-}b\_{n}^{-} is large.
Comparing budget to winner equity:

|  |  |  |
| --- | --- | --- |
|  | HnÏ‰Tâ‰ˆÎ¸nâ€‹â„“âˆ’â„“+â€‹bnâˆ’bn+.\frac{H\_{n}}{\omega\_{T}}\approx\theta\_{n}\frac{\ell^{-}}{\ell^{+}}\frac{b\_{n}^{-}}{b\_{n}^{+}}. |  |

If â„“âˆ’â‰«â„“+\ell^{-}\gg\ell^{+}, even a small severity Î¸n\theta\_{n} creates a haircut larger than the top winnerâ€™s entire position.
Thus, safe severity is throttled not just by market size but by the *leverage imbalance* â„“+/â„“âˆ’\ell^{+}/\ell^{-}.
See AppendixÂ [B.6](https://arxiv.org/html/2512.01112v1#A2.SS6.SSS0.Px2 "Leverage-imbalance construction. â€£ B.6 Randomized constructions for moral-hazard examples â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") for the rigorous construction.

##### Main Result.

The next result makes the leverageâ€“imbalance effect precise.
When loser positions carry much more leverage than winners, the ratio of winner to loser leverage masses â„“n+/â„“nâˆ’\ell\_{n}^{+}/\ell\_{n}^{-} enters multiplicatively in the EV-scale bound for the top winnerâ€™s survival.
In moral-hazard terms, an exchange that tolerates very high loser leverage effectively exposes its best winners to autodeleveraging: even with small severities Î¸n\theta\_{n}, a large imbalance â„“nâˆ’/â„“n+\ell\_{n}^{-}/\ell\_{n}^{+} can still force substantial haircuts on the most profitable traders.

###### Proposition 5.2 (Informal).

Let bn+,bnâˆ’b\_{n}^{+},b\_{n}^{-} be the extreme value scales of the winning and losing traders, respectively.
Furthermore, let the winner and loser side leverage masses be â„“n+,â„“nâˆ’\ell\_{n}^{+},\ell\_{n}^{-}, respectively.
Then we have the general EVT scaling:

|  |  |  |
| --- | --- | --- |
|  | ğ„Ï€[Ï‰TÏ€â€‹(ğ’«n)DTÏ€â€‹(ğ’«n)]â‰â„“n+â„“nâˆ’â‹…bn+bnâˆ’â‹…1Î¸n.\mathop{\bf E{}}\_{\pi}\!\left[\frac{\omega^{\pi}\_{T}(\mathcal{P}\_{n})}{D^{\pi}\_{T}(\mathcal{P}\_{n})}\right]\ \asymp\ \frac{\ell\_{n}^{+}}{\ell\_{n}^{-}}\cdot\frac{b\_{n}^{+}}{b\_{n}^{-}}\cdot\frac{1}{\theta\_{n}}. |  |

The full proof is in AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").

##### Example.

The scaling is now modulated by the *leverage imbalance* Î›n=â„“n+/â„“nâˆ’\Lambda\_{n}=\ell\_{n}^{+}/\ell\_{n}^{-}.

* â€¢

  *Symmetric Leverage (Î›nâ‰1\Lambda\_{n}\asymp 1):* If winner and loser leverages are comparable, the bound reverts to the previous case (bn+/bnâˆ’b\_{n}^{+}/b\_{n}^{-}).
* â€¢

  *High Loser Leverage (Î›nâ‰ª1\Lambda\_{n}\ll 1):* If losers are 10Ã—10\times more leveraged, the safe severity drops by 10Ã—10\times. In the extreme, if â„“nâˆ’âˆ¼n\ell\_{n}^{-}\sim n (e.g., a few massive whales) while â„“n+âˆ¼1\ell\_{n}^{+}\sim 1 (retail winners), the required severity Î¸n\theta\_{n} becomes vanishingly small even faster than the EV scale suggests.
* â€¢

  *High Winner Leverage (Î›nâ‰«1\Lambda\_{n}\gg 1):* Conversely, if winners are highly leveraged (so their equity is sensitive to small price moves, but large in notional), the ratio Î›n\Lambda\_{n} buffers the impact, allowing for larger severities without autodeleveraging the top winner.

##### Moral Hazard Interpretation.

These results formalize the â€œsecond-bestâ€ nature of ADL: perfect insurance without incentive distortion is impossible.
PropositionÂ [5.1](https://arxiv.org/html/2512.01112v1#S5.Thmtheorem1 "Proposition 5.1 (Informal). â€£ Main Result. â€£ 5.1 Impossibility of Avoiding Moral Hazard as ğ‘›â†’âˆ â€£ 5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") implies that tail events necessarily penalize the best traders disproportionately, while PropositionÂ [5.2](https://arxiv.org/html/2512.01112v1#S5.Thmtheorem2 "Proposition 5.2 (Informal). â€£ Main Result. â€£ 5.2 Excessive leverage guarantees large maximal trader loss â€£ 5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") shows that unconstrained loser leverage amplifies this burden.
This mirrors the tension in Central Counterparty (CCP) recovery in traditional clearing, where Variation Gains Haircutting (VGH) socializes losses among winners to avoid insolvency [CPMI\_IOSCO\_2014, Gregory2015].
Like VGH (and unlike assessment powers that call external capital), ADL is an ex-post haircut on unrealized profits, creating similar moral hazard channels [DuffieZhu2011, Pirrong2011].
Practitioners should therefore treat PTSR/PMR as key risk indicators, tuning dynamic severity caps to keep these ratios bounded.

### 5.3 Queue-based Methods are the worst ADL policies for the top winning trade

One result that we see empirically inÂ Â§[9](https://arxiv.org/html/2512.01112v1#S9 "9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") is that the Queue mechanism is by far the worst ADL policy for the top winning trade.
We briefly formalize this with an informal proposition that we prove in AppendixÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.SS3 "B.3 Queue maximizes top-winner damage â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").

###### Proposition 5.3 (Queue Maximizes Damage to Top Winner).

Among all budget-balanced ADL policies with fixed severity Î¸\theta, the *Queue* policy (haircut largest winners first) uniquely minimizes the survival of the top winner.
Let Ï‰TQueue\omega\_{T}^{\text{Queue}} and Ï‰TPR\omega\_{T}^{\text{PR}} be the top winnerâ€™s post-ADL equity under Queue and Pro-Rata, respectively.
Whenever the haircut budget H=Î¸â€‹DTH=\theta D\_{T} satisfies Hâ‰¤e(1)H\leq e\_{(1)}, we have the strict gap

|  |  |  |
| --- | --- | --- |
|  | Ï‰TPRâˆ’Ï‰TQueue=Hâ€‹(1âˆ’e(1)WT)>â€„0.\omega\_{T}^{\text{PR}}-\omega\_{T}^{\text{Queue}}\;=\;H\left(1-\frac{e\_{(1)}}{W\_{T}}\right)\;>\;0. |  |

Consequently, Pro-Rata strictly dominates Queue in terms of fairness metrics:

|  |  |  |
| --- | --- | --- |
|  | ğ–¯ğ–³ğ–²ğ–±Tâ€‹(PR)âˆ’ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Queue)=Î¸â€‹(1âˆ’e(1)WT).\mathsf{PTSR}\_{T}(\text{PR})-\mathsf{PTSR}\_{T}(\text{Queue})\;=\;\theta\left(1-\frac{e\_{(1)}}{W\_{T}}\right). |  |

Thus, Queue maximizes the concentration of haircuts on the most profitable trader, leading to the worst possible PTSR/PMR scores.

The full proof is in AppendixÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.SS3 "B.3 Queue maximizes top-winner damage â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").
AppendixÂ [B.5](https://arxiv.org/html/2512.01112v1#A2.SS5 "B.5 Relationship to Classical Risk Measures â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") further strengthens this statement by proving that Queue also minimizes the VaR and ES of the top survivor at every confidence level, so even classical risk metrics rank Queue as the worst policy for the top winner.

## 6 Fairness

A natural question is whether a particular ADL policy is optimal or fair.
We demonstrate that a modified pro-rata rule respecting per-account constraints, the *capped pro-rata rule*, is the most fair policy in two senses: it minimizes total convex disutility and is the unique rule satisfying key axiomatic properties.

##### Definition of the Capped Pro-Rata Rule.

The capped pro-rata rule is a water-filling algorithm that enforces per-account constraints before applying a pro-rata haircut.
Combining haircut constraintsÂ ([22](https://arxiv.org/html/2512.01112v1#S2.E22 "Equation 22 â€£ Per-account constraints. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) and equity constraintsÂ ([23](https://arxiv.org/html/2512.01112v1#S2.E23 "Equation 23 â€£ Per-account constraints. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")), we define an effective cap Î²i=minâ¡{hÂ¯i,1âˆ’eÂ¯i/eTâ€‹(ğ”­i)}\beta\_{i}=\min\{\overline{h}\_{i},1-\underline{e}\_{i}/e\_{T}(\mathfrak{p}\_{i})\}.
The maximum haircut capacity is

|  |  |  |  |
| --- | --- | --- | --- |
|  | Câ€‹(Î²)=âˆ‘i=1neTâ€‹(ğ”­i)â€‹Î²i.C(\beta)=\sum\_{i=1}^{n}e\_{T}(\mathfrak{p}\_{i})\beta\_{i}. |  | (28) |

If the deficit exceeds this capacity, no feasible haircut exists.
Otherwise, we aim to equalize haircuts subject to these caps.
The capped pro-rata rule Ï€Câ€‹P\pi\_{CP} is defined as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | hÏ€Câ€‹P,i=minâ¡{Î·,Î²i}h\_{\pi\_{CP},i}=\min\{\eta,\beta\_{i}\} |  | (29) |

where Î·âˆˆ[0,1]\eta\in[0,1] is chosen to satisfy the budget constraint

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘i=1nhÏ€Câ€‹P,iâ€‹eTâ€‹(ğ”­i)+=Î¸Ï€â€‹DTâ€‹(ğ’«n).\sum\_{i=1}^{n}h\_{\pi\_{CP},i}e\_{T}(\mathfrak{p}\_{i})\_{+}=\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}). |  | (30) |

This can be computed efficiently by sorting the caps Î²i\beta\_{i} and finding the threshold Î·\eta (see eq.Â ([30](https://arxiv.org/html/2512.01112v1#S6.E30 "Equation 30 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")) and the algorithm in AppendixÂ [D](https://arxiv.org/html/2512.01112v1#A4 "Appendix D Algorithms for Pro-Rata Haircut Rules â€£ Autodeleveraging: Impossibilities and Optimization")).

##### Convex Optimality.

Let Ï•:[0,1]â†’R\phi:[0,1]\rightarrow{\mbox{\bf R}} be an increasing convex function representing the disutility of a haircut.
We formulate the problem of minimizing total disutility subject to per-account constraints:

|  |  |  |  |
| --- | --- | --- | --- |
|  | minhâˆˆ[0,1]nâˆ‘i=1nÏ•â€‹(hi)subject toâˆ€iâˆˆ[n]â€‹hiâ‰¤Î²i(effective cap)\begin{array}[]{ll}\displaystyle{\min\_{h\in[0,1]^{n}}}&\displaystyle{\sum\_{i=1}^{n}\phi(h\_{i})}\\[6.0pt] \text{subject to}&\forall i\in[n]\;\;h\_{i}\leq\beta\_{i}\quad\text{(effective cap)}\end{array} |  | (31) |

In AppendixÂ [C](https://arxiv.org/html/2512.01112v1#A3.SS0.SSS0.Px2 "Convex Optimality â€£ Appendix C Theoretical Properties of Capped Pro-Rata â€£ Autodeleveraging: Impossibilities and Optimization"), we show:

###### Proposition 6.1.

The unique solution toÂ ([31](https://arxiv.org/html/2512.01112v1#S6.E31 "Equation 31 â€£ Convex Optimality. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")) is the capped pro-rata ruleÂ ([29](https://arxiv.org/html/2512.01112v1#S6.E29 "Equation 29 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")).

This implies that for any reasonable model of financial disutility, capped pro-rata maximizes social welfare.

##### Axiomatic Fairness.

We define three natural fairness properties:

* â€¢

  *Sybil resistance:* Outcomes are identity-agnostic and invariant to splitting or merging accounts.
* â€¢

  *Scale invariance:* Haircuts are unchanged if both shortfall and equities are scaled by a common factor.
* â€¢

  *Monotonicity (Stability):* The policy preserves the relative ordering of post-haircut equity. If eiâ‰¥eje\_{i}\geq e\_{j}, then (1âˆ’hi)â€‹eiâ‰¥(1âˆ’hj)â€‹ej(1-h\_{i})e\_{i}\geq(1-h\_{j})e\_{j}.

In AppendixÂ [C](https://arxiv.org/html/2512.01112v1#A3 "Appendix C Theoretical Properties of Capped Pro-Rata â€£ Autodeleveraging: Impossibilities and Optimization"), we formalize the following result:

###### Proposition 6.2 (Informal).

Under mild smoothness conditions, the unique sybil-resistant, scale-invariant, and monotone ADL policy satisfying per-account constraints is capped pro-rata.

This establishes capped pro-rata as the unique fair ordering rule.
In contrast, queue-based rules (ranking by leverage or PNL) are generally not stable or sybil-resistant.
RAP introduces a risk tilt, deviating from strict equity stability to reduce risk, but remains â€œas stable as possibleâ€ within its risk-weighted framework.
In the numerical examples we present in the next section, we will see explicit examples where capped-pro rata is better for both exchange solvency and trader profitability than the PNL-leverage ranking and pure pro-rata.

## 7 Risk-aware Policies (RAP)

Fairness-focused rules like capped pro-rata treat all winning dollars equally, ignoring the heterogeneous risks imposed by different winners.
Higher effective leverage implies thinner liquidation windows and greater sensitivity to execution costsÂ [AlmgrenChriss2001, Gatheral2010].
We introduce *Risk-Aware Pro-Rata* (RAP), a family of rules that preserves the fairness structure of capped pro-rata while tilting haircuts toward higher-risk positions.
This family includes Levered Pro-Rata (LPR) when the risk weighting is linear in leverage.
We derive RAP from a robustness criterion that minimizes a one-step excess-deficit proxy.

##### One-step Next Deficit.

To formalize robustness, we consider the *next-step deficit* DT+1nextD^{\text{next}}\_{T+1} resulting from a price shock ZTZ\_{T} occurring immediately after the ADL procedure.
Let Ï€\pi be an ADL policy yielding post-haircut notional n~T,i\tilde{n}\_{T,i} and equity eT,ie\_{T,i}.
We model the shock ZTZ\_{T} using a Markov kernel sensitive to the state.
The next-step deficit is the negative equity after the shock:

|  |  |  |
| --- | --- | --- |
|  | DT+1next=âˆ‘iâˆˆğ’²T(âˆ’eT,iâˆ’n~T,iâ€‹ZT,i)+=âˆ‘iâˆˆğ’²Tn~T,iâ€‹(1Î»T,i+ZT,i)âˆ’.D^{\text{next}}\_{T+1}=\sum\_{i\in\mathcal{W}\_{T}}(-e\_{T,i}-\tilde{n}\_{T,i}Z\_{T,i})\_{+}=\sum\_{i\in\mathcal{W}\_{T}}\tilde{n}\_{T,i}\left(\frac{1}{\lambda\_{T,i}}+Z\_{T,i}\right)\_{-}. |  |

Our objective is to minimize the conditional expected deficit Î´T=ğ„[DT+1nextâˆ£â„±T]\delta\_{T}=\mathop{\bf E{}}[D^{\text{next}}\_{T+1}\mid\mathcal{F}\_{T}].
Defining Ïˆiâ€‹(u)=ğ„[(u+ZT,i)âˆ’]\psi\_{i}(u)=\mathop{\bf E{}}[(u+Z\_{T,i})\_{-}], we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î´T=âˆ‘iâˆˆğ’²Tn~T,iâ€‹Ïˆiâ€‹(1Î»T,i).\delta\_{T}=\sum\_{i\in\mathcal{W}\_{T}}\tilde{n}\_{T,i}\psi\_{i}\left(\frac{1}{\lambda\_{T,i}}\right). |  | (32) |

AppendixÂ [E.1](https://arxiv.org/html/2512.01112v1#A5.SS1 "E.1 Examples of Risk-Aware Pro-Rata (RAP) and Next Deficit â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") illustrates how pro-rata fails to control this deficit when shocks scale with leverage.

##### Risk Models.

We assume the exchange employs a convex risk model gâ€‹(Î»)g(\lambda) characterizing the risk contribution of leverage Î»\lambda.
Common choices include:

1. 1.

   *Linear*: gâ€‹(Î»)=Î»g(\lambda)=\lambda, corresponding to LPR. Matches VaR/CVaR scaling under linear shocks.
2. 2.

   *Power*: gâ€‹(Î»)=Î»cg(\lambda)=\lambda^{c} (c>1c>1), penalizing high leverage super-linearly.
3. 3.

   *CVaR*: gâ€‹(Î»)=(Î»âˆ’Ï„)+g(\lambda)=(\lambda-\tau)\_{+}, a surrogate for Conditional Value-at-Risk.

AppendixÂ [E.1](https://arxiv.org/html/2512.01112v1#A5.SS1 "E.1 Examples of Risk-Aware Pro-Rata (RAP) and Next Deficit â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") provides numerical examples of these weightings.

### 7.1 Risk-Aware Pro-Rata (RAP) Rule

The RAP rule allocates haircuts using weights wi=Î»T,iâ€‹gâ€‹(Î»T,i)w\_{i}=\lambda\_{T,i}g(\lambda\_{T,i}).
With per-account caps Î²i\beta\_{i}, the haircuts are:

|  |  |  |  |
| --- | --- | --- | --- |
|  | hRAPâ€‹(g),i=minâ¡{Î²i,Ï„â€‹wi},h\_{\mathrm{RAP}(g),i}=\min\{\beta\_{i},\tau w\_{i}\}, |  | (33) |

where Ï„\tau is calibrated to meet the target budget.
This concentrates haircuts on high-risk positions.
See AppendixÂ [D](https://arxiv.org/html/2512.01112v1#A4 "Appendix D Algorithms for Pro-Rata Haircut Rules â€£ Autodeleveraging: Impossibilities and Optimization") for precise implementation of the algorithm.

### 7.2 Convex Dominance of RAP

We can construct an optimal risk model gâˆ—g^{\*} that minimizes Î´T\delta\_{T}.
Intuitively, an optimal risk model should maximize the marginal reduction of Î´T\delta\_{T} per unit of equity eT,ie\_{T,i}.
Differentiating Î´T\delta\_{T} with respect to the haircut hT,ih\_{T,i} reveals:

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ’âˆ‚Î´Tâ€‹(h)âˆ‚hT,i=nT,iâ€‹Ïˆiâ€‹(1Î»T,i)=eT,iâ€‹Î»T,iâ€‹Ïˆiâ€‹(1Î»T,i)=eT,iâ€‹Ïiâ€‹(Î»T,i),-\frac{\partial\,\delta\_{T}(h)}{\partial h\_{T,i}}\ =\ n\_{T,i}\,\psi\_{i}\!\left(\tfrac{1}{\lambda\_{T,i}}\right)\ =\ e\_{T,i}\,\lambda\_{T,i}\,\psi\_{i}\!\left(\tfrac{1}{\lambda\_{T,i}}\right)\ =\ e\_{T,i}\,\rho\_{i}(\lambda\_{T,i}), |  | (34) |

where we define the *perspective transform* Ïiâ€‹(Î»)=Î»â€‹Ïˆiâ€‹(1/Î»)\rho\_{i}(\lambda)=\lambda\,\psi\_{i}(1/\lambda).
The greedy rule that maximizes the marginal reduction per equity-dollar is exactly the rule that prioritizes winners with the largest Ïiâ€‹(Î»T,i)\rho\_{i}(\lambda\_{T,i}).

##### Perspective Transform and Economic Intuition.

The function Ïi\rho\_{i} is the perspective transform of the convex function Ïˆi\psi\_{i} [BoydVandenberghe2004, Â§2.3.3], widely used to induce 1-homogeneity.
Economically, u=1/Î»u=1/\lambda is the bankruptcy buffer, which is the percentage price shock required to wipe out the positionâ€™s equity (since loss equals equity when shock magnitude Z=e/n~=1/Î»Z=e/\tilde{n}=1/\lambda).
Using convex duality, we can write Ïiâ€‹(Î»)=supyâ‰¥0{yâˆ’Î»â€‹Ïˆiâˆ—â€‹(y)}\rho\_{i}(\lambda)=\sup\_{y\geq 0}\{y-\lambda\,\psi\_{i}^{\*}(y)\}, where yy is a â€˜yieldâ€™ (equity change per unit buffer change) and Ïˆiâˆ—â€‹(y)\psi\_{i}^{\*}(y) is the cost to insure a position with yield yy.
Thus, maximizing Ïi\rho\_{i} is equivalent to maximizing the net solvency gain per unit of equity.
For example, if a trader with leverage Î»=10\lambda=10 faces an insurance cost of 0.5% for a yield of 8%, the net solvency gain is 0.08âˆ’10â€‹(0.005)=0.030.08-10(0.005)=0.03 per unit equity.

##### Constructing the optimal risk model.

This suggests the optimal weights wiâ‹†=Ïiâ€‹(Î»T,i)w^{\star}\_{i}=\rho\_{i}(\lambda\_{T,i}) and risk model gâ‹†â€‹(Î»)=Ïâ€‹(Î»)/Î»g^{\star}(\lambda)=\rho(\lambda)/\lambda.

###### Proposition 7.1 (Informal).

For any weighted pro-rata rule comonotone with wâ‹†w^{\star}, the residual risk vector is weakly submajorized by that of RAPâ€‹(gâ‹†)\mathrm{RAP}(g^{\star}).
This implies that RAPâ€‹(gâ‹†)\mathrm{RAP}(g^{\star}) minimizes the total risk for any convex risk measure, assuming the shock process follows the kernel KK.

The proof is in AppendixÂ [E.2](https://arxiv.org/html/2512.01112v1#A5.SS2 "E.2 RAP Optimality and Convex Dominance â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization").
This result implies that if we have prior knowledge about the kernel KK (e.g., from historical data or backtesting), then constructing gâˆ—g^{\*} via the perspective transform yields the optimally robust and fair haircut model.

### 7.3 Limitations of One-Step Optimality

While RAP minimizes the one-step next deficit, it may not be optimal under multiple correlated shocks or broader exchange objectives.

##### Correlated Shocks.

Consider sequential shocks Zt+1,Zt+2Z\_{t+1},Z\_{t+2} with positive correlation.
High-leverage positions might act as a hedge against future shocks.
In such cases, aggressively liquidating high-leverage winners (as in RAP) can increase the two-step deficit compared to pro-rata.
AppendixÂ [E.1](https://arxiv.org/html/2512.01112v1#A5.SS1 "E.1 Examples of Risk-Aware Pro-Rata (RAP) and Next Deficit â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") details an AR(1) shock example where the sum of deficits is lower for pro-rata.

##### Exchange Incentive Compatibility.

Exchanges must also consider *exchange longâ€“term value (LTV)*â€”the future fees and liquidity provided by traders.
RAP targets high-leverage, often high-volume, traders.
Fully liquidating these accounts to minimize immediate risk can reduce the exchangeâ€™s long-term utility.
AppendixÂ [E.3](https://arxiv.org/html/2512.01112v1#A5.SS3 "E.3 Example of the Solvency vs. Long-Term Revenue Trade-Off â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization") provides an example where preserving a high-value trader (via pro-rata) yields higher total utility than the risk-minimizing RAP.

## 8 Multipleâ€“Round ADL as a Stackelberg Control Problem

As the previous section illustrates, risk-aware pro-rata mechanisms work well as robust, static strategies but not in a dynamic setting.
Both exchange future revenue and correlated shocks require including a model of the dynamics of ADL over multiple rounds.
We use the intuition gained from RAP mechanisms for a single round to help extend the model to the multiple round setting.
A common place where there is a difference between one-shot equilibria and multi-round equilibria is in the difference between Nash and Stackelberg games.
We will illustrate how the multi-round ADL problem is naturally a Stackelberg game whereas the ADL policies that we have studied so far are more like Nash optimal strategies.
To do this, we will first briefly describe Stackelberg games and then provide examples demonstrating that it is the right formalism for this extension.

### 8.1 ADL is a Stackelberg Game

##### Definition.

A Stackelberg (leaderâ€“follower) game is a sequential game where the leader first *commits* to a strategy or policy, the follower observes this commitment, and then bestâ€“responds; the leader chooses its commitment anticipating this responseÂ [Stackelberg1934, FudenbergTirole1991, BasarOlsder1999].111111In the finance and control literature, this setup is often framed as â€œDynamic Optimal Control with Rational Expectationsâ€ or a principal-agent problem with commitmentÂ [Puterman1994, Bertsekas2017, LaffontMartimort2002].
The defining features are (i) observable commitment, (ii) sequential move order, and (iii) the leaderâ€™s optimization against the followerâ€™s bestâ€“response correspondence.
In repeated or multiâ€“round settings, the leader can *learn* a nearâ€“optimal commitment by updating its policy from round to round using feedback from realized follower responses and shocks; this supports standard online learning guarantees when losses are convex (or admit convex surrogates)Â [Zinkevich2003, ShalevShwartz2012, Hazan2019], and, under additional regularity, learnability results specific to Stackelberg games [conitzer2006].

##### ADL and Stackelberg games.

ADL naturally fits the setup of a Stackelberg game: the exchange (leader) *publishes* its ADL policy each round by choosing a severity budget Î¸tâˆˆ[0,1]\theta\_{t}\in[0,1] and a haircut rule.
As we saw inÂ Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"), the queueing rules used by Binance and Hyperliquid imply both a static severity and haircut rule and are published on their websites (which is their form of commitment).
Market participants (e.g.Â traders, LPs) and the stochastic environment (order flow, depth, liquidation behavior, oracle and price shocks) then respond as followers given the announced policy.
After market participants (followers) respond, the residual exposure (i.e.,Â the remaining negative equity) is measured and the leader decides on a next action (which could include to stop the game and not perform an ADL policy).
The commitment of the exchange allows followers to construct a *local* best response that can adapt as the number of rounds of the game increases.

##### Credibility and Time Inconsistency.

Crucially, the Stackelberg formulation assumes the leader can credibly commit to a policy path.
In decentralized venues (e.g., Hyperliquid), this is enforced via on-chain code or DAO governance, making the commitment verifiable.
In centralized venues (e.g., Binance), the commitment is reputational.
Without commitment, the game reverts to a Nash setting where the exchange suffers from *time inconsistency*: ex-ante, it prefers a â€œgentleâ€ policy to attract liquidity, but ex-post (once a deficit DtD\_{t} materializes), it has a dominant incentive to defect to maximal severity (Queue ADL) to minimize immediate insolvency risk.
This temptation to defect undermines liquidity provision unless the commitment is binding, further justifying the Stackelberg framework over pure control theory.

##### Stackelberg vs. Nash.

Nash equilibria are oneâ€“shot, *simultaneousâ€“move* fixed points where each player bestâ€“responds to the otherâ€™s action but no one commits *ex ante*Â [FudenbergTirole1991].
By contrast, Stackelberg equilibria embed the leaderâ€™s commitment advantage, often producing different (and more robust or revenueâ€“enhancing) outcomes [Stackelberg1934, BasarOlsder1999].
Static ADL strategies such as venue queues (Binance/Hyperliquid) or singleâ€“round RAP can be analyzed under a Nash lens, as we assume there is no further response by a leader after a single execution of an ADL policy.
In practice, ADL controllers are used repeatedly (such as on October 10, 2025; seeÂ Â§[9](https://arxiv.org/html/2512.01112v1#S9 "9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization")) which more resembles a Stackelberg game.
In AppendixÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.SS3 "F.3 Stackelberg vs. Nash in a Two-Round ADL Game â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") we give an explicit example for ADL where a Stackelberg equilibrium differs from a Nash outcome and in which the Stackelberg equilibrium strictly improves exchange revenue and robustness.

##### Robustness and Learnability of Stackelberg games.

Robust Stackelberg models capture the leaderâ€™s desire to hedge against uncertainty hidden in the followerâ€™s strategy by optimizing for *worstâ€“case* responsesÂ [aghassi2006].
In ADL, robustness corresponds to resilience against adverse price/oracle shocks, liquidity droughts, and fundingâ€“rate shocks.
Specifically, the exchange chooses a policy that anticipates such perturbations and steers the system toward states with smaller tail externalities (analogous to Stackelberg Security GamesÂ [Tambe2011, conitzer2006]).

When the leaderâ€™s per round objective function is convex in its policy (or admits convex surrogates) and constraints are convex, standard online methods (mirror descent, FTRL) achieve sublinear regret and convergence to nearâ€“optimal commitmentsÂ [Zinkevich2003, ShalevShwartz2012, Hazan2019].
Recent work studies gradientâ€“based learning in Stackelberg games directly, providing conditions under which leader updates converge to Stackelberg equilibria, including bandit/noisy feedback regimes.
These tools align well with ADLâ€™s multiâ€“round nature and with the RAP geometry used for choosing haircuts.

### 8.2 Why do we need a dynamic model?

Stackelberg games are inherently dynamic due to the alternating move order between the leader and follower.
A natural question is whether we really need to use a dynamic method or if a static method is â€˜good enough.â€™
In this section, we will provide our first formal results showing that dynamic ADL rules are necessary if you want to optimize both time to recover solvency and exchange revenue after repeated shocks.
This will motivate the construction of the dynamic ADL policy in the sequel.

##### Exchange Long-Term Value (LTV) and the Trilemma.

Recall the ADL Trilemma from Â§[2.5](https://arxiv.org/html/2512.01112v1#S2.SS5 "2.5 ADL Trilemma â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"), which posits a conflict between Solvency (S), Fairness (F), and Revenue (R).
To quantify the *Revenue* objective, we define the *Exchange Long-Term Value* (LTV).
Unlike immediate fee capture, LTV accounts for the long-run impact of ADL on trader participation: heavy haircuts on winners cause them to exit or reduce activity (â€œchurnâ€), eroding future fees.

For a policy Ï€\pi, let ht,iâˆˆ[0,1]h\_{t,i}\in[0,1] be the haircut fraction on winner ii at time tt.
We model trader retention via a revenue retention curve rt,iâ€‹(ht,i)r\_{t,i}(h\_{t,i}) which is decreasing in the haircut size (larger haircuts drive away more volume).
The per-period expected revenue from trader ii is then Rt,i=et,iâ€‹rt,iâ€‹(ht,i)R\_{t,i}=e\_{t,i}r\_{t,i}(h\_{t,i}), where et,ie\_{t,i} is their equity.
The LTV is the discounted sum of these revenues:

|  |  |  |
| --- | --- | --- |
|  | LTVTâ€‹(Ï€)=âˆ‘t=0TÎ²tâ€‹âˆ‘iâˆˆWtet,iâ€‹rt,iâ€‹(ht,i).\mathrm{LTV}\_{T}(\pi)=\sum\_{t=0}^{T}\beta^{t}\sum\_{i\in W\_{t}}e\_{t,i}\,r\_{t,i}(h\_{t,i}). |  |

Maximizing LTV corresponds directly to the *(R)* vertex of the trilemma.

##### Competing Time Scales.

To compare policies dynamically, we track two opposing clocks starting from a default event at Ï„def\tau\_{\mathrm{def}}:

* â€¢

  *Solvency Recovery Time* (Ï„solv\tau\_{\mathrm{solv}}): The time required for the insurance fund (or deficit) to fully recover to a safe level Î´\delta.
* â€¢

  *Revenue Recovery Time* (Ï„rev\tau\_{\mathrm{rev}}): The time required for the exchangeâ€™s expected LTV to return to pre-shock levels (1âˆ’Ïµ)â€‹LTVpre(1-\epsilon)\mathrm{LTV}\_{\text{pre}}.

Intuitively, Ï„solv\tau\_{\mathrm{solv}} measures how fast the â€œhole is plugged,â€ while Ï„rev\tau\_{\mathrm{rev}} measures how fast the â€œbusiness recovers.â€
Static policies face a fundamental trade-off between these times, governed by the concentration of haircuts.

##### Example.

We can rigorously rank policies using the Schur-convex (majorization) order from Â§[3](https://arxiv.org/html/2512.01112v1#S3 "3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization").
Consider two canonical policies:

* â€¢

  *Queue ADL (Concentrated):* This policy fully haircuts the largest winner until the deficit is covered. It is extremely Schur-convex (unequal).
  By targeting the deepest pocket, it clears the deficit with the minimal total haircut volume, minimizing Ï„solv\tau\_{\mathrm{solv}}.
  However, it destroys the highest-value traders (the â€œwhalesâ€), causing a massive drop in LTV and maximizing Ï„rev\tau\_{\mathrm{rev}}.
* â€¢

  *Pro-Rata ADL (Diffused):* This policy spreads the haircut proportionally across all winners. It is Schur-concave (equal).
  It preserves the whales but requires a larger total haircut volume to clear the same deficit (due to many small accounts having insufficient equity), effectively delaying Ï„solv\tau\_{\mathrm{solv}}.
  However, because the per-trader impact is small, churn is low, and Ï„rev\tau\_{\mathrm{rev}} is minimized.

This intuition is formalized in the following proposition, which states that any policy that concentrates haircuts (like Queue) will recover solvency faster but revenue slower than a diffuse policy (like Pro-Rata).

##### Opposing Schur orderings.

Let ztâ€‹(Ï€)z\_{t}(\pi) be the vector of post-haircut residual equities.
If policy AA is more concentrated than policy BB (i.e., ztâ€‹(A)â‰»Schurztâ€‹(B)z\_{t}(A)\succ\_{\text{Schur}}z\_{t}(B)), then AA recovers solvency faster but revenue slower.

###### Proposition 8.1 (Informal).

Under separable convex stage losses and monotone shock dynamics, if the residual exposure of policy AA majorizes policy BB (e.g., Queue vs. Pro-Rata), then:

|  |  |  |
| --- | --- | --- |
|  | Ï„solvâ€‹(A)â‰¤Ï„solvâ€‹(B)butLTVtâ€‹(A)â‰¤LTVtâ€‹(B)for allÂ â€‹t.\tau\_{\mathrm{solv}}(A)\leq\tau\_{\mathrm{solv}}(B)\quad\text{but}\quad\mathrm{LTV}\_{t}(A)\leq\mathrm{LTV}\_{t}(B)\quad\text{for all }t. |  |

This implies no static policy can simultaneously minimize both recovery times.

##### Endogenous Price Feedback.

Static models typically treat the deficit DtD\_{t} as exogenous.
In reality, large ADL events create *endogenous* feedback: the act of closing positions (even if socialized among winners) reduces open interest and can signal distress, causing market makers to widen spreads or withdraw bids.
This secondary liquidity shock can drive mark prices further against the exchange, increasing Dt+1D\_{t+1}.
Dynamic policies like Ï€md\pi\_{\text{md}} (Â§[8.5](https://arxiv.org/html/2512.01112v1#S8.SS5 "8.5 Learning the Optimal ADL Policy â€£ 8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization")) naturally handle this by treating the environment as adversarial (or responsive), whereas static policies risk under-estimating the â€œdeath spiralâ€ effect of the ADL action itself.

### 8.3 Incentive Compatibility and Constraints

We frame the problem as a Stackelberg game: the exchange (leader) commits to a policy, and traders (followers) best-respond.
*Follower Incentive Compatibility* requires tradersâ€™ actionsâ€”liquidity provision and liquidationsâ€”to satisfy feasibility and non-bankruptcy conditions given this commitment.
The exchangeâ€™s policy is subject to *Revenue Constraints* (ensuring profitability via fees and net liquidation revenues) and *Solvency Constraints* (bounding tail risk via coherent measures like ES or CVaRÂ [RockafellarUryasev2002, BCBS2019FRTB]).
These constraints define the feasible region for the loss minimization problem.

### 8.4 ADL Constraints and Objective

##### Composite Loss Function.

We formulate the ADL control problem as minimizing a composite loss function that explicitly balances exchange revenue, solvency, and fairness.
Let Ï€t=(Î¸t,ht)\pi\_{t}=(\theta\_{t},h\_{t}) denote the ADL policy at round tt, where Î¸tâˆˆ[0,1]\theta\_{t}\in[0,1] is the severity (fraction of deficit socialized) and htâˆˆ[0,1]nh\_{t}\in[0,1]^{n} parameterizes the inner allocation rule (e.g., weights for RAP or Pro-Rata).
Based on our empirical framework, the per-round loss â„“tâ€‹(Ï€t)\ell\_{t}(\pi\_{t}) is defined as:

|  |  |  |
| --- | --- | --- |
|  | â„“tâ€‹(Ï€t)=Î»revâ‹…â„’trevâ€‹(Ï€t)+Î»solvâ‹…â„’tsolvâ€‹(Ï€t)+Î»fairâ‹…â„’tfairâ€‹(Ï€t),\ell\_{t}(\pi\_{t})\;=\;\lambda\_{\text{rev}}\cdot\mathcal{L}^{\text{rev}}\_{t}(\pi\_{t})\;+\;\lambda\_{\text{solv}}\cdot\mathcal{L}^{\text{solv}}\_{t}(\pi\_{t})\;+\;\lambda\_{\text{fair}}\cdot\mathcal{L}^{\text{fair}}\_{t}(\pi\_{t}), |  |

where the components are:

* â€¢

  *Revenue Loss (â„’*rev*\mathcal{L}^{\text{rev}}):* The discounted stream of future fees lost due to liquidating positions. This incentivizes the exchange to preserve valuable, high-volume users when possible.
* â€¢

  *Solvency Cost (â„’*solv*\mathcal{L}^{\text{solv}}):* A penalty on the *residual deficit* (the portion of the loss DtD\_{t} not covered by the ADL recovery) and *overshoot* (excessive liquidation beyond what is needed). This ensures the mechanism actually restores system health without unnecessary destruction.
* â€¢

  *Fairness Cost (â„’*fair*\mathcal{L}^{\text{fair}}):* Penalties based on the Profit-to-Solvency Ratio (PTSR) and Profit-Margin Ratio (PMR). These terms enforce that the burden of ADL is distributed equitably relative to tradersâ€™ profitability and risk contribution, preventing the â€œdeath spiralâ€ of adverse selection.

##### Stackelberg vs. Nash Equilibria.

We model the interaction between the exchange and traders as a Stackelberg game where the exchange (leader) commits to a policy Ï€t\pi\_{t}, and traders (followers) subsequently respond (e.g., by adjusting liquidity or closing positions).
This commitment power is crucial.
As we show in AppendixÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.SS3 "F.3 Stackelberg vs. Nash in a Two-Round ADL Game â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") (PropositionÂ [F.6](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem6 "Proposition F.6 (Stackelberg Dominance). â€£ Simultaneous play (Nash). â€£ F.3 Stackelberg vs. Nash in a Two-Round ADL Game â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")), a simultaneous-move (Nash) game admits a â€œbadâ€ equilibrium where traders withdraw liquidity anticipating high severity, which in turn forces the exchange to set high severity to cover the deficit.
In the Stackelberg model, the exchange can commit to a policy that eliminates this inefficient equilibrium, coordinating the market towards a high-liquidity, lower-severity outcome that improves welfare for all participants.

### 8.5 Learning the Optimal ADL Policy

##### Mirror Descent with IC constraints (MDIC).

We adopt a primalâ€“dual mirrorâ€“descent scheme tailored to the RAP geometry and nonâ€“smooth constraints:

1. 1.

   Choose a mirror map Ïˆ\psi on the policy domain Î \Pi (e.g., a separable entropy or a Bregman geometry aligned with capped proâ€“rata).
2. 2.

   Initialize Ï€1âˆˆÎ \pi\_{1}\in\Pi and dual multipliers Î»1â‰¥0\lambda\_{1}\!\geq 0 for constraints câ€‹(â‹…;â‹…)â‰¤0c(\cdot;\cdot)\leq 0.
3. 3.

   For rounds t=1,2,â€¦t=1,2,\dots:

   1. (a)

      Observe state sts\_{t}; publish Ï€t\pi\_{t} (commitment). The follower/environment bestâ€“responds; incur loss â„“tâ€‹(Ï€t)\ell\_{t}(\pi\_{t}) and observe a subgradient gtâˆˆâˆ‚â„“tâ€‹(Ï€t)g\_{t}\in\partial\ell\_{t}(\pi\_{t}) and constraint feedback ct=câ€‹(Ï€t;st)c\_{t}=c(\pi\_{t};s\_{t}).
   2. (b)

      Primal update (mirror step with penalties):

      |  |  |  |
      | --- | --- | --- |
      |  | Ï€t+1=argminÏ€âˆˆÎ {âŸ¨gt+âˆ‡Ï€âŸ¨Î»t,câ€‹(Ï€;st)âŸ©,Ï€âŸ©+1Î·tâ€‹DÏˆâ€‹(Ï€âˆ¥Ï€t)}.\pi\_{t+1}\;=\;\mathop{\rm argmin}\_{\pi\in\Pi}\;\Big\{\langle g\_{t}+\nabla\_{\pi}\langle\lambda\_{t},c(\pi;s\_{t})\rangle,\,\pi\rangle\;+\;\tfrac{1}{\eta\_{t}}D\_{\psi}(\pi\,\|\,\pi\_{t})\Big\}. |  |
   3. (c)

      Dual update (projected subgradient ascent on violations):

      |  |  |  |
      | --- | --- | --- |
      |  | Î»t+1=[Î»t+Î³tâ€‹ct]+.\lambda\_{t+1}\;=\;\big[\lambda\_{t}+\gamma\_{t}\,c\_{t}\big]\_{+}. |  |
4. 4.

   Tune (Î·t,Î³t)(\eta\_{t},\gamma\_{t}) as Oâ€‹(tâˆ’1/2)O(t^{-1/2}) to balance regret and constraint violations.

This controller reduces to standard OCO when constraints are absent, while handling nonâ€“smooth IC/solvency constraints via the dual iterates.

##### Why MDIC vs. Online Convex Optimization.

All constraints in ğ’tIC\mathcal{C}\_{t}^{\mathrm{IC}} are convex but can be non-smooth (e.g.Â hinge losses, maximizing over scenarios).
Mirror descent handles this composite structure while matching the geometry: KL geometry on the simplex reduces diameter to Oâ€‹(logâ¡|Wt|)O(\log|W\_{t}|); the log-barrier keeps Î¸\theta interior and gives stable 1-D projections.
This improves constants relative to Euclidean OGD while preserving the same rate.

##### Algorithmic Guarantees.

Assume ftf\_{t} is â„“\ell-Lipschitz in the dual norms of (Ï•,Î¦)(\phi,\Phi), the follower is an
Îµ\varepsilon-best responder, and ğ’tIC\mathcal{C}\_{t}^{\mathrm{IC}} is nonempty with bounded diameter in the same
norms. Then MDIC with Î·tâˆ1/T\eta\_{t}\propto 1/\sqrt{T} achieves

|  |  |  |
| --- | --- | --- |
|  | RegretT=Oâ€‹(Tâ€‹DÏ•â€‹(Î¸â‹†âˆ¥Î¸1)+Tâ€‹DÎ¦â€‹(hâ‹†âˆ¥h1))+Îµâ€‹T,\mathrm{Regret}\_{T}\;=\;O\!\Big(\sqrt{T\,D\_{\phi}(\theta^{\star}\|\theta\_{1})}+\sqrt{T\,D\_{\Phi}(h^{\star}\|h\_{1})}\Big)\;+\;\varepsilon T, |  |

and enforces the IC rows per round (or, in a primalâ€“dual variant with long-term ES, sublinear average
violation). A full theorem and proof (via the standard MD telescoping bound plus feasibility of the
Bregman projection) appear in AppendixÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.SS2 "F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization"); see also TheoremÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem2 "Theorem F.2 (OMD Regret). â€£ Master Mirror Descent Bound. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") for the unconstrained MD bound.
Under these convexity, Lipschitz, and feasibility assumptions, MDIC attains Oâ€‹(T)O(\sqrt{T}) regret and sublinear average IC/solvency violations, whereas any static policy incurs Î©â€‹(T)\Omega(T) regret on an alternating environment (see AppendixÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.SS2 "F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") for details).

##### Linear Regret for Static Strategies.

Consider a simplified environment that alternates between two regimes: AA (liquidity) and BB (stress). We fix a maximum severity cap Î¸Â¯\bar{\theta} (e.g., Î¸Â¯=0.30\bar{\theta}=0.30).
The per-round loss function ftâ€‹(Î¸)f\_{t}(\theta) captures the trade-off between revenue and solvency:

|  |  |  |
| --- | --- | --- |
|  | ftâ€‹(Î¸)={Î¸ifÂ â€‹tâˆˆAâ€‹Â (minimize severity to protect revenue),Î¸Â¯âˆ’Î¸ifÂ â€‹tâˆˆBâ€‹Â (maximize severity to ensure solvency).f\_{t}(\theta)=\begin{cases}\theta&\text{if }t\in A\text{ (minimize severity to protect revenue)},\\ \bar{\theta}-\theta&\text{if }t\in B\text{ (maximize severity to ensure solvency)}.\end{cases} |  |

The optimal static policy must choose a fixed Î¸âˆˆ[0,Î¸Â¯]\theta\in[0,\bar{\theta}]. However, any fixed Î¸\theta incurs linear regret:

|  |  |  |
| --- | --- | --- |
|  | âˆ‘t=1T(ftâ€‹(Î¸)âˆ’ftâ€‹(Î¸tâ‹†))=T2â€‹Î¸+T2â€‹(Î¸Â¯âˆ’Î¸)=T2â€‹Î¸Â¯=Î©â€‹(T).\sum\_{t=1}^{T}(f\_{t}(\theta)-f\_{t}(\theta^{\star}\_{t}))=\frac{T}{2}\theta+\frac{T}{2}(\bar{\theta}-\theta)=\frac{T}{2}\bar{\theta}=\Omega(T). |  |

In contrast, MDIC adapts Î¸t\theta\_{t} online. Using a standard mirror descent bound (TheoremÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem2 "Theorem F.2 (OMD Regret). â€£ Master Mirror Descent Bound. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")), MDIC achieves

|  |  |  |
| --- | --- | --- |
|  | ğ–±ğ–¾ğ—€ğ—‹ğ–¾ğ—T=Oâ€‹(Î¸Â¯â€‹T).\mathsf{Regret}\_{T}=O(\bar{\theta}\sqrt{T}). |  |

Numerically, for T=104T=10^{4} and Î¸Â¯=0.30\bar{\theta}=0.30, a static policy suffers regret â‰ˆ1500\approx 1500, while MDIC suffers â‰ˆ30\approx 30.

### 8.6 Follower Robustness

So far, we have focused on the leader (e.g.Â the exchange), as they have to commit to a policy.
However, it is possible that if the follower (i.e.,Â a trader who reduces the deficit) knows enough about the leaderâ€™s strategy to adversely select against other traders.
We address the strategic behavior of traders (â€œfollowersâ€) in response to ADL policies, focusing on adverse selection and timing games that naturally occur.
Our coverage of this will be minimal with most details in AppendixÂ [F.4](https://arxiv.org/html/2512.01112v1#A6.SS4 "F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization").

##### Adverse Selection and the Pro-Rata Death Spiral.

If an ADL policy socializes losses uniformly (like Pro-Rata), low-risk traders subsidize high-risk traders.
If this subsidy exceeds the utility of trading, low-risk traders exit, increasing both the exchangeâ€™s average risk and probability of future deficits.
This is a direct consequence of the followerâ€™s strategic response: low-risk traders, observing a policy that penalizes them disproportionately, rationally choose to exit (or not participate), leaving the exchange with a riskier pool of traders.

Formally, a participation constraint Î¼iâˆ’ğ„[HÏ€â€‹(Î»i,ğ’«n)]â‰¥u0\mu\_{i}-\mathop{\bf E{}}[H\_{\pi}(\lambda\_{i},\mathcal{P}\_{n})]\geq u\_{0} must hold.
Here Î¼i\mu\_{i} denotes trader iiâ€™s baseline per-round utility in the absence of ADL haircuts, HÏ€â€‹(Î»i,ğ’«n)H\_{\pi}(\lambda\_{i},\mathcal{P}\_{n}) is the random haircut mass assigned to a type-ii winner with leverage Î»i\lambda\_{i} under policy Ï€\pi when the market state is ğ’«n\mathcal{P}\_{n}, and u0u\_{0} is the reservation utility defined in AppendixÂ [F.4.1](https://arxiv.org/html/2512.01112v1#A6.SS4.SSS1 "F.4.1 Adverse Selection Under Pro-Rata â€£ F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization").
Under Pro-Rata, ğ„[HÏ€Pâ€‹R]\mathop{\bf E{}}[H\_{\pi\_{PR}}] depends on average leverage, which penalizes low-risk traders and potentially causes a â€œdeath spiralâ€ of exits.
This â€œdeath spiralâ€ refers to the adverse selection that the exchange faces as the pool of traders becomes increasingly risky from a leverage standpoint.

In contrast, RAPâ€™s haircut is proportional to risk weight Î»iâ€‹gâ€‹(Î»i)\lambda\_{i}g(\lambda\_{i}), minimizing the burden on low-risk traders and stabilizing the pool.
AppendixÂ [F.4.1](https://arxiv.org/html/2512.01112v1#A6.SS4.SSS1 "F.4.1 Adverse Selection Under Pro-Rata â€£ F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")Â formalizes this participation test and provides explicit death-spiral examples.

##### The Waiting Game.

Traders may act as â€œBackstop Liquidity Providersâ€ (BLP) by voluntarily filling liquidation orders to reduce the deficit DtD\_{t}.
For instance, traders who deposit to Hyperliquidâ€™s HLP pool around the time of an ADL event do this.
This presents an optimal stopping problem: a BLP can absorb the deficit immediately (incurring market risk and execution costs) or wait, hoping that the exchange reduces ADL severity Î¸t\theta\_{t} (and thus the potential haircut) in subsequent rounds.
If the exchange employs a policy like exponential backoff that lowers severity over time, it incentivizes traders to wait, potentially exacerbating the deficit.

To prevent such strategic delays, the exchange must satisfy a â€œNo-Waitâ€ constraint: Î¸tâ€‹Dtâ‰¥Î“t\theta\_{t}D\_{t}\geq\Gamma\_{t}, where Î“t\Gamma\_{t} is the liquidity premium.
Intuitively, Î“t\Gamma\_{t} quantifies the cost of immediate intervention, capturing the execution slippage and inventory risk premium required for a BLP to step in.
By adjusting incentives that are paid to BLPs, an exchange can incentivize â€œno-waitâ€ conditions and lower the overall time to recover solvency.
We formalize this with the following proposition:

###### Proposition 8.2 (No-Wait Condition).

Let Î“t\Gamma\_{t} be the liquidity premium required for a Backstop Liquidity Provider (BLP) to absorb deficit DtD\_{t} immediately rather than waiting for Î”â€‹t\Delta t.
If the severity policy Î¸t\theta\_{t} is a decreasing function of time (e.g., exponential backoff), a BLP will withhold liquidity unless the immediate haircut cost is cheaper than the discounted future cost:

|  |  |  |
| --- | --- | --- |
|  | Î¸tâ€‹Dtâ‰¤ğ„t[Î¸t+Î”â€‹tâ€‹Dt+Î”â€‹t]âˆ’Î“t.\theta\_{t}D\_{t}\;\leq\;\mathop{\bf E{}}\_{t}[\theta\_{t+\Delta t}D\_{t+\Delta t}]-\Gamma\_{t}. |  |

Violating this condition induces a â€œWaiting Gameâ€ where solvency recovery is delayed purely by the followerâ€™s strategy.

AppendixÂ [F.4.2](https://arxiv.org/html/2512.01112v1#A6.SS4.SSS2 "F.4.2 Waiting Game and MDIC-NW â€£ F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") details the construction of Î“t\Gamma\_{t} and proves this proposition.

### 8.7 Dynamic Phase Transition in ADL

In SectionÂ [5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization"), we established that static ADL rules face fundamental scaling limits.
To quantify the efficiency gap between static (Nash) and dynamic (Stackelberg) control, we evaluate the system using welfare functionals Wâ€‹(Ï€)W(\pi) corresponding to the trilemma (PropositionÂ [I.7](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem7 "Theorem I.7 (ADL Trilemma). â€£ Formal Statement of the Trilemma. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")) objectives.
We consider both a fairness welfare WFairâ€‹(Ï€)=ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Ï€)W\_{\text{Fair}}(\pi)=\mathsf{PTSR}\_{T}(\pi) and a revenue welfare WLTVâ€‹(Ï€)=LTVTâ€‹(Ï€)W\_{\text{LTV}}(\pi)=\text{LTV}\_{T}(\pi).
The severity load Îºn=Î¸nâ€‹n/bn\kappa\_{n}=\theta\_{n}n/b\_{n} serves as the order parameter for the fairness transition, while the heavy-tail index Î±\alpha (seeÂ Â§[3.1.2](https://arxiv.org/html/2512.01112v1#S3.SS1.SSS2 "3.1.2 ADL-Specific Efficiency Metrics â€£ 3.1 Risk Metrics â€£ 3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization")) governs the revenue transition.
Together, they drive a *phase transition* in the efficiency of static policies relative to dynamic ones.

##### Why PoA for Nash vs. Stackelberg?

PoA is the standard metric for quantifying efficiency loss from strategic behavior across equilibrium conceptsÂ [Roughgarden2005SelfishRouting, roughgarden15intrinsic].
In Stackelberg settings, a leaderâ€™s commitment reshapes follower best responses and can systematically lower inefficiency relative to simultaneous-move (Nash) play.
This is well documented in dynamic game modelsÂ [BasarOlsder1999] and in smoothness-based PoA analyses that extend uniformly across equilibrium notions, including sequential and composed mechanismsÂ [SyrgkanisTardos2013, roughgarden15intrinsic].
In our ADL context, the venue is a natural leader that can commit to a severity path, while traders react myopically to current and anticipated haircuts.
This makes a PoA comparison between one-shot (Nash-like) and multi-round (Stackelberg) control both natural and informative.

We define the Price of Anarchy (PoA) as the ratio of the optimal dynamic Stackelberg welfare to the welfare of a static, one-shot policy Ï€nstat\pi^{\mathrm{stat}}\_{n}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | PoAnâ€‹(W)=Wâ€‹(Ï€ndyn)Wâ€‹(Ï€nstat)\mathrm{PoA}\_{n}(W)=\frac{W(\pi^{\mathrm{dyn}}\_{n})}{W(\pi^{\mathrm{stat}}\_{n})} |  | (35) |

Using smoothness argumentsÂ [roughgarden15intrinsic] and extreme-value analysis, we obtain PoA bounds that are robust to the precise equilibrium concept. AppendixÂ [G](https://arxiv.org/html/2512.01112v1#A7 "Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization") formalizes our mean-field scaling assumptions and presents the theorem. Informally:

###### Proposition 8.3 (Informal).

Let Îºn=Î¸â€‹n/bn\kappa\_{n}=\theta n/b\_{n} be the normalized severity relative to the winner equity scale bnb\_{n}.

* â€¢

  *Bounded PoA (Static Sufficient):* If severity is EV-scaled (supÎºn<âˆ\sup\kappa\_{n}<\infty), leverage is balanced (â„“n+â‰â„“nâˆ’\ell\_{n}^{+}\asymp\ell\_{n}^{-}), and impact is smooth (Î¼OB<1\mu\_{\mathrm{OB}}<1), then static ADL is constant-factor optimal for both Fairness and Revenue: supnPoAnFair<âˆ\sup\_{n}\mathrm{PoA}^{\text{Fair}}\_{n}<\infty and supnPoAnLTV<âˆ\sup\_{n}\mathrm{PoA}^{\text{LTV}}\_{n}<\infty.
* â€¢

  *Unbounded PoA (Dynamic Necessary):* If severity is excessive (Îºnâ†’âˆ\kappa\_{n}\to\infty) or leverage is concentrated (â„“n+/â„“nâˆ’â†’0\ell\_{n}^{+}/\ell\_{n}^{-}\to 0), then static policies fail on at least one objective: maxâ¡(PoAnFair,PoAnLTV)â†’âˆ\max(\mathrm{PoA}^{\text{Fair}}\_{n},\mathrm{PoA}^{\text{LTV}}\_{n})\to\infty. Specifically, heavy tails force static policies to choose between fairness collapse (Î¸â‰ˆ1\theta\approx 1) or revenue collapse (Î´â‰ˆ1\delta\approx 1).

This implies a screening rule: if estimates satisfy Îº^nâ‰¤K\widehat{\kappa}\_{n}\leq K and Î›^nâˆˆ[c,C]\widehat{\Lambda}\_{n}\in[c,C], static ADL suffices; otherwise, dynamic control is required to navigate the Trilemma.

Practically, this result suggests that exchanges can screen assets using historical data to determine whether a simple static rule suffices or if a dynamic policy is required.
Formal statements and proofs are given by TheoremÂ [G.3](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem3 "Theorem G.3 (Fairness PoA Phase Transition). â€£ G.1.2 Phase Transition â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization")
and PropositionÂ [G.5](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem5 "Proposition G.5 (Revenue PoA Phase Transition). â€£ G.2.2 Phase Transition â€£ G.2 Revenue Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization")
in AppendixÂ [G](https://arxiv.org/html/2512.01112v1#A7 "Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization"), and by
ExampleÂ [G.4](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem4 "Example G.4 (Light-tailed Failure). â€£ G.1.2 Phase Transition â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization").

## 9 Empirical Analysis: The October 10 Event

We evaluate the proposed ADL mechanisms using a high-fidelity replay of the October 10, 2025 liquidation cascade on HyperliquidÂ [CoinDesk2025LargestLiquidations].
This event serves as a practical testbed for the theoretical phase transitions identified in SectionÂ [8.7](https://arxiv.org/html/2512.01112v1#S8.SS7 "8.7 Dynamic Phase Transition in ADL â€£ 8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization"), characterizing the performance gap between static and dynamic policies in a high-stress regime (Dtâ‰«0D\_{t}\gg 0).

### 9.1 Experimental Setup

##### Dataset.

We utilize the canonical reconstruction of the eventÂ [HyperMultiAssetedADL], covering a 12-minute window (21:16â€“21:27 UTC) with $2.1B in liquidations across 161 assets.
The replay comprises T=1108T=1108 ADL shocks (998 with Dt>0D\_{t}>0).
Each shock records the realized deficit DtD\_{t} (total negative equity of the losers) and the account-level winner capacities wtw\_{t}.
Summing DtD\_{t} across the positive-deficit shocks yields $304.5M of shortfall that must be socialized, whereas the feasible haircut mass âˆ‘iwt,i\sum\_{i}w\_{t,i} totals only $95.8M, so at least $208.6M of losses remain uncovered irrespective of policy.
These pathwise statistics match the appendix methodology and provide the baseline against which we evaluate each controller.
The dataset provides the exact sequence of exogenous price shocks and trader positions, allowing for a counterfactual analysis of ADL responses holding market conditions fixed.

##### Policies.

We compare the static benchmark Ï€queue\pi\_{\text{queue}} against the dynamic controllers defined in AppendixÂ [H.3](https://arxiv.org/html/2512.01112v1#A8.SS3 "H.3 Policies â€£ Appendix H Empirical Methodology â€£ Autodeleveraging: Impossibilities and Optimization"):

* â€¢

  *Static Priority (Ï€*queue*,Ï€*smart*\pi\_{\text{queue}},\pi\_{\text{smart}}):* The standard greedy mechanism (Queue) and its deficit-capped variant (Smart Queue). Ï€smart\pi\_{\text{smart}} enforces Htâ‰¤DtH\_{t}\leq D\_{t} but retains the greedy priority ranking.
* â€¢

  *Dynamic Severity (Ï€*exp*,Ï€*md*\pi\_{\text{exp}},\pi\_{\text{md}}):* The Exponential Backoff and Mirror Descent controllers that optimize the scalar severity Î¸t\theta\_{t} while allocating haircuts pro-rata.
* â€¢

  *Vector Optimization (Ï€*vec*\pi\_{\text{vec}}):* The full allocation policy minimizing the composite loss LtL\_{t} via high-dimensional mirror descent.

##### Revenue proxy.

We construct a *revenue proxy* that estimates the expected fee and revenue loss for the exchange given a set of ADL haircuts.
At a high level, we model how much churn traders experience post haircut, akin to other customer retention modelsÂ [Acerbi2002, Bolton1998Duration, Schmittlein1987Customers].
Given the churn, we model a fee proxy that estimate the loss in fees per unit of notional size that churns.
Formally, define the *churn probability* of winner ii as the probability that the account exits the venue after receiving a haircut in round tt.
Empirically, this quantity controls how much future revenue the exchange forfeits.
We model churn with the exponential hazard pt,i=1âˆ’expâ¡(âˆ’Î²â€‹ht,i/wt,i)p\_{t,i}=1-\exp(-\beta h\_{t,i}/w\_{t,i}), which keeps responses linear for small haircuts yet saturates toward one for severe cuts, matching the account-level attrition we measure in the Hyperliquid replay.
This mirrors the survival-style retention curves widely used in both classic and modern marketing-science churn modelsÂ [Bolton1998Duration, Schmittlein1987Customers, AscarzaHardie2013UsageChurn, LemmensGupta2020Churn, Ascarza2018RetentionFutility].
Full details of the calculation and the fee proxy are in AppendixÂ [H.2](https://arxiv.org/html/2512.01112v1#A8.SS2.SSS0.Px3 "Revenue loss proxy. â€£ H.2 Losses and objectives â€£ Appendix H Empirical Methodology â€£ Autodeleveraging: Impossibilities and Optimization").

### 9.2 Results

##### Overshoot and Efficiency.

Consistent with the theoretical prediction of excessive severity in static regimes (SectionÂ [5](https://arxiv.org/html/2512.01112v1#S5 "5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization")), Ï€queue\pi\_{\text{queue}} amassed a cumulative overshoot of $630M (FigureÂ [3](https://arxiv.org/html/2512.01112v1#S9.F3 "Figure 3 â€£ Overshoot and Efficiency. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization")).
While Ï€smart\pi\_{\text{smart}} eliminates this technical inefficiency by capping haircuts at the deficit, it does so by concentrating losses on the largest winners.
This triggers the adverse selection feedback loop: Ï€smart\pi\_{\text{smart}} induces high churn among liquidity providers, paradoxically resulting in a larger residual deficit than the dynamic policies (FigureÂ [4](https://arxiv.org/html/2512.01112v1#S9.F4 "Figure 4 â€£ The ADL Trilemma. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization")).

![Refer to caption](adl-simulation-retry/results/overshoot_time_series_with_cumulative.png)


Figure 3: ADL overshoot (Htâˆ’DtH\_{t}-D\_{t}). Dashed: per-shock overshoot. Solid: cumulative overshoot. The static policy Ï€queue\pi\_{\text{queue}} accumulates â‰ˆ$â€‹630\approx\mathdollar 630M of excess haircutting. Dynamic policies (Ï€md,Ï€vec\pi\_{\text{md}},\pi\_{\text{vec}}) keep overshoot negligible by construction, while Ï€exp\pi\_{\text{exp}} maintains it within a bounded constant factor.

##### The ADL Trilemma.

We analyze the ADL trilemma (PropositionÂ [2.1](https://arxiv.org/html/2512.01112v1#S2.Thmtheorem1 "Proposition 2.1 (Trilemma, Informal). â€£ Three competing desiderata. â€£ 2.5 ADL Trilemma â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization") empirically by looking at the components of regret for each policy.
These components represent the shortfall, fairness, and revenue loss realized by using each ADL policy.
FigureÂ [7](https://arxiv.org/html/2512.01112v1#S9.F7 "Figure 7 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") anchors the â€œsolvency-at-any-costâ€ corner of the trilemma: Ï€queue\pi\_{\text{queue}} slashes residual deficits (i.e.,Â higher solvency) yet incurs runaway overshoot and fairness penalties (i.e.,Â lower fairness and revenue).
FigureÂ [8](https://arxiv.org/html/2512.01112v1#S9.F8 "Figure 8 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") shows that capping overshoot via Ï€smart\pi\_{\text{smart}} still leaves concentrated losses (i.e.,Â low fairness) and elevated residual deficits once churn feedback kicks in (i.e.,Â lower long term revenue).
FiguresÂ [9](https://arxiv.org/html/2512.01112v1#S9.F9 "Figure 9 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") andÂ [10](https://arxiv.org/html/2512.01112v1#S9.F10 "Figure 10 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") illustrate how dynamic mirror-descent controllers match the queueâ€™s residual deficits without its welfare cost, i.e.,Â they have better revenue preserving properties than Queue while preserving approximately the same amount of solvency.
On the other hand, FigureÂ [11](https://arxiv.org/html/2512.01112v1#S9.F11 "Figure 11 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") demonstrates that (static) exponential backoff strategies can be competitive with dynamic policies if the deficit is sufficiently bounded.
By jointly optimizing allocation and severity, FigureÂ [12](https://arxiv.org/html/2512.01112v1#S9.F12 "Figure 12 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") shows Ï€vec\pi\_{\text{vec}} delivering the fairest loss sharing and the steepest long term revenue recovery.

![Refer to caption](adl-simulation-retry/results/deficit_flow/outstanding_overlay.png)


Figure 4: Outstanding negative equity (cumulative residual deficits). Lower is better. Despite its aggression, Ï€queue\pi\_{\text{queue}} fails to clear the deficit effectively due to feedback loops. Ï€exp\pi\_{\text{exp}} achieves competitive solvency without the welfare cost.

![Refer to caption](adl-simulation-retry/results/top_winner_haircut_time_series.png)


Figure 5: Largest winner haircut (USD). Ï€queue\pi\_{\text{queue}} places a massive, spikey burden on single participants. Dynamic policies (Ï€md,Ï€exp\pi\_{\text{md}},\pi\_{\text{exp}}) distribute the load, respecting fairness constraints.

![Refer to caption](adl-simulation-retry/results/ptsr_pmr_time_series.png)


Figure 6: PTSR (top) and PMR (bottom) on log scale. Ï€queue\pi\_{\text{queue}} exhibits ratios >106>10^{6}, indicating extreme moral hazard. Adaptive policies remain within the theoretical corridor (â‰ˆ1\approx 1â€“1010).

##### Regret Decomposition.

FigureÂ [7](https://arxiv.org/html/2512.01112v1#S9.F7 "Figure 7 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") makes clear that overshoot (orange) and fairness (red) dominate the queue baseline.
FigureÂ [8](https://arxiv.org/html/2512.01112v1#S9.F8 "Figure 8 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") cuts the overshoot bar almost entirely but replaces it with a larger residual (blue) mass as liquidity flees.
Mirror-descent controllers in FiguresÂ [9](https://arxiv.org/html/2512.01112v1#S9.F9 "Figure 9 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") andÂ [10](https://arxiv.org/html/2512.01112v1#S9.F10 "Figure 10 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") shrink every component simultaneously by aligning severity with observed deficits, with the warm-started variant tightening the residual tail.
FigureÂ [11](https://arxiv.org/html/2512.01112v1#S9.F11 "Figure 11 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") trades a small overshoot allowance for even lower fairness cost, while FigureÂ [12](https://arxiv.org/html/2512.01112v1#S9.F12 "Figure 12 â€£ Regret Decomposition. â€£ 9.2 Results â€£ 9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") compresses all three components and traces the Pareto frontier across solvency, fairness, and revenue.

![Refer to caption](adl-simulation-retry/results/regret_components_queue.png)


Figure 7: Regret decomposition for the production Queue baseline Ï€queue\pi\_{\text{queue}}. Overshoot (orange) and fairness (red) penalties dominate, illustrating static inefficiency.

![Refer to caption](adl-simulation-retry/results/regret_components_smart_queue.png)


Figure 8: Regret decomposition for the Smart Queue Ï€smart\pi\_{\text{smart}}. Capping overshoot helps, but churn-driven residual deficits and fairness costs still dominate regret.

![Refer to caption](adl-simulation-retry/results/regret_components_mirror.png)


Figure 9: Regret decomposition for Mirror Descent Ï€md\pi\_{\text{md}}. Adaptive severity minimizes overshoot while balancing fairness and residual losses.

![Refer to caption](adl-simulation-retry/results/regret_components_dyn2.png)


Figure 10: Regret decomposition for the Dynamic2 controller Ï€dyn2\pi\_{\text{dyn2}}. Warm-started mirror descent keeps overshoot tame while moderating fairness penalties.

![Refer to caption](adl-simulation-retry/results/regret_components_backoff.png)


Figure 11: Regret decomposition for Exponential Backoff Ï€exp\pi\_{\text{exp}}. Feedback-tuned severity contains overshoot without sacrificing solvency or fairness.

![Refer to caption](adl-simulation-retry/results/regret_components_vector.png)


Figure 12: Regret decomposition for Vector Mirror Ï€vec\pi\_{\text{vec}}. Joint severity and allocation updates compress every component, tracing the Pareto frontier.

### 9.3 Interpretation

In aggregate, the empirical evidence of this section strongly suggests that the standard Queue mechanism operates in the unbounded PoA regime defined in PropositionÂ [8.3](https://arxiv.org/html/2512.01112v1#S8.Thmtheorem3 "Proposition 8.3 (Informal). â€£ Why PoA for Nash vs. Stackelberg? â€£ 8.7 Dynamic Phase Transition in ADL â€£ 8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization").
It fails to balance the competing objectives of a perpetuals exchange, sacrificing trader welfare and future revenue for marginal (and often negative) gains in immediate solvency.
The decoupling of severity (Î¸t\theta\_{t}) from allocation (hth\_{t}) via policies like Exponential Backoff (Ï€exp\pi\_{\text{exp}}) offers a strictly dominant strategy, improving fairness and revenue retention without compromising system stability.

Based on these results, we offer three concrete prescriptions for Hyperliquid and similar venues:

1. 1.

   *Decouple Severity from Allocation.* Current mechanisms conflate the decision of *how much* to haircut with *who* to haircut. We recommend adopting a scalar feedback controller (e.g., Ï€exp\pi\_{\text{exp}} or Ï€md\pi\_{\text{md}}) to determine the aggregate severity Î¸t\theta\_{t} dynamically based on the observed deficit DtD\_{t}.
2. 2.

   *Adopt Fairer Allocations.* The greedy ranking used by Ï€queue\pi\_{\text{queue}} maximizes the fairness penalty and adverse selection. Shifting to a *Levered Pro-Rata* (LPR) rule (or the optimized vector hth\_{t} from Ï€vec\pi\_{\text{vec}}) ensures that loss socialization is proportional to risk and capacity, maintaining PTSRâ‰ˆ1\text{PTSR}\approx 1.
3. 3.

   *Implement a Hybrid Controller.* We recommend a hybrid approach: use LPR (Eq.Â [21](https://arxiv.org/html/2512.01112v1#S2.E21 "Equation 21 â€£ Pro-Rata Rules. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) for allocation to satisfy fairness constraints, paired with the Ï€exp\pi\_{\text{exp}} controller for severity to manage the deficit. This combination provides the robustness of dynamic severity with the transparency and fairness of pro-rata allocation, minimizing the long-term revenue impact of ADL events.

## 10 Conclusion and Future Work

In this paper, we provide the first formalism for ADL mechanisms that allows us to compare the performance of different policies.
We first that a negative result: it is impossible for a perpetuals to optimize for exchange solvency, long term revenue, and fairness to traders.
We then try to get around the negative result by analyzing strategies that optimize each of these components individually.
Our results demonstrate that the heuristic strategy employed by Hyperliquid, Binance, and others that stems from 2015 is actually suboptimal in all dimensions.
We empirically validate our results on Hyperliquid data from October 10, 2025 and demonstrate the superiority of dynamic and even other static algorithms to the live policy.

Our results suggest a few directions for future inquiry.
Implementing these policies in production has a number of challenges that we donâ€™t consider in the paper.
For instance, as exchanges grow and have many accounts with very smaller notation sizes, it makes more sense to choose a subset of users who are â€œeligible for ADLâ€.
This lowers the computational burden of executing ADL during times of duress (when execution latency is high) while also ensuring that smaller users are not subsidizing larger users.
Practical limits on ADL applicability likely change the results we have here and need to be studied further.

ADL policies also likely change in their efficacy if they were able to be executed in a fully privately manner.
In this paper, we ignored modeling execution costs for exchanges upon liquidation and position closure.
The modeling of such execution costs is nuanced and likely leads to incorrect conclusions about ADL if not carefully handled121212See, e.g.Â Storm2025ADLThread1, Storm2025ADLThread2 for examples of overly naive analyses that conflate execution costs with ADL mechanism design..
When private execution is possible, the impact of these costs is muted as follower strategies are not able to react to ADL shocks.

While centralized exchanges effectively offer ADL privacy (i.e.,Â other users do not know who else was autodeleveraged besides themselves), they still leak information to the market via public changes to the order book.
With superior privacy guarantess (likely provided by fully homomorphic encryption, zero knowledge proofs, and secure multi-party computation), one could imagine ADL policies being able to avoid the adverse selection effects we describe in the follower strategies section.
As ADL mechanisms rely increasingly on backstop liquidity vaults (such as Hyperliquidâ€™s HLP and Lighterâ€™s LLP), privacy of ADL execution becomes increasingly important to reduce costs for the exchange and traders.

Finally, we note that the results in this paper focused on a single margin model, where the posted collateral was the numÃ©raire.
Many exchanges, including Hyperliquid, have cross-margin ADL support.
This changes the modeling of execution costs and forces us to explicitly model market impact on cash / collateral balances.

## 11 Acknowledgments

The author would like to thank Udai Parvathaneni, Nathan Sheng, JD Maturen, Kamil Yusubov, and Luke Sterle from Gauntlet for helpful dicussions around how to quantify realistic ADL scenarios (such as October 10, 2025).
The author would also like to thank Matheus V. X. Ferreira, Guillermo Angeris, Victor Xu, and Vinayak Kurup for helpful discussions.
Finally, the author really appreciates the data provided by SonarX, Hydromancer, and Mauricio Trujillo.

## Notation and conventions

Throughout the appendix we use consistent notation:

* â€¢

  Shocks are indexed by t=1,2,â€¦,Tt=1,2,\dots,T; winners WtW\_{t} with equities et,i>0e\_{t,i}>0 and losers LtL\_{t}.
* â€¢

  Deficit Dtâ‰¥0D\_{t}\geq 0; severity Î¸tâ‰¥0\theta\_{t}\geq 0; haircut vector htâˆˆ[0,1]|Wt|h\_{t}\in[0,1]^{|W\_{t}|} with survivors st,i=(1âˆ’ht,i)â€‹et,is\_{t,i}=(1-h\_{t,i})e\_{t,i}.
* â€¢

  Perâ€“round budget Bt=minâ¡{Î¸tâ€‹Dt,âˆ‘iwt,i}B\_{t}=\min\{\theta\_{t}D\_{t},\ \sum\_{i}w\_{t,i}\} for severity policies and Bt=wtâŠ¤â€‹htB\_{t}=w\_{t}^{\top}h\_{t} for vector policies; Btâ‹†=minâ¡{Dt,âˆ‘iwt,i}B\_{t}^{\star}=\min\{D\_{t},\sum\_{i}w\_{t,i}\}.
* â€¢

  Perâ€“account caps are Î²t,iâˆˆ[0,1]\beta\_{t,i}\in[0,1] so that 0â‰¤ht,iâ‰¤Î²t,i0\leq h\_{t,i}\leq\beta\_{t,i}.
* â€¢

  Risk weights: Ïâ€‹(Î»)=Î»â€‹Ïˆâ€‹(1/Î»)\rho(\lambda)=\lambda\,\psi(1/\lambda) and gâ€‹(Î»)=Ïâ€‹(Î»)/Î»g(\lambda)=\rho(\lambda)/\lambda; when ordering by risk we use Ï\rho.
* â€¢

  Orders: xâ‰ºwyx\prec\_{w}y denotes weak submajorization (on decreasing rearrangements).
* â€¢

  Asymptotics: Xnâ‰pYnX\_{n}\asymp\_{p}Y\_{n} means there exist constants c,C>0c,C>0 such that câ€‹|Yn|â‰¤|Xn|â‰¤Câ€‹|Yn|c|Y\_{n}|\leq|X\_{n}|\leq C|Y\_{n}| with high probability.

## Appendix A Liquidations, Autodeleveraging, and Insurance Funds

### A.1 Bankruptcy Price Example

We illustrate the bankruptcy price calculation with an example.
Fix â„“max=10\ell^{\max}=10 (so mI=0.10m\_{I}=0.10) and p0=1p\_{0}=1.
Consider the five running positions from ğ’«5\mathcal{P}\_{5}:

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | ğ”­A\displaystyle\mathfrak{p}\_{A} | =(q,c,b)=(1,â€‰2,+1),\displaystyle=(q,c,b)=(1,\,2,\,+1), | ğ”­B\displaystyle\mathfrak{p}\_{B} | =(1,â€‰2/3,+1),\displaystyle=(1,\,2/3,\,+1), | ğ”­C\displaystyle\mathfrak{p}\_{C} | =(4,â€‰8/3,âˆ’1),\displaystyle=(4,\,8/3,\,-1), |  |
|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | ğ”­D\displaystyle\mathfrak{p}\_{D} | =(1,â€‰2/19,+1),\displaystyle=(1,\,2/19,\,+1), | ğ”­E\displaystyle\mathfrak{p}\_{E} | =(1,â€‰10/99,âˆ’1).\displaystyle=(1,\,10/99,\,-1). |  | | |

Applying Eq.Â ([10](https://arxiv.org/html/2512.01112v1#S2.E10 "Equation 10 â€£ Bankruptcy Price. â€£ 2.2.1 Liquidation Prices â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) with Î“=0\Gamma=0 and pt=p0=1p\_{t}=p\_{0}=1 gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­A)\displaystyle p^{bk}(\mathfrak{p}\_{A}) | =maxâ¡{0,â€‰1âˆ’2}=0,\displaystyle=\max\{0,\,1-2\}=0, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­B)\displaystyle p^{bk}(\mathfrak{p}\_{B}) | =1âˆ’23=13,\displaystyle=1-\tfrac{2}{3}=\tfrac{1}{3}, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­C)\displaystyle p^{bk}(\mathfrak{p}\_{C}) | =1âˆ’â€‰8/3âˆ’4=1+23=53â€‹(1.6667),\displaystyle=1-\tfrac{\,8/3\,}{-4}=1+\tfrac{2}{3}=\tfrac{5}{3}\ (1.6667), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­D)\displaystyle p^{bk}(\mathfrak{p}\_{D}) | =1âˆ’219â‰ˆ0.8947,\displaystyle=1-\tfrac{2}{19}\approx 0.8947, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­E)\displaystyle p^{bk}(\mathfrak{p}\_{E}) | =1+1099â‰ˆ1.1010.\displaystyle=1+\tfrac{10}{99}\approx 1.1010. |  |

Thus A is robust to a full drop to zero; B (long 1.5x) has a low bankruptcy price; C (short 1.5x) bankrupts only if the mark rises above 53\tfrac{5}{3}; D/E (long Â 9.5x/9.9x) have high bankruptcy prices close to 11, making negative equity likely if liquidations lag.

### A.2 Liquidation Price Example

For Î¼=0.10\mu=0.10 the liquidation prices evaluate to factors 11âˆ’Î¼\tfrac{1}{1-\mu} for longs and 11+Î¼\tfrac{1}{1+\mu} for shorts. Using the same five positions with pti=1p\_{t\_{i}}=1 and Î“=0\Gamma=0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­A,0.10)\displaystyle\hat{p}^{liq}(\mathfrak{p}\_{A},0.10) | =10.9â‹…0=0,\displaystyle=\tfrac{1}{0.9}\cdot 0=0, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­B,0.10)\displaystyle\hat{p}^{liq}(\mathfrak{p}\_{B},0.10) | =10.9â‹…13â‰ˆ0.3704,\displaystyle=\tfrac{1}{0.9}\cdot\tfrac{1}{3}\approx 0.3704, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­C,0.10)\displaystyle\hat{p}^{liq}(\mathfrak{p}\_{C},0.10) | =11.1â‹…53â‰ˆ1.5152,\displaystyle=\tfrac{1}{1.1}\cdot\tfrac{5}{3}\approx 1.5152, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­D,0.10)\displaystyle\hat{p}^{liq}(\mathfrak{p}\_{D},0.10) | =10.9â‹…1719â‰ˆ0.9942,\displaystyle=\tfrac{1}{0.9}\cdot\tfrac{17}{19}\approx 0.9942, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | p^lâ€‹iâ€‹qâ€‹(ğ”­E,0.10)\displaystyle\hat{p}^{liq}(\mathfrak{p}\_{E},0.10) | =11.1â‹…10999â‰ˆ1.0010.\displaystyle=\tfrac{1}{1.1}\cdot\tfrac{109}{99}\approx 1.0010. |  |

Long A would liquidate only if the oracle fell to 0 (i.e.,Â never occurs in practice). The short CC becomes liquidatable only when the oracle exceeds its threshold; the high-leverage long DD and short EE become liquidatable close to 11 if collateral is not topped up.

### A.3 Execution Price Example

We summarize execution with a directional linear impact rule consistent with our notation: selling to close a long uses Psâ€‹eâ€‹lâ€‹lâ€‹(x)=ptâˆ’Î±â€‹xP^{sell}(x)=p\_{t}-\alpha x and buying to close a short uses Pbâ€‹uâ€‹yâ€‹(x)=pt+Î±â€‹xP^{buy}(x)=p\_{t}+\alpha x with Î±>0\alpha>0; the volumeâ€“weighted execution for a slice is
peâ€‹xâ€‹eâ€‹c=ptâˆ’Î±2â€‹Î”â€‹q\;p^{exec}=p\_{t}-\tfrac{\alpha}{2}\Delta q if bi=+1b\_{i}=+1 (sell) and peâ€‹xâ€‹eâ€‹c=pt+Î±2â€‹Î”â€‹qp^{exec}=p\_{t}+\tfrac{\alpha}{2}\Delta q if bi=âˆ’1b\_{i}=-1 (buy).
Directional linear impact with a single Î±\alpha: selling (closing a long) uses Psâ€‹eâ€‹lâ€‹lâ€‹(x)=ptâˆ’Î±â€‹xP^{sell}(x)=p\_{t}-\alpha x, buying (closing a short) uses Pbâ€‹uâ€‹yâ€‹(x)=pt+Î±â€‹xP^{buy}(x)=p\_{t}+\alpha x. The slice VWAP over [0,Î”â€‹q][0,\Delta q] is peâ€‹xâ€‹eâ€‹c=ptâˆ“Î±2â€‹Î”â€‹qp^{exec}=p\_{t}\mp\tfrac{\alpha}{2}\Delta q (minus for sells, plus for buys). Fix Î±=1.0\alpha=1.0 and choose Î”â€‹q\Delta q per case:

* â€¢

  ğ”­A\mathfrak{p}\_{A} (Long): pt=1.30p\_{t}=1.30, Î”â€‹q=0.5\Delta q=0.5 gives peâ€‹xâ€‹eâ€‹c=1.30âˆ’0.5â‹…0.5=1.05p^{exec}=1.30-0.5\cdot 0.5=1.05. Here pbâ€‹kâ€‹(ğ”­A)=maxâ¡{ptâˆ’2,0}=0p^{bk}(\mathfrak{p}\_{A})=\max\{p\_{t}-2,0\}=0, so peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk}.
* â€¢

  ğ”­B\mathfrak{p}\_{B} (Long): pt=0.95p\_{t}=0.95, Î”â€‹q=0.2\Delta q=0.2 gives peâ€‹xâ€‹eâ€‹c=0.95âˆ’0.5â‹…0.2=0.85p^{exec}=0.95-0.5\cdot 0.2=0.85. With pbâ€‹kâ€‹(ğ”­B)=maxâ¡{0.95âˆ’23,0}â‰ˆ0.2833p^{bk}(\mathfrak{p}\_{B})=\max\{0.95-\tfrac{2}{3},0\}\approx 0.2833, we have peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk}.
* â€¢

  ğ”­C\mathfrak{p}\_{C} (Short): pt=1.60p\_{t}=1.60, Î”â€‹q=2.0\Delta q=2.0 gives peâ€‹xâ€‹eâ€‹c=1.60+0.5â‹…2.0=2.60p^{exec}=1.60+0.5\cdot 2.0=2.60. Since pbâ€‹kâ€‹(ğ”­C)=pt+8/34=pt+23=2.2667p^{bk}(\mathfrak{p}\_{C})=p\_{t}+\tfrac{8/3}{4}=p\_{t}+\tfrac{2}{3}=2.2667, peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk} (adverse for a short).
* â€¢

  ğ”­D\mathfrak{p}\_{D} (Long; targeted): pt=0.98p\_{t}=0.98, Î”â€‹q=0.4\Delta q=0.4 gives peâ€‹xâ€‹eâ€‹c=0.98âˆ’0.5â‹…0.4=0.78p^{exec}=0.98-0.5\cdot 0.4=0.78. With pbâ€‹kâ€‹(ğ”­D)=ptâˆ’219â‰ˆ0.8747p^{bk}(\mathfrak{p}\_{D})=p\_{t}-\tfrac{2}{19}\approx 0.8747, we achieve peâ€‹xâ€‹eâ€‹c<pbâ€‹kp^{exec}<p^{bk}.
* â€¢

  ğ”­E\mathfrak{p}\_{E} (Short): pt=1.05p\_{t}=1.05, Î”â€‹q=0.4\Delta q=0.4 gives peâ€‹xâ€‹eâ€‹c=1.05+0.5â‹…0.4=1.25p^{exec}=1.05+0.5\cdot 0.4=1.25. With pbâ€‹kâ€‹(ğ”­E)=pt+1099â‰ˆ1.151p^{bk}(\mathfrak{p}\_{E})=p\_{t}+\tfrac{10}{99}\approx 1.151, we have peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk}.

### A.4 Liquidation Costs Example

To ground the fee model, let Ï„â€‹(Î”â€‹q)=Ï„fâ€‹iâ€‹x+Ï•mâ€‹aâ€‹râ€‹kâ€‹ptâ€‹Î”â€‹q+Ï•eâ€‹xâ€‹eâ€‹câ€‹peâ€‹xâ€‹eâ€‹câ€‹Î”â€‹q\tau(\Delta q)=\tau^{fix}+\phi^{mark}p\_{t}\,\Delta q+\phi^{exec}p^{exec}\,\Delta q as in practice.
Consider pt=1.30p\_{t}=1.30, a slice Î”â€‹q=0.50\Delta q=0.50, and a realized peâ€‹xâ€‹eâ€‹c=1.32p^{exec}=1.32.
Two parameterizations:

* â€¢

  Binance: (Ï„fâ€‹iâ€‹x,Ï•mâ€‹aâ€‹râ€‹k,Ï•eâ€‹xâ€‹eâ€‹c)=(0,â€‰40â€‹bps,â€‰0)(\tau^{fix},\phi^{mark},\phi^{exec})=(0,\,40\,\mathrm{bps},\,0) [BinanceFuturesInsuranceFund]. Then Ï„=0.0040â‹…1.30â‹…0.50=0.0026\tau=0.0040\cdot 1.30\cdot 0.50=0.0026.
* â€¢

  Hyperliquid: (Ï„fâ€‹iâ€‹x,Ï•mâ€‹aâ€‹râ€‹k,Ï•eâ€‹xâ€‹eâ€‹c)=(0,â€‰20â€‹bps,â€‰10â€‹bps)(\tau^{fix},\phi^{mark},\phi^{exec})=(0,\,20\,\mathrm{bps},\,10\,\mathrm{bps}) [HyperliquidDocsLiquidations]. Then Ï„=0.0020â‹…1.30â‹…0.50+0.0010â‹…1.32â‹…0.50â‰ˆ0.00130+0.00066=0.00196\tau=0.0020\cdot 1.30\cdot 0.50+0.0010\cdot 1.32\cdot 0.50\approx 0.00130+0.00066=0.00196.

Rates and formulas vary by venue and contract; the above are illustrative parameterizations consistent with public documentation that liquidation fees are charged and, on centralized venues like Binance, credited to the insurance fund.

### A.5 Liquidation Strategy Example

Consider short ğ”­E\mathfrak{p}\_{E} when the mark jumps to pt=5.5p\_{t}=5.5 (ignore funding for this step).
Equity before liquidation is eâ‰ˆcEâˆ’qEâ€‹(ptâˆ’p0)=1099âˆ’1â‹…4.5â‰ˆâˆ’4.399e\approx c\_{E}-q\_{E}(p\_{t}-p\_{0})=\tfrac{10}{99}-1\cdot 4.5\approx-4.399.
Let Î¼=0.10\mu=0.10 and a linear fee Ï„â€‹(Î”â€‹q)=Ï•â€‹ptâ€‹Î”â€‹q\tau(\Delta q)=\phi\,p\_{t}\,\Delta q with Ï•=30\phi=30bps. Suppose execution is peâ€‹xâ€‹eâ€‹c=5.55p^{exec}=5.55.
Using ([11](https://arxiv.org/html/2512.01112v1#S2.E11 "Equation 11 â€£ Liquidation Strategies. â€£ 2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) and b=âˆ’1b=-1, the minimal slice that restores maintenance solves

|  |  |  |
| --- | --- | --- |
|  | Î”â€‹q=Î¼â€‹ptâ€‹qâˆ’ebâ€‹(peâ€‹xâ€‹eâ€‹câˆ’pt)âˆ’Ï•â€‹pt+Î¼â€‹pt=0.1â‹…5.5â‹…1âˆ’(âˆ’4.399)âˆ’0.05âˆ’0.003â‹…5.5+0.1â‹…5.5â‰ˆ4.9490.4835â‰ˆ 10.24.\Delta q\;=\;\frac{\mu p\_{t}q-e}{\,b(p^{exec}-p\_{t})-\phi p\_{t}+\mu p\_{t}\,}\;=\;\frac{0.1\cdot 5.5\cdot 1-(-4.399)}{-0.05-0.003\cdot 5.5+0.1\cdot 5.5}\ \approx\ \frac{4.949}{0.4835}\ \approx\ 10.24. |  |

Since Î”â€‹q>qE\Delta q>q\_{E}, a greedy policy would fully close E (cap at Î”â€‹q=qE=1\Delta q=q\_{E}=1).

### A.6 Bad Debt Example

Consider the high-leverage long ğ”­D\mathfrak{p}\_{D} and a slice of size Î”â€‹q=0.4\Delta q=0.4 at pt=0.98p\_{t}=0.98.
Suppose the realized execution is pDeâ€‹xâ€‹eâ€‹c=0.78p^{exec}\_{D}=0.78 while the bankruptcy level is pDbâ€‹kâ‰ˆ0.8747p^{bk}\_{D}\approx 0.8747.
Since pDeâ€‹xâ€‹eâ€‹c<pDbâ€‹kp^{exec}\_{D}<p^{bk}\_{D}, the realized shortfall from this slice is

|  |  |  |
| --- | --- | --- |
|  | (pDbâ€‹kâˆ’pDeâ€‹xâ€‹eâ€‹c)â€‹Î”â€‹qâ‰ˆ(0.8747âˆ’0.78)â‹…0.4â‰ˆ 0.0379,(p^{bk}\_{D}-p^{exec}\_{D})\,\Delta q\ \approx\ (0.8747-0.78)\cdot 0.4\ \approx\ 0.0379, |  |

which contributes this amount to the period bad debt DtD\_{t} (cf. Eq.Â ([13](https://arxiv.org/html/2512.01112v1#S2.E13 "Equation 13 â€£ Bad Debt. â€£ 2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))).
Coverage follows the solvency waterfall: the insurance fund pays minâ¡{ğ–¨ğ–¥t,Dt}\min\{\mathsf{IF}\_{t},D\_{t}\} and any residual shortfall is socialized via ADL (see Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"), Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
The short case is symmetric: buying to close above bankruptcy (peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk}) realizes a positive contribution to DtD\_{t}.

### A.7 Anatomy of a Liquidation

Given the bankruptcy, liquidation, and execution prices, we can now describe the high-level algorithm that liquidations follow.
We note that many live liquidation systems will have much more complex liquidation algorithms.
These complexities deal with the coordination costs of coordinating many parties (e.g.Â oracle provider, liquidators, spot order book liquidity) and precise models that exchanges use for their liquidation strategy.
However, we effectively lump all of these complexities into the definition of the liquidation strategy.
The following liquidation loop is run on every oracle update received by a perpetuals exchange:

* â€¢

  For ğ”­i,tâˆˆğ’«n\mathfrak{p}\_{i,t}\in\mathcal{P}\_{n}

  + â€“

    If the maintenance margin conditionÂ ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) is violated for ğ”­i,t\mathfrak{p}\_{i,t}

    1. 1.

       Remove the position ğ’«nâ†ğ’«nâˆ’{ğ”­i,t}\mathcal{P}\_{n}\leftarrow\mathcal{P}\_{n}-\{\mathfrak{p}\_{i,t}\}
    2. 2.

       Estimate quantity to liquidate Î”â€‹qiâ†Lâ€‹(ğ”­i,t,p1:T,p^1:T)\Delta q\_{i}\leftarrow L(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T})
    3. 3.

       Liquidator executes Î”â€‹qi\Delta q\_{i}-sized liquidation and returns their execution price peâ€‹xâ€‹eâ€‹câ€‹(Î”â€‹qi)p^{exec}(\Delta q\_{i})
    4. 4.

       Update position: ğ”­i,tâ€²=(qiâˆ’Î”â€‹qi,ci+peâ€‹xâ€‹eâ€‹câ€‹Î”â€‹qiâˆ’Ï„tâ€‹(Î”â€‹qi),ti,bi)\mathfrak{p}^{\prime}\_{i,t}=(q\_{i}-\Delta q\_{i},c\_{i}+p^{exec}\Delta q\_{i}-\tau\_{t}(\Delta q\_{i}),t\_{i},b\_{i})
    5. 5.

       Re-add the position position: ğ’«nâ†ğ’«nâˆª{ğ”­i,tâ€²}\mathcal{P}\_{n}\leftarrow\mathcal{P}\_{n}\cup\{\mathfrak{p}^{\prime}\_{i,t}\}
    6. 6.

       Update equity usingÂ ([12](https://arxiv.org/html/2512.01112v1#S2.E12 "Equation 12 â€£ Bad Debt. â€£ 2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))
* â€¢

  If ğ”­i,t\mathfrak{p}\_{i,t} has bad debt, e~â€‹(ğ”­i,t,p1:T,p^1:T,Î”â€‹qi)<0\tilde{e}(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T},\Delta q\_{i})<0, then

  + â€“

    Attempt to use the insurance fund, if it exists, to cover the bad debt (Â§[2.3](https://arxiv.org/html/2512.01112v1#S2.SS3 "2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))
  + â€“

    If the insurance fund is insufficiently sized, utilize an ADL mechanism (Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))

##### Example.

We illustrate a fiveâ€“step path using the running set ğ’«5\mathcal{P}\_{5} from above. Take T=5T=5, p0=1p\_{0}=1 and

|  |  |  |
| --- | --- | --- |
|  | p0:5=(1.00, 0.96, 0.94, 0.97, 1.05, 1.12),p^t=pt(t=0,â€¦,5),Î¼=mI=0.10.p\_{0:5}=(1.00,\ 0.96,\ 0.94,\ 0.97,\ 1.05,\ 1.12),\qquad\hat{p}\_{t}=p\_{t}\ \ (t=0,\dots,5),\qquad\mu=m\_{I}=0.10. |  |

Executions follow the directional linear impact rule introduced in the execution example: for a slice of size Î”â€‹q\Delta q at time tt, the volume-weighted execution is

|  |  |  |  |
| --- | --- | --- | --- |
|  | peâ€‹xâ€‹eâ€‹c=ptâˆ’Î±2â€‹Î”â€‹q\displaystyle p^{exec}\;=\;p\_{t}-\tfrac{\alpha}{2}\,\Delta q | (sell to close a long,Â b=+1),\displaystyle\quad\text{(sell to close a long, $b=+1$)}, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | peâ€‹xâ€‹eâ€‹c=pt+Î±2â€‹Î”â€‹q\displaystyle p^{exec}\;=\;p\_{t}+\tfrac{\alpha}{2}\,\Delta q | (buy to close a short,Â b=âˆ’1).\displaystyle\quad\text{(buy to close a short, $b=-1$)}. |  |

with Î±>0\alpha>0. We take Î±=1.0\alpha=1.0 and choose Î”â€‹q\Delta q via the loopâ€™s liquidation size Î”â€‹qi=Lâ€‹(ğ”­i,t,p1:T,p^1:T)\Delta q\_{i}=L(\mathfrak{p}\_{i,t},p\_{1:T},\hat{p}\_{1:T}).

##### D liquidates at t=2t=2 (no bad debt).

At t=2t=2 we have p2=0.94p\_{2}=0.94 and the maintenance condition ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) is violated for ğ”­D,2\mathfrak{p}\_{D,2}, so the loop attempts a partial liquidation. Take Î”â€‹qD=Lâ€‹(ğ”­D,2,â‹…)=0.20\Delta q\_{D}=L(\mathfrak{p}\_{D,2},\cdot)=0.20 for illustration. By ([10](https://arxiv.org/html/2512.01112v1#S2.E10 "Equation 10 â€£ Bankruptcy Price. â€£ 2.2.1 Liquidation Prices â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")),

|  |  |  |
| --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­D,2)=p2âˆ’219â‰ˆâ€„0.8347,pDeâ€‹xâ€‹eâ€‹c=p2âˆ’Î±2â€‹Î”â€‹qD=â€„0.94âˆ’0.10=â€„0.84.p^{bk}(\mathfrak{p}\_{D,2})\;=\;p\_{2}-\tfrac{2}{19}\;\approx\;0.8347,\qquad p^{exec}\_{D}\;=\;p\_{2}-\tfrac{\alpha}{2}\Delta q\_{D}\;=\;0.94-0.10\;=\;0.84. |  |

Since pDeâ€‹xâ€‹eâ€‹c>pbâ€‹kâ€‹(ğ”­D,2)p^{exec}\_{D}>p^{bk}(\mathfrak{p}\_{D,2}), this slice executes without bad debt; the position is updated to ğ”­D,2â€²=(qDâˆ’Î”â€‹qD,cD+pDeâ€‹xâ€‹eâ€‹câ€‹Î”â€‹qDâˆ’Ï„2â€‹(Î”â€‹qD),tD,bD)\mathfrak{p}^{\prime}\_{D,2}=(q\_{D}-\Delta q\_{D},\ c\_{D}+p^{exec}\_{D}\Delta q\_{D}-\tau\_{2}(\Delta q\_{D}),\ t\_{D},\ b\_{D}) and equity is updated per ([12](https://arxiv.org/html/2512.01112v1#S2.E12 "Equation 12 â€£ Bad Debt. â€£ 2.2.2 Liquidation Mechanics â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) before reinserting ğ”­D,2â€²\mathfrak{p}^{\prime}\_{D,2} into ğ’«n\mathcal{P}\_{n}.

##### E becomes bad debt at t=4t=4 (short; liquidation fails).

At t=4t=4 we have p4=1.05p\_{4}=1.05 and ([7](https://arxiv.org/html/2512.01112v1#S2.E7 "Equation 7 â€£ Maintenance Margin. â€£ 2.1 Perpetuals Exchanges. â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) is violated for ğ”­E,4\mathfrak{p}\_{E,4} with bE=âˆ’1b\_{E}=-1. The loop selects a liquidation size; take a full close Î”â€‹qE=Lâ€‹(ğ”­E,4,â‹…)=1\Delta q\_{E}=L(\mathfrak{p}\_{E,4},\cdot)=1. By ([10](https://arxiv.org/html/2512.01112v1#S2.E10 "Equation 10 â€£ Bankruptcy Price. â€£ 2.2.1 Liquidation Prices â€£ 2.2 Liquidations â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")),

|  |  |  |
| --- | --- | --- |
|  | pbâ€‹kâ€‹(ğ”­E,4)=p4+1099â‰ˆâ€„1.1510,pEeâ€‹xâ€‹eâ€‹c=p4+Î±2â€‹Î”â€‹qE=â€„1.05+0.50=â€„1.55.p^{bk}(\mathfrak{p}\_{E,4})\;=\;p\_{4}+\tfrac{10}{99}\;\approx\;1.1510,\qquad p^{exec}\_{E}\;=\;p\_{4}+\tfrac{\alpha}{2}\Delta q\_{E}\;=\;1.05+0.50\;=\;1.55. |  |

For a short, peâ€‹xâ€‹eâ€‹c>pbâ€‹kp^{exec}>p^{bk} realizes bad debt. The loop records the shortfall

|  |  |  |
| --- | --- | --- |
|  | D4=(pEeâ€‹xâ€‹eâ€‹câˆ’pbâ€‹kâ€‹(ğ”­E,4))â€‹Î”â€‹qEâ‰ˆâ€„0.399,e~â€‹(ğ”­E,4,p1:5,p^1:5,Î”â€‹qE)=âˆ’D4<0,D\_{4}\;=\;\big(p^{exec}\_{E}-p^{bk}(\mathfrak{p}\_{E,4})\big)\,\Delta q\_{E}\;\approx\;0.399,\qquad\tilde{e}\big(\mathfrak{p}\_{E,4},p\_{1:5},\hat{p}\_{1:5},\Delta q\_{E}\big)\;=\;-D\_{4}<0, |  |

and then attempts coverage via the insurance fund (up to minâ¡{ğ–¨ğ–¥4,D4}\min\{\mathsf{IF}\_{4},D\_{4}\}); any residual shortfall R4R\_{4} defined by Eq.Â ([16](https://arxiv.org/html/2512.01112v1#S2.E16 "Equation 16 â€£ Insurance Funds. â€£ 2.3 Exchange Solvency â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) is socialized by ADL (see Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).

### A.8 Optimal Capital Structure Derivation

In this section, we compute the optimal static insurance fund size Iâ€‹Fâ‹†IF^{\star} that trades off the opportunity cost of capital and expected uncovered losses beyond Iâ€‹FIF.

##### Setup.

Let DTD\_{T} denote the round deficit with pdf fDf\_{D} and tail FÂ¯Dâ€‹(x)=Prâ¡[DT>x]\bar{F}\_{D}(x)=\Pr[D\_{T}>x]. Let r>0r>0 be the per-unit capital cost and Îº>0\kappa>0 the per-unit social loss weight of uncovered deficits.
The objective is

|  |  |  |
| --- | --- | --- |
|  | minIâ€‹Fâ‰¥0â¡ğ’¥â€‹(Iâ€‹F)=râ€‹Iâ€‹F+Îºâ€‹ğ”¼â€‹[(DTâˆ’Iâ€‹F)+]\min\_{IF\geq 0}\ \mathcal{J}(IF)\;=\;r\,IF\;+\;\kappa\,\mathbb{E}\big[(D\_{T}-IF)\_{+}\big] |  |

which equals râ€‹Iâ€‹F+Îºâ€‹âˆ«Iâ€‹Fâˆ(xâˆ’Iâ€‹F)â€‹fDâ€‹(x)â€‹ğ‘‘xr\,IF+\kappa\int\_{IF}^{\infty}(x-IF)f\_{D}(x)\,dx when DTD\_{T} is continuous.

##### Optimality condition.

Differentiating yields,

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€²â€‹(Iâ€‹F)=râˆ’Îºâ€‹FÂ¯Dâ€‹(Iâ€‹F).\mathcal{J}^{\prime}(IF)=r-\kappa\,\bar{F}\_{D}(IF). |  |

Hence any interior minimizer satisfies FÂ¯Dâ€‹(Iâ€‹Fâ‹†)=r/Îº\bar{F}\_{D}(IF^{\star})=r/\kappa, i.e.,

|  |  |  |
| --- | --- | --- |
|  | Iâ€‹Fâ‹†=FÂ¯Dâˆ’1â€‹(rÎº)=VaRâ€‰1âˆ’r/Îºâ€‹(DT).IF^{\star}\;=\;\bar{F}\_{D}^{-1}\!\Big(\tfrac{r}{\kappa}\Big)\;=\;\mathrm{VaR}\_{\,1-r/\kappa}(D\_{T}). |  |

##### Assumptions.

In order for this argument to hold, we assume that ğ’¥\mathcal{J} is convex and differentiable.
Moreover, if râ‰¥Îºr\geq\kappa then we define Iâ€‹Fâ‹†=0IF^{\star}=0, whereas if râ†’0r\to 0, then Iâ€‹Fâ‹†â†’supDTIF^{\star}\rightarrow\sup D\_{T}.

## Appendix B Moral Hazard and Extreme Value Analysis

In this appendix, we formalize the moral hazard properties of ADL mechanisms.
We analyze the optimal control of the Profitability-to-Total-Solvency Ratio (PTSR) and the Profitability-to-Maximum Solvency Ratio (PMR) defined inÂ Â§[3.1.2](https://arxiv.org/html/2512.01112v1#S3.SS1.SSS2 "3.1.2 ADL-Specific Efficiency Metrics â€£ 3.1 Risk Metrics â€£ 3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization"), and derive their asymptotic behavior under distributional assumptions.

### B.1 Setup and Assumptions

We work in the *large-market limit* (nâ†’âˆn\to\infty) under the heavy-tailed assumptions characteristic of crypto markets.
Recall that DTÏ€=Î¸Ï€â€‹DTD^{\pi}\_{T}=\theta\_{\pi}D\_{T} is the total socialized loss and Î”TÏ€=Î¸Ï€â€‹Î”T\Delta^{\pi}\_{T}=\theta\_{\pi}\Delta\_{T} is the maximum socialized shortfall under policy Ï€\pi.
The survivor of the top winner is denoted Ï‰TÏ€\omega^{\pi}\_{T}.

##### Assumption A (Regular Variation).

The right tail of the winner equity distribution FÂ¯+â€‹(x)\bar{F}\_{+}(x) and the right tail of the loser shortfall distribution FÂ¯âˆ’â€‹(x)\bar{F}\_{-}(x) are regularly varying with indices Î±+>0\alpha\_{+}>0 and Î±âˆ’>0\alpha\_{-}>0, respectively.
That is, FÂ¯Â±â€‹(x)=LÂ±â€‹(x)â€‹xâˆ’Î±Â±\bar{F}\_{\pm}(x)=L\_{\pm}(x)x^{-\alpha\_{\pm}} where LÂ±L\_{\pm} are slowly varying functions.

##### Assumption B (LLN and EVT).

We assume the standard Law of Large Numbers (LLN) and Extreme Value Theory (EVT) scaling limits apply:

* â€¢

  *Aggregates:* WT/nâ†’ğ‘Î¼+W\_{T}/n\xrightarrow{p}\mu\_{+} and DT/nâ†’ğ‘Î¼âˆ’D\_{T}/n\xrightarrow{p}\mu\_{-}, for constants Î¼Â±âˆˆ(0,âˆ)\mu\_{\pm}\in(0,\infty).
* â€¢

  *Extremes:* The maximum winner Ï‰T\omega\_{T} scales as bkn+=F+â†â€‹(1âˆ’1/n)b\_{k\_{n}}^{+}=F\_{+}^{\leftarrow}(1-1/n), and the maximum loser shortfall Î”T\Delta\_{T} scales as bmnâˆ’=Fâˆ’â†â€‹(1âˆ’1/n)b\_{m\_{n}}^{-}=F\_{-}^{\leftarrow}(1-1/n).

### B.2 Optimal Control of Moral Hazard

### B.3 Queue maximizes top-winner damage

We first establish that the *Queue* (or Top-First) rule minimizes the moral hazard metrics defined in the main text for any fixed budget.

###### Proposition B.1 (Queue Minimizes Top Survivor).

Fix a budget H=DTÏ€H=D^{\pi}\_{T}. Let Ï‰T\omega\_{T} be the equity of the largest winner.
For any feasible haircut vector hh satisfying âˆ‘hiâ€‹ei=H\sum h\_{i}e\_{i}=H, the top-winner survivor Ï‰TÏ€\omega^{\pi}\_{T} satisfies

|  |  |  |
| --- | --- | --- |
|  | Ï‰TÏ€â‰¥maxâ¡{Ï‰Tâˆ’H,0}.\omega^{\pi}\_{T}\;\geq\;\max\{\omega\_{T}-H,0\}. |  |

Equality is attained by the Queue rule, which sets the haircut on the top winner to h(1)=minâ¡(H/Ï‰T,1)h\_{(1)}=\min(H/\omega\_{T},1) and others to 0 (until h(1)h\_{(1)} saturates).

###### Proof.

Let h(1)h\_{(1)} be the haircut applied to the top winner.
Since hiâ€‹eiâ‰¥0h\_{i}e\_{i}\geq 0 for all ii, we have h(1)â€‹Ï‰Tâ‰¤âˆ‘ihiâ€‹ei=Hh\_{(1)}\omega\_{T}\leq\sum\_{i}h\_{i}e\_{i}=H.
The survivor is Ï‰TÏ€=Ï‰Tâˆ’h(1)â€‹Ï‰Tâ‰¥Ï‰Tâˆ’H\omega^{\pi}\_{T}=\omega\_{T}-h\_{(1)}\omega\_{T}\geq\omega\_{T}-H.
Since equity cannot be negative, Ï‰TÏ€â‰¥maxâ¡{Ï‰Tâˆ’H,0}\omega^{\pi}\_{T}\geq\max\{\omega\_{T}-H,0\}.
The Queue rule greedily allocates the budget to the largest position, achieving h(1)â€‹Ï‰T=minâ¡(H,Ï‰T)h\_{(1)}\omega\_{T}=\min(H,\omega\_{T}), thus attaining the lower bound.
âˆ

###### Corollary B.2 (Minimality of PTSR/PMR).

Since DTÏ€D^{\pi}\_{T} and Î”TÏ€\Delta^{\pi}\_{T} are fixed for a given policy severity, the Queue rule minimizes both ğ–¯ğ–³ğ–²ğ–±T\mathsf{PTSR}\_{T} and ğ–¯ğ–¬ğ–±T\mathsf{PMR}\_{T} among all budget-balanced policies.

##### Gap versus Pro-Rata.

The Queue rule minimizes moral hazard but concentrates the entire loss on the top winner (extreme inequality).
In contrast, the Pro-Rata rule spreads the loss proportionally across all winners, prioritizing *smoothness* (treating similar positions similarly) over minimizing the top survivorâ€™s burden.
For Hâ‰¤Ï‰TH\leq\omega\_{T}, the survivor gap is

|  |  |  |
| --- | --- | --- |
|  | Ï‰TPRâˆ’Ï‰TQueue=Hâ€‹(1âˆ’Ï‰TWT).\omega^{\mathrm{PR}}\_{T}-\omega^{\mathrm{Queue}}\_{T}\;=\;H\left(1-\frac{\omega\_{T}}{W\_{T}}\right). |  |

This gap scales linearly with the budget HH, quantifying the â€œcost of fairnessâ€: by choosing the smoother Pro-Rata allocation, the system allows the top winner to retain more profit than is strictly necessary to cover the deficit.

### B.4 Asymptotic Scaling Results

We now characterize the asymptotic behavior of PTSR and PMR under â€œgentleâ€ policies (like Pro-Rata) where the top winner is not specifically targeted.

###### Theorem B.3 (PTSR scaling).

Under Assumptions A and B, for any policy Ï€\pi with severity Î¸n\theta\_{n} where Ï‰TÏ€âˆ¼Ï‰T\omega^{\pi}\_{T}\sim\omega\_{T} (e.g., Pro-Rata with Hâ‰ªWTH\ll W\_{T}), the PTSR scales as

|  |  |  |
| --- | --- | --- |
|  | ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Ï€)â‰pbkn+Î¸nâ€‹n.\mathsf{PTSR}\_{T}(\pi)\;\asymp\_{p}\;\frac{b\_{k\_{n}}^{+}}{\theta\_{n}n}. |  |

###### Proof.

By definition, ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Ï€)=ğ„[Ï‰TÏ€/DTÏ€]\mathsf{PTSR}\_{T}(\pi)=\mathop{\bf E{}}[\omega^{\pi}\_{T}/D^{\pi}\_{T}].
Under the hypothesis, the numerator scales as Ï‰Tâˆ¼bkn+\omega\_{T}\sim b\_{k\_{n}}^{+}.
The denominator is DTÏ€=Î¸nâ€‹DTD^{\pi}\_{T}=\theta\_{n}D\_{T}. By the LLN, DTâˆ¼Î¼âˆ’â€‹nD\_{T}\sim\mu\_{-}n, so DTÏ€âˆ¼Î¸nâ€‹Î¼âˆ’â€‹nD^{\pi}\_{T}\sim\theta\_{n}\mu\_{-}n.
Thus, the ratio scales as bkn+/(Î¸nâ€‹n)b\_{k\_{n}}^{+}/(\theta\_{n}n).
Using bounded convergence for the expectation yields the result.
âˆ

##### Implication.

The behavior of PTSR depends critically on the tail class of winner equities:

* â€¢

  *Pareto (Heavy) Tails:* bkn+â‰n1/Î±+b\_{k\_{n}}^{+}\asymp n^{1/\alpha\_{+}}. Here ğ–¯ğ–³ğ–²ğ–±Tâ‰n1/Î±+âˆ’1/Î¸n\mathsf{PTSR}\_{T}\asymp n^{1/\alpha\_{+}-1}/\theta\_{n}. Moral hazard vanishes (ğ–¯ğ–³ğ–²ğ–±â†’0\mathsf{PTSR}\to 0) if and only if winners have finite mean (Î±+>1\alpha\_{+}>1). If Î±+<1\alpha\_{+}<1, the top survivor grows faster than the aggregate deficit, making the moral hazard wedge permanent.
* â€¢

  *Exponential/Gaussian (Light) Tails:* bkn+â‰(logâ¡n)Î³b\_{k\_{n}}^{+}\asymp(\log n)^{\gamma}. Here ğ–¯ğ–³ğ–²ğ–±Tâ‰(logâ¡n)Î³/(nâ€‹Î¸n)\mathsf{PTSR}\_{T}\asymp(\log n)^{\gamma}/(n\theta\_{n}). Since polylog growth is slower than linear, moral hazard vanishes rapidly for any non-vanishing severity Î¸n\theta\_{n}, as the aggregate deficit overwhelms the largest individual winner.

###### Theorem B.4 (PMR Scaling).

Assume winner equities have mass â„“n+\ell\_{n}^{+} and loser deficits have mass â„“nâˆ’\ell\_{n}^{-} (representing total leverage), and that the underlying normalized distributions satisfy Assumption A.
The PMR scales as:

|  |  |  |
| --- | --- | --- |
|  | ğ–¯ğ–¬ğ–±Tâ€‹(Ï€)â‰p1Î¸nâ‹…â„“n+â„“nâˆ’â‹…bkn+bmnâˆ’â‰1Î¸nâ‹…â„“n+â„“nâˆ’â‹…n1Î±+âˆ’1Î±âˆ’.\mathsf{PMR}\_{T}(\pi)\;\asymp\_{p}\;\frac{1}{\theta\_{n}}\cdot\frac{\ell\_{n}^{+}}{\ell\_{n}^{-}}\cdot\frac{b\_{k\_{n}}^{+}}{b\_{m\_{n}}^{-}}\;\asymp\;\frac{1}{\theta\_{n}}\cdot\frac{\ell\_{n}^{+}}{\ell\_{n}^{-}}\cdot n^{\frac{1}{\alpha\_{+}}-\frac{1}{\alpha\_{-}}}. |  |

###### Proof.

We have ğ–¯ğ–¬ğ–±Tâ€‹(Ï€)=ğ„[Ï‰TÏ€/Î”TÏ€]\mathsf{PMR}\_{T}(\pi)=\mathop{\bf E{}}[\omega^{\pi}\_{T}/\Delta^{\pi}\_{T}].
The top winner scales with total winner leverage mass: Ï‰Tâˆ¼â„“n+â€‹bkn+\omega\_{T}\sim\ell\_{n}^{+}b\_{k\_{n}}^{+}.
The maximum loser shortfall scales with total loser leverage mass: Î”Tâˆ¼â„“nâˆ’â€‹bmnâˆ’\Delta\_{T}\sim\ell\_{n}^{-}b\_{m\_{n}}^{-}.
The budget balance condition implies Î”TÏ€=Î¸nâ€‹Î”T\Delta^{\pi}\_{T}=\theta\_{n}\Delta\_{T}.
Thus, the ratio scales as

|  |  |  |
| --- | --- | --- |
|  | â„“n+â€‹bkn+Î¸nâ€‹â„“nâˆ’â€‹bmnâˆ’=1Î¸nâ€‹â„“n+â„“nâˆ’â€‹bkn+bmnâˆ’.\frac{\ell\_{n}^{+}b\_{k\_{n}}^{+}}{\theta\_{n}\ell\_{n}^{-}b\_{m\_{n}}^{-}}\;=\;\frac{1}{\theta\_{n}}\frac{\ell\_{n}^{+}}{\ell\_{n}^{-}}\frac{b\_{k\_{n}}^{+}}{b\_{m\_{n}}^{-}}. |  |

Substituting the regular variation scalings bkn+âˆ¼n1/Î±+b\_{k\_{n}}^{+}\sim n^{1/\alpha\_{+}} and bmnâˆ’âˆ¼n1/Î±âˆ’b\_{m\_{n}}^{-}\sim n^{1/\alpha\_{-}} yields the result.
âˆ

TheoremÂ [B.4](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem4 "Theorem B.4 (PMR Scaling). â€£ Implication. â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") decomposes moral hazard into three components:
(1) *Policy Severity* (1/Î¸n1/\theta\_{n}): Lower severity amplifies PMR.
(2) *Leverage Imbalance* (â„“n+/â„“nâˆ’\ell\_{n}^{+}/\ell\_{n}^{-}): If the winning side holds more leverage mass, PMR increases.
(3) *Tail Risk* (n1/Î±+âˆ’1/Î±âˆ’n^{1/\alpha\_{+}-1/\alpha\_{-}}): Heavier winner tails relative to losers drive PMR divergence.
This decomposition highlights that even with fair tails (Î±+=Î±âˆ’\alpha\_{+}=\alpha\_{-}), a systemic leverage imbalance (â„“n+â‰«â„“nâˆ’\ell\_{n}^{+}\gg\ell\_{n}^{-}) can sustain a high PMR.
Specifically, if the exchange allows winners to be significantly more leveraged than losers (a "risk-on" imbalance), the top winnerâ€™s survival will systematically outstrip the worst-case socialized loss, creating a persistent moral hazard where maximal profits are privatized while maximal losses are capped.

### B.5 Relationship to Classical Risk Measures

These two metrics have natural interpretations in terms of financial risk measures.
The deficit DTD\_{T} corresponds to the aggregate *Expected Shortfall* (ES) of the losing tail, while Î”T\Delta\_{T} corresponds to the *Value-at-Risk* (VaR) at the extreme quantile (1/n1/n).
Specifically, PTSR compares the *Maximum Profit* to the *Aggregate Socialized Loss* (ES-like), measuring efficiency in bulk.
PMR compares the *Maximum Profit* to the *Maximum Socialized Loss* (VaR-like), measuring efficiency in the extreme tail.
A high PMR implies that the system permits â€œunicornâ€ wins that vastly exceed the worst-case individual losses, potentially incentivizing excessive risk-taking if traders perceive a capped downside but unbounded upside.

We further strengthen the connection to classical risk measures by showing that Queue not only minimizes the top survivor in expectation, but also minimizes it in the sense of VaR and ES at *every* tail level.

###### Proposition B.5 (Queue minimizes VaR/ES of the top survivor).

Fix any budget hâ‰¥0h\geq 0 and Î±âˆˆ(0,1)\alpha\in(0,1).
For any feasible haircut vector hh with âˆ‘ihiâ€‹ei=h\sum\_{i}h\_{i}e\_{i}=h,

|  |  |  |
| --- | --- | --- |
|  | Ï‰TÏ€â‰¥(Ï‰Tâˆ’h)+a.s.\omega^{\pi}\_{T}\;\geq\;(\omega\_{T}-h)\_{+}\quad\text{a.s.} |  |

Consequently,

|  |  |  |
| --- | --- | --- |
|  | VaRÎ±â€‹(Ï‰TÏ€)â‰¥VaRÎ±â€‹((Ï‰Tâˆ’h)+),ESÎ±â€‹(Ï‰TÏ€)â‰¥ESÎ±â€‹((Ï‰Tâˆ’h)+).\mathrm{VaR}\_{\alpha}(\omega^{\pi}\_{T})\;\geq\;\mathrm{VaR}\_{\alpha}\big((\omega\_{T}-h)\_{+}\big),\qquad\mathrm{ES}\_{\alpha}(\omega^{\pi}\_{T})\;\geq\;\mathrm{ES}\_{\alpha}\big((\omega\_{T}-h)\_{+}\big). |  |

The Queue rule attains equality. Moreover, the following identities hold:

|  |  |  |
| --- | --- | --- |
|  | VaRÎ±â€‹((Ï‰Tâˆ’h)+)=maxâ¡{VaRÎ±â€‹(Ï‰T)âˆ’h,â€‰0},\mathrm{VaR}\_{\alpha}\big((\omega\_{T}-h)\_{+}\big)\;=\;\max\{\mathrm{VaR}\_{\alpha}(\omega\_{T})-h,\,0\}, |  |

|  |  |  |
| --- | --- | --- |
|  | ESÎ±â€‹((Ï‰Tâˆ’h)+)=11âˆ’Î±â€‹âˆ«Î±1maxâ¡{VaRuâ€‹(Ï‰T)âˆ’h,â€‰0}â€‹ğ‘‘u.\mathrm{ES}\_{\alpha}\big((\omega\_{T}-h)\_{+}\big)\;=\;\frac{1}{1-\alpha}\int\_{\alpha}^{1}\max\{\mathrm{VaR}\_{u}(\omega\_{T})-h,\,0\}\,du. |  |

###### Proof.

The pointwise lower bound Ï‰TÏ€â‰¥(Ï‰Tâˆ’h)+\omega^{\pi}\_{T}\geq(\omega\_{T}-h)\_{+} follows from the budget constraint and nonnegativity of haircuts, as in PropositionÂ [B.1](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem1 "Proposition B.1 (Queue Minimizes Top Survivor). â€£ B.3 Queue maximizes top-winner damage â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").
Monotonicity of risk measures implies that if Xâ‰¥YX\geq Y almost surely, then VaRÎ±â€‹(X)â‰¥VaRÎ±â€‹(Y)\mathrm{VaR}\_{\alpha}(X)\geq\mathrm{VaR}\_{\alpha}(Y) and ESÎ±â€‹(X)â‰¥ESÎ±â€‹(Y)\mathrm{ES}\_{\alpha}(X)\geq\mathrm{ES}\_{\alpha}(Y).
For the identities, observe that xâ†¦(xâˆ’h)+x\mapsto(x-h)\_{+} is nondecreasing; hence quantiles shift: VaRÎ±â€‹((Xâˆ’h)+)=maxâ¡{VaRÎ±â€‹(X)âˆ’h,0}\mathrm{VaR}\_{\alpha}((X-h)\_{+})=\max\{\mathrm{VaR}\_{\alpha}(X)-h,0\}.
The ES identity follows from the Kusuoka representationÂ [Kusuoka2001] ESÎ±â€‹(Z)=11âˆ’Î±â€‹âˆ«Î±1VaRuâ€‹(Z)â€‹ğ‘‘u\mathrm{ES}\_{\alpha}(Z)=\frac{1}{1-\alpha}\int\_{\alpha}^{1}\mathrm{VaR}\_{u}(Z)\,du applied to Z=(Xâˆ’h)+Z=(X-h)\_{+}.
âˆ

##### Implication for severity design.

For a random budget H=Î¸nâ€‹DTH=\theta\_{n}D\_{T}, apply TheoremÂ [B.5](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem5 "Proposition B.5 (Queue minimizes VaR/ES of the top survivor). â€£ B.5 Relationship to Classical Risk Measures â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") conditionally on HH to conclude that Queue minimizes the conditional VaR/ES of the top survivor at every tail level.
When Î±+>1\alpha\_{+}>1 (finite mean winners), the tail-equivalence property of regularly varying distributions yields

|  |  |  |
| --- | --- | --- |
|  | ESuâ€‹(Ï‰T)VaRuâ€‹(Ï‰T)â†’Î±+Î±+âˆ’1asÂ â€‹uâ†‘1,\frac{\mathrm{ES}\_{u}(\omega\_{T})}{\mathrm{VaR}\_{u}(\omega\_{T})}\;\to\;\frac{\alpha\_{+}}{\alpha\_{+}-1}\qquad\text{as }u\uparrow 1, |  |

so VaR- and ES-based moral hazard conclusions coincide asymptotically with those of PTSR and PMR.

### B.6 Randomized constructions for moral-hazard examples

##### Extreme-value moral-hazard (principalâ€“agent).

Fix Ïâˆˆ(0,1)\rho\in(0,1) and kn=âŒŠÏâ€‹nâŒ‹k\_{n}=\lfloor\rho n\rfloor. Draw winner equities Yi(n)Y\_{i}^{(n)} i.i.d. Pareto(Î±+)(\alpha\_{+}) and loser equities Xi(n)X\_{i}^{(n)} with mean Î¼\mu.
Then Mn+=maxâ¡Yi(n)â‰n1/Î±+M\_{n}^{+}=\max Y\_{i}^{(n)}\asymp n^{1/\alpha\_{+}} while non-max winners sum to oâ€‹(Mn+)o(M\_{n}^{+}).
Losers sum to DTâ‰ˆÎ¼â€‹nD\_{T}\approx\mu n.
For fixed severity Î¸nâ‰¡Î¸Â¯\theta\_{n}\equiv\bar{\theta}, the haircut Hnâ‰ˆÎ¸Â¯â€‹Î¼â€‹nH\_{n}\approx\bar{\theta}\mu n exceeds the capacity of non-max winners, forcing the top winner to cover the bulk.
Post-ADL equity is (Mn+âˆ’Î¸Â¯â€‹Î¼â€‹n)+â†’0(M\_{n}^{+}-\bar{\theta}\mu n)\_{+}\to 0 since n1/Î±+â‰ªnn^{1/\alpha\_{+}}\ll n for Î±+<1\alpha\_{+}<1.

##### Leverage-imbalance construction.

Fix leverage masses â„“nâˆ’â‰«â„“n+\ell\_{n}^{-}\gg\ell\_{n}^{+}. Draw loser equities Xi(n)X\_{i}^{(n)} i.i.d. Pareto(Î±âˆ’)(\alpha\_{-}), so DTâ‰ˆMnâˆ’â‰n1/Î±âˆ’D\_{T}\approx M\_{n}^{-}\asymp n^{1/\alpha\_{-}}.
Assign winner leverage câ€‹â„“n+c\,\ell\_{n}^{+} to a random index InI\_{n} and distribute the rest evenly.
Then Ï‰nâ‰(â„“n+/â„“nâˆ’)â€‹n\omega\_{n}\asymp(\ell\_{n}^{+}/\ell\_{n}^{-})n.
This satisfies PropositionÂ [5.2](https://arxiv.org/html/2512.01112v1#S5.Thmtheorem2 "Proposition 5.2 (Informal). â€£ Main Result. â€£ 5.2 Excessive leverage guarantees large maximal trader loss â€£ 5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") assumptions, yielding the claimed threshold.

## Appendix C Theoretical Properties of Capped Pro-Rata

We formalize the theoretical properties of the capped pro-rata rule.
We note that the capped pro-rata algorithm in AlgorithmÂ [1](https://arxiv.org/html/2512.01112v1#alg1 "Algorithm 1 â€£ D.1 Capped Pro-Rata Water-Filling â€£ Appendix D Algorithms for Pro-Rata Haircut Rules â€£ Autodeleveraging: Impossibilities and Optimization") is a standard water-filling algorithmÂ [BoydVandenberghe2004].
The most similar known prior work to this appendix is the study of how such algorithms provide sybil resistance in concave games in decentralized systemsÂ [johnson2023concave].
One can view our result as a generalization of this result.

##### Properties of ADL rules.

Fix time TT, state ğ’«n\mathcal{P}\_{n}, winners ğ’²T\mathcal{W}\_{T}, and equities ei=(eTâ€‹(ğ”­i))+e\_{i}=(e\_{T}(\mathfrak{p}\_{i}))\_{+}.
Let sÏ€,i=(1âˆ’hÏ€,i)â€‹eis\_{\pi,i}=(1-h\_{\pi,i})e\_{i} be the surviving equity of position ii under ADL policy Ï€\pi.
We say that a feasible ADL rule Ï€\pi (Â§[2.4](https://arxiv.org/html/2512.01112v1#S2.SS4 "2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")) satisfies:

1. 1.

   *Sybil resistance:* Outcomes are invariant to splitting/merging accounts. For any split ei=âˆ‘a=1rzae\_{i}=\sum\_{a=1}^{r}z\_{a}, the sum of survivors equals the original survivor: âˆ‘asÏ€,a(iâ†’z)=sÏ€,i\sum\_{a}s^{(i\to z)}\_{\pi,a}=s\_{\pi,i}.
2. 2.

   *Scale invariance:* sÏ€â€‹(câ€‹e;Î¸Ï€)=câ€‹sÏ€â€‹(e;Î¸Ï€)s\_{\pi}(ce;\theta\_{\pi})=c\,s\_{\pi}(e;\theta\_{\pi}) for c>0c>0.
3. 3.

   *Monotonicity:* If e1â‰¥â‹¯â‰¥eke\_{1}\geq\dots\geq e\_{k}, then sÏ€,1â‰¥â‹¯â‰¥sÏ€,ks\_{\pi,1}\geq\dots\geq s\_{\pi,k}.
4. 4.

   *Interior regularity:* The map (e,H)â†¦sÏ€â€‹(e;H)(e,H)\mapsto s\_{\pi}(e;H) is C1C^{1} on the interior, i.e.,Â for ei>0e\_{i}>0 for all ii and 0<H<âˆ‘iei0<H<\sum\_{i}e\_{i}.

Collectively, we refer to these as the *fairness properties* for an ADL rule.

###### Proposition C.1 (Uniqueness of the Pro-Rata Rule).

If a feasible ADL policy Ï€\pi satisfies the fairness properties, then sÏ€â€‹(e;H)=sPRâ€‹(e;H)s\_{\pi}(e;H)=s^{\mathrm{PR}}(e;H) for all feasible inputs.

###### Proof.

Fix a feasible budget HH (e.g.Â maximum value of Î¸nâ€‹DT\theta\_{n}D\_{T}) and write Î²iâˆˆ(0,1]\beta\_{i}\in(0,1] for the haircut cap on winner ii (as in the capped pro-rata ruleÂ ([29](https://arxiv.org/html/2512.01112v1#S6.E29 "Equation 29 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"))), and sort so that e1â‰¥â‹¯â‰¥eke\_{1}\geq\cdots\geq e\_{k}.
View the haircuts as a function of the realized budget bâˆˆ[0,H]b\in[0,H] and write hiâ€‹(b)h\_{i}(b) for the haircut on winner ii when total budget bb has been allocated.
For each bb, define the *active set*

|  |  |  |  |
| --- | --- | --- | --- |
|  | Aâ€‹(b)={i:hiâ€‹(b)<Î²i}A(b)=\{i:\ h\_{i}(b)<\beta\_{i}\} |  | (36) |

of winners whose caps are not yet binding.
Since there are only finitely many caps Î²i\beta\_{i}, there exists a partition 0=b0<b1<â‹¯<bL=H0=b\_{0}<b\_{1}<\cdots<b\_{L}=H such that on each open interval Iâ„“:=(bâ„“âˆ’1,bâ„“)I\_{\ell}:=(b\_{\ell-1},b\_{\ell}) the active set is constant.
Fix one such interval I=(bâˆ’,b+)I=(b\_{-},b\_{+}) and write A=Aâ€‹(b)A=A(b) for any bâˆˆIb\in I.
On this interval, by scale invariance on AA (perâ€“unit budget increases all active haircuts at the same rate) and feasibility,

|  |  |  |
| --- | --- | --- |
|  | dâ€‹hidâ€‹b=1âˆ‘jâˆˆAej(iâˆˆA),dâ€‹hidâ€‹b=0(iâˆ‰A).\frac{dh\_{i}}{db}\;=\;\frac{1}{\sum\_{j\in A}e\_{j}}\quad(i\in A),\qquad\frac{dh\_{i}}{db}=0\quad(i\notin A). |  |

Using the interior regularity property, we can integrate these terms on II.
Integrating from bâˆ’b\_{-} to any bâˆˆIb\in I gives the *unconstrained* evolution

|  |  |  |
| --- | --- | --- |
|  | h~iâ€‹(b)={hiâ€‹(bâˆ’)+bâˆ’bâˆ’âˆ‘jâˆˆAej(iâˆˆA),hiâ€‹(bâˆ’)(iâˆ‰A).\tilde{h}\_{i}(b)\;=\;\begin{cases}h\_{i}(b\_{-})\;+\;\dfrac{b-b\_{-}}{\sum\_{j\in A}e\_{j}}&(i\in A),\\[4.0pt] h\_{i}(b\_{-})&(i\notin A).\end{cases} |  |

All active coordinates in AA move in lockstep, so on II there exists a scalar function Î·Iâ€‹(b)\eta\_{I}(b) such that

|  |  |  |
| --- | --- | --- |
|  | hiâ€‹(b)=minâ¡{Î·Iâ€‹(b),Î²i}(iâˆˆA),hiâ€‹(b)=hiâ€‹(bâˆ’)(iâˆ‰A).h\_{i}(b)\;=\;\min\{\eta\_{I}(b),\beta\_{i}\}\quad(i\in A),\qquad h\_{i}(b)=h\_{i}(b\_{-})\quad(i\notin A). |  |

The budget identity can then be written on II as

|  |  |  |
| --- | --- | --- |
|  | b=âˆ‘iâˆ‰Aeiâ€‹hiâ€‹(bâˆ’)+âˆ‘iâˆˆAeiâ€‹minâ¡{Î·Iâ€‹(b),Î²i},b\;=\;\sum\_{i\notin A}e\_{i}h\_{i}(b\_{-})\;+\;\sum\_{i\in A}e\_{i}\min\{\eta\_{I}(b),\beta\_{i}\}, |  |

which, for fixed bâˆˆIb\in I, is a continuous strictly increasing function of Î·Iâ€‹(b)\eta\_{I}(b) as long as Aâ‰ âˆ…A\neq\emptyset.
Thus for each bâˆˆIb\in I there is a unique Î·Iâ€‹(b)\eta\_{I}(b) solving the budget identity.
In particular, on the *interior* interval where no caps bind (A={1,â€¦,k}A=\{1,\dots,k\} and bâˆˆ(0,WT)b\in(0,W\_{T})), we have hiâ€‹(b)=Î·Iâ€‹(b)h\_{i}(b)=\eta\_{I}(b) for all ii so the budget identity reduces to

|  |  |  |
| --- | --- | --- |
|  | b=âˆ‘i=1keiâ€‹hiâ€‹(b)=Î·Iâ€‹(b)â€‹âˆ‘i=1kei=Î·Iâ€‹(b)â€‹WT,b\;=\;\sum\_{i=1}^{k}e\_{i}h\_{i}(b)\;=\;\eta\_{I}(b)\sum\_{i=1}^{k}e\_{i}\;=\;\eta\_{I}(b)\,W\_{T}, |  |

which implies Î·Iâ€‹(b)=b/WT\eta\_{I}(b)=b/W\_{T}.
Thus on this interval
sÏ€,i=(1âˆ’Î·Iâ€‹(b))â€‹ei=(1âˆ’b/WT)â€‹eis\_{\pi,i}=(1-\eta\_{I}(b))e\_{i}=(1-b/W\_{T})e\_{i}, i.e., proportional to equity.

Sybil resistance implies allocations depend only on total equity: splitting ei=âˆ‘azae\_{i}=\sum\_{a}z\_{a} leaves
âˆ‘azaâ€‹haâ€‹(b)\sum\_{a}z\_{a}h\_{a}(b) and hence the survivor âˆ‘a(1âˆ’haâ€‹(b))â€‹za\sum\_{a}(1-h\_{a}(b))z\_{a} unchanged for each bb, so the proportional form on interior intervals is preserved under arbitrary splits.
Monotonicity further restricts how indices can exit the active set as bb increases.
At an endpoint bâ„“b\_{\ell} where Î·Iâ€‹(bâ„“)\eta\_{I}(b\_{\ell}) first hits some cap Î²m\beta\_{m}, all indices jâ‰¥mj\geq m with Î²jâ‰¤Î²m\beta\_{j}\leq\beta\_{m} must saturate together; otherwise we would have emâ‰¥eje\_{m}\geq e\_{j} but (1âˆ’hmâ€‹(bâ„“))â€‹em<(1âˆ’hjâ€‹(bâ„“))â€‹ej(1-h\_{m}(b\_{\ell}))e\_{m}<(1-h\_{j}(b\_{\ell}))e\_{j}, violating monotonicity.
Thus, as we pass from Iâ„“I\_{\ell} to Iâ„“+1I\_{\ell+1}, a (possibly empty) tail {j>m}\{j>m\} leaves AA, contributing a fixed amount âˆ‘j>mejâ€‹Î²j\sum\_{j>m}e\_{j}\beta\_{j} to the budget, and the same water-filling argument applies on the remaining head with reduced budget.

Concatenating the solution across all intervals Iâ„“I\_{\ell} yields the reverseâ€“waterfilling form
hi=minâ¡{Î·â‹†,Î²i}h\_{i}=\min\{\eta^{\star},\beta\_{i}\} with Î·â‹†\eta^{\star} chosen so that âˆ‘ieiâ€‹hi=H\sum\_{i}e\_{i}h\_{i}=H, which is exactly capped proâ€“rata.
Uniqueness follows either from the strict convexity of the Euclidean projection onto
{hâˆˆ[0,1]k:âˆ‘ieiâ€‹hi=H}\{h\in[0,1]^{k}:\ \sum\_{i}e\_{i}h\_{i}=H\} or from the monotone oneâ€“dimensional search that defines Î·â‹†\eta^{\star}.
âˆ

##### Convex Optimality

We now formalize the convex-welfare interpretation of capped pro-rata from Â§[6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization").
Fix time TT, winners ğ’²T\mathcal{W}\_{T} with equities ei=eTâ€‹(ğ”­i)+e\_{i}=e\_{T}(\mathfrak{p}\_{i})\_{+}, and effective caps Î²i=minâ¡{hÂ¯i,1âˆ’eÂ¯i/eTâ€‹(ğ”­i)}\beta\_{i}=\min\{\overline{h}\_{i},1-\underline{e}\_{i}/e\_{T}(\mathfrak{p}\_{i})\} defined by the haircut and equity constraintsÂ ([22](https://arxiv.org/html/2512.01112v1#S2.E22 "Equation 22 â€£ Per-account constraints. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization"))â€“([23](https://arxiv.org/html/2512.01112v1#S2.E23 "Equation 23 â€£ Per-account constraints. â€£ 2.4 Autodeleveraging â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
Let BT=Î¸Ï€â€‹DTâ€‹(ğ’«n)B\_{T}=\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}) denote the haircut budget fromÂ ([30](https://arxiv.org/html/2512.01112v1#S6.E30 "Equation 30 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")), and let Ï•:[0,1]â†’R\phi:[0,1]\to{\mbox{\bf R}} be a strictly convex increasing function representing per-unit haircut disutility as inÂ ([31](https://arxiv.org/html/2512.01112v1#S6.E31 "Equation 31 â€£ Convex Optimality. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")).
We consider choosing haircuts h=(hi)iâˆˆğ’²Th=(h\_{i})\_{i\in\mathcal{W}\_{T}} to minimize the equity-weighted total disutility âˆ‘iâˆˆğ’²Teiâ€‹Ï•â€‹(hi)\sum\_{i\in\mathcal{W}\_{T}}e\_{i}\phi(h\_{i}) subject to the per-account bounds 0â‰¤hiâ‰¤Î²i0\leq h\_{i}\leq\beta\_{i} and the aggregate budget constraint âˆ‘iâˆˆğ’²Teiâ€‹hi=BT\sum\_{i\in\mathcal{W}\_{T}}e\_{i}h\_{i}=B\_{T}.

###### Proposition C.2 (Convex optimality).

For any strictly convex increasing Ï•\phi, the unique solution to

|  |  |  |
| --- | --- | --- |
|  | minhâ€‹âˆ‘iâˆˆğ’²Teiâ€‹Ï•â€‹(hi)s.t.âˆ‘iâˆˆğ’²Teiâ€‹hi=BT,0â‰¤hiâ‰¤Î²i\min\_{h}\ \sum\_{i\in\mathcal{W}\_{T}}e\_{i}\,\phi(h\_{i})\quad\text{s.t.}\quad\sum\_{i\in\mathcal{W}\_{T}}e\_{i}h\_{i}=B\_{T},\quad 0\leq h\_{i}\leq\beta\_{i} |  |

is the capped pro-rata ruleÂ ([29](https://arxiv.org/html/2512.01112v1#S6.E29 "Equation 29 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")), i.e., hÏ€Câ€‹P,iâ‹†=minâ¡{Î·â‹†,Î²i}h\_{\pi\_{CP},i}^{\star}=\min\{\eta^{\star},\beta\_{i}\}, where Î·â‹†\eta^{\star} is chosen so that âˆ‘iâˆˆğ’²Teiâ€‹hÏ€Câ€‹P,iâ‹†=BT\sum\_{i\in\mathcal{W}\_{T}}e\_{i}h\_{\pi\_{CP},i}^{\star}=B\_{T}.

###### Proof.

The optimization problem is convex with a strictly convex objective and linear constraints, so any point satisfying the Karushâ€“Kuhnâ€“Tucker (KKT) conditions is the unique global minimizerÂ [BoydVandenberghe2004, Ch.Â 5].
For BTB\_{T} in the interior of the feasible region (0<BT<Câ€‹(Î²)0<B\_{T}<C(\beta), where Câ€‹(Î²)C(\beta) is defined inÂ ([28](https://arxiv.org/html/2512.01112v1#S6.E28 "Equation 28 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization"))), Slaterâ€™s condition holds, so KKT conditions are necessary and sufficient.
The Lagrangian is

|  |  |  |
| --- | --- | --- |
|  | â„’â€‹(h,Î»,Î¼,Î½)=âˆ‘iâˆˆğ’²Teiâ€‹Ï•â€‹(hi)+Î»â€‹(âˆ‘iâˆˆğ’²Teiâ€‹hiâˆ’BT)+âˆ‘iâˆˆğ’²TÎ¼iâ€‹(hiâˆ’Î²i)âˆ’âˆ‘iâˆˆğ’²TÎ½iâ€‹hi,\mathcal{L}(h,\lambda,\mu,\nu)\;=\;\sum\_{i\in\mathcal{W}\_{T}}e\_{i}\phi(h\_{i})+\lambda\!\left(\sum\_{i\in\mathcal{W}\_{T}}e\_{i}h\_{i}-B\_{T}\right)+\sum\_{i\in\mathcal{W}\_{T}}\mu\_{i}(h\_{i}-\beta\_{i})-\sum\_{i\in\mathcal{W}\_{T}}\nu\_{i}h\_{i}, |  |

with multipliers Î»âˆˆR\lambda\in{\mbox{\bf R}} and Î¼i,Î½iâ‰¥0\mu\_{i},\nu\_{i}\geq 0.
Stationarity with respect to hih\_{i} gives

|  |  |  |
| --- | --- | --- |
|  | eiâ€‹Ï•â€²â€‹(hi)+Î»â€‹ei+Î¼iâˆ’Î½i=0(iâˆˆğ’²T),e\_{i}\phi^{\prime}(h\_{i})+\lambda e\_{i}+\mu\_{i}-\nu\_{i}=0\quad(i\in\mathcal{W}\_{T}), |  |

together with complementary slackness Î¼iâ€‹(hiâˆ’Î²i)=0\mu\_{i}(h\_{i}-\beta\_{i})=0 and Î½iâ€‹hi=0\nu\_{i}h\_{i}=0.
For any index ii with 0<hi<Î²i0<h\_{i}<\beta\_{i}, we must have Î¼i=Î½i=0\mu\_{i}=\nu\_{i}=0, so Ï•â€²â€‹(hi)=âˆ’Î»\phi^{\prime}(h\_{i})=-\lambda.
Because Ï•â€²\phi^{\prime} is strictly increasing, this implies hi=ch\_{i}=c for some common scalar cc independent of ii.
If hi=Î²ih\_{i}=\beta\_{i} then Î¼iâ‰¥0\mu\_{i}\geq 0 and Î½i=0\nu\_{i}=0, and if hi=0h\_{i}=0 then Î½iâ‰¥0\nu\_{i}\geq 0 and Î¼i=0\mu\_{i}=0, so in all cases the KKT conditions imply the water-filling form

|  |  |  |
| --- | --- | --- |
|  | hi=minâ¡{c,Î²i}(iâˆˆğ’²T).h\_{i}=\min\{c,\beta\_{i}\}\quad(i\in\mathcal{W}\_{T}). |  |

The budget constraint âˆ‘iâˆˆğ’²Teiâ€‹hi=BT\sum\_{i\in\mathcal{W}\_{T}}e\_{i}h\_{i}=B\_{T} then reduces to finding cc such that

|  |  |  |
| --- | --- | --- |
|  | âˆ‘iâˆˆğ’²Teiâ€‹minâ¡{c,Î²i}=BT.\sum\_{i\in\mathcal{W}\_{T}}e\_{i}\min\{c,\beta\_{i}\}=B\_{T}. |  |

The left-hand side is continuous and strictly increasing in cc on [0,1][0,1] as long as some Î²i>0\beta\_{i}>0, so there is a unique c=Î·â‹†c=\eta^{\star} solving this equation.
Thus every KKT point has the capped pro-rata form hi=minâ¡{Î·â‹†,Î²i}h\_{i}=\min\{\eta^{\star},\beta\_{i}\} with Î·â‹†\eta^{\star} determined by the budget, which is exactly the rule inÂ ([29](https://arxiv.org/html/2512.01112v1#S6.E29 "Equation 29 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization")).
Strict convexity of the objective implies this KKT point is the unique global minimizer, proving the claim (see also the standard water-filling derivations inÂ [BoydVandenberghe2004, Ch.Â 5]).
âˆ

## Appendix D Algorithms for Pro-Rata Haircut Rules

This appendix collects the explicit water-filling procedures for both the capped pro-rata rule fromÂ [SectionËœ6](https://arxiv.org/html/2512.01112v1#S6 "6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization") and the Risk-Aware Pro-Rata (RAP) rule fromÂ [SectionËœ7](https://arxiv.org/html/2512.01112v1#S7 "7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization").
Each algorithm takes the winner equities {ei}\{e\_{i}\}, effective caps {Î²i}\{\beta\_{i}\}, and the target budget BT=Î¸Ï€â€‹DTâ€‹(ğ’«n)B\_{T}=\theta\_{\pi}D\_{T}(\mathcal{P}\_{n}), returning the optimal haircut vector hh or declaring infeasibility if the aggregate capacity âˆ‘ieiâ€‹Î²i\sum\_{i}e\_{i}\beta\_{i} is insufficient.

### D.1 Capped Pro-Rata Water-Filling

The procedure below enforces the constraints in [EquationsËœ29](https://arxiv.org/html/2512.01112v1#S6.E29 "In Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization") andÂ [30](https://arxiv.org/html/2512.01112v1#S6.E30 "Equation 30 â€£ Definition of the Capped Pro-Rata Rule. â€£ 6 Fairness â€£ Autodeleveraging: Impossibilities and Optimization") by leveling caps until the target budget is met.

Algorithm 1  Capped Pro-Rata Haircut Allocation (Water-Filling)

1:Winner equities e={e1,â€¦,en}e=\{e\_{1},\dots,e\_{n}\}, Effective caps Î²={Î²1,â€¦,Î²n}\beta=\{\beta\_{1},\dots,\beta\_{n}\}, Target budget BTB\_{T}

2:Haircut vector h={h1,â€¦,hn}h=\{h\_{1},\dots,h\_{n}\} or Infeasible

3:Câ†âˆ‘i=1neiâ€‹Î²iC\leftarrow\sum\_{i=1}^{n}e\_{i}\beta\_{i} âŠ³\triangleright Compute total maximum capacity

4:if BT>CB\_{T}>C then

5:â€ƒâ€‚return Infeasible

6:end if

7:Sort indices pp such that Î²p1â‰¤Î²p2â‰¤â‹¯â‰¤Î²pn\beta\_{p\_{1}}\leq\beta\_{p\_{2}}\leq\dots\leq\beta\_{p\_{n}}

8:Î²p0â†0\beta\_{p\_{0}}\leftarrow 0

9:Vâ†0V\leftarrow 0 âŠ³\triangleright Cumulative value covered

10:Râ†âˆ‘i=1neiR\leftarrow\sum\_{i=1}^{n}e\_{i} âŠ³\triangleright Remaining uncapped equity mass

11:for k=1k=1 to nn do

12:â€ƒâ€‚Î”â€‹Î²â†Î²pkâˆ’Î²pkâˆ’1\Delta\beta\leftarrow\beta\_{p\_{k}}-\beta\_{p\_{k-1}}

13:â€ƒâ€‚Vstepâ†Î”â€‹Î²â‹…RV\_{\mathrm{step}}\leftarrow\Delta\beta\cdot R

14:â€ƒâ€‚if V+Vstepâ‰¥BTV+V\_{\mathrm{step}}\geq B\_{T} then

15:â€ƒâ€ƒâ€ƒÎ·â†Î²pkâˆ’1+(BTâˆ’V)/R\eta\leftarrow\beta\_{p\_{k-1}}+(B\_{T}-V)/R âŠ³\triangleright Found the water level Î·\eta

16:â€ƒâ€ƒâ€ƒbreak

17:â€ƒâ€‚end if

18:â€ƒâ€‚Vâ†V+VstepV\leftarrow V+V\_{\mathrm{step}}

19:â€ƒâ€‚Râ†Râˆ’epkR\leftarrow R-e\_{p\_{k}} âŠ³\triangleright User pkp\_{k} becomes fully capped

20:end for

21:if V<BTV<B\_{T} then âŠ³\triangleright Handling numerical edge cases

22:â€ƒâ€‚Î·â†Î²pn\eta\leftarrow\beta\_{p\_{n}}

23:end if

24:for i=1i=1 to nn do

25:â€ƒâ€‚hiâ†minâ¡{Î·,Î²i}h\_{i}\leftarrow\min\{\eta,\beta\_{i}\}

26:end for

27:return hh

### D.2 Risk-Aware Pro-Rata Water-Filling

The RAP algorithm augments the capped procedure by prioritizing accounts according to their â€œcap-to-weightâ€ ratios Î²i/wi\beta\_{i}/w\_{i}.

Algorithm 2  Risk-Aware Pro-Rata Haircut Allocation (Weighted Water-Filling)

1:Winner equities e={e1,â€¦,en}e=\{e\_{1},\dots,e\_{n}\}, Effective caps Î²={Î²1,â€¦,Î²n}\beta=\{\beta\_{1},\dots,\beta\_{n}\}, Risk weights w={w1,â€¦,wn}w=\{w\_{1},\dots,w\_{n}\}, Target budget BTB\_{T}

2:Haircut vector h={h1,â€¦,hn}h=\{h\_{1},\dots,h\_{n}\} or Infeasible

3:Câ†âˆ‘i=1neiâ€‹Î²iC\leftarrow\sum\_{i=1}^{n}e\_{i}\beta\_{i} âŠ³\triangleright Total capacity

4:if BT>CB\_{T}>C then

5:â€ƒâ€‚return Infeasible

6:end if

7:Compute ratios riâ†Î²i/wir\_{i}\leftarrow\beta\_{i}/w\_{i} for all ii (treat wi=0w\_{i}=0 as ri=âˆr\_{i}=\infty)

8:Sort indices pp such that rp1â‰¤rp2â‰¤â‹¯â‰¤rpnr\_{p\_{1}}\leq r\_{p\_{2}}\leq\dots\leq r\_{p\_{n}}

9:rp0â†0r\_{p\_{0}}\leftarrow 0

10:Vâ†0V\leftarrow 0 âŠ³\triangleright Cumulative value covered

11:Wremâ†âˆ‘i=1neiâ€‹wiW\_{\mathrm{rem}}\leftarrow\sum\_{i=1}^{n}e\_{i}w\_{i} âŠ³\triangleright Remaining weighted equity mass

12:for k=1k=1 to nn do

13:â€ƒâ€‚Î”â€‹Ï„â†rpkâˆ’rpkâˆ’1\Delta\tau\leftarrow r\_{p\_{k}}-r\_{p\_{k-1}}

14:â€ƒâ€‚Vstepâ†Î”â€‹Ï„â‹…WremV\_{\mathrm{step}}\leftarrow\Delta\tau\cdot W\_{\mathrm{rem}}

15:â€ƒâ€‚if V+Vstepâ‰¥BTV+V\_{\mathrm{step}}\geq B\_{T} then

16:â€ƒâ€ƒâ€ƒÏ„â†rpkâˆ’1+(BTâˆ’V)/Wrem\tau\leftarrow r\_{p\_{k-1}}+(B\_{T}-V)/W\_{\mathrm{rem}} âŠ³\triangleright Found the scaling factor Ï„\tau

17:â€ƒâ€ƒâ€ƒbreak

18:â€ƒâ€‚end if

19:â€ƒâ€‚Vâ†V+VstepV\leftarrow V+V\_{\mathrm{step}}

20:â€ƒâ€‚Wremâ†Wremâˆ’epkâ€‹wpkW\_{\mathrm{rem}}\leftarrow W\_{\mathrm{rem}}-e\_{p\_{k}}w\_{p\_{k}} âŠ³\triangleright User pkp\_{k} becomes fully capped

21:end for

22:if V<BTV<B\_{T} then âŠ³\triangleright Numerical edge case

23:â€ƒâ€‚Ï„â†rpn\tau\leftarrow r\_{p\_{n}}

24:end if

25:for i=1i=1 to nn do

26:â€ƒâ€‚hiâ†minâ¡{Î²i,Ï„â€‹wi}h\_{i}\leftarrow\min\{\beta\_{i},\tau w\_{i}\}

27:end for

28:return hh

## Appendix E Risk-Aware Pro-Rata (RAP)

### E.1 Examples of Risk-Aware Pro-Rata (RAP) and Next Deficit

In this section, we provide detailed numerical examples illustrating the properties of the RAP rule and the impact of post-haircut shocks.

##### RAP Weighting Example.

We illustrate the three choices of risk models on an example at T=2T=2 where the winners are ğ’²2={A,C,E}\mathcal{W}\_{2}=\{A,C,E\} with effective leverages Î»A,2+â‰ˆ1.031\lambda^{+}\_{A,2}\approx 1.031, Î»C,2+â‰ˆ0.925\lambda^{+}\_{C,2}\approx 0.925, and Î»E,2+â‰ˆ1.548\lambda^{+}\_{E,2}\approx 1.548.
Recall that under pro-rata, the normalized shares are siPRâˆeT,is^{\mathrm{PR}}\_{i}\propto e\_{T,i}, yielding (sAPR,sCPR,sEPR)â‰ˆ(0.163,0.728,0.109)(s^{\mathrm{PR}}\_{A},s^{\mathrm{PR}}\_{C},s^{\mathrm{PR}}\_{E})\approx(0.163,0.728,0.109).
For RAP with wi=Î»iâ€‹gâ€‹(Î»i)w\_{i}=\lambda\_{i}g(\lambda\_{i}), the shares allocate proportional to eT,iâ€‹wie\_{T,i}w\_{i}.
The resulting shares (order A,C,EA,C,E) are:

* â€¢

  Linear gâ€‹(Î»)=Î»g(\lambda)=\lambda: â‰ˆ(0.164,0.589,0.246)\approx(0.164,0.589,0.246).
* â€¢

  Power gâ€‹(Î»)=Î»2g(\lambda)=\lambda^{2}: â‰ˆ(0.155,0.498,0.348)\approx(0.155,0.498,0.348).
* â€¢

  CVaR gâ€‹(Î»)=(Î»âˆ’0.9)+g(\lambda)=(\lambda-0.9)\_{+}: â‰ˆ(0.149,0.114,0.737)\approx(0.149,0.114,0.737).

RAP shifts haircut mass toward high-leverage winners; the tilt is mild for linear gg, stronger for Î»2\lambda^{2}, and concentrates almost entirely on the over-threshold tail for the CVaR model.

##### Next Deficit and Leverage Sensitivity.

Consider the setup where T=2T=2 with DTâ‰ˆ0.705D\_{T}\approx 0.705 and WTâ‰ˆ7.72W\_{T}\approx 7.72.
Under the normal pro-rata rule, the haircut rate is hTPRâ‰ˆ0.0913h^{\mathrm{PR}}\_{T}\approx 0.0913.
We consider a simple Markovian shock whose direction is uniformly random and whose magnitude grows with the winner leverage mass:

|  |  |  |
| --- | --- | --- |
|  | ZT,i=Î¾Tâ€‹Î¶T,Î¾Tâˆˆ{âˆ’1,+1}â€‹Â equiprobable,Î¶T=Î±â€‹â„“T+kT.Z\_{T,i}=\xi\_{T}\zeta\_{T},\quad\xi\_{T}\in\{-1,+1\}\text{ equiprobable},\quad\zeta\_{T}=\alpha\frac{\ell^{+}\_{T}}{k\_{T}}. |  |

With Î±=1.2\alpha=1.2, the expected next deficit is:

|  |  |  |
| --- | --- | --- |
|  | ğ„[DT+1nextâˆ£â„±T]â‰ˆ1.46>DT.\mathop{\bf E{}}[D^{\mathrm{next}}\_{T+1}\mid\mathcal{F}\_{T}]\approx 1.46>D\_{T}. |  |

This illustrates a failure mode for pro-rata when the shock kernel scales strongly with leverage: pro-rata shrinks all winners uniformly and leaves effective leverages Î»T,i\lambda\_{T,i} unchanged, so the shock magnitude Î¶T\zeta\_{T} is unaffected while residual exposure remains large on high-leverage winners.

##### Correlated Shocks Example.

Consider two winners with equal equity ee and leverage levels Î»t,1>Î»t,2â‰¥1\lambda\_{t,1}>\lambda\_{t,2}\geq 1, and budget bt=2â€‹Îµâ€‹eb\_{t}=2\varepsilon e.
Assume price shocks are AR(1): Zt+2=Ïâ€‹Zt+1+Îµt+2Z\_{t+2}=\rho Z\_{t+1}+\varepsilon\_{t+2}, Ïâˆˆ(0,1)\rho\in(0,1).
RAP with wt,iâˆÎ»t,iâ€‹Ïˆâ€‹(1/Î»t,i)w\_{t,i}\propto\lambda\_{t,i}\psi(1/\lambda\_{t,i}) puts more haircut mass on account 1 (the higher leverage account).
Assume account 1â€™s exposure to Zt+1Z\_{t+1} offsets the loss term (a "hedge") in the next step deficit: Dt+1next=(Î±âˆ’Î²â€‹st,1)â€‹Zt+1D^{\text{next}}\_{t+1}=(\alpha-\beta s\_{t,1})Z\_{t+1}.
Shrinking st,1s\_{t,1} (winner 1â€™s residual equity) weakens the hedge into t+2t+2.
Since st,1RAP<st,1PRs^{\mathrm{RAP}}\_{t,1}<s^{\mathrm{PR}}\_{t,1}, the two-step sum of deficits StS\_{t} can satisfy Stâ€‹(htPR)<Stâ€‹(htRAP)S\_{t}(h^{\mathrm{PR}}\_{t})<S\_{t}(h^{\mathrm{RAP}}\_{t}), even if RAP minimizes the one-step deficit.

##### Exchange Incentive Compatibility Example.

Consider two positions ğ”­A\mathfrak{p}\_{A} (high value, Î¸A=100\theta\_{A}=100) and ğ”­B\mathfrak{p}\_{B} (low value, Î¸B=5\theta\_{B}=5) with equal initial leverage â„“=1\ell=1.
Suppose the exchange must reduce total leverage by 1 unit.

* â€¢

  RAP (Targeted): Fully liquidates ğ”­A\mathfrak{p}\_{A}. Continuation value: 5â€‹Î²5\beta.
* â€¢

  Pro-Rata: Reduces both by 50%. Continuation value: 52.5â€‹Î²52.5\beta.

Pro-rata yields significantly higher utility by preserving the high-value trader, demonstrating that RAP need not be incentive compatible for the exchange.

### E.2 RAP Optimality and Convex Dominance

In this appendix, we prove two statements: 1) RAP optimizes the one-step next deficitÂ ([32](https://arxiv.org/html/2512.01112v1#S7.E32 "Equation 32 â€£ One-step Next Deficit. â€£ 7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization")) and 2) RAP has a smaller residual than any other comonotone haircut rule.

##### RAP optimizes Î´T\delta\_{T}.

In this section, we briefly show that RAP optimizes the one-step deficit proxy Î´T\delta\_{T}.
We do this by showing that the weights determined by the perspective transformr Ïâ€‹(Î»)\rho(\lambda), which define gâ‹†g^{\star}, optimize Î´T\delta\_{T}.

###### Proposition E.1.

Fix a round tt with budget bt=Î¸tâ€‹|Dt|b\_{t}=\theta\_{t}|D\_{t}| and per-account caps 0â‰¤Ht,iâ‰¤10\leq H\_{t,i}\leq 1. For

|  |  |  |
| --- | --- | --- |
|  | Î´tâ€‹(h)=âˆ‘iâˆˆWt(1âˆ’ht,i)â€‹Î»t,iâ€‹et,iâ€‹Ïˆiâ€‹(1Î»t,i)\delta\_{t}(h)=\sum\_{i\in W\_{t}}(1-h\_{t,i})\,\lambda\_{t,i}e\_{t,i}\,\psi\_{i}\!\Big(\tfrac{1}{\lambda\_{t,i}}\Big) |  |

the capped reverse-waterfilling with weights wt,i=Ïâ€‹(Î»t,i)=Î»t,iâ€‹Ïˆiâ€‹(1/Î»t,i)w\_{t,i}=\rho(\lambda\_{t,i})=\lambda\_{t,i}\psi\_{i}(1/\lambda\_{t,i}) minimizes Î´tâ€‹(h)\delta\_{t}(h) among all hh with âˆ‘iet,iâ€‹ht,i=bt\sum\_{i}e\_{t,i}h\_{t,i}=b\_{t} and 0â‰¤ht,iâ‰¤Ht,i0\leq h\_{t,i}\leq H\_{t,i}.

###### Proof.

Using Ïâ€‹(Î»)=Î»â€‹Ïˆâ€‹(1/Î»)\rho(\lambda)=\lambda\psi(1/\lambda),

|  |  |  |
| --- | --- | --- |
|  | Î´tâ€‹(h)=âˆ‘i(1âˆ’ht,i)â€‹Î»t,iâ€‹et,iâ€‹Ïˆâ€‹(1/Î»t,i)â‰¡Châˆ’âˆ‘iÏâ€‹(Î»t,i)â€‹et,iâ€‹ht,i\delta\_{t}(h)=\sum\_{i}(1-h\_{t,i})\,\lambda\_{t,i}e\_{t,i}\,\psi(1/\lambda\_{t,i})\equiv C\_{h}-\sum\_{i}\rho(\lambda\_{t,i})e\_{t,i}h\_{t,i} |  |

where ChC\_{h} is a constant independent of hh (can depend on Î»t,i\lambda\_{t,i}).
Maximizing âˆ‘iÏâ€‹(Î»t,i)â€‹et,iâ€‹ht,i\sum\_{i}\rho(\lambda\_{t,i})\,e\_{t,i}h\_{t,i} under âˆ‘ist,i=bt\sum\_{i}s\_{t,i}=b\_{t} and 0â‰¤st,iâ‰¤et,iâ€‹Ht,i0\leq s\_{t,i}\leq e\_{t,i}H\_{t,i} is a fractional knapsack problem solved by sorting the values Ïâ€‹(Î»t,i)\rho(\lambda\_{t,i}).
The optimizer for this problem is reverse-waterfillingÂ [BoydVandenberghe2004]:

|  |  |  |
| --- | --- | --- |
|  | ht,i=minâ¡{Ht,i,Ï„tâ‹†â€‹wt,i},wt,i=Ïâ€‹(Î»t,i),h\_{t,i}=\min\{H\_{t,i},\ \tau^{\star}\_{t}\,w\_{t,i}\},\qquad w\_{t,i}=\rho(\lambda\_{t,i}), |  |

with Ï„tâ‹†\tau^{\star}\_{t} set by âˆ‘iet,iâ€‹ht,i=bt\sum\_{i}e\_{t,i}h\_{t,i}=b\_{t}.
This choice of ww minimizes Î´t\delta\_{t} among all weighted reverse-waterfilling rules.
âˆ

##### RAP realizes Schur-convex dominance.

We first note that theoretical results from the measure theoretic literature imply than RAP should provide Schur-convex dominance.
RAP weights wi=Î»T,iâ€‹gâ€‹(Î»T,i)w\_{i}=\lambda\_{T,i}g(\lambda\_{T,i}) can be interpreted as allocating budget proportional to a coherent, law-invariant risk measure.
Specifically, let Ïâ€‹(Î»)=Î»â€‹Ïˆâ€‹(1/Î»)\rho(\lambda)=\lambda\,\psi(1/\lambda) be a risk density with Ïˆ\psi convex and nonincreasing.
This corresponds to a spectral risk measure Ïâ€‹(X)=âˆ«01ESÎ±â€‹(X)â€‹ğ‘‘Î¼â€‹(Î±)\rho(X)=\int\_{0}^{1}\mathrm{ES}\_{\alpha}(X)\,d\mu(\alpha) via the Kusuoka representationÂ [Kusuoka2001, Acerbi2002].
Choosing gâ€‹(Î»)=Ïâ€‹(Î»)/Î»g(\lambda)=\rho(\lambda)/\lambda aligns the RAP allocation with this spectral density.
Known results fromÂ [Kusuoka2001] then imply RAP with a â€œmore convexâ€ risk density (in the Schur sense) will weakly Schur-dominate any other weighted pro-rata rule with a less concentrated density.
Instead of utilizing such strong measure theoretic tools, we instead prove this directly below in an elementary manner.

###### Theorem E.2 (Constructive Schurâ€“convex dominance).

Fix TT, budget bTb\_{T}, and caps (Î²i)(\beta\_{i}). Let Ï\rho be nondecreasing and gâ‹†â€‹(Î»)=Ïâ€‹(Î»)/Î»g^{\star}(\lambda)=\rho(\lambda)/\lambda.
Consider any weighted pro-rata rule h(w)h^{(w)} with weights ww.
If the haircut share vector of h(w)h^{(w)} is no more concentrated on high-Ï\rho indices than that of RAPâ€‹(gâ‹†)\mathrm{RAP}(g^{\star}) on any fixed active set, then the residual vector of RAPâ€‹(gâ‹†)\mathrm{RAP}(g^{\star}) weakly submajorizes that of h(w)h^{(w)}:

|  |  |  |
| --- | --- | --- |
|  | zTâ€‹(RAPâ€‹(gâ‹†))âª¯wzTâ€‹(h(w)).z\_{T}(\mathrm{RAP}(g^{\star}))\preceq\_{w}z\_{T}(h^{(w)}). |  |

Thus, for any convex increasing Ï•\phi, âˆ‘Ï•â€‹(zT,iâ€‹(RAP))â‰¤âˆ‘Ï•â€‹(zT,iâ€‹(h(w)))\sum\phi(z\_{T,i}(\mathrm{RAP}))\leq\sum\phi(z\_{T,i}(h^{(w)})).

###### Proof.

We split this proof into three steps.
The first step is analogous to the proof of PropositionÂ [C.1](https://arxiv.org/html/2512.01112v1#A3.Thmtheorem1 "Proposition C.1 (Uniqueness of the Pro-Rata Rule). â€£ Properties of ADL rules. â€£ Appendix C Theoretical Properties of Capped Pro-Rata â€£ Autodeleveraging: Impossibilities and Optimization"), where we analyze the change to the weights on a piecewise constant set of intervals.
The second step is to analyze how the residuals change with budget using the piecewise-constant representation.
Given the change in residual, the final step uses the majorization inequality to show that the residual vector of RAP weakly submajorizes that of any other weighted pro-rata rule.

*Step 1: Active set and parameterization.*
We first define the active set Aâ€‹(b)A(b) as inÂ ([36](https://arxiv.org/html/2512.01112v1#A3.E36 "Equation 36 â€£ Properties of ADL rules. â€£ Appendix C Theoretical Properties of Capped Pro-Rata â€£ Autodeleveraging: Impossibilities and Optimization")).
Any weighted reverse-waterfilling with weights ww admits the water-level form

|  |  |  |
| --- | --- | --- |
|  | hT,i(w)â€‹(b)=minâ¡{Î²i,Ï„(w)â€‹(b)â€‹wi},h^{(w)}\_{T,i}(b)\;=\;\min\{\beta\_{i},\ \tau^{(w)}(b)\,w\_{i}\}, |  |

where Ï„(w)â€‹(b)\tau^{(w)}(b) is chosen so that âˆ‘ieT,iâ€‹hT,i(w)â€‹(b)=b\sum\_{i}e\_{T,i}\,h^{(w)}\_{T,i}(b)=b.
On an interval [b0,b1][b\_{0},b\_{1}] with fixed Aâ€‹(b)A(b) we have

|  |  |  |
| --- | --- | --- |
|  | dâ€‹bdâ€‹Ï„(w)=âˆ‘jâˆˆAâ€‹(b)eT,jâ€‹wj,dâ€‹hT,i(w)dâ€‹b={wiâˆ‘jâˆˆAâ€‹(b)eT,jâ€‹wj,iâˆˆAâ€‹(b),0,iâˆ‰Aâ€‹(b).\frac{db}{d\tau^{(w)}}=\sum\_{j\in A(b)}e\_{T,j}w\_{j},\qquad\frac{dh^{(w)}\_{T,i}}{db}\;=\;\begin{cases}\displaystyle\frac{w\_{i}}{\sum\_{j\in A(b)}e\_{T,j}w\_{j}},&i\in A(b),\\[4.30554pt] 0,&i\notin A(b).\end{cases} |  |

*Step 2: Residual dynamics.*
Next we look at how the residuals (e.g.Â post haircut equity) change with budget.
Write the reweighted residuals as

|  |  |  |
| --- | --- | --- |
|  | zT,iâ€‹(b)=Ïâ€‹(Î»T,i)â€‹eT,iâ€‹(1âˆ’hT,iâ€‹(b)).z\_{T,i}(b)\;=\;\rho(\lambda\_{T,i})\,e\_{T,i}\,\bigl(1-h\_{T,i}(b)\bigr). |  |

Then on [b0,b1][b\_{0},b\_{1}],

|  |  |  |
| --- | --- | --- |
|  | dâ€‹zT,i(w)dâ€‹b={âˆ’Ïâ€‹(Î»T,i)â€‹eT,iâ€‹wiâˆ‘jâˆˆAâ€‹(b)eT,jâ€‹wj,iâˆˆAâ€‹(b),0,iâˆ‰Aâ€‹(b).\frac{dz^{(w)}\_{T,i}}{db}\;=\;\begin{cases}\displaystyle-\frac{\rho(\lambda\_{T,i})\,e\_{T,i}\,w\_{i}}{\sum\_{j\in A(b)}e\_{T,j}w\_{j}},&i\in A(b),\\[4.30554pt] 0,&i\notin A(b).\end{cases} |  |

For RAPâ€‹(gâ‹†)\mathrm{RAP}(g^{\star}) we take wi=Ïâ€‹(Î»T,i)w\_{i}=\rho(\lambda\_{T,i}), giving

|  |  |  |
| --- | --- | --- |
|  | dâ€‹zT,i(RAP)dâ€‹b={âˆ’Ïâ€‹(Î»T,i)2â€‹eT,iâˆ‘jâˆˆAâ€‹(b)eT,jâ€‹Ïâ€‹(Î»T,j),iâˆˆAâ€‹(b),0,iâˆ‰Aâ€‹(b).\frac{dz^{(\mathrm{RAP})}\_{T,i}}{db}\;=\;\begin{cases}\displaystyle-\frac{\rho(\lambda\_{T,i})^{2}\,e\_{T,i}}{\sum\_{j\in A(b)}e\_{T,j}\rho(\lambda\_{T,j})},&i\in A(b),\\[4.30554pt] 0,&i\notin A(b).\end{cases} |  |

*Step 3: Majorization at each budget.* On a fixed Aâ€‹(b)A(b), sort indices by decreasing Ïâ€‹(Î»T,i)\rho(\lambda\_{T,i}).
By the hypothesis that the haircut share vector of h(w)h^{(w)} on Aâ€‹(b)A(b),

|  |  |  |
| --- | --- | --- |
|  | Ïƒi(w)â€‹(b):=eT,iâ€‹wiâˆ‘jâˆˆAâ€‹(b)eT,jâ€‹wj,\sigma^{(w)}\_{i}(b)\ :=\ \frac{e\_{T,i}w\_{i}}{\sum\_{j\in A(b)}e\_{T,j}w\_{j}}, |  |

is no more concentrated on high-Ï\rho indices than the RAP share
Ïƒi(RAP)â€‹(b)=eT,iâ€‹Ïâ€‹(Î»T,i)âˆ‘jâˆˆAâ€‹(b)eT,jâ€‹Ïâ€‹(Î»T,j)\sigma^{(\mathrm{RAP})}\_{i}(b)=\frac{e\_{T,i}\rho(\lambda\_{T,i})}{\sum\_{j\in A(b)}e\_{T,j}\rho(\lambda\_{T,j})}, the rearrangement/majorization inequality implies that for every kk,

|  |  |  |
| --- | --- | --- |
|  | âˆ‘iâ‰¤kdâ€‹zT,(i)(RAP)dâ€‹bâ‰¤âˆ‘iâ‰¤kdâ€‹zT,(i)(w)dâ€‹b\sum\_{i\leq k}\!\frac{dz^{(\mathrm{RAP})}\_{T,(i)}}{db}\;\leq\;\sum\_{i\leq k}\!\frac{dz^{(w)}\_{T,(i)}}{db} |  |

where (i)(i) denotes the order by decreasing Ï\rho.
Hence the instantaneous decrease vector under RAP weakly submajorizes that under h(w)h^{(w)} on [b0,b1][b\_{0},b\_{1}].
Integrating over bb preserves â‰ºw\prec\_{w} on the interval, and concatenating the finitely many intervals where Aâ€‹(b)A(b) changes preserves the order overall:
zTâ€‹(RAPâ€‹(gâ‹†))âª¯wzTâ€‹(h(w))z\_{T}(\mathrm{RAP}(g^{\star}))\preceq\_{w}z\_{T}(h^{(w)}).
Schurâ€“convexity then yields the separable convex loss comparison.
âˆ

### E.3 Example of the Solvency vs. Long-Term Revenue Trade-Off

This example illustrates a fundamental tension: the risk-minimizing policy (RAP) may be suboptimal for the exchangeâ€™s long-term value (LTV) because it disproportionately liquidates high-leverage users who generate the most fees. Under certain conditions, a â€œfairerâ€ policy like Pro-Rata (PR), which preserves these high-value users, yields higher total utility for the exchange.

##### Setup.

Consider an exchange with two profitable users iâˆˆ{H,L}i\in\{H,L\}. User HH is high-leverage (Î»H>Î»L\lambda\_{H}>\lambda\_{L}) and high-revenue; user LL is safer but generates less fee volume.
The exchange must raise a budget bb via haircuts h=(hH,hL)h=(h\_{H},h\_{L}) to cover a deficit.
Its objective combines immediate safety (minimizing insolvency risk) and future revenue (LTV):

|  |  |  |
| --- | --- | --- |
|  | Uexchâ€‹(h)=âˆ’Lossâ€‹(h)âŸImmediate Safety+Î²â€‹âˆ‘iâˆˆ{H,L}Î¸iâ€‹(1âˆ’hi)â€‹Î»iâŸFuture Revenue (LTV),U^{\mathrm{exch}}(h)\;=\;\underbrace{-\mathrm{Loss}(h)}\_{\text{Immediate Safety}}\;+\;\underbrace{\beta\sum\_{i\in\{H,L\}}\theta\_{i}(1-h\_{i})\lambda\_{i}}\_{\text{Future Revenue (LTV)}}, |  |

where Lossâ€‹(h)=L0âˆ’Î±Hâ€‹hHâˆ’Î±Lâ€‹hL\mathrm{Loss}(h)=L\_{0}-\alpha\_{H}h\_{H}-\alpha\_{L}h\_{L} is the expected insurance fund draw, and Î¸iâ€‹Î»i\theta\_{i}\lambda\_{i} is the expected future fee revenue per unit of equity from user ii.
We assume Î±H/eH>Î±L/eL\alpha\_{H}/e\_{H}>\alpha\_{L}/e\_{L}, meaning user HH provides the cheapest risk reduction per dollar of haircut.

##### Policy Comparison.

We compare two policies:

* â€¢

  *RAP (Risk-Minimizing):* Prioritizes risk reduction above all.
  Since HH offers the best â€œbang for the buckâ€ in safety (Î±H/eH>Î±L/eL\alpha\_{H}/e\_{H}>\alpha\_{L}/e\_{L}),131313The marginal reduction in loss per unit of budget is âˆ‚Lossâˆ‚hiâ€‹dâ€‹hidâ€‹(budget)=Î±iei\frac{\partial\mathrm{Loss}}{\partial h\_{i}}\frac{dh\_{i}}{d(\text{budget})}=\frac{\alpha\_{i}}{e\_{i}}. Since user HH has higher leverage, they have a higher risk coefficient Î±H\alpha\_{H}, making Î±H/eH\alpha\_{H}/e\_{H} the steepest descent direction for the loss function. RAP fully targets HH first: hRAP=(b/eH,0)h^{\mathrm{RAP}}=(b/e\_{H},0) (assuming b<eHb<e\_{H}).
* â€¢

  *Pro-Rata (Revenue-Preserving):* Spreads the pain evenly, setting hiPR=beH+eLh^{\mathrm{PR}}\_{i}=\frac{b}{e\_{H}+e\_{L}} for both users. This is less efficient for immediate safety but preserves more of user HHâ€™s position.

##### When an exchange prefers Pro-Rata to maximize long-term revenue.

The exchange prefers PR over RAP when the LTV gain from saving user HH outweighs the increased immediate risk.
The utility difference is:

|  |  |  |
| --- | --- | --- |
|  | Î”â€‹U=Uexchâ€‹(hPR)âˆ’Uexchâ€‹(hRAP)=Î”â€‹hHâ€‹(Î²â€‹Î¸Hâ€‹Î»Hâˆ’Î±H)âŸGain from savingÂ â€‹Hâˆ’hLPRâ€‹(Î±Lâˆ’Î²â€‹Î¸Lâ€‹Î»L)âŸCost of cuttingÂ â€‹L.\Delta U=U^{\mathrm{exch}}(h^{\mathrm{PR}})-U^{\mathrm{exch}}(h^{\mathrm{RAP}})\;=\;\underbrace{\Delta h\_{H}(\beta\theta\_{H}\lambda\_{H}-\alpha\_{H})}\_{\text{Gain from saving }H}\;-\;\underbrace{h^{\mathrm{PR}}\_{L}(\alpha\_{L}-\beta\theta\_{L}\lambda\_{L})}\_{\text{Cost of cutting }L}. |  |

If user HH is sufficiently profitable (Î¸H\theta\_{H} is large), then Î”â€‹U>0\Delta U>0.
Specifically, PR dominates RAP if the relative revenue of the high-leverage user exceeds a threshold:

|  |  |  |
| --- | --- | --- |
|  | Î¸HÎ¸Lâ‰¥Î˜â‹†=hLPRÎ”â€‹hHâ‹…Î»LÎ»H+Î±Hâˆ’hLPRÎ”â€‹hHâ€‹Î±LÎ²â€‹Î»Hâ€‹Î¸L.\frac{\theta\_{H}}{\theta\_{L}}\;\geq\;\Theta^{\star}\;=\;\frac{h^{\mathrm{PR}}\_{L}}{\Delta h\_{H}}\cdot\frac{\lambda\_{L}}{\lambda\_{H}}\;+\;\frac{\alpha\_{H}-\frac{h^{\mathrm{PR}}\_{L}}{\Delta h\_{H}}\alpha\_{L}}{\beta\,\lambda\_{H}\,\theta\_{L}}. |  |

While RAP is â€œoptimalâ€ for preventing immediate insolvency, it can be myopic. If high-leverage traders are the exchangeâ€™s cash cows, the exchange has a rational incentive to use Pro-Rata to keep them active, even at the cost of slightly higher short-term risk.

## Appendix F Stackelberg Control

In this appendix, we formalize the results ofÂ Â§[8](https://arxiv.org/html/2512.01112v1#S8 "8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization"), where we model ADL as a Stackelberg game.

### F.1 Opposing Schur orderings for time to solvency and LTV

We formalize the fundamental trade-off between aggressive debt reduction (safety) and trader fee retention (value), formalizing the example in AppendixÂ [E.3](https://arxiv.org/html/2512.01112v1#A5.SS3 "E.3 Example of the Solvency vs. Long-Term Revenue Trade-Off â€£ Appendix E Risk-Aware Pro-Rata (RAP) â€£ Autodeleveraging: Impossibilities and Optimization").
Let nt=|ğ’²t|n\_{t}=|\mathcal{W}\_{t}|.
Given any feasible strategy Ï€\pi, write ztâ€‹(Ï€)âˆˆR+ntz\_{t}(\pi)\in{\mbox{\bf R}}\_{+}^{n\_{t}} for the vector of residual debts at time tt (sorted in decreasing order).
Let ht,iÏ€âˆˆ[0,1]h\_{t,i}^{\pi}\in[0,1] be the haircut fraction for agent ii with equity et,ie\_{t,i}, so that the haircut mass is mt,iâ€‹(Ï€)=ht,iÏ€â€‹et,im\_{t,i}(\pi)=h\_{t,i}^{\pi}e\_{t,i}.
We write mtâ€‹(Ï€)âˆˆR+ntm\_{t}(\pi)\in{\mbox{\bf R}}\_{+}^{n\_{t}} for the corresponding vector of haircut masses.
Let ZtâˆˆR+ntZ\_{t}\in{\mbox{\bf R}}\_{+}^{n\_{t}} denote the equity shock at time tt, following the notation of SectionÂ [7](https://arxiv.org/html/2512.01112v1#S7.SS0.SSS0.Px1 "One-step Next Deficit. â€£ 7 Risk-aware Policies (RAP) â€£ Autodeleveraging: Impossibilities and Optimization").
These evolve componentwise as

|  |  |  |
| --- | --- | --- |
|  | zt+1,iâ€‹(Ï€)=zt,iâ€‹(Ï€)+Zt+1,iâˆ’mt,iâ€‹(Ï€),z\_{t+1,i}(\pi)=z\_{t,i}(\pi)+Z\_{t+1,i}-m\_{t,i}(\pi), |  |

so summing from Ï„=0\tau=0 to tâˆ’1t-1 yields the conservationâ€“ofâ€“mass identity

|  |  |  |  |
| --- | --- | --- | --- |
|  | ztâ€‹(Ï€)=z0+âˆ‘Ï„=1tZÏ„âˆ’âˆ‘Ï„=0tâˆ’1mÏ„â€‹(Ï€).z\_{t}(\pi)=z\_{0}+\sum\_{\tau=1}^{t}Z\_{\tau}-\sum\_{\tau=0}^{t-1}m\_{\tau}(\pi). |  | (37) |

This ensures that the equity at time tt is either initial equity, was gained or lost in a price shock, or haircut.

###### Proposition F.1 (Solvency-Revenue Trade-off).

Let AA and BB be two strategies facing the same shock sequence (Zt)t(Z\_{t})\_{t}. Assume:

1. (i)

   *Safety Dominance:* For all t<Ï„solvâ€‹(A)t<\tau\_{\mathrm{solv}}(A), strategy AA maintains weakly smaller residuals than BB in the weak submajorization order: ztâ€‹(A)âª¯wztâ€‹(B)z\_{t}(A)\preceq\_{w}z\_{t}(B).
2. (ii)

   *Retention Value:* Let Mtâ€‹(Ï€):=âˆ‘Ï„=0tâˆ’1mÏ„â€‹(Ï€)M\_{t}(\pi):=\sum\_{\tau=0}^{t-1}m\_{\tau}(\pi) be the cumulative haircut vector and suppose the lifetime value takes the form

   |  |  |  |
   | --- | --- | --- |
   |  | LTVâ€‹(Ï€)=âˆ‘tÎ²tâ€‹Gtâ€‹(Mtâ€‹(Ï€)),\mathrm{LTV}(\pi)=\sum\_{t}\beta^{t}G\_{t}(M\_{t}(\pi)), |  |

   where each stage value Gt:R+ntâ†’RG\_{t}:{\mbox{\bf R}}\_{+}^{n\_{t}}\to{\mbox{\bf R}} is Schurâ€“concave and coordinate-wise nonincreasing in MtM\_{t} (more cumulative liquidations in the weak submajorization order reduce exchange LTV).

Then:

1. (a)

   Ï„solvâ€‹(A)â‰¤Ï„solvâ€‹(B)\tau\_{\mathrm{solv}}(A)\leq\tau\_{\mathrm{solv}}(B) (Strategy AA is safer).
2. (b)

   LTVâ€‹(A)â‰¤LTVâ€‹(B)\mathrm{LTV}(A)\leq\mathrm{LTV}(B) (Strategy BB generates more value).

###### Proof.

We prove this in two steps.

*Step 1: Solvency time.*
For any t<Ï„solvâ€‹(A)t<\tau\_{\mathrm{solv}}(A) we have ztâ€‹(A)âª¯wztâ€‹(B)z\_{t}(A)\preceq\_{w}z\_{t}(B) by (i).
If BB is solvent at some such time tt so that ztâ€‹(B)=0z\_{t}(B)=0, then weak submajorization on R+nt{\mbox{\bf R}}\_{+}^{n\_{t}} forces ztâ€‹(A)=0z\_{t}(A)=0 as well, since the zero vector is minimal in this order.
Hence BB cannot become solvent strictly before AA, and Ï„solvâ€‹(A)â‰¤Ï„solvâ€‹(B)\tau\_{\mathrm{solv}}(A)\leq\tau\_{\mathrm{solv}}(B) almost surely.

*Step 2: LTV.*
From the conservationâ€“ofâ€“mass identityÂ ([37](https://arxiv.org/html/2512.01112v1#A6.E37 "Equation 37 â€£ F.1 Opposing Schur orderings for time to solvency and LTV â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")) and the fact that z0z\_{0} and (ZÏ„)Ï„(Z\_{\tau})\_{\tau} are common across strategies, the cumulative haircuts Mtâ€‹(Ï€):=âˆ‘Ï„=0tâˆ’1mÏ„â€‹(Ï€)M\_{t}(\pi):=\sum\_{\tau=0}^{t-1}m\_{\tau}(\pi) satisfy

|  |  |  |
| --- | --- | --- |
|  | Mtâ€‹(Ï€)=z0+âˆ‘Ï„=1tZÏ„âˆ’ztâ€‹(Ï€),M\_{t}(\pi)=z\_{0}+\sum\_{\tau=1}^{t}Z\_{\tau}-z\_{t}(\pi), |  |

so that

|  |  |  |
| --- | --- | --- |
|  | Mtâ€‹(A)âˆ’Mtâ€‹(B)=ztâ€‹(B)âˆ’ztâ€‹(A).M\_{t}(A)-M\_{t}(B)=z\_{t}(B)-z\_{t}(A). |  |

For each t<Ï„solvâ€‹(A)t<\tau\_{\mathrm{solv}}(A), assumptionÂ (i) gives ztâ€‹(A)âª¯wztâ€‹(B)z\_{t}(A)\preceq\_{w}z\_{t}(B), and subtracting from the common vector z0+âˆ‘Ï„=1tÎ¾Ï„z\_{0}+\sum\_{\tau=1}^{t}\xi\_{\tau} reverses the weak submajorization order, yielding Mtâ€‹(A)âª°wMtâ€‹(B)M\_{t}(A)\succeq\_{w}M\_{t}(B).
By Schurâ€“concavity and coordinate-wise monotonicity of each GtG\_{t} in (ii), this implies Gtâ€‹(Mtâ€‹(A))â‰¤Gtâ€‹(Mtâ€‹(B))G\_{t}(M\_{t}(A))\leq G\_{t}(M\_{t}(B)) for all tt, so

|  |  |  |
| --- | --- | --- |
|  | LTVâ€‹(A)=âˆ‘tÎ²tâ€‹Gtâ€‹(Mtâ€‹(A))â‰¤âˆ‘tÎ²tâ€‹Gtâ€‹(Mtâ€‹(B))=LTVâ€‹(B).\mathrm{LTV}(A)\;=\;\sum\_{t}\beta^{t}G\_{t}(M\_{t}(A))\;\leq\;\sum\_{t}\beta^{t}G\_{t}(M\_{t}(B))\;=\;\mathrm{LTV}(B). |  |

âˆ

##### Examples.

We first give a oneâ€“step illustration of PropositionÂ [F.1](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem1 "Proposition F.1 (Solvency-Revenue Trade-off). â€£ F.1 Opposing Schur orderings for time to solvency and LTV â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") and then show how its hypotheses can fail for the literal queue versus capped proâ€“rata policies.

##### Singleâ€“period trade-off.

Consider a single round with two winners and common initial residuals z0=(1,1)z\_{0}=(1,1).
Let strategy AA use aggressive haircuts M1â€‹(A)=(1,1)M\_{1}(A)=(1,1), fully clearing both accounts so that z1â€‹(A)=(0,0)z\_{1}(A)=(0,0).
Let strategy BB use milder haircuts M1â€‹(B)=(1,0)M\_{1}(B)=(1,0), clearing only the first account and leaving z1â€‹(B)=(0,1)z\_{1}(B)=(0,1).
Then z1â€‹(A)âª¯wz1â€‹(B)z\_{1}(A)\preceq\_{w}z\_{1}(B) and M1â€‹(A)âª°wM1â€‹(B)M\_{1}(A)\succeq\_{w}M\_{1}(B), so the hypotheses of PropositionÂ [F.1](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem1 "Proposition F.1 (Solvency-Revenue Trade-off). â€£ F.1 Opposing Schur orderings for time to solvency and LTV â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") hold with T=1T=1.
For a Schurâ€“concave, coordinate-wise nonincreasing stage value such as

|  |  |  |
| --- | --- | --- |
|  | G1â€‹(M):=âˆ’â€–Mâ€–22,G\_{1}(M)\;:=\;-\|M\|\_{2}^{2}, |  |

we obtain G1â€‹(M1â€‹(A))=âˆ’2G\_{1}(M\_{1}(A))=-2 and G1â€‹(M1â€‹(B))=âˆ’1G\_{1}(M\_{1}(B))=-1, so LTVâ€‹(A)â‰¤LTVâ€‹(B)\mathrm{LTV}(A)\leq\mathrm{LTV}(B), exactly exhibiting the safetyâ€“versusâ€“value trade-off.

##### Queue versus capped proâ€“rata.

Now consider the familiar oneâ€“round example with two winners, equities e=(1,1)e=(1,1), and budget b=1b=1.
Under capped proâ€“rata we have haircuts hPR=(12,12)h^{\mathrm{PR}}=(\tfrac{1}{2},\tfrac{1}{2}), masses mPR=(12,12)m^{\mathrm{PR}}=(\tfrac{1}{2},\tfrac{1}{2}), and residuals zPR=(12,12)z^{\mathrm{PR}}=(\tfrac{1}{2},\tfrac{1}{2}).
Under a queue policy we instead have hQ=(1,0)h^{\mathrm{Q}}=(1,0), so mQ=(1,0)m^{\mathrm{Q}}=(1,0) and zQ=(0,1)z^{\mathrm{Q}}=(0,1).
In weak submajorization order, zPRâ‰ºwzQz^{\mathrm{PR}}\prec\_{w}z^{\mathrm{Q}} and likewise mPRâ‰ºwmQm^{\mathrm{PR}}\prec\_{w}m^{\mathrm{Q}}.
Thus no choice of labels A,BA,B can make proâ€“rata simultaneously satisfy the safety-dominance condition ztâ€‹(A)âª¯wztâ€‹(B)z\_{t}(A)\preceq\_{w}z\_{t}(B) and the â€œmore cumulative haircutsâ€ condition Mtâ€‹(A)âª°wMtâ€‹(B)M\_{t}(A)\succeq\_{w}M\_{t}(B) in PropositionÂ [F.1](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem1 "Proposition F.1 (Solvency-Revenue Trade-off). â€£ F.1 Opposing Schur orderings for time to solvency and LTV â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization").
Moreover, for any Schurâ€“concave, coordinate-wise nonincreasing GG (for instance Gâ€‹(M)=âˆ’â€–Mâ€–22G(M)=-\|M\|\_{2}^{2}), we have Gâ€‹(mQ)â‰¤Gâ€‹(mPR)G(m^{\mathrm{Q}})\leq G(m^{\mathrm{PR}}), so in this toy case the safer policy (proâ€“rata) also delivers *higher* user value.
This shows that while PropositionÂ [F.1](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem1 "Proposition F.1 (Solvency-Revenue Trade-off). â€£ F.1 Opposing Schur orderings for time to solvency and LTV â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") captures a structural opposingâ€“orders phenomenon, its hypotheses do not hold mechanically for every queue versus capped proâ€“rata comparison.

### F.2 Regret Analysis

In this appendix, we unify the regret analysis for the severity (scalar) and MDIC (vector) controllers. We present a master theorem for Online Mirror Descent (OMD) with constraints and then specialize it to our specific settings.

##### Master Mirror Descent Bound.

Consider a sequence of convex loss functions ft:ğ’³â†’â„f\_{t}:\mathcal{X}\to\mathbb{R} on a convex set ğ’³\mathcal{X}. A learner chooses xtâˆˆğ’³x\_{t}\in\mathcal{X} and updates using Online Mirror Descent (OMD) with a proximal function (Bregman divergence) D(â‹…âˆ¥â‹…)D(\cdot\|\cdot).

###### Theorem F.2 (OMD Regret).

Let subgradients be bounded by â€–gtâ€–âˆ—â‰¤G\|g\_{t}\|\_{\*}\leq G in the dual norm, and let the domain diameter be bounded by Dmax2â‰¥maxxâ¡Dâ€‹(xâˆ¥x1)D\_{\max}^{2}\geq\max\_{x}D(x\|x\_{1}). With step size Î·t=DmaxGâ€‹t\eta\_{t}=\frac{D\_{\max}}{G\sqrt{t}}, the regret satisfies:

|  |  |  |
| --- | --- | --- |
|  | âˆ‘t=1Tftâ€‹(xt)âˆ’minxâˆˆğ’³â€‹âˆ‘t=1Tftâ€‹(x)â‰¤â€„2â€‹Dmaxâ€‹Gâ€‹T.\sum\_{t=1}^{T}f\_{t}(x\_{t})-\min\_{x\in\mathcal{X}}\sum\_{t=1}^{T}f\_{t}(x)\;\leq\;2D\_{\max}G\sqrt{T}. |  |

When convex constraints ctâ€‹(x)â‰¤0c\_{t}(x)\leq 0 are imposed, applying OMD to the Lagrangian guarantees the same Oâ€‹(T)O(\sqrt{T}) regret and Oâ€‹(Tâˆ’1/2)O(T^{-1/2}) average constraint violation [Hazan2019].

We refer the interested reader to the standard referenceÂ [Hazan2019] for a detailed proof.

##### Residual Value Function and Subgradients.

We now describe the residual value function, which is the main subject of mirror descent analysis.
For each round tt, let ğ’²t\mathcal{W}\_{t} be the set of winners with equities et,i>0e\_{t,i}>0, haircut caps Î²t,iâˆˆ[0,1]\beta\_{t,i}\in[0,1], and weights wt,iâ‰¥0w\_{t,i}\geq 0.
The residual value function parametrized by a haircut budget bb is

|  |  |  |
| --- | --- | --- |
|  | L~tâ€‹(b)=minhâˆˆ[0,1]|Wt|â€‹âˆ‘iâˆˆWt(1âˆ’hi)â€‹Î»t,iâ€‹et,is.t.âˆ‘iâˆˆWtet,iâ€‹hi=b,â€„â€„0â‰¤hiâ‰¤Î²t,i.\tilde{L}\_{t}(b)\;=\;\min\_{h\in[0,1]^{|W\_{t}|}}\;\sum\_{i\in W\_{t}}(1-h\_{i})\,\lambda\_{t,i}e\_{t,i}\quad\text{s.t.}\quad\sum\_{i\in W\_{t}}e\_{t,i}h\_{i}=b,\;\;0\leq h\_{i}\leq\beta\_{t,i}. |  |

Let Ï„tâ€‹(b)\tau\_{t}(b) be the KKT multiplier of the budget constraint at bb.

###### Lemma F.3 (Convexity and subgradient).

For each tt, bâ†¦L~tâ€‹(b)b\mapsto\tilde{L}\_{t}(b) is convex, nonincreasing, and piecewise-linear on [0,bÂ¯t][0,\bar{b}\_{t}]; any KKT multiplier âˆ’Ï„tâ€‹(b)âˆˆâˆ‚L~tâ€‹(b)-\tau\_{t}(b)\in\partial\tilde{L}\_{t}(b) is a valid subgradient.
Moreover |Ï„tâ€‹(b)|â‰¤maxiâˆˆWtâ¡wt,i|\tau\_{t}(b)|\leq\max\_{i\in W\_{t}}w\_{t,i}.

###### Proof.

The program is a linear minimization with a right-hand-side parameter bb.
Sensitivity analysis implies that the optimal value is convex and piecewise-linear in bb, and that the negative of the budget multiplier is a subgradient.
Complementary slackness yields hi=minâ¡{Î²t,i,Ï„tâ€‹(b)â€‹wt,i}h\_{i}=\min\{\beta\_{t,i},\tau\_{t}(b)w\_{t,i}\} on active coordinates, which bounds |Ï„tâ€‹(b)||\tau\_{t}(b)| by the maximum weight.
âˆ

LemmaÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem3 "Lemma F.3 (Convexity and subgradient). â€£ Residual Value Function and Subgradients. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") verifies the curvature and bounded-subgradient assumptions required by the master OMD regret theorem (TheoremÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem2 "Theorem F.2 (OMD Regret). â€£ Master Mirror Descent Bound. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")) hold, so we can directly plug L~t\tilde{L}\_{t} into that framework.

##### Severity Optimization.

In the main text, the severity controller selects a scalar severity Î¸tâˆˆ[0,Î˜t]\theta\_{t}\in[0,\Theta\_{t}] that determines the haircut budget via bt=Î¸tâ€‹Dtb\_{t}=\theta\_{t}D\_{t}.
Optimizing over btb\_{t} or Î¸t\theta\_{t} is equivalent; we keep btb\_{t} as the decision variable in the appendix for notational convenience.
The loss is ftâ€‹(b)=L~tâ€‹(b)f\_{t}(b)=\tilde{L}\_{t}(b), which is convex by LemmaÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem3 "Lemma F.3 (Convexity and subgradient). â€£ Residual Value Function and Subgradients. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization").
We use the Euclidean divergence Dâ€‹(xâˆ¥y)=12â€‹(xâˆ’y)2D(x\|y)=\tfrac{1}{2}(x-y)^{2}, reducing OMD to projected gradient descent.

###### Corollary F.4 (Severity Regret).

Let G=maxt,iâ¡wt,iG=\max\_{t,i}w\_{t,i} be the bound on subgradients (marginal haircut savings). The severity controller achieves:

|  |  |  |
| --- | --- | --- |
|  | RegretT(sev)â‰¤â€„2â€‹bÂ¯â€‹Gâ€‹T.\mathrm{Regret}\_{T}^{(\mathrm{sev})}\;\leq\;2\bar{b}G\sqrt{T}. |  |

###### Proof.

The domain diameter is bÂ¯\bar{b}. By LemmaÂ [F.3](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem3 "Lemma F.3 (Convexity and subgradient). â€£ Residual Value Function and Subgradients. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization"), subgradients correspond to dual variables bounded by the maximum weight GG. The result follows directly from TheoremÂ [F.2](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem2 "Theorem F.2 (OMD Regret). â€£ Master Mirror Descent Bound. â€£ F.2 Regret Analysis â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization").
âˆ

##### Haircut Optimization (MDIC).

The MDIC controller optimizes ut=(Î¸t,vt)u\_{t}=(\theta\_{t},v\_{t}), where Î¸t\theta\_{t} is severity and vtv\_{t} are ranking weights. We use a block-separable divergence D=DÏ•âŠ•DÎ¦D=D\_{\phi}\oplus D\_{\Phi}, where DÎ¦D\_{\Phi} is the KL-divergence for the weights.

###### Corollary F.5 (MDIC Regret).

The MDIC controller achieves regret bounded by:

|  |  |  |
| --- | --- | --- |
|  | Oâ€‹(Tâ€‹DÏ•â€‹(Î¸â‹†âˆ¥Î¸1)+Tâ€‹DÎ¦â€‹(vâ‹†âˆ¥v1)).O\left(\sqrt{TD\_{\phi}(\theta^{\star}\|\theta\_{1})}\;+\;\sqrt{TD\_{\Phi}(v^{\star}\|v\_{1})}\right). |  |

Initializing v1v\_{1} as the uniform distribution over the active winners (so every coordinate is strictly positive) minimizes DÎ¦â€‹(vâ‹†âˆ¥v1)D\_{\Phi}(v^{\star}\|v\_{1}) to Oâ€‹(logâ¡|ğ’²t|)O(\log|\mathcal{W}\_{t}|), yielding better scaling than Euclidean approaches for high-dimensional weight vectors.

###### Proof of the ğ’ªâ€‹(logâ¡|ğ’²t|)\mathcal{O}(\log|\mathcal{W}\_{t}|) claim.

The divergence DÎ¦D\_{\Phi} induced by the entropy mirror map equals the Kullbackâ€“Leibler divergence:

|  |  |  |
| --- | --- | --- |
|  | DÎ¦â€‹(vâ‹†âˆ¥v1)=âˆ‘iâˆˆWtviâ‹†â€‹logâ¡viâ‹†v1,i.D\_{\Phi}(v^{\star}\|v\_{1})=\sum\_{i\in W\_{t}}v^{\star}\_{i}\log\frac{v^{\star}\_{i}}{v\_{1,i}}. |  |

Uniform initialization over active winners sets v1,i=1/|ğ’²t|v\_{1,i}=1/|\mathcal{W}\_{t}|.
Hence

|  |  |  |
| --- | --- | --- |
|  | DÎ¦â€‹(vâ‹†âˆ¥v1)=âˆ‘iviâ‹†â€‹logâ¡viâ‹†+logâ¡|ğ’²t|.D\_{\Phi}(v^{\star}\|v\_{1})=\sum\_{i}v^{\star}\_{i}\log v^{\star}\_{i}+\log|\mathcal{W}\_{t}|. |  |

The first term is the negative Shannon entropy of vâ‹†v^{\star} and is therefore non-positive, implying DÎ¦â€‹(vâ‹†âˆ¥v1)â‰¤logâ¡|Wt|D\_{\Phi}(v^{\star}\|v\_{1})\leq\log|W\_{t}|.
Thus the initialization costs at most Oâ€‹(logâ¡|ğ’²t|)O(\log|\mathcal{W}\_{t}|).
âˆ

### F.3 Stackelberg vs. Nash in a Two-Round ADL Game

This appendix illustrates how the timing of moves affects equilibrium selection in ADL scenarios. We show that while simultaneous moves (Nash) can result in a coordination failure where no one unwinds, sequential moves (Stackelberg) allow a leader to induce the efficient high-unwind outcome.

##### Setup.

Consider two agents iâˆˆ{1,2}i\in\{1,2\}, each holding one unit of position.
At t=1t=1, each agent chooses whether to *unwind* (voluntarily close) their position (xi=1x\_{i}=1) or maintain it (xi=0x\_{i}=0).
Let X=x1+x2X=x\_{1}+x\_{2} be the total volume of voluntary unwinds.
We assume that forced ADL occurs at t=2t=2 if this volume is insufficient, i.e., if X<TX<T for some safety threshold Tâˆˆ(1,2]T\in(1,2].
Voluntary unwinding incurs a transaction cost f>0f>0.
However, if ADL is triggered (because X<TX<T), *every* agent suffers an additional penalty cost c>fc>f, regardless of their individual choice.

##### Simultaneous play (Nash).

In simultaneous play, there are two pure Nash equilibria and we effectively have a Coordination GameÂ [FudenbergTirole1991]:

* â€¢

  *Coordination failure (0,0)(0,0):* If the opponent plays 0, playing 11 results in volume 1<T1<T. ADL still triggers, yielding a total cost f+c>cf+c>c. Thus, the best response is 0, making (0,0)(0,0) stable.
* â€¢

  *Coordination success (1,1)(1,1):* If the opponent plays 11, playing 11 achieves volume 2â‰¥T2\geq T at cost ff. Since f<cf<c, this is preferred to playing 0 (which yields volume 1<T1<T and cost cc), making (1,1)(1,1) stable.

This creates a coordination problem: agents may get stuck in the inefficient (0,0)(0,0) equilibrium where ADL triggers.

###### Proposition F.6 (Stackelberg Dominance).

In sequential play where Agent 1 moves first, the unique subgame-perfect equilibrium is (1,1)(1,1). Agent 2 observes Agent 1 and will match their action (per the logic above). Agent 1 anticipates this: playing 0 leads to (0,0)(0,0) with cost cc, while playing 11 induces (1,1)(1,1) with cost ff. Since f<cf<c, Agent 1 chooses 11, eliminating the bad equilibrium.

##### Numerical Example.

Let f=1f=1, c=5c=5, and T=1.5T=1.5.
In simultaneous play, (0,0)(0,0) is stable because deviating costs 1+5=6>51+5=6>5. In Stackelberg play, the leader plays 11, knowing the follower will respond with 11 (cost 11) rather than triggering ADL (cost 55). From the exchangeâ€™s perspective, if ADL losses exceed 2â€‹f2f, the sequential outcome (1,1)(1,1) is strictly preferred as it collects fees and preserves solvency.

### F.4 Follower Strategic Responses

We study two types of follower strategic responses.
First, we show that pro-rata haircuts can lead to low leverage users responding by leaving an exchange earlier than higher leverage users.
This imposes a negative feedback loop as the exchangeâ€™s remaining users are higher risk.
Secondly, we study traders who aim to add liquidity to the exchange to cover a deficit.
These traders are speculating on profits that can be made after an ADL event.
We show that such users are incentivized to wait long than the exchange solvency time.

#### F.4.1 Adverse Selection Under Pro-Rata

We model the ADL interaction as a repeated Stackelberg game: in every round tt the exchange (leader) moves first and the surviving winners (followers) best respond.
Each stage looks like a one-round Stackelberg problem, but the outcomes feed into subsequent rounds through the evolving of winner equities eT,ie\_{T,i} and the winning set ğ’²t\mathcal{W}\_{t}.
At the start of round tt the exchange publicly commits to a severity/haircut rule (e.g.Â queue, pro-rata, RAP) that maps the realized deficit DtD\_{t} and winner book ğ’²t\mathcal{W}\_{t} to haircut shares.
After observing Î¸t\theta\_{t} and anticipating DtD\_{t}, each winner chooses whether to keep its position active (accepting the induced haircut) or to exit/migrate, receiving outside option u0u\_{0}.
Payoffs are Ui(Ï€)=Î¼iâˆ’ğ„[Ht,i(Ï€)]U\_{i}^{(\pi)}=\mu\_{i}-\mathop{\bf E{}}[H\_{t,i}^{(\pi)}]; type ii exits whenever this falls below u0u\_{0}.

A *death spiral* occurs when pro-rata haircuts force the safest (low-leverage) winners to churn first, shrinking WtW\_{t}, which in turn raises the future haircut share for the remaining winners, triggering additional exits and further eroding liquidity.
We show that RAP breaks this feedback loop by tilting the follower game against high-leverage accounts.

##### Setup.

Let ii index a profitable trader with effective equity et,ie\_{t,i}, leverage Î»t,i\lambda\_{t,i}, and expected per-round utility Î¼i\mu\_{i}.
Normalize severity and deficits by Î¸Â¯=ğ„[Î¸t]\bar{\theta}=\mathop{\bf E{}}[\theta\_{t}], DÂ¯=ğ„[Dt]\bar{D}=\mathop{\bf E{}}[D\_{t}], and write WÂ¯=ğ„[Wt]\bar{W}=\mathop{\bf E{}}[W\_{t}] for the expected equity mass of winners.
Under pro-rata, the haircut share of ii is st,iPR=et,i/Wts^{\mathrm{PR}}\_{t,i}=e\_{t,i}/W\_{t}, so the realized haircut mass is

|  |  |  |
| --- | --- | --- |
|  | Ht,iPR=Î¸tâ€‹Dtâ€‹st,iPR.H^{\mathrm{PR}}\_{t,i}=\theta\_{t}D\_{t}\,s^{\mathrm{PR}}\_{t,i}. |  |

For RAP with a nondecreasing weight gg, the share becomes

|  |  |  |
| --- | --- | --- |
|  | st,iRAP=et,iâ€‹Î»t,iâ€‹gâ€‹(Î»t,i)âˆ‘jâˆˆWtet,jâ€‹Î»t,jâ€‹gâ€‹(Î»t,j),Ht,iRAP=Î¸tâ€‹Dtâ€‹st,iRAP.s^{\mathrm{RAP}}\_{t,i}=\frac{e\_{t,i}\,\lambda\_{t,i}g(\lambda\_{t,i})}{\sum\_{j\in W\_{t}}e\_{t,j}\,\lambda\_{t,j}g(\lambda\_{t,j})},\qquad H^{\mathrm{RAP}}\_{t,i}=\theta\_{t}D\_{t}\,s^{\mathrm{RAP}}\_{t,i}. |  |

##### Risk-intensity comparator.

Define the equity-weighted market risk intensity at round tt by

|  |  |  |
| --- | --- | --- |
|  | Î¼t(g):=âˆ‘jâˆˆWtet,jâ€‹Î»t,jâ€‹gâ€‹(Î»t,j)âˆ‘jâˆˆWtet,j.\mu^{(g)}\_{t}\ :=\ \frac{\sum\_{j\in W\_{t}}e\_{t,j}\,\lambda\_{t,j}g(\lambda\_{t,j})}{\sum\_{j\in W\_{t}}e\_{t,j}}. |  |

###### Lemma F.7 (When RAP burdens a trader less than Pro-Rata).

For any winner ii,

|  |  |  |
| --- | --- | --- |
|  | st,iRAPâ‰¤st,iPRâŸºÎ»t,iâ€‹gâ€‹(Î»t,i)â‰¤Î¼t(g).s^{\mathrm{RAP}}\_{t,i}\ \leq\ s^{\mathrm{PR}}\_{t,i}\quad\Longleftrightarrow\quad\lambda\_{t,i}\,g(\lambda\_{t,i})\ \leq\ \mu^{(g)}\_{t}. |  |

If gg is strictly increasing and Î»t,i\lambda\_{t,i} is strictly below the equity-weighted market average in the gg-scale, the inequality is strict.

###### Proof.

Compute

|  |  |  |
| --- | --- | --- |
|  | st,iRAPst,iPR=et,iâ€‹Î»t,iâ€‹gâ€‹(Î»t,i)/âˆ‘jet,jâ€‹Î»t,jâ€‹gâ€‹(Î»t,j)et,i/âˆ‘jet,j=Î»t,iâ€‹gâ€‹(Î»t,i)Î¼t(g).\frac{s^{\mathrm{RAP}}\_{t,i}}{s^{\mathrm{PR}}\_{t,i}}\ =\ \frac{e\_{t,i}\lambda\_{t,i}g(\lambda\_{t,i})/\sum\_{j}e\_{t,j}\lambda\_{t,j}g(\lambda\_{t,j})}{e\_{t,i}/\sum\_{j}e\_{t,j}}\ =\ \frac{\lambda\_{t,i}g(\lambda\_{t,i})}{\mu^{(g)}\_{t}}. |  |

The claim follows immediately.
âˆ

##### Participation thresholds.

Each trader type ii has a reservation utility u0u\_{0}: the expected per-round payoff it can secure outside the ADL venue (e.g.Â by migrating flow to another exchange, posting liquidity in a different product, or simply investing idle cash in a risk-free instrument).
We treat u0>0u\_{0}>0 as exogenous and, unless stated otherwise, common across trader types.
We note that heterogeneity in reservation utility can be captured by indexing it as u0,iu\_{0,i} without changing the argument.

A trader remains active only if the ADL-adjusted payoff exceeds this fallback value.
We formalize this by defining the net utility under policy Ï€\pi as

|  |  |  |
| --- | --- | --- |
|  | Ui(Ï€):=Î¼iâˆ’ğ„[Ht,i(Ï€)],U\_{i}^{(\pi)}:=\mu\_{i}-\mathop{\bf E{}}[H\_{t,i}^{(\pi)}], |  |

and saying that ii participates in a given regime iff Ui(Ï€)â‰¥u0U\_{i}^{(\pi)}\geq u\_{0}.
Equivalently, the *participation threshold* is the maximum haircut burden ğ„[Ht,i(Ï€)]\mathop{\bf E{}}[H\_{t,i}^{(\pi)}] that keeps ii indifferent, namely Î¼iâˆ’u0\mu\_{i}-u\_{0}.

###### Corollary F.8 (Pro-Rata death spiral vs. RAP retention).

Fix a type ii and suppose there is a set of rounds of positive probability on which Î»t,iâ€‹gâ€‹(Î»t,i)â‰¤Î¼t(g)\lambda\_{t,i}g(\lambda\_{t,i})\leq\mu^{(g)}\_{t} (so st,iRAPâ‰¤st,iPRs^{\mathrm{RAP}}\_{t,i}\leq s^{\mathrm{PR}}\_{t,i} by LemmaÂ [F.7](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem7 "Lemma F.7 (When RAP burdens a trader less than Pro-Rata). â€£ Risk-intensity comparator. â€£ F.4.1 Adverse Selection Under Pro-Rata â€£ F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization")).
If, over the same distribution of rounds,

|  |  |  |
| --- | --- | --- |
|  | Î¼iâˆ’ğ„[Î¸tâ€‹Dtâ€‹st,iPR]<u0â‰¤Î¼iâˆ’ğ„[Î¸tâ€‹Dtâ€‹st,iRAP],\mu\_{i}-\mathop{\bf E{}}\big[\theta\_{t}D\_{t}\,s^{\mathrm{PR}}\_{t,i}\big]\ <\ u\_{0}\ \ \leq\ \ \mu\_{i}-\mathop{\bf E{}}\big[\theta\_{t}D\_{t}\,s^{\mathrm{RAP}}\_{t,i}\big], |  |

then the participation constraint fails under pro-rata but holds under RAP: type ii exits in the pro-rata regime while remaining under RAP.

##### Examples and calibration.

Consider two winners, LL (low leverage) and HH (high leverage), who trade for two rounds.
Equities are (eL,eH)=(60,40)(e\_{L},e\_{H})=(60,40), leverage levels are (Î»L,Î»H)=(2,6)(\lambda\_{L},\lambda\_{H})=(2,6), expected per-round utilities are (Î¼L,Î¼H)=(12,40)(\mu\_{L},\mu\_{H})=(12,40), and the outside option is u0=2u\_{0}=2.
Each round the deficit equals the total haircut budget (Î¸t=1\theta\_{t}=1) with D1=40D\_{1}=40 and D2=30D\_{2}=30.

*Pro-rata.*
Shares equal equity weights: siPR=ei/(eL+eH)s\_{i}^{\mathrm{PR}}=e\_{i}/(e\_{L}+e\_{H}), so sPR=(0.6,0.4)s^{\mathrm{PR}}=(0.6,0.4) even though both traders lose the *same haircut factor* hPR=HiPR/ei=Î¸tâ€‹Dt/Wt=0.4h^{\mathrm{PR}}=H\_{i}^{\mathrm{PR}}/e\_{i}=\theta\_{t}D\_{t}/W\_{t}=0.4.
RoundÂ 1 haircut masses are HPR=(24,16)H^{\mathrm{PR}}=(24,16) and utilities are UPR=(âˆ’12,24)U^{\mathrm{PR}}=(\!-12,24).
Trader LL churns because ULPR<u0U\_{L}^{\mathrm{PR}}<u\_{0}, leaving only HH for roundÂ 2.
With W2=40W\_{2}=40 the next deficit D2=30D\_{2}=30 forces H2,HPR=30H\_{2,H}^{\mathrm{PR}}=30 (i.e., haircut factor 0.750.75), giving U2,HPR=10U\_{2,H}^{\mathrm{PR}}=10; solvency is preserved but the equity base has already halved, so any larger D2D\_{2} would wipe out the last winner, illustrating the death spiral.

*RAP with gâ€‹(Î»)=Î»g(\lambda)=\lambda.*
Weights scale as eiâ€‹Î»i2e\_{i}\lambda\_{i}^{2}, so LLâ€™s share collapses to sLRAP=240/(240+1440)â‰ˆ0.14s\_{L}^{\mathrm{RAP}}=240/(240+1440)\approx 0.14 and HHâ€™s share rises to 0.860.86.
The roundÂ 1 haircut factors become hLRAPâ‰ˆ0.095h\_{L}^{\mathrm{RAP}}\approx 0.095 and hHRAPâ‰ˆ0.86h\_{H}^{\mathrm{RAP}}\approx 0.86 (masses HRAP=(5.7,34.3)H^{\mathrm{RAP}}=(5.7,34.3)), yielding URAP=(6.3,5.7)>u0U^{\mathrm{RAP}}=(6.3,5.7)>u\_{0}, so both types remain for roundÂ 2.
With both accounts active in roundÂ 2, shares remain tilted toward HH and haircuts (4.3,25.7)(4.3,25.7) keep both traders above u0u\_{0}, preventing churn and stabilizing WtW\_{t}.
This concrete two-player, two-round example mirrors the equilibria predicted by AppendixÂ [B.6](https://arxiv.org/html/2512.01112v1#A2.SS6 "B.6 Randomized constructions for moral-hazard examples â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization") and the empirical replay in Â§[9](https://arxiv.org/html/2512.01112v1#S9 "9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization"): pro-rata drives the safest capital away first, whereas RAP reallocates the burden toward high-leverage accounts and keeps the equity base intact.

#### F.4.2 Waiting Game and MDIC-NW

##### Game.

When an ADL event creates a deficit DtD\_{t}, the exchange moves first: it announces the contemporaneous severity Î¸t\theta\_{t} (hence the haircut budget Î¸tâ€‹Dt\theta\_{t}D\_{t}) together with the liquidity premium Îºt\kappa\_{t} it is willing to pay per unit of external capital.141414In practice, this occurs via either an increase in the expected payment for users who stake to an insurance fund (e.g.Â [DriftInsuranceFund]) or add assets to an HLP/LLP style vaultÂ [HyperliquidHLPVaults, LighterWhitepaper]
A Backstop Liquidity Provider (BLP) then decides whether to intervene immediately by injecting any qtâˆˆ[0,Dt]q\_{t}\in[0,D\_{t}] units, or to wait uâ‰¥1u\geq 1 additional rounds before posting the same quantity.
Waiting exposes the BLP to time discounting (with a factor Î²u\beta^{u}) and to the future premium schedule (Î¸t+u,Îºt+u)(\theta\_{t+u},\kappa\_{t+u}).
The BLPâ€™s payoff from intervening in round t+ut+u with size qq is Î²uâ€‹qâ€‹(Î¸t+uâˆ’Îºt+u)\beta^{u}q(\theta\_{t+u}-\kappa\_{t+u}), while the exchangeâ€™s objective is to restore solvency before a deadline by ensuring that the entire deficit is filled (so delay harms solvency).

This Stackelberg game involves the exchange posting incentives as leader and BLPs optimally choose a stopping time and quantity as a follower.
The setup captures the â€œwaiting gameâ€ intuition: unless the contract guarantees non-negative per-unit surplus right now, rational liquidity providers will defer, pushing resolution beyond the solvency window.
We note that this resembles other waiting games in Maximal Extractable Value (MEV) auctions that have been studied empirically on live systemsÂ [messias2025express, mamageishvili2025timeboost].

##### Per-unit surplus and waiting.

Let a Backstop Liquidity Provider (BLP) be able to absorb up to DtD\_{t} units at time tt.
Write the per-unit liquidity premium as Îºtâ‰¥0\kappa\_{t}\geq 0 (execution cost plus risk per unit, e.g., Îºt=Î“t/Dt\kappa\_{t}=\Gamma\_{t}/D\_{t} when the premium is linear in size) and define the per-unit net surplus

|  |  |  |
| --- | --- | --- |
|  | Î´t:=Î¸tâˆ’Îºt.\delta\_{t}\ :=\ \theta\_{t}-\kappa\_{t}. |  |

If the BLP executes qâˆˆ[0,Dt]q\in[0,D\_{t}] units at time tt, the immediate surplus is qâ€‹Î´tq\,\delta\_{t}; deferring the same qq to a later time t+ut+u yields discounted surplus Î²uâ€‹qâ€‹Î´t+u\beta^{u}q\,\delta\_{t+u}.

##### No-wait condition.

We say the exchange enforces a per-unit â€œNo-Waitâ€ constraint when Î´tâ‰¥0\delta\_{t}\geq 0 (equivalently, Î¸tâ€‹Dtâ‰¥Î“t\theta\_{t}D\_{t}\geq\Gamma\_{t} in the linear-premium case).

###### Lemma F.9 (Per-unit No-Wait implies immediate action).

Suppose Î²âˆˆ(0,1]\beta\in(0,1], the exchange enforces Î´tâ‰¥0\delta\_{t}\geq 0, and the net per-unit surplus is nonincreasing over time: Î´t+uâ‰¤Î´t\delta\_{t+u}\leq\delta\_{t} for all uâ‰¥0u\geq 0 (e.g., when Î¸t+uâ‰¤Î¸t\theta\_{t+u}\leq\theta\_{t} and Îºt+uâ‰¥Îºt\kappa\_{t+u}\geq\kappa\_{t}).
Then for any qâˆˆ[0,Dt]q\in[0,D\_{t}], executing qq immediately at tt weakly dominates waiting:

|  |  |  |
| --- | --- | --- |
|  | qâ€‹Î´tâ‰¥Î²uâ€‹qâ€‹Î´t+uâˆ€uâ‰¥0.q\,\delta\_{t}\ \geq\ \beta^{u}\,q\,\delta\_{t+u}\qquad\forall\,u\geq 0. |  |

In particular, the BLPâ€™s optimal stopping time is Ï„â‹†=t\tau^{\star}=t and, if capacity allows, qtâ‹†=Dtq\_{t}^{\star}=D\_{t}.

###### Proof.

By assumption, Î´t+uâ‰¤Î´t\delta\_{t+u}\leq\delta\_{t} and Î²uâ‰¤1\beta^{u}\leq 1 for all uâ‰¥0u\geq 0, hence Î²uâ€‹qâ€‹Î´t+uâ‰¤qâ€‹Î´t\beta^{u}q\,\delta\_{t+u}\leq q\,\delta\_{t} for any fixed qâˆˆ[0,Dt]q\in[0,D\_{t}].
Summing over an optimal decomposition of DtD\_{t} into infinitesimal units yields the stated dominance and the immediate-execution optimality.
âˆ

###### Corollary F.10 (No-Wait bounds solvency recovery).

Let Ï„def\tau\_{\mathrm{def}} denote the default time and recall the solvency recovery clock Ï„solv\tau\_{\mathrm{solv}} from Â§[8.2](https://arxiv.org/html/2512.01112v1#S8.SS2.SSS0.Px4 "Opposing Schur orderings. â€£ 8.2 Why do we need a dynamic model? â€£ 8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization").
If the exchange enforces Î´tâ‰¥0\delta\_{t}\geq 0 for all rounds between Ï„def\tau\_{\mathrm{def}} and the first round in which the deficit is zero, then Ï„solv=Ï„def+1\tau\_{\mathrm{solv}}=\tau\_{\mathrm{def}}+1.
Hence solvency is restored within a single round of the default event.

###### Proof.

LemmaÂ [F.9](https://arxiv.org/html/2512.01112v1#A6.Thmtheorem9 "Lemma F.9 (Per-unit No-Wait implies immediate action). â€£ No-wait condition. â€£ F.4.2 Waiting Game and MDIC-NW â€£ F.4 Follower Strategic Responses â€£ Appendix F Stackelberg Control â€£ Autodeleveraging: Impossibilities and Optimization") implies that at Ï„def\tau\_{\mathrm{def}} the BLP injects qÏ„defâ‹†=DÏ„defq\_{\tau\_{\mathrm{def}}}^{\star}=D\_{\tau\_{\mathrm{def}}}, so the entire deficit is covered immediately.
Therefore the insurance fund (or deficit buffer) reaches the safety level Î´\delta after the same round, yielding Ï„solv=Ï„def+1\tau\_{\mathrm{solv}}=\tau\_{\mathrm{def}}+1.
âˆ

This result states that if the no-wait condition is enforced, BLPs will inject liquidity such that the solvency time is minimized.
In theory, an exchange can use some of its future revenue or profits (e.g.Â via token issuance) to enforce the no-wait constraint.

##### Proof of PropositionÂ [8.2](https://arxiv.org/html/2512.01112v1#S8.Thmtheorem2 "Proposition 8.2 (No-Wait Condition). â€£ The Waiting Game. â€£ 8.6 Follower Robustness â€£ 8 Multipleâ€“Round ADL as a Stackelberg Control Problem â€£ Autodeleveraging: Impossibilities and Optimization")

###### Proof.

Let Uâ€‹(Ï„,q)=Î²Ï„âˆ’tâ€‹qâ€‹(Î¸Ï„âˆ’ÎºÏ„)U(\tau,q)=\beta^{\tau-t}q(\theta\_{\tau}-\kappa\_{\tau}) be the discounted utility of a BLP who provides liquidity qq at time Ï„â‰¥t\tau\geq t.
Here, Î¸Ï„\theta\_{\tau} represents the payment per unit of liquidity (derived from the ADL severity) and ÎºÏ„\kappa\_{\tau} represents the cost per unit (liquidity premium).
The BLP solves the optimal stopping problem (see, e.g.Â [Peskir2006]):

|  |  |  |
| --- | --- | --- |
|  | maxÏ„â‰¥t,qâˆˆ[0,Dt]â€‹ğ„t[Uâ€‹(Ï„,q)].\max\_{\tau\geq t,q\in[0,D\_{t}]}\mathop{\bf E{}}\_{t}\left[U(\tau,q)\right]. |  |

This objective captures the trade-off between acting immediately to capture the current spread versus waiting for potentially higher future premiums, discounted by the time cost of delay.
Assuming the BLP is risk-neutral and has capacity q=Dtq=D\_{t}, the condition for immediate stopping at Ï„=t\tau=t is that the immediate payoff exceeds the expected discounted future value:

|  |  |  |
| --- | --- | --- |
|  | Dtâ€‹(Î¸tâˆ’Îºt)â‰¥Î²â€‹ğ„t[Vt+1â€‹(Dt+1)],D\_{t}(\theta\_{t}-\kappa\_{t})\;\geq\;\beta\mathop{\bf E{}}\_{t}[V\_{t+1}(D\_{t+1})], |  |

where Vt+1â€‹(Dt+1)=maxÏ„â‰¥t+1,qâˆˆ[0,Dt+1]â€‹ğ„t+1[Uâ€‹(Ï„,q)]V\_{t+1}(D\_{t+1})=\max\_{\tau\geq t+1,q\in[0,D\_{t+1}]}\mathop{\bf E{}}\_{t+1}[U(\tau,q)] is the value function from t+1t+1 onwards.
Substituting the per-unit surplus Î´t=Î¸tâˆ’Îºt\delta\_{t}=\theta\_{t}-\kappa\_{t} and rearranging gives the condition:

|  |  |  |
| --- | --- | --- |
|  | Î¸tâ€‹Dtâ‰¥Î“t+Î²â€‹ğ„t[Vt+1â€‹(Dt+1)].\theta\_{t}D\_{t}\;\geq\;\Gamma\_{t}+\beta\mathop{\bf E{}}\_{t}[V\_{t+1}(D\_{t+1})]. |  |

In the simplified case where the BLP compares acting now vs. acting at t+Î”â€‹tt+\Delta t, and assuming capacity constraints are non-binding, the condition reduces to comparing marginal costs.
Specifically, if the cost of waiting is strictly positive (due to discounting Î²<1\beta<1 or decreasing surplus Î´t+Î”â€‹t<Î´t\delta\_{t+\Delta t}<\delta\_{t}), then the optimal strategy is to act immediately.
If, however, Î¸t\theta\_{t} decays rapidly such that Î¸tâ€‹Dt>ğ„[Î¸t+Î”â€‹tâ€‹Dt+Î”â€‹t]\theta\_{t}D\_{t}>\mathop{\bf E{}}[\theta\_{t+\Delta t}D\_{t+\Delta t}], but the premium Î“t\Gamma\_{t} makes immediate action costly, the inequality flips.
Rearranging the condition in the proposition statement:

|  |  |  |
| --- | --- | --- |
|  | Î¸tâ€‹Dt+Î“tâ‰¤ğ„t[Î¸t+Î”â€‹tâ€‹Dt+Î”â€‹t]\theta\_{t}D\_{t}+\Gamma\_{t}\leq\mathop{\bf E{}}\_{t}[\theta\_{t+\Delta t}D\_{t+\Delta t}] |  |

implies that the future expected payout (even after discounting) is higher than the current payout net of costs, incentivizing delay.
Thus, to enforce no-wait, the exchange must ensure the reverse inequality holds.
âˆ

## Appendix G Price of Anarchy Phase Transitions

We characterize the efficiency gap between static (Nash) and dynamic (Stackelberg) ADL policies via Price of Anarchy (PoA) phase transitions.
We analyze two distinct welfare objectives: *Fairness* (minimizing haircuts to winners) and *Revenue* (maximizing exchange value).
In both cases, we find a sharp transition from a bounded regime, where static policies are constant-factor optimal, to an unbounded regime, where dynamic control is strictly necessary.
Throughout, we work with the terminal book ğ’«n\mathcal{P}\_{n} of size nn as nâ†’âˆn\to\infty.

### G.1 Fairness Phase Transition

We first analyze fairness using the Profitability-to-Total-Solvency Ratio (PTSR), which measures the survival rate of winner equity relative to the total deficit covered.

#### G.1.1 Welfare and Assumptions

##### Fairness Welfare.

We define the fairness welfare of a policy Ï€\pi as its expected PTSR:

|  |  |  |
| --- | --- | --- |
|  | WFairâ€‹(Ï€):=ğ„[Ï‰TÏ€DTÏ€].W\_{\mathrm{Fair}}(\pi)\;:=\;\mathop{\bf E{}}\left[\frac{\omega\_{T}^{\pi}}{D\_{T}^{\pi}}\right]. |  |

This metric captures the efficiency of haircuts: higher values imply that the policy covers deficits DTÏ€D\_{T}^{\pi} while preserving maximal winner equity Ï‰TÏ€\omega\_{T}^{\pi}.
Extreme-value scaling implies WFairW\_{\mathrm{Fair}} scales inversely with the severity load.

##### Price of Anarchy.

We compare the welfare of a static policy Ï€stat\pi^{\mathrm{stat}} (simultaneous move) against the optimal dynamic Stackelberg policy Ï€â‹†\pi^{\star}. The Price of Anarchy is defined as the ratio:

|  |  |  |
| --- | --- | --- |
|  | PoAFair:=WFairâ€‹(Ï€â‹†)WFairâ€‹(Ï€stat).\mathrm{PoA}\_{\mathrm{Fair}}\;:=\;\frac{W\_{\mathrm{Fair}}(\pi^{\star})}{W\_{\mathrm{Fair}}(\pi^{\mathrm{stat}})}. |  |

We require the following regularity assumptions.
*LLN and EV Scaling (Prop.Â [G.1](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem1 "Proposition G.1 (LLN and EV scaling). â€£ Price of Anarchy. â€£ G.1.1 Welfare and Assumptions â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization"))* establish the baseline scales for deficits (Oâ€‹(n)O(n)) and equity (Oâ€‹(bn)O(b\_{n})).
*Anti-concentration (Prop.Â [G.2](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem2 "Proposition G.2 (Anti-concentration). â€£ Price of Anarchy. â€£ G.1.1 Welfare and Assumptions â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization"))* ensures that bnâ‰ªnb\_{n}\ll n, creating the scarcity of winner equity that drives the phase transition.

###### Proposition G.1 (LLN and EV scaling).

The number of winners knk\_{n} and losers mnm\_{n} satisfy kn,mnâ‰nk\_{n},m\_{n}\asymp n.
Winner equity and loser deficits satisfy extreme-value limits with scales bn:=bkn+b\_{n}:=b^{+}\_{k\_{n}} and bmnâˆ’b^{-}\_{m\_{n}}.

###### Proposition G.2 (Anti-concentration).

(i) *Equity:* The top winner is not dominant: bn=oâ€‹(n)b\_{n}=o(n).
(ii) *Leverage:* Max leverage scales with average leverage: maxiâ¡Î»i,TÂ±â‰¤Câ€‹â„“nÂ±/n\max\_{i}\lambda\_{i,T}^{\pm}\leq C\ell^{\pm}\_{n}/n.
(iii) *Balance:* Winner and loser leverage masses are comparable: â„“n+â‰â„“nâˆ’\ell^{+}\_{n}\asymp\ell^{-}\_{n}.

#### G.1.2 Phase Transition

The efficiency of static ADL depends on the *load* Îºn=Î¸nâ€‹n/bn\kappa\_{n}=\theta\_{n}n/b\_{n}, which measures the severity intensity relative to the tail of the winner distribution.

###### Theorem G.3 (Fairness PoA Phase Transition).

Suppose AssumptionsÂ [G.1](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem1 "Proposition G.1 (LLN and EV scaling). â€£ Price of Anarchy. â€£ G.1.1 Welfare and Assumptions â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization")â€“[G.2](https://arxiv.org/html/2512.01112v1#A7.Thmtheorem2 "Proposition G.2 (Anti-concentration). â€£ Price of Anarchy. â€£ G.1.1 Welfare and Assumptions â€£ G.1 Fairness Phase Transition â€£ Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization") hold.
Let Ï€â‹†\pi^{\star} be the optimal dynamic policy and Ï€stat\pi^{\mathrm{stat}} be any static policy with load Îºnstat\kappa\_{n}^{\mathrm{stat}}.

1. 1.

   *Bounded Regime (Low Load):*
   If supnÎºnstat<âˆ\sup\_{n}\kappa\_{n}^{\mathrm{stat}}<\infty, then static ADL is constant-factor optimal:

   |  |  |  |
   | --- | --- | --- |
   |  | lim supnâ†’âˆPoAFairâ‰¤C<âˆ.\limsup\_{n\to\infty}\mathrm{PoA}\_{\mathrm{Fair}}\;\leq\;C<\infty. |  |
2. 2.

   *Unbounded Regime (High Load):*
   If Îºnstatâ†’âˆ\kappa\_{n}^{\mathrm{stat}}\to\infty (e.g., due to heavy tails or fixed severity with bn=oâ€‹(n)b\_{n}=o(n)), then the Price of Anarchy diverges:

   |  |  |  |
   | --- | --- | --- |
   |  | PoAFairâ‰Îºnstatâ†’âˆ.\mathrm{PoA}\_{\mathrm{Fair}}\;\asymp\;\kappa\_{n}^{\mathrm{stat}}\;\to\;\infty. |  |

###### Proof.

We prove the result by establishing the scaling limits of the dynamic benchmark, the static cost, and their asymptotic ratio.

First, for the dynamic benchmark, the optimal Stackelberg policy Ï€â‹†\pi^{\star} minimizes haircuts ex-post to cover the realized deficit DTâ‰nD\_{T}\asymp n.
By targeting the haircut to preserve the top winnerâ€™s equity Ï‰Tâ‰bn\omega\_{T}\asymp b\_{n}, the dynamic policy achieves a Profitability-to-Total-Solvency Ratio (PTSR) that concentrates around a constant, WFairâ€‹(Ï€â‹†)â‰1W\_{\mathrm{Fair}}(\pi^{\star})\asymp 1 (TheoremÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem3 "Theorem B.3 (PTSR scaling). â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization")).
This is possible because the controller can observe the realization of heavy-tailed variates and adjust the severity Î¸\theta precisely to the minimal necessary level.

Second, for the static policy, the severity Î¸n\theta\_{n} is fixed ex-ante and applies a uniform pressure Î¸nâ€‹n\theta\_{n}n on the book, which must be absorbed by individual winners with capacity scaling as bnb\_{n}.
Under heavy-tailed scaling, PropositionÂ [5.1](https://arxiv.org/html/2512.01112v1#S5.Thmtheorem1 "Proposition 5.1 (Informal). â€£ Main Result. â€£ 5.1 Impossibility of Avoiding Moral Hazard as ğ‘›â†’âˆ â€£ 5 Negative Results â€£ Autodeleveraging: Impossibilities and Optimization") shows that this mismatch leads to a welfare decay WFairâ€‹(Ï€)â‰bn/(Î¸nâ€‹n)=1/ÎºnW\_{\mathrm{Fair}}(\pi)\asymp b\_{n}/(\theta\_{n}n)=1/\kappa\_{n}, as the policy blindly destroys small winners or fails to extract sufficient capital from the tail without excessive rates.
Crucially, as nâ†’âˆn\to\infty, the gap between the aggregate load Oâ€‹(n)O(n) and individual capacity Oâ€‹(bn)O(b\_{n}) widens (since bn=oâ€‹(n)b\_{n}=o(n)), forcing Îºn\kappa\_{n} to grow if Î¸n\theta\_{n} does not vanish rapidly enough.

Finally, combining these estimates yields the Price of Anarchy PoAFairâ‰1/(1/Îºnstat)=Îºnstat\mathrm{PoA}\_{\mathrm{Fair}}\asymp 1/(1/\kappa\_{n}^{\mathrm{stat}})=\kappa\_{n}^{\mathrm{stat}}.
In the bounded regime (Îºnstat=Oâ€‹(1)\kappa\_{n}^{\mathrm{stat}}=O(1)), the ratio is constant, but in the unbounded regime (Îºnstatâ†’âˆ\kappa\_{n}^{\mathrm{stat}}\to\infty), the efficiency of the static policy collapses relative to the dynamic optimum, proving the divergence.
âˆ

###### Example G.4 (Light-tailed Failure).

If winner equities are sub-Gaussian (bnâ‰logâ¡nb\_{n}\asymp\sqrt{\log n}) but the exchange uses fixed severity Î¸>0\theta>0, then Îºnstatâ‰n/logâ¡nâ†’âˆ\kappa\_{n}^{\mathrm{stat}}\asymp n/\sqrt{\log n}\to\infty.
Static ADL unnecessarily destroys winner equity compared to a dynamic policy that scales Î¸âˆ¼1/n\theta\sim 1/n, leading to infinite PoA.

### G.2 Revenue Phase Transition

We now extend the analysis to the *Revenue* objective, formalizing the trade-off between solvency and capital efficiency (LTV).

#### G.2.1 Joint Welfare

##### Solvency-Revenue Welfare.

We define the joint welfare WRevâ€‹(Ï€)W\_{\mathrm{Rev}}(\pi) as the risk-adjusted LTV, penalizing insolvency RTR\_{T} with weight Î»>1\lambda>1:

|  |  |  |
| --- | --- | --- |
|  | WRevâ€‹(Ï€):=ğ„[LTVTâ€‹(Ï€)âˆ’Î»â‹…RTâ€‹(Ï€)].W\_{\mathrm{Rev}}(\pi)\;:=\;\mathop{\bf E{}}\left[\mathrm{LTV}\_{T}(\pi)-\lambda\cdot R\_{T}(\pi)\right]. |  |

The tension arises from provisioning: Dynamic policies provision for the *average* deficit, while static policies must provision for the *tail* to ensure solvency.

#### G.2.2 Phase Transition

###### Proposition G.5 (Revenue PoA Phase Transition).

Suppose deficits have heavy tails with index Î±âˆˆ(1,2)\alpha\in(1,2) (infinite variance) and the exchange operates in the structural deficit regime (Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi}).
Let WRevâ‹†=supÏ€WRevâ€‹(Ï€)W\_{\mathrm{Rev}}^{\star}=\sup\_{\pi}W\_{\mathrm{Rev}}(\pi).

1. 1.

   *Bounded Regime (Light Tails):*
   If deficits are light-tailed, static policies that provision for the mean are efficient:

   |  |  |  |
   | --- | --- | --- |
   |  | PoARev:=WRevâ‹†WRevâ€‹(Ï€stat)â‰¤C<âˆ.\mathrm{PoA}\_{\mathrm{Rev}}\;:=\;\frac{W\_{\mathrm{Rev}}^{\star}}{W\_{\mathrm{Rev}}(\pi^{\mathrm{stat}})}\;\leq\;C<\infty. |  |
2. 2.

   *Unbounded Regime (Heavy Tails):*
   If deficits are heavy-tailed (Î±<2\alpha<2), any static policy Ï€stat\pi^{\mathrm{stat}} satisfying solvency condition (S) diverges:

   |  |  |  |
   | --- | --- | --- |
   |  | PoARevâ†’âˆ.\mathrm{PoA}\_{\mathrm{Rev}}\;\to\;\infty. |  |

###### Proof.

We establish the result by comparing the linear scaling of dynamic welfare with the sub-linear or negative welfare of static policies under heavy tails.

First, the optimal dynamic policy Ï€â‹†\pi^{\star} operates as a regulator that clears the market based on realized deficits, diverting fees Î¦T\Phi\_{T} only as strictly needed to cover DTD\_{T}.
By the Law of Large Numbers, both Î¦T\Phi\_{T} and DTD\_{T} scale linearly with nn, yielding an expected welfare WRevâ‹†â‰nâ€‹(Î¼Î¦âˆ’Î¼âˆ’)W\_{\mathrm{Rev}}^{\star}\asymp n(\mu\_{\Phi}-\mu\_{-}) that is positive and proportional to market size.

Second, a static policy is parameterized by a fixed fee diversion rate Î´âˆˆ[0,1]\delta\in[0,1] chosen ex-ante, meaning it diverts a constant fraction of fees ğ’Ÿt=Î´â€‹Ï•t\mathcal{D}\_{t}=\delta\phi\_{t} (where Î¦T=âˆ‘Ï•t\Phi\_{T}=\sum\phi\_{t} follows the scaling in AssumptionÂ [I.2](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem2 "Assumption I.2 (LLN and EVT Scaling). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")) to the insurance fund.
To build a fund KtK\_{t} capable of absorbing heavy-tailed shocks with infinite variance (Î±<2\alpha<2),
Standard ruin theoryÂ [AsmussenAlbrecher2010, Embrechts1997] implies that to ensure Solvency Condition (S) (DefinitionÂ [I.4](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem4 "Definition I.4 (Solvency). â€£ Formal Desiderata. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")) against the maximum jump Î”Tâˆ¼n1/Î±\Delta\_{T}\sim n^{1/\alpha}, the policy must essentially set Î´â†’1\delta\to 1 to handle the timing mismatch where large shocks occur before the fund accumulates.
Any policy that attempts to maintain Î´<1\delta<1 will fail solvency with probability approaching 1, while a policy with Î´â‰ˆ1\delta\approx 1 consumes the entire revenue stream, driving WRevâ€‹(Ï€stat)â†’0W\_{\mathrm{Rev}}(\pi^{\mathrm{stat}})\to 0 or into negative territory due to insolvency penalties.

Finally, the Price of Anarchy is the ratio of the linear dynamic payoff to the vanishing static payoff: PoARevâ‰n/oâ€‹(n)â†’âˆ\mathrm{PoA}\_{\mathrm{Rev}}\asymp n/o(n)\to\infty.
This divergence confirms that in the heavy-tailed regime, the information advantage of the dynamic controller (i.e.,Â knowing exactly when to divert funds) is infinitely valuable compared to a static rule.
âˆ

### G.3 The Aggregation Paradox

We conclude by observing that the divergence of PoA depends on how objectives are aggregated.

###### Proposition G.6 (Sum vs. Min Aggregation).

Let WÎ£=WFair+WRevW\_{\Sigma}=W\_{\mathrm{Fair}}+W\_{\mathrm{Rev}} and Wmin=minâ¡(WFair,WRev)W\_{\min}=\min(W\_{\mathrm{Fair}},W\_{\mathrm{Rev}}) be normalized combined objectives.

1. 1.

   *Sum-Welfare is Bounded:* PoAÎ£â‰¤2\mathrm{PoA}\_{\Sigma}\leq 2. A static policy can always choose to satisfy one objective fully, achieving at least half the optimal total score.
2. 2.

   *Min-Welfare is Unbounded:* PoAminâ†’âˆ\mathrm{PoA}\_{\min}\to\infty. In the heavy-tailed regime, static policies face the ADL Trilemma and must drive at least one objective to zero, while dynamic policies maintain both.

This implies that static ADL is sufficient if objectives are substitutes, but catastrophically inefficient if they are complements (i.e., if the exchange requires *both* fairness and revenue to survive).

## Appendix H Empirical Methodology

We backtest the mechanisms ofÂ Â§[9](https://arxiv.org/html/2512.01112v1#S9 "9 Empirical Analysis: The October 10 Event â€£ Autodeleveraging: Impossibilities and Optimization") on Hyperliquidâ€™s October 10, 2025 autodeleveraging episode.
Price shocks are represented by timestamps where the chain records an ADL tranche and are indexed by discrete times t=1,â€¦,Tt=1,\dots,T and grouped by coin cc.
Each shock carries a realized deficit Dtâ‰¥0D\_{t}\geq 0, the total negative equity of the losers in that liquidation cluster, and an account-level winner capacity vector wt=(wt,1,â€¦,wt,Wt)âˆˆR+Wtw\_{t}=(w\_{t,1},\dots,w\_{t,W\_{t}})\in{\mbox{\bf R}}\_{+}^{W\_{t}} measured in USD of available positive PNL.
Summing DtD\_{t} across shocks therefore reports the aggregate shortfall that must be socialized during the event.

Controllers either select a scalar severity Î¸tâ‰¥0\theta\_{t}\geq 0 or a haircut vector htâˆˆ[0,1]ğ’²th\_{t}\in[0,1]^{\mathcal{W}\_{t}}, generating a per-round budget Bt=Î¸tâ€‹DtB\_{t}=\theta\_{t}D\_{t} or Bt=wtâŠ¤â€‹htB\_{t}=w\_{t}^{\top}h\_{t}, respectively.
Budgets are always truncated to the realized winner capacity âˆ‘iwt,i\sum\_{i}w\_{t,i}.
The release contains T=1108T=1108 shocks across 161 coins.
Across the positive-deficit shocks this reconstruction captures 304.5304.5M USD of loser shortfall, while the corresponding winner capacity only supports 95.895.8M USD of feasible haircuts, leaving at least 208.6208.6M USD structurally uncovered irrespective of policy.

### H.1 Data construction

##### Event sample.

The data (provided by Hydromancer and SonarX) captured Hyperliquidâ€™s core exchange logs covering 21:15â€“21:30 UTC and retain every coin with at least one liquidation cluster.
There are 998 positive-deficit shocks and 110 shocks with zero deficit (for which policies trivially abstain).

##### Clustering.

Within each coin, fills are sorted by timestamp and grouped into shocks via a fixed inter-arrival rule: a new cluster begins whenever the gap since the previous fill exceeds Î”=5\Delta=5s.
If tkt\_{k} denotes the time of fill kk, the cluster index obeys Îº1=0\kappa\_{1}=0 and Îºk=Îºkâˆ’1+ğŸâ€‹{tkâˆ’tkâˆ’1>Î”}\kappa\_{k}=\kappa\_{k-1}+\mathbf{1}\{t\_{k}-t\_{k-1}>\Delta\}.
All statistics below are computed at the cluster level.

##### Account aggregates and capacities.

We aggregate filled trades (â€˜fillsâ€™) by account within a cluster.
Positive realized PNL marks winners and contributes to capacity, whereas negative PNL marks losers and contributes to the deficit Dt=âˆ‘iâˆˆâ„’t(âˆ’PNLt,i)D\_{t}=\sum\_{i\in\mathcal{L}\_{t}}(-\mathrm{PNL}\_{t,i}).
Capacities are inferred in the order notional â†’\rightarrow |start\_positionÃ—price||\texttt{start\\_position}\times\texttt{price}| â†’\rightarrow |closed\_pnl||\texttt{closed\\_pnl}|, providing a conservative haircut limit when full notional quotes are unavailable.
Queue priority scores replicate the production ranking by summing realized PNL per account within the cluster.

##### Production queue replay.

We reconstruct the realized queue budgets BtQB\_{t}^{\mathrm{Q}} and haircuts by replaying the published priority order and shaving capacity greedily until the recorded budget is exhausted.
This reproduces the overshoot and participation statistics observed on chain and serves as our baseline.

### H.2 Losses and objectives

##### Scalar severity surrogate.

Controllers that only choose Î¸t\theta\_{t} minimize the convex surrogate

|  |  |  |
| --- | --- | --- |
|  | ftâ€‹(Î¸)=âˆ’Î»â€‹Î¸â€‹Dt+Î¼â€‹(Mtâˆ’Î¸â€‹Dt)++Î½â€‹(Î¸â€‹Dtâˆ’Dt)+2,f\_{t}(\theta)=-\lambda\,\theta D\_{t}+\mu\,(M\_{t}-\theta D\_{t})\_{+}+\nu\,(\theta D\_{t}-D\_{t})\_{+}^{2}, |  |

where Mt=maxiâ¡wt,iM\_{t}=\max\_{i}w\_{t,i} is the largest winner, and Î»,Î¼,Î½â‰¥0\lambda,\mu,\nu\geq 0 trade off solvency, shortfall, and overshoot.
The subgradient satisfies

|  |  |  |
| --- | --- | --- |
|  | âˆ‚ftâ€‹(Î¸)=âˆ’Î»â€‹Dtâˆ’Î¼â€‹Dtâ€‹â€‰1â€‹{Mt>Î¸â€‹Dt}+2â€‹Î½â€‹(Î¸â€‹Dtâˆ’Dt)+â€‹Dt.\partial f\_{t}(\theta)=-\lambda D\_{t}-\mu D\_{t}\,\mathbb{1}\{M\_{t}>\theta D\_{t}\}+2\nu(\theta D\_{t}-D\_{t})\_{+}\,D\_{t}. |  |

We tune (Î»,Î¼,Î½)(\lambda,\mu,\nu) and the initialization/step-size grid (Î¸init,Î·0)(\theta\_{\text{init}},\eta\_{0}) by coarse search and fix the best setting for all severity controllers.

##### Vector objective.

When actions are full haircut vectors, we minimize

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„’tâ€‹(h)=\displaystyle\mathcal{L}\_{t}(h)={} | âˆ’Î»vecâ€‹âˆ‘i=1Wtwt,iâ€‹(1âˆ’eâˆ’Î²â€‹hi)+Î¼sprâ€‹â€–hâ€–22+Ï•â€‹â€–hâˆ’Î¸Â¯tâ€‹ğŸâ€–22\displaystyle-\lambda\_{\mathrm{vec}}\sum\_{i=1}^{W\_{t}}w\_{t,i}(1-e^{-\beta h\_{i}})+\mu\_{\mathrm{spr}}\|h\|\_{2}^{2}+\phi\,\|h-\bar{\theta}\_{t}\mathbf{1}\|\_{2}^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +Î½vecâ€‹(wtâŠ¤â€‹hâˆ’Dt)+2+Î³vecâ€‹(Dtâˆ’wtâŠ¤â€‹h)+2+Ïvecâ€‹(Dtâˆ’wtâŠ¤â€‹h)+,\displaystyle+\nu\_{\mathrm{vec}}\,(w\_{t}^{\top}h-D\_{t})\_{+}^{2}+\gamma\_{\mathrm{vec}}\,(D\_{t}-w\_{t}^{\top}h)\_{+}^{2}+\rho\_{\mathrm{vec}}\,(D\_{t}-w\_{t}^{\top}h)\_{+}, |  |

with Î¸Â¯t=minâ¡{Dt,âˆ‘iwt,i}/Dt\bar{\theta}\_{t}=\min\{D\_{t},\sum\_{i}w\_{t,i}\}/D\_{t} when Dt>0D\_{t}>0.
The weights (Î»vec,Î²,Î¼spr,Ï•,Î½vec,Î³vec,Ïvec)(\lambda\_{\mathrm{vec}},\beta,\mu\_{\mathrm{spr}},\phi,\nu\_{\mathrm{vec}},\gamma\_{\mathrm{vec}},\rho\_{\mathrm{vec}}) are fixed to the calibrated values shipped with the release.
We enforce the budget equality constraint wtâŠ¤â€‹h=Btâ‹†w\_{t}^{\top}h=B\_{t}^{\star} with Btâ‹†=minâ¡{Dt,âˆ‘iwt,i}B\_{t}^{\star}=\min\{D\_{t},\sum\_{i}w\_{t,i}\} via the projection described below.

##### Revenue loss proxy.

To translate haircut allocations into an expected loss of future fees we use a funding-rate-based proxy.
For each winner ii in shock tt we observe the realized haircut ratio ft,i=ht,i/wt,if\_{t,i}=h\_{t,i}/w\_{t,i} and treat it as a churn shock with probability pt,i=1âˆ’expâ¡(âˆ’Î²â€‹ft,i)p\_{t,i}=1-\exp(-\beta f\_{t,i}), where Î²=5\beta=5 controls sensitivity.
The remaining positive PNL wt,iw\_{t,i} serves as a conservative proxy for the traderâ€™s deployable notional.
We combine this with an estimate of per-dollar daily revenue,

|  |  |  |
| --- | --- | --- |
|  | rtdaily=24â€‹|ftfund|+Ï„turnâ‹…feetaker,r^{\text{daily}}\_{t}=24\,|f^{\text{fund}}\_{t}|+\tau\_{\text{turn}}\cdot\text{fee}\_{\text{taker}}, |  |

where |ftfund||f^{\text{fund}}\_{t}| is the absolute funding rate observed for the coin (defaulting to 1.5Ã—10âˆ’51.5\times 10^{-5} when data are sparse), Ï„turn=1\tau\_{\text{turn}}=1 assumes one notional turnover per day, and feetaker=4\text{fee}\_{\text{taker}}=4 bps.
Multiplying rtdailyr^{\text{daily}}\_{t} by a two-year horizon H=730H=730 days yields the per-dollar lifetime value estimate.
The per-shock revenue loss is then

|  |  |  |
| --- | --- | --- |
|  | RevLosst=Hâ€‹rtdailyâ€‹âˆ‘iwt,iâ€‹pt,i,\text{RevLoss}\_{t}=H\,r^{\text{daily}}\_{t}\sum\_{i}w\_{t,i}\,p\_{t,i}, |  |

which we aggregate across shocks for each controller.

The exponential hazard ensures that zero haircuts map to zero churn, while large cuts asymptotically drive pt,iâ†’1p\_{t,i}\rightarrow 1, mirroring the threshold-like exits we observe in the account-level replay data.
We set Î²=5\beta=5 so that a 10% haircut implies â‰ˆ39%\approx 39\% churn and a 20% haircut implies â‰ˆ63%\approx 63\% churn, matching the attrition rate measured by comparing pre/post-shock winner mass in the Hyperliquid October 10 datasetÂ [HyperMultiAssetedADL].
Funding rates ftfundf^{\text{fund}}\_{t} come directly from the â€œmisc eventsâ€ stream bundled with the same dataset: we aggregate the absolute funding paid per coin over the preceding hour and divide by the coinâ€™s outstanding notional to obtain an hourly rate.
When the logs lack funding entries for a coin during the 12-minute window we substitute the cross-sectional median absolute rate of 1.5Ã—10âˆ’51.5\times 10^{-5} (the BTC/ETH average).
This proxy ignores second-order follower dynamics (e.g., strategic re-entry) but provides a consistent way to compare policies on a common revenue scale using only observable quantities.

### H.3 Policies

##### Queue (production).

The production policy orders winners by the realized priority score qt,iq\_{t,i} and applies the greedy queue allocator with the recorded budget BtQB\_{t}^{\mathrm{Q}}.
Haircuts therefore match the on-chain execution and may overshoot DtD\_{t}.

##### Smart queue.

We retain the same ordering but cap the budget at the feasible mass: BtSQ=minâ¡{Dt,âˆ‘iwt,i}B\_{t}^{\mathrm{SQ}}=\min\{D\_{t},\sum\_{i}w\_{t,i}\}.
The greedy queue allocator is applied under this cap, eliminating overshoot while keeping the queueâ€™s concentration.

##### Exponential backoff.

We impose the per-round PoA cap Î˜t=R1+Râ€‹MtDt\Theta\_{t}=\frac{R}{1+R}\,\frac{M\_{t}}{D\_{t}} (uncapped if R=âˆR=\infty) and update

|  |  |  |
| --- | --- | --- |
|  | Î¸t=minâ¡{Î¸tcand,Î˜t},Î¸tcand={Î¸0,t=1,maxâ¡{Î±â€‹Î¸tâˆ’1,Î¸0},tâ‰¥2,\theta\_{t}=\min\{\theta^{\mathrm{cand}}\_{t},\Theta\_{t}\},\qquad\theta^{\mathrm{cand}}\_{t}=\begin{cases}\theta\_{0},&t=1,\\ \max\{\alpha\theta\_{t-1},\theta\_{0}\},&t\geq 2,\end{cases} |  |

with Î±âˆˆ(0,1)\alpha\in(0,1).
The resulting budget Bt=minâ¡{Î¸tâ€‹Dt,âˆ‘iwt,i}B\_{t}=\min\{\theta\_{t}D\_{t},\sum\_{i}w\_{t,i}\} is distributed pro-rata across capacities.

##### Mirror descent.

We initialize at Î¸1=Î¸init\theta\_{1}=\theta\_{\mathrm{init}}, compute gtâˆˆâˆ‚ftâ€‹(Î¸t)g\_{t}\in\partial f\_{t}(\theta\_{t}), take Î¸~t+1=Î¸tâˆ’Î·tâ€‹gt\tilde{\theta}\_{t+1}=\theta\_{t}-\eta\_{t}g\_{t} with Î·t=Î·0/t\eta\_{t}=\eta\_{0}/\sqrt{t}, perform a short backtracking line-search, and project onto [0,Î˜t][0,\Theta\_{t}].
Budgets and allocations mirror the backoff policy and differ only through the learning dynamics.

##### Dynamic2 warm start.

Dynamic2 matches mirror descent but sets Î¸1\theta\_{1} to the levered pro-rata fixed point Î¸LPR\theta\_{\mathrm{LPR}} computed from the first shock before continuing with the same updates.

##### Vector mirror descent.

We initialize htâ‰¡0h\_{t}\equiv 0 and iterate for s=1,â€¦,Ss=1,\dots,S

|  |  |  |
| --- | --- | --- |
|  | h~â†hâˆ’Î·sâ€‹âˆ‡â„’tâ€‹(h),hâ†Î ğ’tâ€‹(h~),\tilde{h}\leftarrow h-\eta\_{s}\nabla\mathcal{L}\_{t}(h),\qquad h\leftarrow\Pi\_{\mathcal{C}\_{t}}(\tilde{h}), |  |

where ğ’t={hâˆˆ[0,1]Wt:wtâŠ¤â€‹h=Btâ‹†}\mathcal{C}\_{t}=\{h\in[0,1]^{W\_{t}}:w\_{t}^{\top}h=B\_{t}^{\star}\}.
The projection solves

|  |  |  |
| --- | --- | --- |
|  | minhâˆˆ[0,1]Wtâ¡12â€‹â€–hâˆ’h~â€–22â€‹s.t.â€‹wtâŠ¤â€‹h=Btâ‹†,\min\_{h\in[0,1]^{W\_{t}}}\tfrac{1}{2}\|h-\tilde{h}\|\_{2}^{2}\ \text{s.t.}\ w\_{t}^{\top}h=B\_{t}^{\star}, |  |

and admits the closed form hiâ€‹(Ï„)=[h~iâˆ’Ï„â€‹wt,i]01h\_{i}(\tau)=\big[\tilde{h}\_{i}-\tau w\_{t,i}\big]\_{0}^{1} with Ï„\tau found by bisection so that âˆ‘iwt,iâ€‹hiâ€‹(Ï„)=Btâ‹†\sum\_{i}w\_{t,i}h\_{i}(\tau)=B\_{t}^{\star}.

### H.4 Backtest summary

##### Coverage.

Aggregate deficits over the event sum to $304.5304.5M USD.
Because winner capacity within most clusters is thin, the feasible budget Btâ‹†B\_{t}^{\star} totals only 95.895.8M USD, leaving a structural residual of 208.6208.6M USD that no policy can eliminate.

##### Production queue.

The replayed Hyperliquid queue expends $704.6704.6M USD of budgets while overshooting deficits by $630.5630.5M USD and still leaves $230.3230.3M USD of residual loss.
Average winner participation is 31.7%31.7\%, but the queue routinely concentrates haircuts: the mean budget-to-deficit ratio is 9.4Ã—1039.4\times 10^{3} and the largest single haircut reaches $47.247.2M USD.
This misallocation also destroys $602.8602.8M USD of positive PNL.

##### Queue variants.

Capping the queueâ€™s budget at feasibility removes the $630.5630.5M USD overshoot and improves average participation to 60.9%60.9\%, yet it still leaves $222.1222.1M USD of residual losses and $113.8113.8M USD of revenue destruction.

##### Adaptive severity controllers.

The exponential backoff, mirror-descent, and Dynamic2 controllers each use between $8787M and $146146M USD of budgets, moving residual losses into the $217217M USD range while avoiding overshoot (mirror) or limiting it (Dynamic2 and backoff).
Relative to production, these policies reduce winner haircuts by $365365â€“$461461M USD and modestly raise participation to 3535â€“38%38\% despite operating with the same per-round PoA cap.

##### Vector mirror descent.

Optimizing the full haircut vector supplies $87.587.5M USD of budgets, drives overshoot below 10âˆ’410^{-4} USD, and achieves the lowest residual ($217.0217.0M USD) and second-lowest revenue loss ($136.9136.9M USD).
Winner participation averages 45.2%45.2\%, reflecting the modelâ€™s explicit spreading and budget-equality constraint.

## Appendix I Formal Proof of the ADL Trilemma

In this appendix, we provide a complete formal statement and proof of the ADL Trilemma (PropositionÂ [2.1](https://arxiv.org/html/2512.01112v1#S2.Thmtheorem1 "Proposition 2.1 (Trilemma, Informal). â€£ Three competing desiderata. â€£ 2.5 ADL Trilemma â€£ 2 Background â€£ Autodeleveraging: Impossibilities and Optimization")).
The proof assembles results from AppendicesÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization")â€“[G](https://arxiv.org/html/2512.01112v1#A7 "Appendix G Price of Anarchy Phase Transitions â€£ Autodeleveraging: Impossibilities and Optimization"), demonstrating that the three-way tension between solvency, fairness, and revenue is a fundamental structural constraint under heavy-tailed shortfalls.

##### Formal Setup and Definitions.

We work in the large-market limit nâ†’âˆn\to\infty under the standard assumptions established in Â§[3](https://arxiv.org/html/2512.01112v1#S3 "3 Risk and Fairness Preliminaries â€£ Autodeleveraging: Impossibilities and Optimization") and AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization").

##### Book and Policy Sequences.

Consider a sequence of perpetuals exchanges (ğ’«n)nâ‰¥1(\mathcal{P}\_{n})\_{n\geq 1} with nn positions at terminal time TT.
Let ğ’²T\mathcal{W}\_{T} and â„’T\mathcal{L}\_{T} denote the winner and loser index sets with cardinalities kn=|ğ’²T|k\_{n}=|\mathcal{W}\_{T}| and mn=|â„’T|m\_{n}=|\mathcal{L}\_{T}|.
We assume throughout that kn,mn=Î˜â€‹(n)k\_{n},m\_{n}=\Theta(n).
We further assume the initial insurance fund capital K0K\_{0} satisfies K0=oâ€‹(n)K\_{0}=o(n), ensuring that solvency depends on flow mechanics rather than initial endowment.
A static ADL policy Ï€n\pi\_{n} is characterized by:

* â€¢

  A severity parameter Î¸nâˆˆ[0,1]\theta\_{n}\in[0,1] determining the fraction of deficit socialized;
* â€¢

  An allocation rule hn:R+knâ†’[0,1]knh\_{n}:{\mbox{\bf R}}^{k\_{n}}\_{+}\to[0,1]^{k\_{n}} distributing haircuts across winners;
* â€¢

  Insurance parameters determining the diversion of fees into the insurance fund.

##### Distributional Assumptions.

We impose the following standard assumptions from AppendixÂ [B](https://arxiv.org/html/2512.01112v1#A2 "Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization"):

###### Assumption I.1 (Regular Variation).

The right tails of the winner equity distribution FÂ¯+â€‹(x)\bar{F}\_{+}(x) and loser shortfall distribution FÂ¯âˆ’â€‹(x)\bar{F}\_{-}(x) are regularly varying with indices Î±+>0\alpha\_{+}>0 and Î±âˆ’>0\alpha\_{-}>0, respectively:

|  |  |  |
| --- | --- | --- |
|  | FÂ¯Â±â€‹(x)=LÂ±â€‹(x)â€‹xâˆ’Î±Â±,\bar{F}\_{\pm}(x)=L\_{\pm}(x)x^{-\alpha\_{\pm}}, |  |

where LÂ±L\_{\pm} are slowly varying functions.

###### Assumption I.2 (LLN and EVT Scaling).

The following scaling limits hold:

1. 1.

   *Aggregates:* WT/nâ†’ğ‘Î¼+W\_{T}/n\xrightarrow{p}\mu\_{+}, DT/nâ†’ğ‘Î¼âˆ’D\_{T}/n\xrightarrow{p}\mu\_{-}, and total fees Î¦T/nâ†’ğ‘Î¼Î¦\Phi\_{T}/n\xrightarrow{p}\mu\_{\Phi} for constants Î¼Â±,Î¼Î¦âˆˆ(0,âˆ)\mu\_{\pm},\mu\_{\Phi}\in(0,\infty).
2. 2.

   *Extremes:* The maximum winner equity Ï‰T\omega\_{T} and maximum loser shortfall Î”T\Delta\_{T} satisfy

   |  |  |  |
   | --- | --- | --- |
   |  | Ï‰Tbkn+â†’ğ‘c+,Î”Tbmnâˆ’â†’ğ‘câˆ’,\frac{\omega\_{T}}{b\_{k\_{n}}^{+}}\xrightarrow{p}c\_{+},\qquad\frac{\Delta\_{T}}{b\_{m\_{n}}^{-}}\xrightarrow{p}c\_{-}, |  |

   where bkÂ±=FÂ±âˆ’1â€‹(1âˆ’1/k)b\_{k}^{\pm}=F\_{\pm}^{-1}(1-1/k) are the extreme-value scales.

We abbreviate bn:=bkn+b\_{n}:=b\_{k\_{n}}^{+}.

###### Assumption I.3 (Structural Deficit Regime).

We assume the exchange operates in a regime where insurance alone is insufficient to cover tail risks. Specifically, the expected deficit rate exceeds the maximum sustainable fee diversion rate: Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi}.
This ensures that the Solvency constraint cannot be trivially satisfied by insurance without impacting LTV or requiring haircuts.

##### Formal Desiderata.

We now define the three desiderata precisely:

###### Definition I.4 (Solvency).

A policy family (Ï€n)(\pi\_{n}) satisfies the *solvency* condition (S) if:

1. (S1)

   *Bounded cumulative residual:* âˆ‘t=1TRtâ€‹(Ï€n)=Opâ€‹(1)\sum\_{t=1}^{T}R\_{t}(\pi\_{n})=O\_{p}(1) as nâ†’âˆn\to\infty;
2. (S2)

   *Controlled breach probability:* supn,tğğ«ğ¨ğ›[Rtâ€‹(Ï€n)>0]<1\sup\_{n,t}\mathop{\bf Prob}\!\left[R\_{t}(\pi\_{n})>0\right]<1.

###### Definition I.5 (Fairness / Bounded Moral Hazard).

A policy family (Ï€n)(\pi\_{n}) satisfies the *fairness* condition (F) if:

1. (F1)

   *PTSR stability:* There exist constants 0<cloâ‰¤chi<âˆ0<c\_{\text{lo}}\leq c\_{\text{hi}}<\infty such that

   |  |  |  |
   | --- | --- | --- |
   |  | cloâ‰¤ğ–¯ğ–³ğ–²ğ–±Tâ€‹(ğ’«n,Ï€n):=ğ„[Ï‰TÏ€nDTÏ€n]â‰¤chi;c\_{\text{lo}}\;\leq\;\mathsf{PTSR}\_{T}(\mathcal{P}\_{n},\pi\_{n}):=\mathop{\bf E{}}\left[\frac{\omega\_{T}^{\pi\_{n}}}{D\_{T}^{\pi\_{n}}}\right]\;\leq\;c\_{\text{hi}}; |  |
2. (F2)

   *PMR stability:* There exist constants 0<cloâ€²â‰¤chiâ€²<âˆ0<c^{\prime}\_{\text{lo}}\leq c^{\prime}\_{\text{hi}}<\infty such that

   |  |  |  |
   | --- | --- | --- |
   |  | cloâ€²â‰¤ğ–¯ğ–¬ğ–±Tâ€‹(ğ’«n,Ï€n):=ğ„[Ï‰TÏ€nÎ”TÏ€n]â‰¤chiâ€².c^{\prime}\_{\text{lo}}\;\leq\;\mathsf{PMR}\_{T}(\mathcal{P}\_{n},\pi\_{n}):=\mathop{\bf E{}}\left[\frac{\omega\_{T}^{\pi\_{n}}}{\Delta\_{T}^{\pi\_{n}}}\right]\;\leq\;c^{\prime}\_{\text{hi}}. |  |

These bounds ensure the top winnerâ€™s residual equity remains proportional to the deficit scale.
For brevity we write ğ–¯ğ–³ğ–²ğ–±Tâ€‹(Ï€n)\mathsf{PTSR}\_{T}(\pi\_{n}) (and ğ–¯ğ–¬ğ–±Tâ€‹(Ï€n)\mathsf{PMR}\_{T}(\pi\_{n})) whenever the dependence on ğ’«n\mathcal{P}\_{n} is clear from context.

###### Definition I.6 (Revenue Preservation).

Let Î¦Tâ€‹(Ï€)\Phi\_{T}(\pi) be the cumulative trading fees generated under policy Ï€\pi, and let ğ’ŸTâ€‹(Ï€)\mathcal{D}\_{T}(\pi) be the cumulative diversion of fees into the insurance fund. The *Exchange Long-Term Value* is defined as the net retained revenue:

|  |  |  |
| --- | --- | --- |
|  | LTVTâ€‹(Ï€):=Î¦Tâ€‹(Ï€)âˆ’ğ’ŸTâ€‹(Ï€).\mathrm{LTV}\_{T}(\pi)\;:=\;\Phi\_{T}(\pi)-\mathcal{D}\_{T}(\pi). |  |

A policy family (Ï€n)(\pi\_{n}) satisfies the *revenue* condition (R) if there exists a constant cRâˆˆ(0,1]c\_{R}\in(0,1] such that:

|  |  |  |
| --- | --- | --- |
|  | LTVTâ€‹(Ï€n)â‰¥cRâ‹…supÏ€â€²Î¦Tâ€‹(Ï€â€²).\mathrm{LTV}\_{T}(\pi\_{n})\;\geq\;c\_{R}\cdot\sup\_{\pi^{\prime}}\Phi\_{T}(\pi^{\prime}). |  |

This definition implies that (1) the policy does not cause excessive churn (reducing Î¦T\Phi\_{T}) and (2) the policy does not divert substantially all revenue to insurance (increasing ğ’ŸT\mathcal{D}\_{T} to â‰ˆÎ¦T\approx\Phi\_{T}).

##### Formal Statement of the Trilemma.

###### Theorem I.7 (ADL Trilemma).

Let (ğ’«n)nâ‰¥1(\mathcal{P}\_{n})\_{n\geq 1} be a sequence of perpetuals exchanges satisfying AssumptionsÂ [I.1](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem1 "Assumption I.1 (Regular Variation). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")â€“[I.3](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem3 "Assumption I.3 (Structural Deficit Regime). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization").
For any static ADL policy family (Ï€n)(\pi\_{n}) with severity sequence (Î¸n)(\theta\_{n}), at most two of the three conditions (S), (F), and (R) can hold simultaneously.

More precisely:

1. (I)

   (S) âˆ§\wedge (F) â‡’\Rightarrow Â¬\neg(R):
   If both solvency and fairness hold, then LTV must be sacrificed via full fee diversion, violating (R).
2. (II)

   (S) âˆ§\wedge (R) â‡’\Rightarrow Â¬\neg(F):
   If both solvency and revenue hold, then fairness is sacrificed (ğ–¯ğ–³ğ–²ğ–±Tâ†’0\mathsf{PTSR}\_{T}\to 0).
3. (III)

   (F) âˆ§\wedge (R) â‡’\Rightarrow Â¬\neg(S):
   If both fairness and revenue hold, then solvency is sacrificed (ğğ«ğ¨ğ›[Rt>0]â†’1\mathop{\bf Prob}[R\_{t}>0]\to 1).

### I.1 Proof of the Trilemma

We first establish a fundamental identity linking the three quantities.

###### Lemma I.8 (Solvency-Revenue Identity).

For any policy Ï€\pi, the cumulative deficit DTD\_{T} must be covered by the haircut budget BTB\_{T}, insurance fund diversions ğ’ŸT\mathcal{D}\_{T}, initial capital K0K\_{0}, and residual insolvency RTR\_{T}:

|  |  |  |
| --- | --- | --- |
|  | DTâ‰¤BT+ğ’ŸT+K0+RT.D\_{T}\;\leq\;B\_{T}+\mathcal{D}\_{T}+K\_{0}+R\_{T}. |  |

Substituting the LTV definition ğ’ŸT=Î¦Tâˆ’LTVT\mathcal{D}\_{T}=\Phi\_{T}-\mathrm{LTV}\_{T} and using K0=oâ€‹(n)K\_{0}=o(n), we obtain the asymptotic inequality:

|  |  |  |
| --- | --- | --- |
|  | LTVTâ€‹(Ï€)â‰¤Î¦Tâ€‹(Ï€)+BTâ€‹(Ï€)+RTâ€‹(Ï€)âˆ’DTâ€‹(Ï€)+oâ€‹(n).\mathrm{LTV}\_{T}(\pi)\;\leq\;\Phi\_{T}(\pi)+B\_{T}(\pi)+R\_{T}(\pi)-D\_{T}(\pi)+o(n). |  |

The proof then proceeds by analyzing this identity under different constraint combinations.

##### Proof of Implication (I): (S) âˆ§\wedge (F) â‡’\Rightarrow Â¬\neg(R).

###### Proof.

Suppose both (S) and (F) hold.

1. *Fairness Implication:* By (F), Î¸n=Oâ€‹(bn/n)\theta\_{n}=O(b\_{n}/n) (TheoremÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem3 "Theorem B.3 (PTSR scaling). â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization")). Since bn=oâ€‹(n)b\_{n}=o(n), the haircut budget scales as:

|  |  |  |
| --- | --- | --- |
|  | BT=Î¸nâ€‹DTâ‰bnnâ‹…n=bn=oâ€‹(n).B\_{T}=\theta\_{n}D\_{T}\asymp\frac{b\_{n}}{n}\cdot n=b\_{n}=o(n). |  |

Thus, BT/nâ†’ğ‘0B\_{T}/n\xrightarrow{p}0.

2. *Solvency Implication:* By (S), residual risk is negligible, so RT/nâ†’ğ‘0R\_{T}/n\xrightarrow{p}0.

3. *Identity Analysis:* Using the Solvency-Revenue Identity (divided by nn):

|  |  |  |
| --- | --- | --- |
|  | LTVTnâ‰¤Î¦Tn+BTn+RTnâˆ’DTn+oâ€‹(n)n.\frac{\mathrm{LTV}\_{T}}{n}\;\leq\;\frac{\Phi\_{T}}{n}+\frac{B\_{T}}{n}+\frac{R\_{T}}{n}-\frac{D\_{T}}{n}+\frac{o(n)}{n}. |  |

Taking limits nâ†’âˆn\to\infty:

|  |  |  |
| --- | --- | --- |
|  | limnâ†’âˆLTVTnâ‰¤Î¼Î¦+0+0âˆ’Î¼âˆ’+0.\lim\_{n\rightarrow\infty}\frac{\mathrm{LTV}\_{T}}{n}\;\leq\;\mu\_{\Phi}+0+0-\mu\_{-}+0. |  |

By AssumptionÂ [I.3](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem3 "Assumption I.3 (Structural Deficit Regime). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization"), Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi}.
Thus:

|  |  |  |
| --- | --- | --- |
|  | limnâ†’âˆLTVTnâ‰¤Î¼Î¦âˆ’Î¼âˆ’<â€„0.\lim\_{n\rightarrow\infty}\frac{\mathrm{LTV}\_{T}}{n}\;\leq\;\mu\_{\Phi}-\mu\_{-}\;<\;0. |  |

This inequality implies a contradiction for any solvent, self-sustaining exchange.
Since LTVT\mathrm{LTV}\_{T} represents retained earnings, a strictly negative limit implies the exchange requires external subsidies to cover the structural deficit.
In the absence of external capital, the exchange must either halt or become insolvent.
Consequently, LTVTâ€‹(Ï€n)\mathrm{LTV}\_{T}(\pi\_{n}) cannot satisfy the revenue condition (R), which requires LTVT\mathrm{LTV}\_{T} to be a positive fraction of Î¦T\Phi\_{T}.
âˆ

##### Proof of Implication (II): (S) âˆ§\wedge (R) â‡’\Rightarrow Â¬\neg(F).

###### Proof.

Suppose both (S) and (R) hold.

1. *Revenue Implication:* By (R), LTVTâ‰¥cRâ€‹Î¦T\mathrm{LTV}\_{T}\geq c\_{R}\Phi\_{T}.
This implies diversions are limited: ğ’ŸT=Î¦Tâˆ’LTVTâ‰¤(1âˆ’cR)â€‹Î¦T\mathcal{D}\_{T}=\Phi\_{T}-\mathrm{LTV}\_{T}\leq(1-c\_{R})\Phi\_{T}.

2. *Solvency Implication:* By (S), RTâ‰ˆ0R\_{T}\approx 0.
From DTâ‰¤BT+ğ’ŸT+RTD\_{T}\leq B\_{T}+\mathcal{D}\_{T}+R\_{T}, we have:

|  |  |  |
| --- | --- | --- |
|  | BTâ‰¥DTâˆ’ğ’ŸTâ‰¥DTâˆ’(1âˆ’cR)â€‹Î¦T.B\_{T}\;\geq\;D\_{T}-\mathcal{D}\_{T}\;\geq\;D\_{T}-(1-c\_{R})\Phi\_{T}. |  |

3. *Fairness Violation:*
Dividing by nn and taking limits:

|  |  |  |
| --- | --- | --- |
|  | limnâ†’âˆBTnâ‰¥Î¼âˆ’âˆ’(1âˆ’cR)â€‹Î¼Î¦.\lim\_{n\rightarrow\infty}\frac{B\_{T}}{n}\;\geq\;\mu\_{-}-(1-c\_{R})\mu\_{\Phi}. |  |

Since Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi} (AssumptionÂ [I.3](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem3 "Assumption I.3 (Structural Deficit Regime). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")) and cRâˆˆ(0,1]c\_{R}\in(0,1], the RHS is strictly positive:

|  |  |  |
| --- | --- | --- |
|  | Î¼âˆ’âˆ’(1âˆ’cR)â€‹Î¼Î¦>Î¼Î¦âˆ’(1âˆ’cR)â€‹Î¼Î¦=cRâ€‹Î¼Î¦>â€„0.\mu\_{-}-(1-c\_{R})\mu\_{\Phi}\;>\;\mu\_{\Phi}-(1-c\_{R})\mu\_{\Phi}\;=\;c\_{R}\mu\_{\Phi}\;>\;0. |  |

Thus, BT=Î˜â€‹(n)B\_{T}=\Theta(n).
Since BT=Î¸nâ€‹DTB\_{T}=\theta\_{n}D\_{T} and DT=Î˜â€‹(n)D\_{T}=\Theta(n), this implies Î¸n=Î˜â€‹(1)\theta\_{n}=\Theta(1).

With Î¸n=Î˜â€‹(1)\theta\_{n}=\Theta(1), the load Îºn=Î¸nâ€‹n/bnâ†’âˆ\kappa\_{n}=\theta\_{n}n/b\_{n}\to\infty (since bn=oâ€‹(n)b\_{n}=o(n)).
By TheoremÂ [B.3](https://arxiv.org/html/2512.01112v1#A2.Thmtheorem3 "Theorem B.3 (PTSR scaling). â€£ B.4 Asymptotic Scaling Results â€£ Appendix B Moral Hazard and Extreme Value Analysis â€£ Autodeleveraging: Impossibilities and Optimization"), ğ–¯ğ–³ğ–²ğ–±Tâ‰1/Îºnâ†’0\mathsf{PTSR}\_{T}\asymp 1/\kappa\_{n}\to 0.
This violates (F), which requires ğ–¯ğ–³ğ–²ğ–±T=Î˜â€‹(1)\mathsf{PTSR}\_{T}=\Theta(1).
âˆ

##### Proof of Implication (III): (F) âˆ§\wedge (R) â‡’\Rightarrow Â¬\neg(S).

###### Proof.

Suppose both (F) and (R) hold.

1. *Fairness Implication:* As shown in (I), (F) implies BT=oâ€‹(n)B\_{T}=o(n).

2. *Revenue Implication:* As shown in (II), (R) implies ğ’ŸTâ‰¤(1âˆ’cR)â€‹Î¦T\mathcal{D}\_{T}\leq(1-c\_{R})\Phi\_{T}.

3. *Solvency Violation:*
From the Solvency-Revenue Identity: RTâ‰¥DTâˆ’BTâˆ’ğ’ŸTR\_{T}\geq D\_{T}-B\_{T}-\mathcal{D}\_{T}.
Dividing by nn and taking limits:

|  |  |  |
| --- | --- | --- |
|  | limnâ†’âˆRTnâ‰¥Î¼âˆ’âˆ’0âˆ’(1âˆ’cR)â€‹Î¼Î¦.\lim\_{n\rightarrow\infty}\frac{R\_{T}}{n}\;\geq\;\mu\_{-}-0-(1-c\_{R})\mu\_{\Phi}. |  |

By AssumptionÂ [I.3](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem3 "Assumption I.3 (Structural Deficit Regime). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization") (Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi}), we have:

|  |  |  |
| --- | --- | --- |
|  | Î¼âˆ’âˆ’(1âˆ’cR)â€‹Î¼Î¦>Î¼Î¦âˆ’(1âˆ’cR)â€‹Î¼Î¦=cRâ€‹Î¼Î¦>â€„0.\mu\_{-}-(1-c\_{R})\mu\_{\Phi}\;>\;\mu\_{\Phi}-(1-c\_{R})\mu\_{\Phi}\;=\;c\_{R}\mu\_{\Phi}\;>\;0. |  |

Thus, RTR\_{T} scales as Î˜â€‹(n)\Theta(n).
This implies ğğ«ğ¨ğ›[RT>0]â†’1\mathop{\bf Prob}[R\_{T}>0]\to 1 and âˆ‘Rtâ†’âˆ\sum R\_{t}\to\infty, violating (S).
âˆ

##### Sharpness and Attainability.

The trilemma bound is tight in the sense that each pair of desiderata *can* be achieved by an appropriately designed policy:

###### Proposition I.9 (Attainability of Two Desiderata).

Under AssumptionsÂ [I.1](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem1 "Assumption I.1 (Regular Variation). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization")â€“[I.3](https://arxiv.org/html/2512.01112v1#A9.Thmtheorem3 "Assumption I.3 (Structural Deficit Regime). â€£ Distributional Assumptions. â€£ Appendix I Formal Proof of the ADL Trilemma â€£ Autodeleveraging: Impossibilities and Optimization"):

1. 1.

   (S) âˆ§\wedge (F) is achieved by a *high-diversion* policy: set diversions ğ’ŸTâ‰ˆÎ¦T\mathcal{D}\_{T}\approx\Phi\_{T} (taking all revenue) plus potentially external capital if Î¼âˆ’>Î¼Î¦\mu\_{-}>\mu\_{\Phi} is very large. This covers deficits (DTâ‰ˆğ’ŸTD\_{T}\approx\mathcal{D}\_{T}) with minimal haircuts (BTâ‰ˆ0B\_{T}\approx 0), satisfying (S) and (F), but reducing LTVTâ†’0\mathrm{LTV}\_{T}\to 0, violating (R).
2. 2.

   (S) âˆ§\wedge (R) is achieved by a *Queue* (concentrated haircut) policy: use high severity Î¸n=Î˜â€‹(1)\theta\_{n}=\Theta(1) to generate BTâ‰ˆDTB\_{T}\approx D\_{T}. This ensures solvency and preserves fee revenue (since ğ’ŸTâ‰ˆ0\mathcal{D}\_{T}\approx 0), but destroys the top winners (ğ–¯ğ–³ğ–²ğ–±Tâ†’0\mathsf{PTSR}\_{T}\to 0), violating (F).
3. 3.

   (F) âˆ§\wedge (R) is achieved by a *Pro-Rata with low severity* policy: use EV-scaled severity Î¸n=Oâ€‹(bn/n)\theta\_{n}=O(b\_{n}/n) and low diversion. This keeps LTVTâ‰ˆÎ¦T\mathrm{LTV}\_{T}\approx\Phi\_{T} and ğ–¯ğ–³ğ–²ğ–±T=Î˜â€‹(1)\mathsf{PTSR}\_{T}=\Theta(1), but leaves an unhedged deficit RTâ‰ˆDT>0R\_{T}\approx D\_{T}>0, violating (S).

### I.2 Connection to Classical Impossibility Results

The ADL trilemma echoes classical impossibility results in mechanism design and finance:

* â€¢

  *Arrowâ€™s Impossibility Theorem:* No voting rule satisfies Pareto efficiency, independence of irrelevant alternatives, and non-dictatorship simultaneouslyÂ [Arrow1951].
* â€¢

  *Mundell-Fleming Trilemma:* In international finance, a country cannot simultaneously maintain a fixed exchange rate, free capital movement, and independent monetary policyÂ [Mundell1963, Fleming1962].
* â€¢

  *CAP Theorem:* In distributed systems, a database cannot provide consistency, availability, and partition tolerance simultaneouslyÂ [Brewer2000, GilbertLynch2002].
* â€¢

  *Credibility Trilemma:* Single-item auctions cannot be simultaneously optimal, strategy-proof, and credible, forcing designers to sacrifice at least one desideratumÂ [AkbarpourLi2020].

These connections suggest the trilemma is a fundamental constraint arising from the heavy-tailed nature of crypto markets, not an artifact of specific mechanism choices.

##### Circumventing Impossibility via Relaxations.

While the impossibility results are strict in worst-case settings, recent literature demonstrates that they can be circumvented under probabilistic assumptions or cryptographic commitments:

1. 1.

   *Quantitative Arrowâ€™s Theorem:*
   Recent results in quantitative social choice show that while Arrowâ€™s impossibility holds in the worst case, the probability of paradoxical outcomes (like intransitivity) can be small for many natural distributions of preferencesÂ [MosselNeemanTamuz2014].
   Analogously, our ADL trilemma bounds hold with high probability under heavy-tailed distributions, but dynamic policies (like Stackelberg controllers) can minimize the frequency of trilemma-binding events, achieving a â€œquantitativeâ€ relaxation.
2. 2.

   *Probabilistic CAP Theorem:*
   Blockchains circumvent the strict CAP theorem by weakening consistency to probabilistic finality (e.g., Nakamoto consensus) or availability to liveness under synchronous periodsÂ [PassShi2017, Shi2020, ShiConsensusBook].
   This parallels the (S) vs. (R) trade-off: exchanges effectively accept probabilistic solvency (via insurance funds) to maintain liveness (continuous trading/revenue).
3. 3.

   *Cryptographic Commitments for Credibility:*
   The credibility trilemma of Akbarpour and Li motivates cryptographic mechanisms that make optimal auctions simultaneously credible and strategy-proof by enforcing operator commitmentsÂ [AkbarpourLi2020, FerreiraWeinberg2020, EssaidiFerreiraWeinberg2022, ChitraFerreiraKulkarni2024].
   For ADL, this suggests that verifiable execution (e.g.Â via zero-knowledge proofs or on-chain logic) could allow an exchange to commit to a dynamic policy that balances the trilemma better than any opaque static policy could, by removing the operatorâ€™s incentive to deviate during crises.