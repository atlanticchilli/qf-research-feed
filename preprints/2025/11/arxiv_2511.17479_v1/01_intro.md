---
authors:
- Silvia Onofri
- Andrey Shternshis
- Stefano Marmi
doc_id: arxiv:2511.17479v1
family_id: arxiv:2511.17479
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Emergence of Randomness in Temporally Aggregated Financial Tick Sequences
url_abs: http://arxiv.org/abs/2511.17479v1
url_html: https://arxiv.org/html/2511.17479v1
venue: arXiv q-fin
version: 1
year: 2025
---


Silvia Onofri1111Corresponding author: silvia.onofri@sns.it,
Andrey Shternshis2222andrey.shternshis@it.uu.se, Stefano Marmi1333stefano.marmi@sns.it
  
  
1. Scuola Normale Superiore, Piazza dei Cavalieri 7, Pisa, Italy, 56126
  
2. Uppsala University, Regementsvägen 10, Uppsala, Sweden, 75105

###### Abstract

Markets efficiency implies that the stock returns are intrinsically unpredictable, a property that makes markets comparable to random number generators.
We present a novel methodology to investigate ultra-high frequency financial data and to evaluate the extent to which tick by tick returns resemble random sequences.
We extend the analysis of ultra high-frequency stock market data by applying comprehensive sets of randomness tests, beyond the usual reliance on serial correlation or entropy measures.
Our purpose is to extensively analyze the randomness of these data using statistical tests from standard batteries that evaluate different aspects of randomness.

We illustrate the effect of time aggregation in transforming highly correlated high-frequency trade data to random streams. More specifically, we use many of the tests in the NIST Statistical Test Suite and in the TestU01 battery (in particular the Rabbit and Alphabit sub-batteries), to prove that the degree of randomness of financial tick data increases together with the increase of the aggregation level in transaction time.
Additionally, the comprehensive nature of our tests also uncovers novel patterns, such as non-monotonic behaviors in predictability for certain assets. This study demonstrates a model-free approach for both assessing randomness in financial time series and generating pseudo-random sequences from them, with potential relevance in several applications.

## 1 Introduction

A central concept in finance, the Efficient Market Hypothesis (EMH) [Fama], posits that asset prices fully and fairly reflect all available information. In its weak form, the EMH implies that future price movements are unpredictable and follow a random walk or martingale process: conditional on past information, the expected value of future price changes is zero. In this sense, an efficient market behaves like a random number generator (RNG). For instance, [chiba2024random] demonstrated that random numbers can be generated from Bitcoin price data, while [10.5555/1924892.1924895] proposed stock prices as a source of randomness for cryptographic applications.

However, empirical evidence shows that the degree of randomness in financial markets is not constant. Market efficiency and thus the randomness of price changes can vary across time periods [Lo04, Mensi] and across different markets classes [Risso1]. Moreover, randomness depends on the temporal resolution of the data. At intraday frequencies, asset prices exhibit well-documented stylized facts [Cont], i.e., empirical properties of prices such as higher volatility at market openings and closings. Prices sampled at one-minute intervals already deviate from perfect randomness because of such properties [Calcagnile], while ultra–high-frequency (tick-by-tick) data are even less random, revealing structured patterns that reflect correlated trading activity [Lillo04, Bouchaud09].

We aim to systematically investigate the randomness of financial time series across different levels of temporal aggregation. While tick-level data contain deterministic microstructure patterns, aggregated prices increasingly resemble random sequences over larger time steps. We assess the randomness of financial data across different levels of temporal aggregation using a diverse set of randomness tests. Our approach treats financial price series as potential outputs of a random number generator and applies batteries of RNG tests to measure their degree of randomness. To the best of our knowledge, this is the first study to apply such test batteries to tick-by-tick financial data.

In [10.5555/1924892.1924895, Landis25], authors proposed a methodology of developing randomness beacons from financial data for applications relying on public randomness. Financial time series and sequences generated by RNG were compared in [Moews24]. In [Machicao21], authors classified and ranked pseudo-RNGs by their quality of outputs. Prices of stocks were tested as outputs of RNG in [Doyle13]. The set of tests on efficiency were applied in [Zhang18]. Several authors have used various quantitative measures derived from information theory [Shannon, Kullback] to assess the randomness or complexity of financial time series [Dionisio, Alvarez21, Carbone22]. Comparing stock market data to the output of well-tested PRNGs can highlight areas where market behavior deviates from expected randomness. Deviations from ideal randomness can thus reveal underlying market mechanisms, including algorithmic trading behaviors that follow deterministic rules [hsieh1991chaos, scheinkman1989nonlinear].

Our study builds on previous work [shternshis2025price], in which we examined the predictability of ultra–high-frequency financial time series using entropy-based randomness tests. That analysis showed that as tick-by-tick data are aggregated over larger numbers of transactions, their predictability tends to decrease. In the present study, we extend this approach in two main directions. First, instead of relying solely on entropy-based measures, we apply a comprehensive set of randomness tests from several methodological categories, such as frequency, pattern, and spectral analyses. This allows for a broader characterization of the stochastic properties of financial data. Second, we make use of the full available dataset to obtain empirical distributions of the test outcomes, providing a new way to represent how randomness evolves across different temporal scales.

This study offers three main contributions. First, we systematize the methodology for assessing the randomness of financial time series by integrating standard randomness test suites with entropy-based measures. In particular, we employ the NIST Statistical Test Suite [Bassham\_Rukhin\_Soto\_Nechvatal\_Smid\_Barker\_Leigh\_Levenson\_Vangel\_Banks\_etal.\_2010] and TestU01 [testu01, testu01\_userguide]. As an initial methodological step, we introduce a procedure for selecting subsets of tests that are appropriate for the specific lengths of financial data sequences, ensuring valid results.
Second, we provide a broader perspective on the randomness of binary strings derived from tick-level data. In particular, we have shown that both the rate and monotonicity of convergence toward randomness, as the aggregation level increases, vary between stocks and time periods. Third, we demonstrate that as the data are aggregated, the binarized price sequences undergo a whitening effect, progressively becoming indistinguishable from random sequences. Our methodology enables the generation of ℓ\ell sub-sequences at each aggregation level ℓ\ell. That is, at an appropriate scale depending on the specific financial asset, multiple sequences pass standard randomness tests. Consequently, we propose a model-free approach for generating pseudo-random sequences from financial data, which can be leveraged for further cryptographic and other applications.

The paper is structured as follows. We revise methods used in previous literature and battery tests used to quantify the amount of randomness contained in financial data in Section [2](https://arxiv.org/html/2511.17479v1#S2 "2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). Here we also explain our approach of converting prices to binary strings, together with the description of dataset. We simulate pseudorandom number sequences and apply randomness batteries in Section [3](https://arxiv.org/html/2511.17479v1#S3 "3 Sanity check with Random Number Generators ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") to test the methods’ suitability. In Section [4](https://arxiv.org/html/2511.17479v1#S4 "4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), we conduct experiments and classify the results on randomness into several categories. Finally, in Section [5](https://arxiv.org/html/2511.17479v1#S5 "5 Conclusion and future work ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") we discuss our findings and future work.

## 2 Encoding of prices and randomness tests

We begin by describing our methodology for symbolizing price sequences, which converts financial price data into binary strings.

We focus on executed order prices and compare adjacent transactions to obtain binary strings b¯∈{0,1}∗\overline{b}\in\{0,1\}^{\*}. In more detail, given a sequence of prices {s1,s2,…,sN}\{s\_{1},s\_{2},\dots,s\_{N}\} for a certain day and ticker, we construct our first binary sequence b¯\overline{b} considering, for each i=2,…,Ni=2,\dots,N the ratio r=si−1sir=\frac{s\_{i-1}}{s\_{i}}. Then, if r<1r<1, we add a 0 to b¯\overline{b}; if r>1r>1, we add a 11 to b¯\overline{b}; if r=1r=1, we do not add any value to the sequence b¯\overline{b}.
Then, we construct other sequences by aggregating data by an aggregation level ℓ=1,…,100\ell=1,\dots,100. In order to use the full information even at high aggregation levels, we consider ℓ\ell samplings for each aggregation level ℓ\ell to build binary strings b¯j\overline{b}\_{j}, j=1,…,ℓj=1,\dots,\ell in the way explained before. So, we consider the ratio rr and update the string b¯j\overline{b}\_{j} in such a way:

|  |  |  |
| --- | --- | --- |
|  | r=sj+i​ℓsj+(i−1)​ℓ​{<1 then ​bj¯→bj¯​0=1 then ​bj¯→bj¯>1 then ​bj¯→bj¯​1r=\frac{s\_{j+i\ell}}{s\_{j+(i-1)\ell}}\begin{cases}<1&\text{ then }\overline{b\_{j}}\rightarrow\overline{b\_{j}}0\\ =1&\text{ then }\overline{b\_{j}}\rightarrow\overline{b\_{j}}\\ >1&\text{ then }\overline{b\_{j}}\rightarrow\overline{b\_{j}}1\\ \end{cases} |  |

Then, from each initial sequence of prices {s1,s2,…,sN}\{s\_{1},s\_{2},\dots,s\_{N}\} we get ∑ℓ=1100ℓ=5050\sum\_{\ell=1}^{100}\ell=5050 different binary sequences for each analyzed day. We emphasize that this methodology does not require any future information on the data, since, at the time of transaction ii, we only use one past transaction to build the ratios. This means that it can indeed be interpreted as an online approach.

We use randomness tests on these binary sequences to investigate the amount of predictability in prices.
Batteries of randomness tests are mainly thought for the testing of cryptographic strings, which are usually very long. Since the strings obtained from each analyzed day are not long enough, we run the tests on strings that contain the concatenation of data for an whole month. That is, for each aggregation level ℓ=1,…,100\ell=1,\dots,100 and for each sample j=1,…,ℓj=1,\dots,\ell, we run the test on a concatenated string obtained as b¯m=b¯d1​‖…‖​b¯dn\overline{b}^{m}=\overline{b}^{d\_{1}}||\dots||\overline{b}^{d\_{n}}, where the {b¯di}i=1,…,n\{\overline{b}^{d\_{i}}\}\_{i=1,\dots,n} are the strings obtained for each analyzed day of the month mm.

### 2.1 Randomness tests

There are different perspectives from which randomness could be determined. The variety of tests to identify random sequences investigates, for example, frequencies of strings, patterns and entropy.

In fact, a randomness test is a statistical test that, given a binary string as input, outputs the decision between accepting or rejecting the hypothesis H0H\_{0}=the string is random (or the hypothesis HaH\_{a}=the string is non-random). To test a certain property, each test uses a reference distribution and tests whether the one produced by the tested string is similar to the one produced by a random string.

For each battery, we fix a level of significance α\alpha, that represents the threshold for probability of a false negative error, i.e., α=ℙ​( accept ​Ha|H0​ is true)\alpha=\mathbb{P}(\text{ accept }H\_{a}|H\_{0}\text{ is true}).
The final decision between accepting or rejecting the null hypothesis is made by comparing α\alpha with a p​-valuep\text{-value} obtained from the computed statistic. The p​-valuep\text{-value} represents the probability that a perfect RNG would have produced a sequence less random than the one tested. So, once we have computed the p​-valuep\text{-value}s, we have two possible outcomes. If the test is one-tailed, then:

* •

  if p​-value≥αp\text{-value}\geq\alpha, then accept H0H\_{0}.
* •

  if p​-value<αp\text{-value}<\alpha, then reject H0H\_{0}.

If the test is two-tailed, then the choice is made by:

* •

  if α2≤p​-value≤1−α2\frac{\alpha}{2}\leq p\text{-value}\leq 1-\frac{\alpha}{2}, then accept H0H\_{0}.
* •

  if p​-value<α2p\text{-value}<\frac{\alpha}{2} or p​-value>α2p\text{-value}>\frac{\alpha}{2}, then reject H0H\_{0}.

In the following, the value of α\alpha is always assumed to be fixed to 0.010.01.

Thus, the common output of all tests are pp-values, allowing us to conclude if the hypothesis on randomness can be rejected. Section [2.1.1](https://arxiv.org/html/2511.17479v1#S2.SS1.SSS1 "2.1.1 Entropy-based tests ‣ 2.1 Randomness tests ‣ 2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") demonstrates how entropy-based statistics are constructed. Other tests are taken from two batteries: NIST Statistical Test Suite and TestU01. In particular, we use NIST STS version 2.1.2 and TestU01 version 1.2.3 (we focus on the Alphabit and Rabbit sub-batteries). Through these batteries, we distinguish five main different points of view on randomness analysis:

* •

  Frequency tests: they evaluate in several ways whether the proportion of zeros and ones is coherent with the one of a uniform distribution.
* •

  Pattern tests: they detect specific local structures, repeated patterns, and correlations between bits.
* •

  Entropy and complexity tests: they assess how difficult a sequence is to compress or predict, using measures such as entropy estimation or linear complexity.
* •

  Spectral tests: they apply discrete Fourier transforms to detect periodic structures or unexpected frequency spikes that would not be present in truly random data.
* •

  Random Walks tests: they analyze the cumulative behavior of sequences interpreted as random walks, checking for imbalances, excursions from the origin, and path regularities.

| Category | NIST STS | Rabbit | Alphabit |
| --- | --- | --- | --- |
| Frequency tests | Frequency (Monobit),  Frequency Test within a Block | MultinomialBitsOverlapping,  HammingWeight | MultinomialBitsOverlapping (x4) |
| Pattern tests | Runs Test,  Longest Run of Ones in a Block,  Non‐overlapping Template Matching,  Overlapping Template Matching,  Serial Test | ClosePairsBitMatch(x2),  LongestHeadRun,  PeriodsInStrings,  HammingCorrelation(x3),  HammingIndependence(x3),  AutoCorrelation(x2),  Runs Test | HammingCorrelation,  HammingIndependence (x2) |
| Entropy and complexity tests | Binary Matrix Rank Test,  Maurer’s Universal Statistical Test,  Linear Complexity Test,  Approximate Entropy Test | AppearanceSpacings,  LinearComp,  LempelZiv,  MatrixRank(x3) | – |
| Spectral tests | Discrete Fourier Transform | Fourier1,  Fourier3 | – |
| Random walks tests | Cumulative Sums Test,  Random Excursions Test,  Random Excursions Variant Test | RandomWalk1(x3),  RandomExcursions,  RandomExcursionsVariant | RandomWalk1(x2) |

Table 1: Taxonomy of tests from NIST STS, Alphabit and Rabbit batteries.

A classification of the tests we use is given in Table [1](https://arxiv.org/html/2511.17479v1#S2.T1 "Table 1 ‣ 2.1 Randomness tests ‣ 2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). A description of these tests and how we use them is given in the following subsections.

#### 2.1.1 Entropy-based tests

We recall two entropy-based tests introduced in [shternshis2025price].
Let X={x1,x2,…,xN}X=\{x\_{1},x\_{2},\dots,x\_{N}\}
be a realization of a stationary random process with symbols from a binary alphabet: xi∈{0,1}x\_{i}\in\{0,1\}. If the sequence is fully random, then all strings of length k<Nk<N have equal probabilities to be met in the sequence XX. Then, the hypothesis of full randomness can be tested by evaluating empirical probabilities of appearing all possible blocks of kk symbols. Using the probabilities of a finite set of strings, the authors in [shternshis2025price] employ Shannon entropy [Shannon], a measure of uncertainty, to assess the randomness of the sequence. Below, we revise the step-by-step algorithm for estimating randomness via the Shannon entropy. In the following, we refer to this test as ShannonEntropy test.

* •

  Choose the block length, kk, as suggested in [Shields]. We choose k=[0.5​log2⁡N]k=\left[0.5\log\_{2}{N}\right]: this is a trade-off between ensuring that there are enough blocks to construct a test statistic and ensuring that the blocks are long enough to capture potential dependencies.
* •

  Divide the sequence into Nb=⌊Nk⌋N\_{b}=\lfloor\frac{N}{k}\rfloor non-overlapping blocks, where ⌊⋅⌋\lfloor\cdot\rfloor denotes the floor function (rounding down):

  |  |  |  |
  | --- | --- | --- |
  |  | x^t={x(t−1)​k+1,x(t−1)​k+2,…,xt​k},t∈[1,Nb].\hat{x}\_{t}=\{x\_{(t-1)k+1},x\_{(t-1)k+2},\dots,x\_{tk}\},\qquad t\in[1,N\_{b}]\,. |  |
* •

  Calculate empirical frequencies f^j\hat{f}\_{j} of all blocks of length kk using the indicator function II:

  |  |  |  |
  | --- | --- | --- |
  |  | f^j=∑t=1nbI​(x^t=aj),aj∈Ak,j∈[1,2k]\hat{f}\_{j}=\sum\_{t=1}^{n\_{b}}I(\hat{x}\_{t}=a\_{j})\,,\qquad a\_{j}\in A^{k},j\in[1,2^{k}] |  |
* •

  Estimate the Shannon entropy, which is defined as the averaged measure of uncertainty about a symbol appearing in a sequence:

  |  |  |  |
  | --- | --- | --- |
  |  | H^=−∑jf^jNb​ln⁡f^jNb,\displaystyle\hat{H}=-\sum\_{j}\frac{\hat{f}\_{j}}{N\_{b}}\ln{\frac{\hat{f}\_{j}}{N\_{b}}}, |  |

  where ln​()\ln() is the natural logarithm with the convention 0​ln⁡0=00\ln{0}=0.
* •

  Test if the estimation is close to the possible maximum of entropy. More precisely, we test whether the difference between the maximum possible entropy, k​ln⁡2k\ln{2}, and the estimate follows a χ2\chi^{2}-distribution with 2k−12^{k}-1 degrees of freedom [Zubkov74]:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | Y1\displaystyle Y\_{1} | =2​Nb​(k​ln⁡2−H^)\displaystyle=2N\_{b}(k\ln{2}-\hat{H}) |  |
  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | H0\displaystyle H\_{0} | :Y1∼χ2​(2k−1)\displaystyle:Y\_{1}\sim\chi^{2}(2^{k}-1) |  |

In many applications, such as financial ones, the requirement for equiprobable symbols (0 and 1) can be relaxed, and the hypothesis of randomness is defined only in terms of independence. The second entropy-based test that we recall from [shternshis2025price] aims to test the hypothesis H0=H\_{0}=The occurrence of a new symbol in the sequence XX is independent of the sequence’s preceding symbols, even if they may have different probability of appearance. Moreover, the method considers all overlapping blocks, thereby enriching the dataset for computing the test statistic. The test statistic in this case is the relative entropy between the empirical probabilities and those expected under H0H\_{0}. We keep the same value for kk and follow the procedure below:

* •

  Define No=N−k+1N\_{o}=N-k+1 overlapping blocks

  |  |  |  |
  | --- | --- | --- |
  |  | x¯t={xt,xt+1,…,xt+k−2},t∈[1,No]\bar{x}\_{t}=\{x\_{t},x\_{t+1},\dots,x\_{t+k-2}\}\,,\qquad t\in[1,N\_{o}] |  |
* •

  Calculate empirical frequencies of blocks of length kk

  |  |  |  |
  | --- | --- | --- |
  |  | fi​j=∑t=1NoI​(x¯t=ai)​I​(xt+k−1=aj),ai∈Ak−1,aj∈Af\_{ij}=\sum\_{t=1}^{N\_{o}}I\left(\bar{x}\_{t}=a\_{i}\right)I\left(x\_{t+k-1}=a\_{j}\right)\,,\qquad a\_{i}\in A^{k-1},a\_{j}\in A |  |
* •

  Evaluate the test statistic and assess whether it follows a χ2\chi^{2}-distribution:

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | Y2\displaystyle Y\_{2} | =2​∑i​jfi​j​ln⁡No​fi​jf⋅j​fi⁣⋅,f⋅j=∑ifi​j,fi⁣⋅=∑jfi​j\displaystyle=2\sum\_{ij}f\_{ij}\ln{\frac{N\_{o}f\_{ij}}{f\_{\cdot j}f\_{i\cdot}}}\,,\qquad f\_{\cdot j}=\sum\_{i}f\_{ij}\,,f\_{i\cdot}=\sum\_{j}f\_{ij} |  |
  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | H0:Y2\displaystyle H\_{0}:Y\_{2} | ∼χ2​(2k−1−1)\displaystyle\sim\chi^{2}(2^{k-1}-1) |  |

The proof for the asymptotic distribution can be found in [shternshis2025price]. In the following, we refer to this test as KL test.

#### 2.1.2 NIST Statistical Test Suite

The NIST Statistical Test Suite (STS) [Bassham\_Rukhin\_Soto\_Nechvatal\_Smid\_Barker\_Leigh\_Levenson\_Vangel\_Banks\_etal.\_2010] is a set of tests designed to evaluate the randomness of binary sequences and to ensure their suitability for cryptographic applications. Developed by the National Institute of Standards and Technology (NIST), it was first published in 2000 and then revised in 2010. In 2022 NIST announced [nist\_revision] that they are working on a new revision.

As explained at the beginning of Section [2](https://arxiv.org/html/2511.17479v1#S2 "2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), we run NIST STS tests444We apply slight modifications to the file src/assess.c: we change the type of the expCount variable
from an integer to a float. on binary strings obtained from months of financial data. Nonetheless, some tests require a length for the string to be tested that is impossible to reach by using financial data with this methodology.
The battery also requires the user to select parameters to run the tests. Each test is run on a certain number of subsequences, so we have to decide how to split our string. Some tests also require other parameters (such as block length). In the documentation [Bassham\_Rukhin\_Soto\_Nechvatal\_Smid\_Barker\_Leigh\_Levenson\_Vangel\_Banks\_etal.\_2010], NIST provides details on how to select such parameters. First, we choose 9 of the 15 tests to run on our sequences, since the length of the strings is not sufficient for the others. Then, we focus on the following tests: Frequency, Block Frequency, Cumulative Sums, Runs, Longest Run of Ones, Discrete Fourier Transform, Non-overlapping Template Matching, Approximate Entropy and Serial Test. We divide the tests into two groups: we run Discrete Fourier Transform and Non-Overlapping Template Matching on substrings of 1000 bits, while the others are run on substrings of 128 bits. Other parameters are chosen according to the suggestions of the documentation and are summarized in Table [4](https://arxiv.org/html/2511.17479v1#A1.T4 "Table 4 ‣ Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") in Appendix [A](https://arxiv.org/html/2511.17479v1#A1 "Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences").

We run a sanity check explained in Section [3](https://arxiv.org/html/2511.17479v1#S3 "3 Sanity check with Random Number Generators ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") on the tests, that leads to a more fine-grained selection of the tests. Then, we run the tests on each monthly string obtained from financial data and collect the p​-valuep\text{-value}s obtained from the output files.

#### 2.1.3 TestU01:

TestU01 [testu01, testu01\_userguide] offers a wide variety of tests, organized in sub-batteries. We focus in particular on Alphabit and Rabbit sub-batteries.

In particular, Alphabit is composed of 9 different tests. It contains four Multinomial Bits Overlapping tests, which detect correlations between successive bits in blocks of several lengths; two types of Hamming tests (Independence and Correlation tests) that detect correlations between the successive bits of overlapping blocks, and two Random Walks tests.

Rabbit is composed of a wide variety of tests: they are 26 and analyze randomness from very different perspectives. We find again the Multinomial Bits Overlapping test, the Hamming Correlation and Independence tests and the Random Walk tests from the Alphabit battery, while other tests include Close Pairs Bit Match, Appearance Spacings, Linear Compression, Lempel Ziv, Fourier transforms, Longest Head Run, Periods in strings, Hamming Weight, Autocorrelation, Run, Matrix Rank. Some of them correspond to NIST tests if run with certain choices of parameters.

We choose to run the tests with standard parameters. A detail of the tests and the parameters can be found in Table [5](https://arxiv.org/html/2511.17479v1#A1.T5 "Table 5 ‣ Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") in App. [A](https://arxiv.org/html/2511.17479v1#A1 "Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). Binary strings should be at least 500 bits long to be tested correctly.

We run all the tests on the strings obtained for an whole month, as explained at the beginning of Section [2](https://arxiv.org/html/2511.17479v1#S2 "2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). In some cases tests fail due to insufficient length of the strings at high aggregation levels. Since the standard battery output just prints the p​-valuep\text{-value}s of the failed tests, we slightly modify it to collect all the p​-valuep\text{-value}s of all the tests run555In particular, we modify the prints of the functions WritepVal and WriteReport in testu01/bbattery.c to print all the p​-valuep\text{-value}s..

### 2.2 Dataset

Table 2: Assets and characteristics of prices

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Asset | Ticker | Mean price | Standard deviation of price | Daily trading volume | Daily number of transactions | Average time between transactions |
| Apple Inc. | AAPL | 153.47 | 0.93 | 12,184,032 | 136,136 | 0.165 |
| Microsoft Corporation | MSFT | 251.78 | 1.37 | 4,529,093 | 84,342 | 0.269 |
| Tesla Inc. | TSLA | 388.02 | 3.81 | 8,686,354 | 178,704 | 0.127 |
| Intel Corporation | INTC | 30.15 | 0.20 | 7,055,642 | 38,255 | 0.595 |
| Eli Lilly and Company | LLY | 327.33 | 1.73 | 370,050 | 11,404 | 2.086 |
| Snap Inc. | SNAP | 10.67 | 0.14 | 4,967,779 | 18,521 | 1.358 |
| Ford Motor Company | F | 13.93 | 0.10 | 4,468,175 | 12,954 | 1.815 |
| Carnival Corporation & plc | CCL | 9.24 | 0.12 | 5,874,376 | 15,372 | 1.518 |
| SPDR S&P 500 ETF | SPY | 390.52 | 1.56 | 9,136,137 | 95,181 | 0.246 |

Mean price, its standard deviation, trading volume, number of transactions, and average time between transactions are calculated for each day and then are averaged over 80 days. Trading volume is summed up for each day. Average time is given in seconds.

We now introduce the description of the financial dataset used for our randomness tests.
We analyze data from limit order books obtained from LOBSTER (www.lobsterdata.com). In a limit order book, traders submit buy and sell orders that either execute immediately by matching with an existing opposite order, or remain active until they are either filled or canceled.

Our study covers 80 trading days between 01-08-2022 and 21-11-2022. Each trading day spans from 9:30 to 16:00, that is 390 minutes in total. Table [2](https://arxiv.org/html/2511.17479v1#S2.T2 "Table 2 ‣ 2.2 Dataset ‣ 2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") lists the tickers we selected, along with their key attributes. The sample includes stocks from a variety of sectors, differing in average price, volatility, transaction counts, inter-trade durations (mostly under one second), and daily volumes (0.3 to 12 million shares). We also include the SPY ETF, which tracks the S&P 500 Index. Transaction timestamps are recorded with nanosecond precision.

For each asset, we downloaded the corresponding message file from LOBSTER. These files contain six fields: order ID, time, price, size (volume), event type, and side (buy or sell). Orders that conceal their size are classified as hidden orders [Gould13]. Our analysis focuses specifically on two types of events: executions of visible limit orders and executions of hidden limit orders.

## 3 Sanity check with Random Number Generators

Since some tests depend on the choice of parameters, or in some cases the unexpected short length of the strings could lead to inaccurate outputs, we run a procedure to select which tests we can consider as valid on real data and which not. To do this, we use three RNGs using three different sources of randomness, and we call this procedure sanity check.

We run the sanity check on all the tests that we use, in order to be sure that they work properly with string lengths that we get from financial data. In particular, the three generators are: Quantis QRNG USB [quantisusb] by ID Quantique, that is a quantum RNG; Linux /dev/urandom, an operating system–level pseudorandom number generator (PRNG) seeded from environmental noise; and random strings produced by Möbius function. The first is a quantum RNG whose randomness is enhanced by quantum mechanical principles. The second uses environmental noise entropy and is one of the most commonly used generators. The third is believed to be random due to the connections between the Riemann hypothesis and the Möbius function.
More details about these generators can be found in App. [B](https://arxiv.org/html/2511.17479v1#A2 "Appendix B Random Number Generators used for sanity check ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences").

We generate strings of N=50 000,100 000,500 000,1 000 000N=$50\,000$,$100\,000$,$500\,000$,$1\,000\,000$ bits and handle them similarly as the financial series. This means that, for every generated string {s1,s2,…,sN}\{s\_{1},s\_{2},\dots,s\_{N}\}, for each level of aggregation ℓ=1,…,100\ell=1,\dots,100 and for each sample j=1,…,ℓj=1,\dots,\ell, we consider the ratios r=sj+i​ℓsj+(i−1)​ℓr=\frac{s\_{j+i\ell}}{s\_{j+(i-1)\ell}} and build the binary string, as before, by adding a 0 or 11 to b¯j\overline{b}\_{j} if, respectively, r<1r<1 or r>1r>1. So, again, from each sequence generated from our RNG, we build 5050 different binary strings. We apply all the selected tests from NIST STS, all the test from Alphabit and Rabbit batteries and the two entropy-based tests explained in Section [2.1.1](https://arxiv.org/html/2511.17479v1#S2.SS1.SSS1 "2.1.1 Entropy-based tests ‣ 2.1 Randomness tests ‣ 2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") on the obtained sequences and use the same parameters of the financial series, as explained in Table [4](https://arxiv.org/html/2511.17479v1#A1.T4 "Table 4 ‣ Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") in App. [A](https://arxiv.org/html/2511.17479v1#A1 "Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences").

We fix a threshold of 2%2\% for excluding tests from the analysis. For any test, if the amount of strings that fail the test on all the three RNGs is higher than the threshold, we do not run the test on financial data of the corresponding length, since this is a clue that the test is not working properly with our choice of parameters. Tests are run with the same level of significance of financial data, i.e. α=0.01\alpha=0.01.

The results of the sanity check applied to NIST STS and TestU01 batteries are shown in Table [3](https://arxiv.org/html/2511.17479v1#S3.T3 "Table 3 ‣ 3 Sanity check with Random Number Generators ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). For ShannonEntropy and KL tests, every string-length passes every test.

|  |  |  |  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| NIST STS | | | | | | RABBIT BATTERY | | | | | |
| N. | Test | 50K | 100K | 500K | 1M | N. | Test | 50K | 100K | 500K | 1M |
| 1 | Frequency | ✓\checkmark |  |  |  | 1 | MultinomialBitsOverlapping |  |  |  |  |
| 2 | BlockFrequency | ✓\checkmark | ✓\checkmark |  |  | 2 | ClosePairsBitMatch, t=2t=2 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 3 | CumulativeSums | ✓\checkmark | ✓\checkmark |  |  | 3 | ClosePairsBitMatch, t=4t=4 |  | ✓\checkmark |  |  |
| 4 | Runs | ✓\checkmark | ✓\checkmark | ✓\checkmark |  | 4 | AppearanceSpacings |  |  | ✓\checkmark | ✓\checkmark |
| 5 | LongestRun | ✓\checkmark | ✓\checkmark | ✓\checkmark |  | 5 | LinearComp | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 6 | Approx. Entropy | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 6 | LempelZiv | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 7 | Serial | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 7 | Fourier1 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 8 | FFT | ✓\checkmark | ✓\checkmark |  |  | 8 | Fourier3 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 9 | NonOverlappingTemplate | ✓\checkmark | ✓\checkmark |  |  | 9 | LongestHeadRun | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| ALPHABIT BATTERY | | | | | | 10 | PeriodsInStrings | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 1 | MultinomialBitsOverlapping, L=2L=2 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 11 | HammingWeight, L=32L=32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 2 | MultinomialBitsOverlapping, L=4L=4 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 12 | HammingCorrelation, L=32L=32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 3 | MultinomialBitsOverlapping, L=8L=8 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 13 | HammingCorrelation, L=64L=64 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 4 | MultinomialBitsOverlapping, L=16L=16 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 14 | HammingCorrelation, L=128L=128 |  | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 5 | HammingIndependence, L=16L=16 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 15 | HammingIndependence, L=16L=16 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 6 | HammingIndependence, L=32L=32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 16 | HammingIndependence, L=32L=32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 7 | HammingCorrelation, L=32L=32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark | 17 | HammingIndependence, L=64L=64 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 8 | RandomWalk1, L=64L=64 | ✓\checkmark | ✓\checkmark |  |  | 18 | AutoCorrelation, d=1d=1 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
| 9 | RandomWalk1, L=320L=320 | ✓\checkmark | ✓\checkmark | ✓\checkmark |  | 19 | AutoCorrelation, d=2d=2 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 20 | Run |  |  | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 21 | MatrixRank, 32×3232\times 32 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 22 | MatrixRank, 320×320320\times 320 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 23 | MatrixRank, 1024×10241024\times 1024 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 24 | RandomWalk1, L=128L=128 | ✓\checkmark |  |  |  |
|  |  |  |  |  |  | 25 | RandomWalk1, L=1024L=1024 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |
|  |  |  |  |  |  | 26 | RandomWalk1, L=10016L=10016 | ✓\checkmark | ✓\checkmark | ✓\checkmark | ✓\checkmark |

Table 3: Results of sanity check applied to NIST STS, Alphabit, and Rabbit tests on selected string sizes.

The length of the strings generated from financial data can be approximated as follows: N=50 000N=$50\,000$ for the tickers CCL, F and SNAP; N=100 000N=$100\,000$ for the tickers INTC and LLY; N=500 000N=$500\,000$ for the tickers AAPL, MSFT; N=1 000 000N=$1\,000\,000$ for the tickers SPY and TSLA. We then consider tests on these tickers to be valid only if they passed the sanity check on the corresponding string length.

## 4 Randomness tests applied to tick data

After the selection made by the sanity check, we run randomness tests from NIST STS, Alphabit, Rabbit and the two entropy-based tests on the strings obtained from UHF data. We show some of the results in the following, while the total collection can be found in our GitHub repository666<https://github.com/Silvia895/Emergence-of-Randomness-in-Temporally-Aggregated-Financial-Tick-Sequences>. Results of the tests are shown as boxplots: we plot aggregation levels on the x-axis, and for every aggregation level ℓ\ell we show the boxplot of −log10⁡(pj)-\log\_{10}(p\_{j}), j=1,…,ℓj=1,\dots,\ell, where pjp\_{j} is the p​-valuep\text{-value} of the sample jj. The threshold of 22 then represents α=0.01\alpha=0.01: if −log10⁡(pj)-\log\_{10}(p\_{j}) is under the threshold, this means that the test has been passed, then the corresponding string can be considered as random; otherwise, the test has rejected the randomness hypothesis.

Our main results can be summarized as follows:

1. 1.

   Our study aligns with the findings in [shternshis2025price], reaffirming that, generally, randomness tends to increase as the aggregation level grows up.
2. 2.

   However, novel methods and tests sometimes reveal exceptions; for instance, there are cases where even at high aggregation levels the result of tests reveals predictability.
3. 3.

   Some of the tests display a novel pattern in predictability-aggregation plots: an example is Fourier3 test, from Rabbit battery. In this case, the maximum of predictability for some stocks occurs at aggregation level higher than 1; after that peak, randomness starts to increase.
4. 4.

   In another particular case, we find an unexpected behavior. This is the result of the HammingCorrelation tests (both in Alphabit and Rabbit batteries) applied on strings generated from INTC data: in the month of August, we see predictability increasing as the level of aggregation increases. A deeper analysis is run on this example to understand the nature of such behavior.

Every case in this list is analyzed in the following paragraphs.

##### Cases 1 and 2:

![Refer to caption](Mix_plots/grid_smultin_MultinomialBitsOver_L4_CCL_INTC_LLY_SPY.png)


Figure 1: Results of smultin\_MultinomialBitsOver (L=4)(L=4) test from Alphabit applied to CCL, INTC, LLY and SPY data.

![Refer to caption](Mix_plots/grid_Runs_AAPL_CCL_MSFT_TSLA.png)


Figure 2: Results of Runs test from NIST STS applied to AAPL, CCL, MSFT and TSLA data.

![Refer to caption](Mix_plots/grid_ApproximateEntropy_AAPL_CCL_INTC_SPY.png)


Figure 3: Results of ApproximateEntropy test from NIST STS applied to AAPL, CCL, INTC and SPY data.

![Refer to caption](Mix_plots/grid_Kullback-Leibler_AAPL_INTC_MSFT_SPY.png)


Figure 4: Results of KL test applied to AAPL, INTC, MSFT and SPY data.

![Refer to caption](Mix_plots/grid_sspectral_Fourier3_AAPL_LLY_SPY_TSLA.png)


Figure 5: Results of Fourier3 test from Rabbit applied to AAPL, LLY, SPY and TSLA data.

![Refer to caption](Mix_plots/grid_CumulativeSums_CCL_INTC_LLY_SNAP.png)


Figure 6: Results of CumulativeSums test from NIST STS applied to CCL, INTC, LLY, and SNAP data.

In the following, we provide examples of tests that analyse randomness from different points of view: Figure [1](https://arxiv.org/html/2511.17479v1#S4.F1 "Figure 1 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") shows the results of smultin\_MultinomialBitsOver (L=4)(L=4), a frequency test; Figure [2](https://arxiv.org/html/2511.17479v1#S4.F2 "Figure 2 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") represents the results of the pattern test Runs; Figures [3](https://arxiv.org/html/2511.17479v1#S4.F3 "Figure 3 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") and [4](https://arxiv.org/html/2511.17479v1#S4.F4 "Figure 4 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") give the results of two entropy tests (ApproximateEntropy and KL); Figure [5](https://arxiv.org/html/2511.17479v1#S4.F5 "Figure 5 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") shows the results of the spectral test Fourier3, which will be also analysed for Case 3 in the following; finally, Figure [6](https://arxiv.org/html/2511.17479v1#S4.F6 "Figure 6 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") gives the results of CumulativeSums test, that is a random walk test. Every figure shows the test applied to four stocks. The general behavior is consistent with expectations: aggregation induces randomness, so the predictability of the strings decreases while increasing the level of the aggregation.

However, we observe in some cases the phenomenon of slow increasing (or not increasing at all) of randomness at high aggregation levels for certain stocks in particular. For example, many tests for AAPL and TSLA highlight predictability also at high aggregation levels (see e.g. Figures [2](https://arxiv.org/html/2511.17479v1#S4.F2 "Figure 2 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), [3](https://arxiv.org/html/2511.17479v1#S4.F3 "Figure 3 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") and [4](https://arxiv.org/html/2511.17479v1#S4.F4 "Figure 4 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences")).

We attribute this persistent predictability to their high trading activity: AAPL and TSLA have an average of respectively 6 and 8 trades per second (whereas CCL and LLY on average have 0.6 and 0.5 trades per second). While our results demonstrate that the general trend is towards increasing randomness (decreasing predictability) with aggregation for almost all the stocks in our datasets, sometimes it happens that aggregating until level 100 is not enough to see randomness emerge from the strings.

Also, our methodology shows the usefulness of such a multifaceted approach: different tests analyse different properties of the strings. This means that even if one string appears random with respect to one property, it may not appear random with respect to another. Examples can be seen in Figures [1](https://arxiv.org/html/2511.17479v1#S4.F1 "Figure 1 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") and [3](https://arxiv.org/html/2511.17479v1#S4.F3 "Figure 3 ‣ Cases 1 and 2: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). Consider the month of August 2022 for SPY: although the ApproximateEntropy test suggests that randomness is achieved at level 20, aggregation up to level 100 is insufficient to guarantee randomness with respect to the MultinomialBitsOverlapping test with L=4L=4.

##### Case 3:

![Refer to caption](Mix_plots/grid_sspectral_Fourier3_CCL_F_INTC_SNAP.png)


Figure 7: Results of sspectral\_Fourier3 test from the Rabbit battery applied to CCL, F, INTC and SNAP.

The Fourier3 spectral test on CCL, F, INTC and SNAP stocks, whose results are shown in Figure [7](https://arxiv.org/html/2511.17479v1#S4.F7 "Figure 7 ‣ Case 3: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), shows a rare behavior compared to other tests. Here, the maximum of predictability is reached at a level higher than one, and then decreases. This means that the level of randomness has a non-monotone behavior, that was not detected by previous works.

Such non-monotonic behavior highlighting deterministic patterns at some levels of aggregations can be explained by algorithmic trading. Since the major trading activities are done algorithmically in stock markets, it is possible that the impact of algorithms becomes visible. Actions by a specific algorithm are launched with some periodicity that may coincide with peaks of predictability in the resulting plots. Alternatively, this phenomenon can be attributed to microstructure in high frequency trading. For instance, splitting large orders into smaller pieces happens with some periodicity and not with any transaction.

We note that Fourier3 is not the only test to detect such behavior. Other examples on some of the stocks are given by the AutoCorrelation (d=1)(d=1) test in Rabbit battery, BlockFrequency and CumulativeSums tests in NIST STS, ShannonEntropy and KL tests. Results for these tests are available in our GitHub repository.

##### Case 4:

The HammingCorrelation tests applied on INTC data give results that look different from all the other tests and stocks: we analyze more in detail what could be the reason of such a particular behavior.

![Refer to caption](Mix_plots/single_sstring_HammingCorr_L32_INTC_August_2022.png)


(a) HammingCorrelation (L=32)(L=32)

![Refer to caption](Mix_plots/single_p-value_INTC_August_2022.png)


(b) Arithmetic mean test

![Refer to caption](Mix_plots/single_median_sstring_HammingCorr_L32_INTC_August_2022.png)


(c) HammingCorrelation (L=32)(L=32) with median

Figure 8: The boxplots show the results of three tests applied to INTC data of August 2022: (a) HammingCorrelation (L=32)(L=32) from Rabbit battery; (b) Arithmetic mean test; (c) HammingCorrelation (L=32)(L=32) test after balancing the frequencies.

HammingCorrelation is a pattern test that analyzes blocks of the sequences and compares their Hamming weights. Then, it is strongly connected with the frequencies of the string and to its distance from having exactly 50%50\% of zeros and 50%50\% of ones. We analyze in more details frequencies of INTC data, in particular in August, where the particular behavior seems to be particularly far from the other tests and stocks. We apply an arithmetic mean test on our data to measure how far they are from having a perfect balance between zeros and ones. We define

|  |  |  |
| --- | --- | --- |
|  | Z=2N⋅|c−N2|,Z=\frac{2}{\sqrt{N}}\cdot\bigg|c-\frac{N}{2}\bigg|, |  |

where cc is the number of zeros in the sequence whose length is NN. In Figure [8(b)](https://arxiv.org/html/2511.17479v1#S4.F8.sf2 "In Figure 8 ‣ Case 4: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), the results of the arithmetic mean test are shown for INTC in the month of August 2022. Frequencies appear really biased, far from equiprobability, and this leads to an obvious rejection of the randomness hypothesis by tests like HammingCorrelation. However, the assumption of equiprobability is not mandatory for some randomness tests. For instance, we assessed the independence of successive symbols using the KL test, checking whether the sequence consists of Bernoulli(pp) variables, where pp may differ from 12\tfrac{1}{2}.

In fact, if we try to balance these frequencies and we generate new strings starting from the same data, we get this result to be partly corrected.

To obtain binary strings that contain 50%50\% zeros and 50%50\% ones, we apply a similar methodology to the one used before, but this time we need to use the full information on the prices of the day in order to compute the median of them. This means that this is no more an online process, but we have to wait the end of the trading day to compute the binary strings.

Starting from the sequence of prices {s1,s2,…,sN}\{s\_{1},s\_{2},\dots,s\_{N}\}, we consider the sequence {sm}\{s\_{m}\} where m=j+i​ℓm=j+i\ell for each aggregation level ℓ=1,…,100\ell=1,\dots,100 and for each sample j=1,…,ℓj=1,\dots,\ell. Then, we compute the median MM of all the ratios r=sm+1smr=\frac{s\_{m+1}}{s\_{m}} and build the string b¯j\overline{b}\_{j} in such a way:

|  |  |  |
| --- | --- | --- |
|  | r=sm+1sm​{<M then ​bj¯→bj¯​0>M then ​bj¯→bj¯​1r=\frac{s\_{m+1}}{s\_{m}}\begin{cases}<M&\text{ then }\overline{b\_{j}}\rightarrow\overline{b\_{j}}0\\ >M&\text{ then }\overline{b\_{j}}\rightarrow\overline{b\_{j}}1\\ \end{cases} |  |

We highlight that in such a way we get a daily string that is perfectly balanced by construction, but computing the median of the prices of the whole day requires the computation to be done at the end of day. Then, we concatenate daily strings as before to obtain the monthly ones. For each aggregation level ℓ=1,…,100\ell=1,\dots,100 and for each sample j=1,…,ℓj=1,\dots,\ell, we run the test on a concatenated string obtained as b¯m=b¯d1​‖…‖​b¯dn\overline{b}^{m}=\overline{b}^{d\_{1}}||\dots||\overline{b}^{d\_{n}}, where the {b¯di}i=1,…,n\{\overline{b}^{d\_{i}}\}\_{i=1,\dots,n} are the strings obtained for each analyzed day of the month mm.

Results of this approach applied to INTC data of August 2022 are shown in Figure [8(c)](https://arxiv.org/html/2511.17479v1#S4.F8.sf3 "In Figure 8 ‣ Case 4: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"). The slow decrease of randomness indeed shows the existence of some patterns inside the sequence, particularly at low aggregation levels; anyway, when we reach level 70, the sequence appears to be random, while if not balancing the frequencies we get a non-decreasing behavior. We emphasize how other tests (for example KL test shown in Figure [9](https://arxiv.org/html/2511.17479v1#S4.F9 "Figure 9 ‣ Case 4: ‣ 4 Randomness tests applied to tick data ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences")) consider the same string random starting from aggregation level nearly 50, and how the methodology (either balancing the frequencies or not) does not affect the result.

![Refer to caption](Mix_plots/single_Kullback-Leibler_INTC_August_2022.png)


(d) Without balancing frequencies

![Refer to caption](Mix_plots/single_median_Kullback-Leibler_INTC_August_2022.png)


(e) With balanced frequencies

Figure 9: The boxplots show the results of KL test applied to INTC data from August 2022. (a) Results of test on the original string; (b) Results on test after balancing the frequencies of the string.

##### Application:

The methodology we introduce in this paper gives us the possibility to let non-random binary strings obtained by UHF data be whitened out by the process of aggregation for the most of the stocks. Our randomizing process can be seen as an online-process: it does not require future information on tick data, so we do not have to collect data before computing the strings, but we can update the strings as new data becomes available. So, strings can be computed on-the-fly. Moreover, it does not assume any hypothesis, any model and does not require to run any simulation. Since our monthly strings have lengths of up to 1 000 0001\,000\,000 of bits, depending on the stock - i.e., up to 10 00010\,000 bits at aggregation level 100100 -, and since one month is composed of nearly 20 trading days, we claim that our methodology can produce up to 10 00020=500\frac{$10\,000$}{20}=500 entropy bits per day. If we select stocks not involved in cases 2 and 4, and we use the binary strings that we obtain at level of aggregation 100100 as a source of randomness, we have a verifiable source certified to be random by all our tests, that is, by the most common and standard batteries of randomness tests used to certify RNGs. We thus provide an alternative approach for extracting random number sequences from financial data [chiba2024random, 10.5555/1924892.1924895, Landis25]. The proposed methodology of whitening financial time series through aggregation can further be examined for its potential applications, for instance, in the implementation of randomness beacons [10.5555/1924892.1924895]. Our source of randomness from aggregated prices can then be classified and ranked among PRNGs using the framework of [Machicao21].

## 5 Conclusion and future work

In this paper, we introduce a new methodology to manage strings obtained by symbolizing UHF data in order to let the randomness emerge from them.

Systemic analyses are in line with results of the paper on entropy-based approaches [shternshis2025price]. However, with the extension of the methodology and inclusion of standard batteries of tests, we have investigated the data from new perspectives. In particular, some tests identify random numbers sequences well, but determine predictability in stocks such as AAPL and TSLA even after price aggregation. Previous analyses have not discover the slow decay for AAPL stock.

Methods cited in case 3 have displayed a novel pattern in predictability-aggregation plots. The maximum of predictability occurs at aggregation level higher than 1 and then goes down. One of the directions for future work is to investigate such patterns and interpret them. For instance, such a pattern can be caused by algorithmic trading happening after a certain number of transactions. The method shown in case 4 is an example for tests that require equal marginal probabilities of symbols. The future research direction is to construct a battery of tests which do not demand such an assumption. One method with this property was developed in [shternshis2025price], however, there is a need in developing more methods to make the analysis more systematic. For instance, frequency tests based on χ\chi-squared distribution [Ecuyer99, Rukhin01] may be modified for this task. Finally, the plan for future work is to extend the data in applications to larger basket of assets. This task will require a visualization technique allowing to summarize the randomness of each stock at different aggregation levels.

## Appendix A Details of randomness tests

Tables [4](https://arxiv.org/html/2511.17479v1#A1.T4 "Table 4 ‣ Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") and [5](https://arxiv.org/html/2511.17479v1#A1.T5 "Table 5 ‣ Appendix A Details of randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") provide details about the tests contained in, respectively, NIST STS and TestU01 Alphabit and Rabbit. In the first case we specify the suggested parameters and our choices, while in the second case we just run tests with the standard parameters.

| Test | Suggested values | Chosen values |
| --- | --- | --- |
| Frequency (Monobit) Test | t≥100t\geq 100 | t=128t=128 |
| Frequency Test within a Block | t≥100t\geq 100, t≥M​Jt\geq MJ, M≥20M\geq 20, M<0.01​ℓM<0.01\ell, J<100J<100 | t=128t=128, M=20M=20 |
| Runs Test | t≥100t\geq 100 | t=128t=128 |
| Tests for the Longest-Run-of-Ones in a Block | t≥128t\geq 128 and if 128≤t≤6272128\leq t\leq 6272 M=8M=8 | t=128t=128, M=8M=8 |
| Binary Matrix Rank Test | t≥38912t\geq 38912 | Not executed |
| Discrete Fourier Transform (Spectral) Test (FFT) | t≥1000t\geq 1000 | t=1000t=1000 |
| Non-overlapping Template Matching Test | m∈{9,10}m\in\{9,10\},J=8J=8, M>0.01​ℓM>0.01\ell | t=1000t=1000, m=9m=9 |
| Overlapping Template Matching Test | t≥106t\geq 10^{6} | Not executed |
| Maurer’s ”Universal Statistical” Test | t≥387840t\geq 387840 | Not executed |
| Linear Complexity Test | t≥106t\geq 10^{6} | Not executed |
| Serial Test | m<⌊log2⁡t⌋−2m<\lfloor\log\_{2}t\rfloor-2 | t=128t=128, m=2m=2 |
| Approximate Entropy Test | m<⌊log2⁡t⌋−5m<\lfloor\log\_{2}t\rfloor-5 | t=128t=128, m=5m=5 |
| Cumulative Sums (Cusums) Test | t≥100t\geq 100 | t=128t=128 |
| Random Excursions Test | t≥106t\geq 10^{6} | Not executed |
| Random Excursions Variant Test | t≥106t\geq 10^{6} | Not executed |

Table 4: This table shows tests contained in NIST STS. We summarize here the suggestions contained in the documentation for tt=length of substrings in bits, MM=block length in bits, J=⌊tM⌋J=\lfloor\frac{t}{M}\rfloor number of blocks, mm=template length in bits.



| N. Test | Alphabit | Rabbit |
| --- | --- | --- |
| 1 | MultinomialBitsOverlapping, L=2L=2 | MultinomialBitsOverlapping |
| 2 | MultinomialBitsOverlapping, L=4L=4 | ClosePairsBitMatch, t=2t=2 |
| 3 | MultinomialBitsOverlapping, L=8L=8 | ClosePairsBitMatch, t=4t=4 |
| 4 | MultinomialBitsOverlapping, L=16L=16 | AppearanceSpacings |
| 5 | HammingIndependence, L=16L=16 bits | LinearComp |
| 6 | HammingIndependence, L=32L=32 bits | LempelZiv |
| 7 | HammingCorrelation, L=32L=32 bits | Fourier1 |
| 8 | RandomWalk1, L=64L=64 | Fourier3 |
| 9 | RandomWalk1, L=320L=320 | LongestHeadRun |
| 10 |  | PeriodsInStrings |
| 11 |  | HammingWeight, L=32L=32 bits. |
| 12 |  | HammingCorrelation, L=32L=32 bits |
| 13 |  | HammingCorrelation, L=64L=64 bits |
| 14 |  | HammingCorrelation, L=128L=128 bits |
| 15 |  | HammingIndependence, L=16L=16 bits |
| 16 |  | HammingIndependence, L=32L=32 bits |
| 17 |  | HammingIndependence, L=64L=64 bits |
| 18 |  | AutoCorrelation, d=1d=1 |
| 19 |  | AutoCorrelation, d=2d=2 |
| 20 |  | Run |
| 21 |  | MatrixRank, 32×3232\times 32 matrices |
| 22 |  | MatrixRank, 320×320320\times 320 matrices |
| 23 |  | MatrixRank, 1024×10241024\times 1024 matrices |
| 24 |  | RandomWalk1, L=128L=128 |
| 25 |  | RandomWalk1, L=1024L=1024 |
| 26 |  | RandomWalk1, L=10016L=10016 |

Table 5: Detail of the tests contained in Alphabit and Rabbit sub-batteries of TestU01. LL is the block length (or the random walk length), tt is the dimension, dd represents the lag.

Randomness tests contained in NIST STS, Alphabit and Rabbit batteries can be divided in five main categories: frequency tests, pattern tests, entropy and complexity tests, spectral tests and random walks tests.

* •

  Frequency tests: in this category we can find Frequency (Monobit) Test and Frequency Test within a Block from the NIST STS, MultinomialBitsOverlapping and HammingWeight from Rabbit and the four MultinomialBitsOverlapping of the Alphabit battery.
* •

  Pattern tests: in this category we have Runs Test, Tests for the Longest-Run-of-Ones in a Block, Non-overlapping Template
  Matching Test and Overlapping Template Matching Test from the NIST STS; in the battery Rabbit there are the two ClosePairsBitMatch tests, LongestHeadRun, PeriodsInStrings, the three HammingCorrelation and the three HammingIndependence tests, two AutoCorrelation and the Run tests, while Alphabit analyzes patterns by, again, HammingIndependence and HammingCorrelation tests.
* •

  Entropy and complexity tests: they comprehend Binary Matrix Rank Test, Maurer’s “Universal Statistical” Test, Linear Complexity Test, Serial Test and Approximate Entropy Test from NIST STS and AppearanceSpacings, LinearComp, LempelZiv and the three MatrixRank in Rabbit battery. Moreover, the ShannonEntropy and KL tests described in Section [2.1.1](https://arxiv.org/html/2511.17479v1#S2.SS1.SSS1 "2.1.1 Entropy-based tests ‣ 2.1 Randomness tests ‣ 2 Encoding of prices and randomness tests ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences") belong to this category.
* •

  Spectral tests: they comprehend the Discrete Fourier Transform
  (Spectral) Test of NIST STS and the Fourier1 and Fourier3 tests from the Rabbit battery.
* •

  Random Walks tests: they comprehend the Cumulative Sums
  Test, the Random Excursions Test and the Random Excursions Variant Test from the NIST STS, the three Random Walk tests in Rabbit and the two Random Walk tests in Alphabit.

## Appendix B Random Number Generators used for sanity check

As explained in Section [3](https://arxiv.org/html/2511.17479v1#S3 "3 Sanity check with Random Number Generators ‣ Emergence of Randomness in Temporally Aggregated Financial Tick Sequences"), we use three RNGs to run a sanity check on the tests of the batteries. Our aim is to validate the efficiency of the tests with given string lengths and parameters: since the batteries are mainly thought for cryptographic purposes, and since we have mandatory choices for some parameters due to the fact that we want to apply tests on real data, we want to certify if tests with such parameters work in a proper way. That is, if a test does not recognize more than the 2%2\% of the strings produced by the chosen RNGs as random, then we assume that the test does not work correctly with such parameters and just avoid to run it on financial data.

We use three RNGs with three different sources of randomness: quantum physics, environmental noise and pure mathematics. For the first case, we use Quantis QRNG USB by ID Quantique [quantisusb]: this is a quantum random number generator, that exploits natural randomness coming from the principles of quantum mechanics to generate random numbers. In particular, this generator uses individual photons sent onto a semi-transparent mirror; each photon has a 50%50\% chance of being reflected or transmitted. These two outcomes are detected and encoded as the binary bits 0 or 1.

The second generator that we use is /dev/urandom, the random number generator built into the Linux kernel. The Linux /dev/urandom accumulates environmental noise from device drivers and other system activities into a central entropy pool, while maintaining an internal estimate of the available entropy. Random values are generated by extracting data from this pool, and these are used to reseed periodically a PRNG.

The generator that uses randomness derived from pure mathematics exploits the Möbius function. The Möbius function is defined as

|  |  |  |
| --- | --- | --- |
|  | μ​(n)={1if ​n=1(−1)kif ​n​ is product of ​k​ distinct primes0if ​n​ is divisible by a square >1\mu(n)=\begin{cases}1&\text{if }n=1\\ (-1)^{k}&\text{if }n\text{ is product of }k\text{ distinct primes}\\ 0&\text{if }n\text{ is divisible by a square }>1\\ \end{cases} |  |

We manage to obtain binary strings from this function by just considering μ​(n)\mu(n) such that μ​(n)=±1\mu(n)=\pm 1, discarding the zeros.

Considerable attention has been given in literature to the analysis of the randomness of the Möbius function.

The Riemann Hypothesis can be reformulated as |∑n≤xμ​(n)|=O​(x12+ϵ)​∀ϵ>0|\sum\_{n\leq x}\mu(n)|=O(x^{\frac{1}{2}+\epsilon})\,\forall\epsilon>0.
This is equivalent to say that μ​(n)\mu(n) consists of a random walk. So, if the Riemann Hypothesis holds, then it is true that μ​(n)\mu(n) can be considered a source of randomness.

Moreover, in [Wintner\_1944], Wintner defined the Rademacher random multiplicative function β\beta:

|  |  |  |
| --- | --- | --- |
|  | β​(n)={−1,+1​ with prob. ​12if ​n​ is prime∏p|nβ​(p)if ​n​ is product of distinct primes0if ​n​ has a repeated prime factor.\beta(n)=\begin{cases}-1,+1\text{ with prob. }\frac{1}{2}&\text{if }n\text{ is prime}\\ \prod\_{p|n}\beta(p)&\text{if }n\text{ is product of distinct primes}\\ 0&\text{if }n\text{ has a repeated prime factor}\\ \end{cases}\,. |  |

For β\beta it has been proven that |∑n≤xβ​(n)|=O​(x12+ϵ)|\sum\_{n\leq x}\beta(n)|=O(x^{\frac{1}{2}+\epsilon}), ϵ>0\epsilon>0.

Furthermore, in [Mussardo\_LeClair\_2021], Mussardo and LeClair test the randomness of Möbius function by tests similar to the ones we use.