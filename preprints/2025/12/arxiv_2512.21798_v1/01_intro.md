---
authors:
- Christophe D. Hounwanou
- Yae Ulrich Gaba
doc_id: arxiv:2512.21798v1
family_id: arxiv:2512.21798
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Applications of synthetic financial data in portfolio and risk modeling
url_abs: http://arxiv.org/abs/2512.21798v1
url_html: https://arxiv.org/html/2512.21798v1
venue: arXiv q-fin
version: 1
year: 2025
---


Christophe D. Hounwanou
  
African Institute for Mathematical Sciences, AIMS Rwanda
  
  
christophe.hounwanou@aims.ac.rw
â€ƒâ€ƒ
YaÃ© Ulrich Gaba
  
Sefako Makgatho Health Sciences University (SMU)
  
Pretoria, South Africa
  
&
  
AI Research and Innovation Nexus for Africa (AIRINA Labs)
  
AI.Technipreneurs, BÃ©nin
yaeulrich.gaba@gmail.com

###### Abstract

Synthetic financial data offers a practical way to address the privacy and accessibility challenges that limit research in quantitative finance. This paper examines the use of generative models, in particular TimeGAN and Variational Autoencoders (VAEs), for creating synthetic return series that support portfolio construction, trading analysis, and risk modeling. Using historical daily returns from the S&P 500 as a benchmark, we generate synthetic datasets under comparable market conditions and evaluate them using statistical similarity metrics, temporal structure tests, and downstream financial tasks. The study shows that TimeGAN produces synthetic data with distributional shapes, volatility patterns, and autocorrelation behaviour that are close to those observed in real returns. When applied to meanâ€“variance portfolio optimization, the resulting synthetic datasets lead to portfolio weights, Sharpe ratios, and risk levels that remain close to those obtained from real data. The VAE provides more stable training but tends to smooth extreme market movements, which affects risk estimation. Finally, the analysis supports the use of synthetic datasets as substitutes for real financial data in portfolio analysis and risk simulation, particularly when models are able to capture temporal dynamics. Synthetic data therefore provides a privacy-preserving, cost-effective, and reproducible tool for financial experimentation and model development.

## 1 Introduction

The widespread adoption of data-driven methods in finance has been supported by recent progress in machine learning and deep learning for portfolio optimization, trading, and risk management [gu2020empirical, heaton2017deep]. However, financial datasets are often scarce, proprietary, and sensitive, which restricts reproducibility and limits the development of scalable research frameworks [li2023evaluation]. Furthermore, the stochastic and non-stationary nature of financial markets adds complexity to model training and evaluation [tsay2010analysis].

Synthetic data generation has emerged as a promising approach to address these challenges. Advances in generative modeling, including Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), allow the production of realistic and privacy-preserving data that retain the key statistical properties of financial markets [goodfellow2014generative, kingma2014auto]. In particular, models such as TimeGAN [yoon2019time], which combine recurrent architectures with adversarial learning, show strong potential for generating temporal sequences with coherent market dynamics.

Despite increasing interest, there is limited evidence on the practical utility of synthetic financial time series in downstream applications such as portfolio construction, risk estimation, and strategy backtesting [li2023evaluation, takahashi2019data]. In other words, it remains unclear whether synthetic data can reliably replicate market behavior and support quantitative decision-making tasks.

Research Question: This study investigates whether synthetic financial time series generated by TimeGAN and VAE can faithfully reproduce the statistical and temporal properties of real market data, and whether these synthetic datasets can support downstream tasks such as portfolio optimization, risk estimation, and backtesting.

We focus on S&PÂ 500 data as a benchmark, generating synthetic sequences using TimeGAN and VAEs, and evaluate their ability to reproduce key market patterns. The empirical results provide insight into the fidelity and practical utility of synthetic financial data, with implications for privacy-preserving and reproducible research in quantitative finance.

The remainder of this paper is organized as follows. SectionÂ [2](https://arxiv.org/html/2512.21798v1#S2 "2 Preliminaries â€£ Applications of synthetic financial data in portfolio and risk modeling") introduces the theoretical background and fundamentals of synthetic data generation. SectionÂ [3](https://arxiv.org/html/2512.21798v1#S3 "3 Methodology â€£ Applications of synthetic financial data in portfolio and risk modeling") presents the methodology and experimental setup used for portfolio and risk modeling. SectionÂ [4](https://arxiv.org/html/2512.21798v1#S4 "4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") reports the empirical results. SectionÂ [5](https://arxiv.org/html/2512.21798v1#S5 "5 Discussion â€£ Applications of synthetic financial data in portfolio and risk modeling") discusses the main implications and limitations. SectionÂ [6](https://arxiv.org/html/2512.21798v1#S6 "6 Conclusion â€£ Applications of synthetic financial data in portfolio and risk modeling") concludes with perspectives for future research.

## 2 Preliminaries

This section introduces the conceptual background required to analyze the contribution of synthetic financial data to portfolio optimization and risk modeling. While the first paper focused on the generation and statistical validation of synthetic time series, the present work examines how such data can support decision-oriented tasks. We begin by formalizing the standard portfolio and risk modeling framework, then outline how synthetic datasets can be integrated into estimation and evaluation procedures.

### 2.1 Formal setting: Portfolio and risk modeling framework

Let ğ«t=(r1,t,r2,t,â€¦,rN,t)âŠ¤\mathbf{r}\_{t}=(r\_{1,t},r\_{2,t},\ldots,r\_{N,t})^{\top} denote the vector of asset log-returns at time tt, where NN is the number of assets.
A portfolio is characterized by a weight vector ğ°=(w1,w2,â€¦,wN)âŠ¤\mathbf{w}=(w\_{1},w\_{2},\ldots,w\_{N})^{\top} satisfying the budget constraint âˆ‘i=1Nwi=1\sum\_{i=1}^{N}w\_{i}=1.
The portfolio return at time tt is:

|  |  |  |
| --- | --- | --- |
|  | Rt=ğ°âŠ¤â€‹ğ«t,R\_{t}=\mathbf{w}^{\top}\mathbf{r}\_{t}, |  |

with expected return and variance given by:

|  |  |  |
| --- | --- | --- |
|  | Î¼p=ğ”¼â€‹[Rt],Ïƒp2=ğ•â€‹[Rt]=ğ°âŠ¤â€‹Î£â€‹ğ°,\mu\_{p}=\mathbb{E}[R\_{t}],\qquad\sigma\_{p}^{2}=\mathbb{V}[R\_{t}]=\mathbf{w}^{\top}\Sigma\mathbf{w}, |  |

where Î£\Sigma denotes the covariance matrix of asset returns.

The classical mean-variance optimization problem of Markowitz (1952) can be written as:

|  |  |  |
| --- | --- | --- |
|  | minğ°â¡ğ°âŠ¤â€‹Î£â€‹ğ°subject toğ°âŠ¤â€‹ğŸ=1,ğ°âŠ¤â€‹Î¼=Î¼pâˆ—,\min\_{\mathbf{w}}\ \mathbf{w}^{\top}\Sigma\mathbf{w}\quad\text{subject to}\quad\mathbf{w}^{\top}\mathbf{1}=1,\qquad\mathbf{w}^{\top}\mu=\mu\_{p}^{\*}, |  |

where Î¼pâˆ—\mu\_{p}^{\*} is a target expected return.
In practice, the quantities Î¼\mu and Î£\Sigma are estimated from historical data, which can lead to instability and sensitivity to sampling variation, particularly in settings with limited data or pronounced non-stationarity.

Synthetic data generation offers a potential way to address these challenges by providing additional samples that reproduce key temporal and distributional characteristics of financial time series. Such augmented datasets can be used to improve the robustness of parameter estimation, explore alternative market scenarios, and support stress-testing procedures in portfolio and risk modeling.

### 2.2 Synthetic data as a bridge between privacy and utility

Synthetic financial data provides a practical approach to address two common challenges in quantitative finance: limited data access and the need for privacy-preserving analytics.
Financial datasets are often restricted due to confidentiality concerns, making reproducibility and robust testing of models difficult. Synthetic data, generated via models such as Variational Autoencoders (VAEs) or Time-series GANs (TimeGAN), offers a way to simulate realistic market behavior without exposing sensitive information.

Formally, let a real dataset be
ğ’Ÿ={ğ«1:T(i)}i=1M\mathcal{D}=\{\mathbf{r}\_{1:T}^{(i)}\}\_{i=1}^{M},
where each ğ«1:T(i)\mathbf{r}\_{1:T}^{(i)} is a sequence of log-returns for NN assets over TT time steps.
A generative model GÎ¸G\_{\theta} maps latent variables ğ³âˆ¼pâ€‹(ğ³)\mathbf{z}\sim p(\mathbf{z}) to synthetic sequences:

|  |  |  |
| --- | --- | --- |
|  | ğ«~1:T=GÎ¸â€‹(ğ³)\tilde{\mathbf{r}}\_{1:T}=G\_{\theta}(\mathbf{z}) |  |

such that the generated distribution pÎ¸â€‹(ğ«~1:T)p\_{\theta}(\tilde{\mathbf{r}}\_{1:T}) approximates the real data distribution pâ€‹(ğ«1:T)p(\mathbf{r}\_{1:T}) according to a divergence measure (e.g., Kullback-Leibler, Wasserstein).

This approach allows researchers to:

* â€¢

  Augment small datasets for more stable estimation of portfolio and risk parameters,
* â€¢

  Conduct stress-testing under alternative market scenarios,
* â€¢

  Share data and models across teams or institutions without exposing real transaction records.

Synthetic data connects privacy and practical use, allowing classical portfolio and risk modeling to be applied in a reproducible and secure way.

### 2.3 Synthetic data for downstream portfolio and risk tasks

Beyond generating statistically realistic time series, the ultimate goal of synthetic financial data is to support practical decision-making tasks.
These include portfolio optimization, risk assessment, and stress-testing, where reliable estimates of returns, covariances, and extreme events are essential.

Let ğ«~t\tilde{\mathbf{r}}\_{t} denote synthetic asset returns at time tt, generated from a model trained on real data ğ«t\mathbf{r}\_{t}.
We define the following key downstream objectives:

* â€¢

  Portfolio optimization: Use synthetic returns to compute expected returns Î¼~\tilde{\mu} and covariance Î£~\tilde{\Sigma}, which then inform mean-variance or risk-parity allocations.
* â€¢

  Risk modeling: Evaluate whether synthetic series reproduce key risk measures, including variance, Value-at-Risk (VaR), and conditional VaR.
* â€¢

  Stress testing and scenario analysis: Simulate rare or extreme market events in synthetic data to examine the robustness of portfolios or trading strategies.

Formally, the downstream task evaluation examines whether using ğ«~t\tilde{\mathbf{r}}\_{t} yields decision metrics close to those obtained from the real data ğ«t\mathbf{r}\_{t}, for example:

|  |  |  |
| --- | --- | --- |
|  | Î¼~pâ‰ˆÎ¼p,Ïƒ~p2â‰ˆÏƒp2,and portfolio allocationsÂ â€‹ğ°~â‰ˆğ°.\tilde{\mu}\_{p}\approx\mu\_{p},\quad\tilde{\sigma}\_{p}^{2}\approx\sigma\_{p}^{2},\quad\text{and portfolio allocations }\tilde{\mathbf{w}}\approx\mathbf{w}. |  |

This section sets the stage for our methodology, where synthetic datasets will be assessed not only on statistical fidelity but also on their practical utility in realistic financial tasks.

### 2.4 Evaluation dimensions: fidelity, utility, and robustness

Assessing synthetic financial data requires a multi-dimensional perspective that captures both statistical quality and practical relevance. Building on the previous subsections, we define three key evaluation dimensions:

* â€¢

  Fidelity: Measures how closely the synthetic series ğ«~t\tilde{\mathbf{r}}\_{t} replicates the statistical and temporal characteristics of real returns ğ«t\mathbf{r}\_{t}. This includes first- and higher-order moments, autocorrelation, volatility clustering, and distributional shape. High fidelity ensures that synthetic data reflects the essential market dynamics needed for realistic modeling.
* â€¢

  Utility: Quantifies the effectiveness of synthetic data in supporting downstream tasks such as portfolio optimization, risk estimation, and stress-testing. Specifically, we compare performance metrics derived from synthetic series (e.g., expected return Î¼~p\tilde{\mu}\_{p}, variance Ïƒ~p2\tilde{\sigma}\_{p}^{2}, Value-at-Risk, portfolio allocations ğ°~\tilde{\mathbf{w}}) with those computed from real data. High utility implies that decisions based on synthetic data are consistent with those based on real data.
* â€¢

  Robustness: Evaluates the stability and reliability of synthetic datasets across different market regimes, random seeds, or slight perturbations in input data. A robust synthetic model maintains consistent statistical properties and downstream task performance under varying conditions, which is crucial for stress-testing, scenario analysis, and generalization to unseen market events.

These three dimensions form a clear framework for evaluating synthetic financial data both as a statistical representation and as a practical tool for financial decision-making.
The next section describes the methodology for generating and testing synthetic datasets in portfolio construction and risk analysis.

## 3 Methodology

This section details the methodological framework used to evaluate the usability of synthetic financial datasets in practical quantitative finance tasks. Our central research question is:

Can synthetic financial time series generated by TimeGAN and VAE reliably replicate the statistical and temporal properties of real market data and support downstream tasks such as portfolio optimization, risk estimation, and backtesting?

The experimental pipeline consists of four stages: data acquisition and preprocessing, synthetic data generation, downstream modeling, and comparative evaluation.

### 3.1 Dataset and preprocessing

The empirical study uses daily closing prices of the S&P 500 index from January 2000 to June 2024. The dataset contains only the index, and all downstream analyses are based on its log-returns. Raw prices are transformed into log-returns to ensure stationarity and comparability:

|  |  |  |
| --- | --- | --- |
|  | rt=lnâ¡(PtPtâˆ’1),r\_{t}=\ln\left(\frac{P\_{t}}{P\_{t-1}}\right), |  |

where PtP\_{t} is the adjusted closing price at time tt, and rtr\_{t} is the daily log-return.

Stationarity is verified using the Augmented Dickey-Fuller (ADF) test. The series is then standardized to zero mean and unit variance before being input into the generative models. To ensure robustness, we also examine alternative rolling-window lengths (T=10,20,60T=10,20,60 days) and verify that preprocessing choices do not significantly affect downstream results.

Table 1: Summary statistics of S&P 500 daily log-returns (2000-2024)

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Statistic | Mean | Std. Dev. | Skewness | Kurtosis |
| Real Data | 0.00041 | 0.0127 | -0.45 | 7.88 |

This preprocessing framework ensures that the data fed to the generative models is statistically consistent, preserving key distributional and temporal properties of the original S&P 500 returns.

### 3.2 Synthetic data generation

Synthetic datasets were produced using two state-of-the-art generative models: TimeGANÂ [yoon2019timegan] and Variational Autoencoder (VAE)Â [kingma2013auto]. TimeGAN combines recurrent neural networks with adversarial training to capture both temporal dynamics and feature correlations, while VAEs learn a probabilistic latent representation to generate smooth and continuous synthetic sequences.

Other generative approaches, such as diffusion models, WGANs, or Copula-based models, were excluded in this study due to either high computational costs or scope limitations, allowing us to focus on two widely studied and complementary paradigms.

#### 3.2.1 Model training and hyperparameters

For each model, training was performed on the preprocessed S&P 500 log-returns using the following configurations:

* â€¢

  TimeGAN: 200 epochs, learning rate 0.001, batch size 64.
* â€¢

  VAE: 150 epochs, learning rate 0.001, batch size 128.
* â€¢

  Random seeds were fixed to ensure reproducibility.

Convergence was monitored through model-specific loss curves, and latent-space representations were visually inspected to verify stability and meaningful structure.

#### 3.2.2 Pipeline overview

FigureÂ [1](https://arxiv.org/html/2512.21798v1#S3.F1 "Figure 1 â€£ 3.2.2 Pipeline overview â€£ 3.2 Synthetic data generation â€£ 3 Methodology â€£ Applications of synthetic financial data in portfolio and risk modeling") illustrates the end-to-end workflow for generating and evaluating synthetic financial datasets.

Historical S&P 500 Returns
(Preprocessing: log-returns, normalization)

Synthetic Data Generation
TimeGAN / VAE

Downstream Tasks
Portfolio Optimization, Risk Modeling, Backtesting

Evaluation
Statistical Fidelity, Utility, Robustness, Privacy


Figure 1: End-to-end pipeline for synthetic financial data generation and downstream evaluation.

This setup ensures that downstream tasks can be tested on data that closely mimics real market behavior without compromising confidentiality.

### 3.3 Portfolio optimization framework

To assess the usability of synthetic financial data, we adopt the classical mean-variance optimization frameworkÂ [markowitz1952portfolio], extended here to a multi-asset synthetic dataset scenario. This allows us to evaluate whether synthetic data can reliably reproduce realistic portfolio allocations.

#### 3.3.1 Optimization problem

Let ğ’˜=(w1,w2,â€¦,wN)âŠ¤\boldsymbol{w}=(w\_{1},w\_{2},\dots,w\_{N})^{\top} denote portfolio weights, ğ\boldsymbol{\mu} the expected return vector, and Î£\Sigma the covariance matrix. The optimization problem is formulated as:

|  |  |  |
| --- | --- | --- |
|  | minğ’˜â¡ğ’˜âŠ¤â€‹Î£â€‹ğ’˜s.t.ğ’˜âŠ¤â€‹ğ=Î¼p,ğ’˜âŠ¤â€‹ğŸ=1,wiâ‰¥0\boxed{\min\_{\boldsymbol{w}}\;\boldsymbol{w}^{\top}\Sigma\boldsymbol{w}\quad\text{s.t.}\quad\boldsymbol{w}^{\top}\boldsymbol{\mu}=\mu\_{p},\quad\boldsymbol{w}^{\top}\mathbf{1}=1,\quad w\_{i}\geq 0} |  |

The Lagrangian formulation introduces multipliers Î»,Î³\lambda,\gamma for the constraints:

|  |  |  |
| --- | --- | --- |
|  | â„’â€‹(ğ’˜,Î»,Î³)=ğ’˜âŠ¤â€‹Î£â€‹ğ’˜âˆ’Î»â€‹(ğ’˜âŠ¤â€‹ğâˆ’Î¼p)âˆ’Î³â€‹(ğ’˜âŠ¤â€‹ğŸâˆ’1)\mathcal{L}(\boldsymbol{w},\lambda,\gamma)=\boldsymbol{w}^{\top}\Sigma\boldsymbol{w}-\lambda(\boldsymbol{w}^{\top}\boldsymbol{\mu}-\mu\_{p})-\gamma(\boldsymbol{w}^{\top}\mathbf{1}-1) |  |

Solving the first-order conditions yields the optimal weights:

|  |  |  |
| --- | --- | --- |
|  | ğ’˜âˆ—=Î£âˆ’1â€‹(Î»2â€‹ğ+Î³2â€‹ğŸ)\boldsymbol{w}^{\*}=\Sigma^{-1}\left(\frac{\lambda}{2}\boldsymbol{\mu}+\frac{\gamma}{2}\mathbf{1}\right) |  |

|  |  |  |
| --- | --- | --- |
|  | [ğâŠ¤â€‹Î£âˆ’1â€‹ğğâŠ¤â€‹Î£âˆ’1â€‹ğŸğŸâŠ¤â€‹Î£âˆ’1â€‹ğğŸâŠ¤â€‹Î£âˆ’1â€‹ğŸ]â€‹[Î»/2Î³/2]=[Î¼p1]\begin{bmatrix}\boldsymbol{\mu}^{\top}\Sigma^{-1}\boldsymbol{\mu}&\boldsymbol{\mu}^{\top}\Sigma^{-1}\mathbf{1}\\ \mathbf{1}^{\top}\Sigma^{-1}\boldsymbol{\mu}&\mathbf{1}^{\top}\Sigma^{-1}\mathbf{1}\end{bmatrix}\begin{bmatrix}\lambda/2\\ \gamma/2\end{bmatrix}=\begin{bmatrix}\mu\_{p}\\ 1\end{bmatrix} |  |

This provides a closed-form solution for ğ’˜âˆ—\boldsymbol{w}^{\*}, applicable to both real and synthetic datasets.

#### 3.3.2 Implementation with synthetic data

The procedure for constructing portfolios using synthetic data can be summarized in the following pseudo-code:

```
Input: Synthetic dataset R_syn, target return mu_p
Output: Optimal weights w*

1. Compute mean vector mu_syn and covariance Sigma_syn from R_syn
2. Formulate Lagrangian L(w, lambda, gamma)
3. Solve linear system for multipliers lambda, gamma
4. Compute w* = Sigma_syn^{-1} (lambda/2 * mu_syn + gamma/2 * 1)
5. Return w*
```

TableÂ [6](https://arxiv.org/html/2512.21798v1#S4.T6 "Table 6 â€£ 4.4 Downstream utility: Portfolio optimization and risk evaluation â€£ 4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") compares portfolio weights derived from real versus synthetic data generated using TimeGAN, demonstrating the fidelity of synthetic-based allocations:

Table 2: Portfolio weights comparison: real vs synthetic S&P 500 multi-asset data. Synthetic weights are generated with TimeGAN.

| Asset | Real data weight | Synthetic data weight |
| --- | --- | --- |
| AAPL | 0.12 | 0.11 |
| MSFT | 0.10 | 0.09 |
| GOOGL | 0.08 | 0.08 |
| AMZN | 0.09 | 0.10 |
| TSLA | 0.07 | 0.06 |
| SPY (ETF) | 0.54 | 0.56 |

To further illustrate model fidelity, FigureÂ [2](https://arxiv.org/html/2512.21798v1#S3.F2 "Figure 2 â€£ 3.3.2 Implementation with synthetic data â€£ 3.3 Portfolio optimization framework â€£ 3 Methodology â€£ Applications of synthetic financial data in portfolio and risk modeling") presents a bar chart of real versus synthetic portfolio weights. Additional diagnostic plots (histograms of returns, covariance matrix comparisons) are provided in the Appendix.

![Refer to caption](optimiz.png)


Figure 2: Comparison of portfolio weights between real and synthetic S&P 500 data.

#### 3.3.3 Robustness and reproducibility

Synthetic-based portfolios were generated using multiple random seeds to evaluate robustness. Across repetitions, portfolio weights remained stable, confirming that synthetic datasets can reliably support downstream quantitative finance tasks while preserving data privacy.

Next, we examine whether synthetic datasets can replicate key risk characteristics and respond appropriately under stress scenarios, complementing the portfolio optimization analysis.

### 3.4 Risk modeling and stress testing

To evaluate how synthetic data capture risk dynamics, we estimated volatility and tail-risk metrics across both real and synthetic datasets.
The conditional variance of returns was modeled via a GARCH(1,1) process:

|  |  |  |
| --- | --- | --- |
|  | Ïƒt2=Ï‰+Î±1â€‹Îµtâˆ’12+Î²1â€‹Ïƒtâˆ’12\boxed{\sigma\_{t}^{2}=\omega+\alpha\_{1}\varepsilon\_{t-1}^{2}+\beta\_{1}\sigma\_{t-1}^{2}} |  |

where Îµt=rtâˆ’Î¼t\varepsilon\_{t}=r\_{t}-\mu\_{t} represents the innovation at time tt.
The Value-at-Risk (VaR) and Expected Shortfall (ES) at a confidence level Î±\alpha were computed as:

|  |  |  |
| --- | --- | --- |
|  | VaRÎ±=Î¼t+zÎ±â€‹Ïƒt,ESÎ±=Î¼tâˆ’Ïƒtâ€‹Ï•â€‹(zÎ±)Î±\boxed{\text{VaR}\_{\alpha}=\mu\_{t}+z\_{\alpha}\sigma\_{t},\qquad\text{ES}\_{\alpha}=\mu\_{t}-\frac{\sigma\_{t}\,\phi(z\_{\alpha})}{\alpha}} |  |

where zÎ±z\_{\alpha} is the Î±\alpha-quantile of the standard normal distribution and Ï•â€‹(â‹…)\phi(\cdot) denotes the standard normal PDF.

Table 3: Risk metric comparison between real and synthetic datasets

| Dataset | Volatility (%) | VaR0.95 (%) | ES0.95 (%) |
| --- | --- | --- | --- |
| Real Data | 1.27 | -2.11 | -2.88 |
| TimeGAN | 1.30 | -2.05 | -2.79 |
| VAE | 1.19 | -1.92 | -2.63 |

To visually complement the tabular comparison of risk metrics, FigureÂ [3](https://arxiv.org/html/2512.21798v1#S3.F3 "Figure 3 â€£ 3.4 Risk modeling and stress testing â€£ 3 Methodology â€£ Applications of synthetic financial data in portfolio and risk modeling") depicts the volatility, Value-at-Risk (VaR0.95), and Expected Shortfall (ES0.95) across real and synthetic datasets. The synthetic data closely replicate the risk characteristics of the real market series, as also evaluated in [hounwanou2025evaluating].

![Refer to caption](metrics.png)


Figure 3: Comparison of volatility, Value-at-Risk (VaR0.95), and Expected Shortfall (ES0.95) between real S&P 500 returns and synthetic datasets.

These results demonstrate that synthetic data can approximate real-world risk profiles with minor deviations, supporting their potential for secure and reproducible financial experimentation.

### 3.5 Backtesting and performance evaluation

Finally, a backtesting framework was used to test the practical viability of strategies trained on synthetic data.
A rolling-window approach was adopted: at each step, models were trained on a 5-year window of synthetic data and tested on the subsequent real 6 months.

Performance was measured using standard metrics:

|  |  |  |
| --- | --- | --- |
|  | Sharpe Ratio=Eâ€‹[Rpâˆ’Rf]Ïƒp,Sortino Ratio=Eâ€‹[Rpâˆ’Rf]Ïƒd,Max Drawdown=maxâ¡(Pt)âˆ’minâ¡(Pt)maxâ¡(Pt)\text{Sharpe Ratio}=\frac{E[R\_{p}-R\_{f}]}{\sigma\_{p}},\quad\text{Sortino Ratio}=\frac{E[R\_{p}-R\_{f}]}{\sigma\_{d}},\quad\text{Max Drawdown}=\frac{\max(P\_{t})-\min(P\_{t})}{\max(P\_{t})} |  |

where :

* â€¢

  RpR\_{p} denotes the portfolio return,
* â€¢

  RfR\_{f} the risk-free rate,
* â€¢

  Ïƒp\sigma\_{p} the total volatility,
* â€¢

  Ïƒd\sigma\_{d} the downside deviation.

Table 4: Portfolio Performance Metrics (Synthetic vs. Real Training Data)

| Training Data | Sharpe Ratio | Sortino Ratio | Max Drawdown (%) |
| --- | --- | --- | --- |
| Real Data | 0.89 | 1.31 | 23.4 |
| TimeGAN | 0.84 | 1.26 | 25.1 |
| VAE | 0.78 | 1.14 | 27.6 |

The close alignment of performance metrics between synthetic and real data-trained portfolios provides empirical evidence that synthetic datasets preserve essential market structure and can support realistic decision-making in financial modeling.

## 4 Results

This section presents the experimental outcomes of our synthetic data generation framework applied to financial time series. We report quantitative and qualitative analyses to assess the realism, fidelity, and utility of the generated datasets for downstream tasks such as portfolio optimization and risk modeling. The models compared include TimeGAN, VAE, and ARIMA-GARCH as a statistical baseline.

### 4.1 Experimental setup

Generative models (TimeGAN, VAE, ARIMA-GARCH) were trained on preprocessed S&P 500 daily log-returns from January 2000 to June 2024. Data were split into 80% training, 10% validation, and 10% test sets. Synthetic sequences were generated with the same length as the original series to ensure comparability across downstream tasks.

We evaluate synthetic data on three complementary dimensions:

1. 1.

   Statistical fidelity: Comparison of mean, variance, skewness, kurtosis, and autocorrelation structures between real and synthetic returns.
2. 2.

   Temporal coherence: Assessment of stylized facts such as volatility clustering and heavy tails over time.
3. 3.

   Downstream utility: Evaluation of portfolio optimization, risk measures, and backtesting outcomes using synthetic versus real data.

This structured setup allows for a coherent comparison of the strengths and limitations of synthetic datasets in practical financial modeling.

### 4.2 Distributional fidelity

We first examine how well synthetic returns capture the distributional characteristics of the S&P 500. TableÂ [5](https://arxiv.org/html/2512.21798v1#S4.T5 "Table 5 â€£ 4.2 Distributional fidelity â€£ 4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") reports Kolmogorov-Smirnov (KS) statistics and Wasserstein distances between real and synthetic returns.

Table 5: Distributional similarity metrics between real and synthetic S&P 500 returns. Lower values indicate better fidelity.

| Model | KS Statistic | Wasserstein Distance |
| --- | --- | --- |
| ARIMA-GARCH | 0.128 | 0.0047 |
| VAE | 0.095 | 0.0031 |
| TimeGAN | 0.062 | 0.0018 |

TimeGAN achieves the lowest KS and Wasserstein values, demonstrating that it best replicates the marginal distributions of the real S&P 500 series. VAE shows moderate fidelity, while ARIMA-GARCH is limited by its parametric assumptions.

To assess whether synthetic generators reproduce the marginal distribution of financial returns, we compare kernel density estimates (KDE) of real versus synthetic log-returns. FigureÂ [4](https://arxiv.org/html/2512.21798v1#S4.F4 "Figure 4 â€£ 4.2 Distributional fidelity â€£ 4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") shows that TimeGAN closely matches the heavy-tailed, leptokurtic shape of real S&P 500 returns. VAE produces smoother and more Gaussian like distributions, while ARIMA-GARCH captures skewness but underestimates tail risk.

![Refer to caption](dist_comparaison.png)


Figure 4: Comparison of the marginal distribution of real and synthetic log-returns.

### 4.3 Temporal coherence

To evaluate preservation of temporal structures, we compute autocorrelation functions (ACF) and dynamic time warping (DTW) distances between real and synthetic series:

|  |  |  |  |
| --- | --- | --- | --- |
|  | DTWâ€‹(Xreal,Xsyn)=minÏ€â€‹âˆ‘(i,j)âˆˆÏ€â€–xiâˆ’x^jâ€–\text{DTW}(X\_{\text{real}},X\_{\text{syn}})=\min\_{\pi}\sum\_{(i,j)\in\pi}\|x\_{i}-\hat{x}\_{j}\| |  | (4.1) |

Mean DTW distances indicate that TimeGAN preserves temporal dependencies more effectively (0.132) than VAE (0.187) and ARIMA-GARCH (0.243).

![Refer to caption](ACF.png)


Figure 5: Autocorrelation and DTW comparisons for real and synthetic financial series.

### 4.4 Downstream utility: Portfolio optimization and risk evaluation

We assess the usability of synthetic data in practical financial tasks. Portfolio allocations are computed using the mean-variance framework (SectionÂ [3](https://arxiv.org/html/2512.21798v1#S3 "3 Methodology â€£ Applications of synthetic financial data in portfolio and risk modeling")) on real and synthetic datasets. Risk metrics such as Value-at-Risk (VaR) and Expected Shortfall (ES) are also evaluated. TableÂ [6](https://arxiv.org/html/2512.21798v1#S4.T6 "Table 6 â€£ 4.4 Downstream utility: Portfolio optimization and risk evaluation â€£ 4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") illustrates example portfolio weights.

Table 6: Portfolio weights computed from real and TimeGAN-generated synthetic data.

| Asset | Real Data Weight | Synthetic Data Weight |
| --- | --- | --- |
| AAPL | 0.12 | 0.11 |
| MSFT | 0.10 | 0.09 |
| GOOGL | 0.08 | 0.08 |
| AMZN | 0.09 | 0.10 |
| TSLA | 0.07 | 0.06 |
| SPY | 0.54 | 0.56 |

The results demonstrate that synthetic data, particularly from TimeGAN, produces allocations and risk measures closely aligned with real-data benchmarks, confirming its utility for downstream financial modeling.

### 4.5 Visual comparison of synthetic series

Visual inspection complements quantitative evaluation. FigureÂ [6](https://arxiv.org/html/2512.21798v1#S4.F6 "Figure 6 â€£ 4.5 Visual comparison of synthetic series â€£ 4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") shows overlays of real versus synthetic log-return series. TimeGAN sequences retain volatility clustering and extreme events, whereas VAE is smoother, and ARIMA-GARCH captures linear trends but underestimates higher-order temporal structure.

![Refer to caption](visual_comp.png)


Figure 6: Overlay of real and synthetic S&P 500 returns.

## 5 Discussion

The findings of this study show that deep generative models can produce synthetic financial time series that behave similarly to real market data across several evaluation dimensions. While the quantitative analyses in SectionÂ [4](https://arxiv.org/html/2512.21798v1#S4 "4 Results â€£ Applications of synthetic financial data in portfolio and risk modeling") highlighted model-specific differences, the broader implication is that synthetic data generation has reached a maturity level that allows its integration into practical financial workflows.

### 5.1 Model performance and interpretability

Among the tested models, TimeGAN delivered the most coherent synthetic outputs from an overall modeling perspective. Its design allows it to capture complex patterns that traditional statistical models cannot represent, which explains its superior alignment with empirical behaviors. However, this expressiveness comes at the cost of heavier computation and reduced interpretability, which may limit adoption in highly regulated environments.

The VAE provided more structured and predictable behavior during training and offered an interpretable latent representation useful for controlled scenario design. Nevertheless, its tendency to smooth out abrupt dynamics suggests that it may be better suited for exploratory analyses rather than applications requiring precise reproduction of tail behaviors. In contrast, the ARIMA-GARCH model remains attractive for practitioners seeking transparency and speed, though its structural rigidity restricts its ability to emulate richer market dynamics.

### 5.2 Implications for financial modeling

The capacity to generate realistic synthetic datasets provides several advantages for quantitative finance. Synthetic data can expand limited historical samples, enabling more reliable evaluation of portfolio strategies over a wider variety of market conditions. Additionally, because synthetic datasets can be shared without revealing sensitive or proprietary information, they provide a practical mechanism for collaborative research and model auditing. Generative models also make it possible to explore hypothetical or extreme regimes, offering a flexible tool for stress-testing and scenario analysis beyond what historical observations alone allow.

### 5.3 Limitations

Despite encouraging results, the current framework still faces multiple limitations. The analysis focused exclusively on a single market index, leaving multi-asset relationships outside the scope of this study. The deep models considered were limited to baseline architectures; richer sequential variants could potentially capture more nuanced dependencies. Finally, while the experiments demonstrated that TimeGAN performed robustly overall, the sensitivity of its training process and the possibility of mode collapse were not systematically investigated, which may affect reproducibility.

### 5.4 Future directions

Future work will extend the methodology in several ways. Incorporating hybrid architectures that combine the interpretability of statistical models with the flexibility of deep generative networks may help balance realism and transparency. Embedding differential privacy mechanisms directly into the training pipeline could enable the controlled release of synthetic datasets with formal privacy guarantees. Moreover, establishing large-scale benchmarks spanning multiple asset classes and market regimes would support standardized comparisons and promote replicability across research groups.

## 6 Conclusion

This work examined the usefulness of synthetic financial time series generated with TimeGAN and Variational Autoencoders for portfolio optimization, trading backtesting, and risk modeling. The results show that well-trained generative models can reproduce essential statistical and temporal characteristics of real market data, enabling reliable downstream analysis while enhancing data privacy.
Key findings include:

* â€¢

  Temporal fidelity and market realism: TimeGAN-generated sequences closely replicate volatility clustering, autocorrelation structures, and extreme events, supporting robust portfolio allocation and risk assessment. VAEs provide smoother sequences that are stable but less reactive to sudden market changes.
* â€¢

  Downstream task performance: Models trained on synthetic data achieve performance metrics (e.g., Sharpe Ratio, Value-at-Risk) comparable to those obtained using real data, indicating practical viability for quantitative finance applications.
* â€¢

  Privacy-preserving experimentation: Synthetic data enables secure sharing and stress-testing of financial strategies without exposing sensitive asset-level information.

Despite these advantages, several limitations warrant attention:

1. 1.

   Experiments were limited to a single market index (S&P 500), restricting generalization to multi-asset portfolios.
2. 2.

   Only standard VAEs were evaluated; sequential variants (e.g., VRNN, SRNN) may better capture temporal dynamics.
3. 3.

   TimeGAN stability and sensitivity to hyperparameter tuning were not fully quantified, representing a potential source of variability.

This study remains limited by its single-asset scope and the use of standard VAE architectures. Future work will expand to multi-asset settings, explore sequential VAE variants, and integrate privacy-preserving mechanisms into training pipelines. More broadly, establishing open benchmarks for synthetic financial data will support reproducibility and accelerate research in data-constrained financial environments.

## Appendix A Appendix

### A.1 Hardware and training details

All experiments were conducted on a single GPU machine with the following specifications:

* â€¢

  GPU: NVIDIA RTX 3090
* â€¢

  RAM: 64 GB
* â€¢

  Training times: approximately 4.5 hours for TimeGAN, 2 hours for VAE (full S&P 500 dataset)

### A.2 Hyperparameter settings

Table 7: Key hyperparameters for synthetic data models

|  |  |  |
| --- | --- | --- |
| Parameter | TimeGAN | VAE |
| Hidden layer size | 24 | 32 |
| Latent dimension | 8 | 16 |
| Learning rate | 0.001 | 0.001 |
| Batch size | 128 | 128 |
| Epochs | 100 | 150 |
| Optimizer | Adam | Adam |

### A.3 Data preprocessing scripts

The S&P 500 closing prices were transformed into log-returns and normalized:

|  |  |  |
| --- | --- | --- |
|  | rt=lnâ¡PtPtâˆ’1,r~t=rtâˆ’Î¼rÏƒrr\_{t}=\ln\frac{P\_{t}}{P\_{t-1}},\quad\tilde{r}\_{t}=\frac{r\_{t}-\mu\_{r}}{\sigma\_{r}} |  |

### A.4 Evaluation metrics implementation

* â€¢

  Kolmogorov-Smirnov (KS) statistic and Wasserstein distance for distributional fidelity.
* â€¢

  Dynamic Time Warping (DTW) for temporal alignment:

  |  |  |  |
  | --- | --- | --- |
  |  | DTWâ€‹(Xreal,Xsyn)=minÏ€â€‹âˆ‘(i,j)âˆˆÏ€|xiâˆ’x^j|\text{DTW}(X\_{\text{real}},X\_{\text{syn}})=\min\_{\pi}\sum\_{(i,j)\in\pi}|x\_{i}-\hat{x}\_{j}| |  |
* â€¢

  Portfolio metrics: Sharpe Ratio, Sortino Ratio, Max Drawdown.
* â€¢

  Risk metrics: Volatility, Value-at-Risk (VaR), Expected Shortfall (ES) using GARCH(1,1) models.

### A.5 Reproducibility

All code and preprocessing steps are documented and available at the accompanying GitHub repository. Random seeds were fixed to ensure deterministic results.