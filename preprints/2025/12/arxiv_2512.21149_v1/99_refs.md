---
authors:
- Luca De Gennaro Aquino
- Sascha Desmettre
- Yevhen Havrylenko
- Mogens Steffensen
doc_id: arxiv:2512.21149v1
family_id: arxiv:2512.21149
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Equilibrium investment under dynamic preference uncertainty
url_abs: http://arxiv.org/abs/2512.21149v1
url_html: https://arxiv.org/html/2512.21149v1
venue: arXiv q-fin
version: 1
year: 2025
---


Luca De Gennaro Aquino111Department of Engineering, Reykjavik University, Iceland. <lucaa@ru.is>â€ƒSascha Desmettre222Institute of Financial Mathematics and Applied Number Theory, Johannes Kepler University Linz, Austria. <sascha.desmettre@jku.at>
  
Yevhen Havrylenko333Faculty of Business and Economics, University of Lausanne, Switzerland. [yevhen.havrylenko@unil.ch](yevhen.havrylenko@unil.cg) â€ƒMogens Steffensen444Department of Mathematical Sciences, University of Copenhagen, Denmark. <mogens@math.ku.dk>

###### Abstract

We study a continuous-time portfolio choice problem for an investor whose state-dependent preferences are determined by an exogenous factor that evolves as an ItÃ´ diffusion process. Since risk attitudes at the end of the investment horizon are uncertain, terminal wealth is evaluated under a set of utility functions corresponding to all possible future preference states. These utilities are first converted into certainty equivalents at their respective levels of terminal risk aversion and then (nonlinearly) aggregated over the conditional distribution of future states, yielding an inherently time-inconsistent optimization criterion. We approach this problem by developing a general equilibrium framework for such state-dependent preferences and characterizing subgame-perfect equilibrium investment policies through an extended Hamiltonâ€“Jacobiâ€“Bellman system. This system gives rise to a coupled nonlinear partial integro-differential equation for the value functions associated with each state. We then specialize the model to a tractable constant relative risk aversion specification in which the preference factor follows an arithmetic Brownian motion. In this setting, the equilibrium policy admits a semi-explicit representation that decomposes into a standard myopic demand and a novel preference-hedging component that captures incentives to hedge against anticipated changes in risk aversion. Numerical experiments illustrate how features of the preference dynamics â€“most notably the drift of the preference process and the correlation between preference shocks and asset returnsâ€“ jointly determine the sign and magnitude of the hedging demand and the evolution of the equilibrium risky investment over time.

Keywords: Preference uncertainty, time-inconsistency, equilibrium control theory, certainty equivalents

AMS subject classifications: 91B16, 91B42, 91G10

## 1 Introduction

Optimal dynamic investment problems under uncertainty form a central theme in mathematical finance.
Classical formulations of these problems typically vary along three main dimensions: (i) the nature of the decisions to be made (investment, consumption, insurance, etc.); (ii) the structure of the underlying market (completeness, presence of jumps, stochastic market coefficients, and related features); and (iii) the objective functional (mean-variance trade-offs, expected utility maximization, constraints, or combinations thereof). Within this broad landscape, expected utility maximization remains the dominant paradigm, thanks to its well-established axiomatic foundation and compatibility with dynamic programming.

Most of the existing literature adopts a fixed parametric specification of preferences, typically power utility with a constant relative risk aversion (CRRA). While substantial effort has gone into modeling uncertainty in the financial market (e.g., by replacing deterministic returns and volatilities with stochastic processes), far less attention has been devoted to modeling uncertainty in preferences themselves. The prevailing assumption is that the decision maker knows her utility function and its parameters exactly. As a consequence, comparative statics with respect to the risk aversion coefficient are usually interpreted as comparisons across different agents, rather than as reflecting the uncertainty a single individual may face regarding her own risk attitudes. From a practical perspective, however, the choice of a utility function and its parameters is often the most contentious aspect of the modeling exercise, and skepticism about these inputs can undermine the normative force of the resulting optimization results.

This paper takes a different perspective by treating risk aversion itself as an uncertain and dynamically evolving quantity. Modeling such preference uncertainty introduces a number of conceptual choices. Even in the simple power utility setting, one must specify whether the risk aversion parameter is a random variable or a random process, whether it is observable or latent, what information about it can be learned over time, and whether it should be correlated with the financial market. Each of these modeling choices leads to a distinct dynamic optimization problem. In this paper, we focus on an investor who observes her current level of risk aversion, anticipates that it will evolve randomly over time, and takes this evolution into account when forming long-term investment plans. To capture this, we model risk aversion as a function of an observable diffusion, which may be correlated with the market, and thus can span cases where preferences and returns are independent as well as cases where they are systematically linked.

When formulating a decision problem under random risk aversion, a technical difficulty arises: outcomes evaluated under different utility functions are not directly comparable. Even for power utility, a payoff preferred at one risk aversion level may not be preferred at another, and utilities themselves live on incomparable scales. To resolve this, we map utilities associated with different future risk aversion levels onto a common scale by means of certainty equivalents, and then aggregate them through a flexible second-stage operator. The objective functional resulting from this normalization-aggregation procedure involves an integral of nonlinear transformations of conditional expectations, a structure known to generate time-inconsistency. As a consequence, the usual notion of optimal control is no longer appropriate. Instead, the proper solution concept is that of a time-consistent equilibrium strategy, meaning a strategy that is locally optimal at every point in time.

We develop a continuous-time framework for portfolio choice under evolving, state-dependent preferences and provide both the theoretical foundations and explicit characterizations of an equilibrium investment behavior in this setting.

Our first contribution is to formulate a coherent intertemporal criterion for a decision maker who anticipates that her future risk attitudes will change and that terminal wealth will ultimately be evaluated under the utility corresponding to the realized future state. As mentioned, to compare outcomes evaluated under different utilities, we normalize them through state-specific certainty equivalents and aggregate across future preference realizations using an outer evaluation function. This construction accommodates broad classes of utility functions and preference specifications, and it makes explicit how random, evolving risk aversion generates intrinsic time-inconsistency, even when preferences are fully observable and the market is otherwise standard.

Our second contribution is methodological. The equilibrium Hamiltonâ€“Jacobiâ€“Bellman (HJB) formulations available in earlier studies cannot be applied directly to our framework: the objective involves conditioning on future preference states and an uncountable family of nonlinear transformations of conditional expected utilities. We develop an extension of the equilibrium HJB approach that addresses these two difficulties simultaneously. The key steps are: (i) deriving the dynamics of the state variables under conditioning on a future preference state (Section [3.1](https://arxiv.org/html/2512.21149v1#S3.SS1 "3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")); and (ii) establishing the limiting form â€“as the number of approximation terms tends to infinityâ€“ of the extended HJB system (eHJB) characterizing an equilibrium strategy for a finite-sum approximation of the original reward functional (Section [3.2](https://arxiv.org/html/2512.21149v1#S3.SS2 "3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). This yields a new system that captures the structure of preference uncertainty and is linked to several existing results on equilibrium investment under random risk aversion.

Our third contribution is a verification theorem showing that any solution to the eHJB indeed generates an equilibrium strategy (Section [3.3](https://arxiv.org/html/2512.21149v1#S3.SS3 "3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). This result provides the conceptual bridge between the abstract equilibrium definition and the PDE characterization.

Finally, we apply our framework to a tractable CRRA specification in which the preference factor follows an arithmetic Brownian motion (Section [4](https://arxiv.org/html/2512.21149v1#S4 "4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")). In this setting, the equilibrium conditions reduce to a system that yields the semi-explicit representation of an equilibrium portfolio rule. The resulting policy decomposes into the familiar myopic demand and a new preference-hedging component that reflects the investorâ€™s incentive to adjust her exposure in anticipation of future changes in risk aversion. The structure, sign, and magnitude of this hedging term depend on the drift and volatility of the preference process, its correlation with asset returns, and the shape of the certainty equivalent aggregator.

Even in this simplified CRRA environment, the equilibrium conditions give rise to a coupled nonlinear partial integro-differential equation (PIDE) for the auxiliary value functions associated with each potential preference state. This system cannot be solved analytically and presents significant numerical challenges due to its dimensionality and the continuum of conditioning arguments. To address this, we apply a neural network-based solution method that formulates the PIDE system as a physics-informed learning problem.

Numerical experiments based on this approach illustrate how preference dynamics shape both the hedging demand and the evolution of the equilibrium risky investment over time.

#### Related literature.

Our work relates to and expands several research areas. Optimal investment under state-dependent utility has been studied in BVY18, who adopt the martingale method to obtain explicit solutions and avoid issues of time-inconsistency by not using certainty equivalents for normalization. In their framework, random preferences are fully correlated with the financial market. Optimal consumption, investment, and insurance under state-dependent risk aversion in the health dimension are analyzed in SoS23. As in BVY18, they do not use certainty equivalents, but, in contrast, their random preferences are not correlated with asset returns.

Beyond these contributions, several papers consider time-varying risk attitudes more generally, including Netzer2009:AER, Schildberg2018:JEP, and Bekaert2022:MS, who document how attitudes toward risk may adjust with economic conditions, learning, or endogenous feedback mechanisms. In addition, a substantial body of empirical evidence suggests that preferences themselves are uncertain and subject to latent heterogeneity. Experimental studies, such as WeberMilliman1997:MS, Fischer2000:MS, AndersenEtAl2008:IER, and Brunnermeier2008:AER, show that individuals display significant variation in measured risk aversion across tasks, contexts, and time, supporting the view that preferences may evolve with economic or personal circumstances.

A paper that is particularly close in spirit to ours is DesmettreSteffensen2023:MF, who average over the distribution of certainty equivalents associated with different realizations of an individualâ€™s risk aversion. The primary distinction is that they treat risk aversion as a static random variable, about which the decision maker receives no new information. In contrast, we model risk aversion as an observable stochastic process driven by a stochastic differential equation (SDE), thus offering a greater level of flexibility and dynamic structure.

BS21 also employ certainty equivalents to normalize across a heterogeneous set of agents with varying preferences. More specifically, their objective is formulated as a two-stage utility functional, where an outer utility function is applied to the distribution of the agentsâ€™ certainty equivalents. Another related work is ChenGuanLiang2025, in which risk aversion is determined by a finite-state Markov chain that identifies market regimes. Each regime determines both the drift and volatility of returns and the level of risk aversion, and the optimization problem aggregates expected certainty equivalents across regimes, leading to time-inconsistency.

On the methodological side, our approach is rooted in the equilibrium concept for time-inconsistent control problems. The interpretation that dynamically inconsistent preferences can be treated as a non-cooperative game between successive selves goes back to Strotz1956:RES. A precise mathematical formalization in continuous time was provided by EkelandLazrak2010:MFE, EkelandPirvu2008:MFE, and EkelandMbodjiPirvu2012:SIFIN, primarily in the context of non-exponential discounting. The mean-variance optimization problem, initially incorporated in this framework by BasakChabakauri2010:RFS, was subsequently formalized in the general equilibrium approach by BjorkMurgoci2014:FS, BjorkMurgociZhou2014:MF, and BjorkKhapkoMurgoci2017:FS. KrygerNordfangSteffensen2020:MMRO provide a survey-style overview of objectives where time-inconsistency originates from nonlinearities such as the square function. A comprehensive review of time-inconsistent control theory with applications in finance is given in BjoerkKhapkoMurgoci2021:TICT. Problems in which time-inconsistency arises from certainty equivalents have also been approached through equilibrium theory; see, for example, JensenSteffensen2015:IME and FahrenwaldtJensenSteffensen2020:JME, who aggregate certainty equivalents to disentangle time and risk preferences.

The structure of our objective functional also bears a formal resemblance to the smooth ambiguity model of KlibanoffMarinacciMukerji2005:Econometrica; KlibanoffMarinacciMukerji2009:JET, which separates attitudes toward risk from attitudes toward model uncertainty. However, the rationale is fundamentally different, as in our model, the aggregation reflects uncertainty about future preferences rather than ambiguity about probability models; we expand on this parallel in Remark [2.2](https://arxiv.org/html/2512.21149v1#S2.Thmtheorem2 "Remark 2.2. â€£ 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"). Similar themes of model uncertainty in dynamic equilibrium problems can be found in GuanLiangXia2025:MOR, who combine smooth ambiguity preferences with equilibrium strategies and learning about uncertain asset drift.

Finally, our setting is related to the literature on forward performance processes, as established by MusielaZariphopoulou2007investment; MusielaZariphopoulou2008optimal and Z09. They introduce a new class of dynamic utilities generated forward in time and allow these utilities to be stochastic processes, similar to the exposition in this paper. The key difference is that they do not rely on certainty equivalents, and time-inconsistency does not arise. In that direction, Maggis2025 more recently elaborated on the consistency of optimal portfolio choice for state-dependent exponential utilities, and found that a unique forward prediction of random risk aversion exists, ensuring the consistency of optimal strategies across any time horizon.

#### Structure of the paper

The rest of the paper unfolds as follows. Section [2](https://arxiv.org/html/2512.21149v1#S2 "2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty") introduces the economic environment, including the financial market, the preference state process, and the reward functional used to evaluate portfolio strategies. Section [3](https://arxiv.org/html/2512.21149v1#S3 "3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty") develops the extended equilibrium HJB system and contains the verification theorem. Section [4](https://arxiv.org/html/2512.21149v1#S4 "4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty") specializes the framework to a tractable CRRA setting. Section [5](https://arxiv.org/html/2512.21149v1#S5 "5 Conclusion â€£ Equilibrium investment under dynamic preference uncertainty") concludes. All technical proofs and auxiliary results are collected in the Appendices.

## 2 Problem formulation

Let (Î©,â„±,(â„±t)0â‰¤tâ‰¤T,â„™)(\Omega,\mathcal{F},(\mathcal{F}\_{t})\_{0\leq t\leq T},\mathbb{P}) be a filtered probability space satisfying the usual conditions, where T>0T>0 is a fixed time horizon, and let B1B^{1} and B2B^{2} be two independent standard Brownian motions on this space. We denote by ğ’¯:=[0,T]\mathcal{T}:=[0,T] the investment period.

The investor operates under a classical Blackâ€“Scholes financial market with a risk-free asset and one risky asset:

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹St0\displaystyle dS^{0}\_{t} | =St0â€‹râ€‹dâ€‹t,\displaystyle=S^{0}\_{t}rdt\,, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹St1\displaystyle dS^{1}\_{t} | =St1â€‹(Î¼Sâ€‹dâ€‹t+ÏƒSâ€‹(Ïâ€‹dâ€‹Bt1+1âˆ’Ï2â€‹dâ€‹Bt2)),\displaystyle=S^{1}\_{t}\left(\mu\_{S}dt+\sigma\_{S}\left(\rho dB^{1}\_{t}+\sqrt{1-\rho^{2}}dB^{2}\_{t}\right)\right)\,, |  |

with r,Î¼Sâˆˆâ„,ÏƒS>0r,\mu\_{S}\in\mathbb{R},\sigma\_{S}>0, Ïâˆˆ[âˆ’1,1]\rho\in[-1,1] constants. Here, we introduced two Brownian motions to keep track of two distinct sources of uncertainty. One of them, B1B^{1}, will also drive the evolution of the preference factor (described below) so that shocks to the risky asset can be correlated with shocks to risk aversion. The second, B2B^{2}, provides an independent source of randomness.

In what follows, we denote by Ï€â€‹(t,x,y)âˆˆâ„\pi(t,x,y)\in\mathbb{R} the fraction of wealth invested in the stock S1S^{1} at timeÂ tt, given current wealth xx and preference state yy. The process Ï€=(Ï€â€‹(t,XtÏ€,Yt))tâˆˆğ’¯\pi=\left(\pi(t,X^{\pi}\_{t},Y\_{t})\right)\_{t\in\mathcal{T}} is referred to as the portfolio strategy, the investment strategy, or simply the control. For brevity, we will often write Ï€â€‹(t)\pi(t) in place of Ï€â€‹(t,XtÏ€,Yt)\pi(t,X^{\pi}\_{t},Y\_{t}). (We adopt the notation Ï€â€‹(t)\pi(t), instead of Ï€t\pi\_{t}, to emphasize that the control depends explicitly on the current time â€“and state variablesâ€“, rather than to suggest a dynamic process indexed by tt.)

The controlled wealth process XÏ€=(XtÏ€)tâˆˆğ’¯X^{\pi}=\left(X^{\pi}\_{t}\right)\_{t\in\mathcal{T}}, under an admissible portfolio strategy Ï€\pi, is given by the solution of the SDE

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹XtÏ€=XtÏ€â€‹(r+Ï€â€‹(t)â€‹(Î¼Sâˆ’r))â€‹dâ€‹t+XtÏ€â€‹Ï€â€‹(t)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹Bt1+1âˆ’Ï2â€‹dâ€‹Bt2),X0Ï€=x0>0.\begin{split}dX^{\pi}\_{t}&=X^{\pi}\_{t}(r+\pi(t)(\mu\_{S}-r))dt+X^{\pi}\_{t}\pi(t)\sigma\_{S}\left(\rho dB^{1}\_{t}+\sqrt{1-\rho^{2}}dB^{2}\_{t}\right)\,,\\ X^{\pi}\_{0}&=x\_{0}>0.\end{split} |  | (2.1) |

The drift Î¼X\mu\_{X} and diffusion ÏƒX\sigma\_{X} of XÏ€X^{\pi}, in accordance with ([2.1](https://arxiv.org/html/2512.21149v1#S2.E1 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")), may be written compactly as

|  |  |  |
| --- | --- | --- |
|  | dâ€‹XtÏ€=Î¼Xâ€‹(t,XtÏ€,Ï€â€‹(t))â€‹dâ€‹t+ÏƒXâ€‹(t,XtÏ€,Ï€â€‹(t))â€‹dâ€‹Bt,dX^{\pi}\_{t}=\mu\_{X}(t,X^{\pi}\_{t},\pi(t))dt+\sigma\_{X}(t,X^{\pi}\_{t},\pi(t))dB\_{t}, |  |

where B:=(B1,B2)B:=(B^{1},B^{2}). The wealth process takes values in ğ’³:=(0,âˆ)\mathcal{X}:=(0,\infty).

To model time variation in risk attitudes, we introduce an exogenous factor process YY, taking values in a state space ğ’´\mathcal{Y}, and governed by the diffusion process

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Yt=Î¼Yâ€‹(t,Yt)â€‹dâ€‹t+ÏƒYâ€‹(t,Yt)â€‹dâ€‹Bt1,Y0=y0âˆˆâ„,dY\_{t}=\mu\_{Y}(t,Y\_{t})dt+\sigma\_{Y}(t,Y\_{t})dB^{1}\_{t},\qquad Y\_{0}=y\_{0}\in\mathbb{R}, |  | (2.2) |

where Î¼Y,ÏƒY:ğ’¯Ã—ğ’´â†¦â„\mu\_{Y},\sigma\_{Y}:\mathcal{T}\times\mathcal{Y}\mapsto\mathbb{R} are continuous functions ensuring that ([2.2](https://arxiv.org/html/2512.21149v1#S2.E2 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) has a unique strong solution and ÏƒYâ€‹(t,y)â‰ 0\sigma\_{Y}(t,y)\neq 0 for all (t,y)âˆˆğ’¯Ã—ğ’´(t,y)\in\mathcal{T}\times\mathcal{Y}. Note that while ChenGuanLiang2025 assume the independence between the preference factor and the risky asset, we allow for arbitrary correlation through the common Brownian motion B1B^{1}.

The process YY serves as the sole driver of intertemporal fluctuations in preferences; that is, the investorâ€™s risk attitude at time tt is captured through the mapping Î³:ğ’´â†¦â„\gamma:\mathcal{Y}\mapsto\mathbb{R}, which parametrizes the curvature of the instantaneous utility function. Therefore, all changes in risk aversion arise from the stochastic evolution of YY.

Intuitively, the factor YY may represent broad economic indicators, such as stock prices or volatility, or more individual circumstances, such as health conditions or habits. For a fixed realization of YT=yÂ¯Y\_{T}=\bar{y}, the value Î³â€‹(yÂ¯)\gamma(\bar{y}) is then inserted into a utility specification, where, depending on the chosen utility family, it parametrizes either relative risk aversion or absolute risk aversion. (In the present formulation, only the terminal value YTY\_{T} enters the utility evaluation, so we only require a parameterization of Î³\gamma at time TT. Nonetheless, if one were to introduce intermediate consumption, the same mechanism would naturally extend to a time-varying risk aversion index Î³â€‹(Yt)\gamma(Y\_{t}), applied at each consumption time.)

The usual notions of constant relative or absolute risk aversion refer primarily to the parameterâ€™s independence on wealth, and this feature is preserved here. What we allow, however, is that risk aversion may shift in response to the evolution of the underlying state variable YY. Thus, along the wealth dimension, the investor behaves like a standard CRRA or CARA agent, while economic or personal conditions summarized by YY can make the investor effectively more or less risk-averse over time.

For each possible future preference state yÂ¯âˆˆğ’´\bar{y}\in\mathcal{Y}, we denote by uÎ³â€‹(yÂ¯):ğ’³â†’â„u^{\gamma(\bar{y})}:\mathcal{X}\to\mathbb{R} the von-Neumann-Morgenstern utility function associated with the risk aversion level Î³â€‹(yÂ¯)\gamma(\bar{y}). We assume that each uÎ³â€‹(yÂ¯)u^{\gamma(\bar{y})} is increasing, strictly concave, and twice continuously differentiable, with strictly nonvanishing marginal utility, i.e., (uÎ³â€‹(yÂ¯))â€²â€‹(x)â‰ 0,(u^{\gamma(\bar{y})})^{\prime}(x)\neq 0, for all xâˆˆğ’³x\in\mathcal{X}.

###### Remark 2.1.

The pair (Y,Î³)(Y,\gamma) is intentionally not uniquely determined. Only the composite quantity Î³â€‹(yÂ¯)\gamma(\bar{y}) matters for preferences, and different choices of yÂ¯\bar{y} and Î³\gamma can produce the same effective specification. For example, in the numerical section, we formalize the state variable as an arithmetic Brownian motion and take Î³â€‹(yÂ¯)=expâ¡(yÂ¯)\gamma(\bar{y})=\exp(\bar{y}), which leads to the risk aversion becoming a geometric Brownian motion.
The very same structure could instead be obtained by choosing YY directly as a geometric Brownian motion and letting Î³\gamma be the identity function. More generally, any monotone reparameterization of YY, combined with the corresponding inverse adjustment of Î³\gamma, leaves the induced preferences unchanged.

This apparent ambiguity is a feature rather than a limitation: it enables us to place different *types* of risk aversion, such as relative and absolute risk aversion, within a common framework, in the sense that the same underlying factor YY, be that a stock price or a health index, may drive both the CRRA and the CARA. The model, therefore, accommodates situations in which several facets of risk attitudes respond to the same economic or personal conditions.

Before defining the objective functional, we describe the utility structure induced by preference uncertainty. As mentioned, at the investment horizon, terminal wealth is evaluated under the utility function uÎ³â€‹(yÂ¯)u^{\gamma(\bar{y})}, for each yÂ¯âˆˆğ’´\bar{y}\in\mathcal{Y}. However, utilities arising from different preference states are not directly comparable, hence after computing the conditional expected utility under the scenario YT=yÂ¯,Y\_{T}=\bar{y},
we normalize it via the inverse utility (uÎ³â€‹(yÂ¯))âˆ’1\left(u^{\gamma(\bar{y})}\right)^{-1}, obtaining the certainty equivalent at the preference state yÂ¯\bar{y}:

|  |  |  |
| --- | --- | --- |
|  | (uÎ³â€‹(YT))âˆ’1â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)]),\left(u^{\gamma(Y\_{T})}\right)^{-1}\Big(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\Big), |  |

with the conditional expectation meant as ğ”¼t,x,y,yÂ¯[â‹…]:=ğ”¼[â‹…|XtÏ€=x,Yt=y,YT=yÂ¯].\mathbb{E}\_{t,x,y,\overline{y}}\big[\cdot\big]:=\mathbb{E}\big[\cdot\,|\,X^{\pi}\_{t}=x,Y\_{t}=y,Y\_{T}=\overline{y}\big].
These state-dependent certainty equivalents are then aggregated across all possible future preference states through a function v:ğ’³â†’â„v:\mathcal{X}\to\mathbb{R}, which is assumed to be increasing and twice continuously differentiable.

This produces the reward functional

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€â€‹(t,x,y):=ğ”¼t,x,yâ€‹[vâˆ˜(uÎ³â€‹(YT))âˆ’1â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)])],J^{\pi}(t,x,y):=\mathbb{E}\_{t,x,y}\left[v\circ\left(u^{\gamma(Y\_{T})}\right)^{-1}\Big(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\Big)\right]\,,\\ |  | (2.3) |

where vâˆ˜(uÎ³â€‹(YT))âˆ’1v\circ\left(u^{\gamma(Y\_{T})}\right)^{-1} denotes the composition of vv and (uÎ³â€‹(YT))âˆ’1\left(u^{\gamma(Y\_{T})}\right)^{-1}.

This two-stage normalization-aggregation structure provides a coherent way to compare utilities generated under different future preference states, but it also introduces nonlinear conditioning on both the present and future preference states, thereby generating time-inconsistency.

###### Remark 2.2.

The outer function vv in ([2.3](https://arxiv.org/html/2512.21149v1#S2.E3 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) plays a role reminiscent of the second-order utility (also referred to as the ambiguity index) in the smooth ambiguity model of KlibanoffMarinacciMukerji2005:Econometrica. In their model, Klibanoff, Marinacci, and Mukerji (KMM) aggregate expected first-order utility via a fixed function Ï•\phi, whose concavity (convexity) directly encodes ambiguity aversion (ambiguity loving). In our setting, aggregation occurs through the family of functions vâˆ˜(uÎ³â€‹(yÂ¯))âˆ’1v\circ\left(u^{\gamma(\overline{y})}\right)^{-1}, which depend explicitly on the future preference state yÂ¯\overline{y} and are therefore random rather than fixed.

Alternatively, one may regard vv itself as a deterministic aggregator applied to certainty equivalents (instead of expected utilities, as in the KMM model), conditional on YT=yÂ¯Y\_{T}=\overline{y}. The curvature of vv therefore governs the attitude toward ambiguity in certainty equivalents, which is not directly analogous to the curvature of Ï•\phi. Therefore, the economic meaning of concavity differs across the two frameworks: while the concavity of Ï•\phi captures aversion to model uncertainty, the concavity of vv captures aversion to dispersion in normalized payoffs arising from uncertain future preferences.

We next specify the class of admissible investment strategies. Admissibility here requires that the wealth and preference processes remain well-defined under the chosen control, and that the reward functional JÏ€â€‹(t,x,y)J^{\pi}(t,x,y) is finite for all initial states.

###### Definition 2.3 (Admissible control law).

An admissible control law is a map Ï€:ğ’¯Ã—ğ’³Ã—ğ’´â†’â„\pi:\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\to\mathbb{R} satisfying the following conditions:

1. (a)

   For each initial point (t,x,y)âˆˆğ’¯Ã—ğ’³Ã—ğ’´(t,x,y)\in\mathcal{T}\times\mathcal{X}\times\mathcal{Y}, the SDEs ([2.1](https://arxiv.org/html/2512.21149v1#S2.E1 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"))-([2.2](https://arxiv.org/html/2512.21149v1#S2.E2 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"))
   have a unique strong solution denoted by XÏ€X^{\pi}, YY.
2. (b)

   For each point (t,x,y)âˆˆğ’¯Ã—ğ’³Ã—ğ’´(t,x,y)\in\mathcal{T}\times\mathcal{X}\times\mathcal{Y}, we have

   |  |  |  |
   | --- | --- | --- |
   |  | ğ”¼t,x,yâ€‹[vâˆ˜(uÎ³â€‹(YT))âˆ’1â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)])]<âˆ.\mathbb{E}\_{t,x,y}\left[v\circ\left(u^{\gamma(Y\_{T})}\right)^{-1}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\right)\right]<\infty\,. |  |
3. (c)

   Ï€\pi is continuous in t,x,yt,x,y.

The set of admissible strategies is denoted by ğ“\bm{\mathcal{A}}.

Because the objective functional ([2.3](https://arxiv.org/html/2512.21149v1#S2.E3 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) is time-inconsistent, one cannot rely on the dynamic programming principle to find optimal controls. Therefore, we seek to determine equilibrium control laws in the sense of the following definition.

###### Definition 2.4 (Equilibrium control law; cf. Def. 15.3 in BjoerkKhapkoMurgoci2021:TICT).

Consider an admissible control law Ï€^\widehat{\pi} (informally viewed as a candidate equilibrium law). Choose an arbitrary Ï€âˆˆğ“\pi\in\bm{\mathcal{A}} and a fixed real number Î´>0\delta>0. Fix moreover an arbitrary initial point (t,x,y)(t,x,y) and define the control law Ï€Î´\pi\_{\delta} by

|  |  |  |
| --- | --- | --- |
|  | Ï€Î´â€‹(s,x,y)={Ï€â€‹(s,x,y)forâ€‹(s,x,y)âˆˆ[t,t+Î´)Ã—ğ’³Ã—ğ’´,Ï€^â€‹(s,x,y)forâ€‹(s,x,y)âˆˆ[t+Î´,T)Ã—ğ’³Ã—ğ’´.\displaystyle\pi\_{\delta}(s,x,y)=\begin{cases}\pi(s,x,y)&\mbox{for}\,\,(s,x,y)\in[t,t+\delta)\times\mathcal{X}\times\mathcal{Y}\,,\\ \widehat{\pi}(s,x,y)&\mbox{for}\,\,(s,x,y)\in[t+\delta,T)\times\mathcal{X}\times\mathcal{Y}\,.\end{cases} |  |

If, for all Ï€âˆˆğ“\pi\in\bm{\mathcal{A}}, the following condition holds,

|  |  |  |
| --- | --- | --- |
|  | liminfÎ´â†’0JÏ€^â€‹(t,x,y)âˆ’JÏ€Î´â€‹(t,x,y)Î´â‰¥0,\displaystyle\underset{\delta\to 0}{\lim\inf}\quad\frac{J^{\hat{\pi}}(t,x,y)-J^{\pi\_{\delta}}(t,x,y)}{\delta}\geq 0\,, |  |

then Ï€^\widehat{\pi} is referred to as an equilibrium control law.

For an equilibrium control law Ï€^\widehat{\pi}, we define the equilibrium value function V^\widehat{V} by

|  |  |  |
| --- | --- | --- |
|  | V^â€‹(t,x,y):=JÏ€^â€‹(t,x,y).\widehat{V}\left(t,x,y\right):=J^{\widehat{\pi}}\left(t,x,y\right)\,. |  |

## 3 Derivation of equilibrium controls

This section develops the framework needed to characterize equilibrium investment policies. We begin with several preliminary definitions and then describe the dynamics of the state variables under the conditional measure that arises from our preference model. Building on these ingredients, we present a heuristic derivation of the eHJB governing equilibrium behavior, followed by a rigorous verification argument. We conclude the section by situating our eHJB within the broader literature, comparing its structure to existing formulations and highlighting key differences.

### 3.1 Preliminary definitions and state process dynamics under conditional measures

Define, for any yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y},

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï†yÂ¯:=vâˆ˜(uÎ³â€‹(yÂ¯))âˆ’1,\varphi^{\overline{y}}:=v\circ\left(u^{\gamma(\overline{y})}\right)^{-1}\,, |  | (3.1) |

which is twice continuously differentiable as the composition of two functions that are twice continuously differentiable.

Let fYTâ€‹(yÂ¯;t,y)f\_{Y\_{T}}(\overline{y};t,y) and FYTâ€‹(yÂ¯;t,y)F\_{Y\_{T}}(\overline{y};t,y) denote, respectively, the conditional probability density function (PDF) and the conditional cumulative distribution function (CDF) of YTY\_{T} given Yt=yY\_{t}=y. Using this notation, we can rewrite the reward functional ([2.3](https://arxiv.org/html/2512.21149v1#S2.E3 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) as

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€â€‹(t,x,y)=ğ”¼t,x,yâ€‹[vâˆ˜(uÎ³â€‹(YT))âˆ’1â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)])]=âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€)])â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯=âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y).\begin{split}J^{\pi}(t,x,y)&=\mathbb{E}\_{t,x,y}\left[v\circ\left(u^{\gamma(Y\_{T})}\right)^{-1}\Big(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\Big)\right]\,\\[5.69046pt] &=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\Big(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi}\_{T}\right)\right]\Big)f\_{Y\_{T}}(\overline{y};t,y)\,d\overline{y}\\ &=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\Big(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi}\_{T}\right)\right]\Big)\,dF\_{Y\_{T}}(\overline{y};t,y).\end{split} |  | (3.2) |

The state process (XÏ€,Y)\left(X^{\pi},Y\right), conditional on XtÏ€=xX^{\pi}\_{t}=x and Yt=yY\_{t}=y, satisfies the same SDEs ([2.1](https://arxiv.org/html/2512.21149v1#S2.E1 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"))-([2.2](https://arxiv.org/html/2512.21149v1#S2.E2 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) with the initial condition (x,y)(x,y). In particular, under â„™t,x,y\mathbb{P}\_{t,x,y}, we have:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | dâ€‹XtÏ€\displaystyle dX^{\pi}\_{t} | =XtÏ€â€‹(r+Ï€â€‹(t)â€‹(Î¼Sâˆ’r))â€‹dâ€‹t+XtÏ€â€‹Ï€â€‹(t)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹Bt1+1âˆ’Ï2â€‹dâ€‹Bt2),\displaystyle=X^{\pi}\_{t}(r+\pi(t)(\mu\_{S}-r))dt+X^{\pi}\_{t}\pi(t)\sigma\_{S}\left(\rho dB^{1}\_{t}+\sqrt{1-\rho^{2}}dB^{2}\_{t}\right), |  | (3.3) |
|  | dâ€‹Ys\displaystyle dY\_{s} | =Î¼Yâ€‹(s,Ys)â€‹dâ€‹s+ÏƒYâ€‹(s,Ys)â€‹dâ€‹Bs1,\displaystyle=\mu\_{Y}(s,Y\_{s})ds+\sigma\_{Y}(s,Y\_{s})dB^{1}\_{s}, |  |

with Xt=xX\_{t}=x, Yt=yY\_{t}=y, ÏƒS>0\sigma\_{S}>0, ÏƒY>0\sigma\_{Y}>0, and dâ€‹Bs1â€‹dâ€‹Bs2=0dB^{1}\_{s}dB^{2}\_{s}=0 for every sâˆˆ[t,T]s\in[t,T], i.e., B1B^{1} and B2B^{2} are still independent Brownian motions under â„™t,x,y\mathbb{P}\_{t,x,y}.

Because the objective ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) involves the conditional expectation ğ”¼t,x,y,yÂ¯â€‹[â‹…]\mathbb{E}\_{t,x,y,\overline{y}}[\,\cdot\,], we need the dynamics of (XÏ€,Y)\left(X^{\pi},Y\right) under the conditional measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}. For this, we rely on a change-of-measure argument based on the transition density of YY; see DesmettreLeobacherRogers2021ChangeOfDrift for the one-dimensional diffusion case.

Let pYâ€‹(s,y;t,yÂ¯)p\_{Y}(s,y;t,\overline{y}) denote the transition density function of YY, i.e. the density of Yt=yÂ¯Y\_{t}=\overline{y} given Ys=yY\_{s}=y, for 0â‰¤sâ‰¤tâ‰¤T0\leq s\leq t\leq T. The conditional density fYTf\_{Y\_{T}} is obtained as the special case

|  |  |  |
| --- | --- | --- |
|  | fYTâ€‹(yÂ¯;t,y)=pYâ€‹(t,y;T,yÂ¯).f\_{Y\_{T}}(\overline{y};t,y)=p\_{Y}(t,y;T,\overline{y}). |  |

It is convenient to keep both notations: we interpret fYTâ€‹(yÂ¯;t,y)f\_{Y\_{T}}(\overline{y};t,y) as a function of yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y} for fixed (t,y)âˆˆğ’¯Ã—ğ’´(t,y)\in\mathcal{T}\times\mathcal{Y}, whereas pYâ€‹(s,y;t,yÂ¯)p\_{Y}(s,y;t,\overline{y}) will be treated as a function of (s,y)âˆˆğ’¯Ã—ğ’´(s,y)\in\mathcal{T}\times\mathcal{Y} for fixed (t,yÂ¯)âˆˆ[s,T]Ã—ğ’´(t,\overline{y})\in[s,T]\times\mathcal{Y}. Denote by âˆ‚ypYâ€‹(s,y;T,yÂ¯)\partial\_{y}p\_{Y}(s,y;T,\overline{y}) the partial derivative of pYâ€‹(s,y;T,yÂ¯)p\_{Y}(s,y;T,\overline{y}) with respect to yy. We then have the following result.

###### Lemma 3.1.

Let BÂ¯1\overline{B}^{1} and BÂ¯2\overline{B}^{2} be two standard
motions under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}. Then, under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, for sâˆˆ[t,T)s\in[t,T):

* â€¢

  The wealth process XÏ€X^{\pi} evolves as

  |  |  |  |  |  |
  | --- | --- | --- | --- | --- |
  |  | dâ€‹XsÏ€\displaystyle dX^{\pi}\_{s} | =XsÏ€â€‹(r+Ï€â€‹(s)â€‹(Î¼Sâˆ’r)+Ï€â€‹(s)â€‹ÏƒSâ€‹Ïâ€‹ÏƒYâ€‹(s,Ys)â€‹âˆ‚ylnâ¡(pYâ€‹(s,Ys;T,yÂ¯)))â€‹dâ€‹s\displaystyle=X^{\pi}\_{s}\left(r+\pi(s)(\mu\_{S}-r)+\pi(s)\sigma\_{S}\rho\sigma\_{Y}(s,Y\_{s})\partial\_{y}\ln\big(p\_{Y}(s,Y\_{s};{T},\overline{y})\big)\right)ds |  | (3.4) |
  |  |  | +XsÏ€â€‹Ï€â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2),\displaystyle\quad+X^{\pi}\_{s}\pi(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right), |  |

  with XtÏ€=xX^{\pi}\_{t}=x and XTÏ€=limtâ†’TXtÏ€X^{\pi}\_{T}=\lim\_{t\to T}X^{\pi}\_{t}.
* â€¢

  The process YY evolves as

  |  |  |  |  |  |
  | --- | --- | --- | --- | --- |
  |  | dâ€‹Ys\displaystyle d{Y}\_{s} | =(Î¼Yâ€‹(s,Ys)+ÏƒY2â€‹(s,Ys)â€‹âˆ‚ylnâ¡(pYâ€‹(s,Ys;T,yÂ¯)))â€‹dâ€‹s+ÏƒYâ€‹(s,Ys)â€‹dâ€‹BÂ¯s1,\displaystyle=\left(\mu\_{Y}(s,Y\_{s})+\sigma\_{Y}^{2}(s,Y\_{s})\partial\_{y}\ln\big(p\_{Y}(s,{Y}\_{s};{T},\overline{y})\right)\big)ds+\sigma\_{Y}\left(s,Y\_{s}\right)d\overline{B}^{1}\_{s}, |  | (3.5) |

  with Yt=yY\_{t}=y and YT=yÂ¯Y\_{T}=\overline{y}.

Proof. See Appendix [A.1](https://arxiv.org/html/2512.21149v1#A1.SS1 "A.1 Proof of Lemma 3.1 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty").

For later use, it is convenient to introduce compact notation for the drift and diffusion coefficients under the conditional measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î¼Â¯Xâ€‹(t,x,Ï€)\displaystyle\overline{\mu}\_{X}(t,x,\pi) | :=xâ€‹[r+Ï€â€‹(Î¼Sâˆ’r)+Ï€â€‹ÏƒSâ€‹Ïâ€‹ÏƒYâ€‹(t,y)â€‹âˆ‚ylnâ¡pYâ€‹(t,y;T,yÂ¯)],\displaystyle:=x\Bigl[r+\pi(\mu\_{S}-r)+\pi\sigma\_{S}\rho\,\sigma\_{Y}(t,y)\,\partial\_{y}\ln p\_{Y}(t,y;T,\overline{y})\Bigr], |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ÏƒÂ¯Xâ€‹(t,x,Ï€)\displaystyle\overline{\sigma}\_{X}(t,x,\pi) | :=(ÏƒÂ¯X,1â€‹(t,x,Ï€),ÏƒÂ¯X,2â€‹(t,x,Ï€)):=(xâ€‹Ï€â€‹ÏƒSâ€‹Ï,xâ€‹Ï€â€‹ÏƒSâ€‹1âˆ’Ï2),\displaystyle:=\left(\overline{\sigma}\_{X,1}(t,x,\pi),\overline{\sigma}\_{X,2}(t,x,\pi)\right):=\Bigl(x\pi\sigma\_{S}\rho,\;x\pi\sigma\_{S}\sqrt{1-\rho^{2}}\Bigr), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Î¼Â¯Yâ€‹(t,y)\displaystyle\overline{\mu}\_{Y}(t,y) | :=Î¼Yâ€‹(t,y)+ÏƒY2â€‹(t,y)â€‹âˆ‚ylnâ¡pYâ€‹(t,y;T,yÂ¯),\displaystyle:=\mu\_{Y}(t,y)+\sigma\_{Y}^{2}(t,y)\,\partial\_{y}\ln p\_{Y}(t,y;T,\overline{y}), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | ÏƒÂ¯Yâ€‹(t,y)\displaystyle\overline{\sigma}\_{Y}(t,y) | :=ÏƒYâ€‹(t,y).\displaystyle:=\sigma\_{Y}(t,y). |  |

To express the eHJB in compact form, we now introduce the controlled differential operators associated with the dynamics under â„™t,x,y\mathbb{P}\_{t,x,y} and â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}.

###### Definition 3.2.

Let XÏ€X^{\pi} and YY be given by ([2.1](https://arxiv.org/html/2512.21149v1#S2.E1 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")) and ([2.2](https://arxiv.org/html/2512.21149v1#S2.E2 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")), respectively, and let Î¾:ğ’¯Ã—ğ’³Ã—ğ’´â†¦â„\xi:\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\mapsto\mathbb{R} be a map such that Î¾âˆˆ\textgothâ€‹C1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´)\xi\in\textgoth{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right).
(Given positive integers p,q,rp,q,r, we write \textgothâ€‹Cp,q,râ€‹(ğ”»)\textgoth{C}^{p,q,r}(\mathbb{D}) for the space of functions on the domain ğ”»\mathbb{D} that are continuously differentiable up to order p,q,p,q, and rr in the respective arguments.)

For any admissible Ï€âˆˆğ“\pi\in\bm{\mathcal{A}}, the controlled differential operator ğ’ŸÏ€\mathcal{D}^{\pi} under â„™t,x,y\mathbb{P}\_{t,x,y} is defined as follows:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’ŸÏ€â€‹Î¾â€‹(t,x,y)\displaystyle\mathcal{D}^{\pi}\xi(t,x,y) | =âˆ‚tÎ¾â€‹(t,x,y)+Î¼Xâ€‹(t,x,Ï€â€‹(t,x,y))â€‹âˆ‚xÎ¾â€‹(t,x,y)+Î¼Yâ€‹(t,y)â€‹âˆ‚yÎ¾â€‹(t,x,y)\displaystyle=\partial\_{t}\xi(t,x,y)+\mu\_{X}(t,x,\pi(t,x,y))\partial\_{x}\xi(t,x,y)+\mu\_{Y}(t,y)\partial\_{y}\xi(t,x,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +12â€‹â€–ÏƒXâ€‹(t,x,y)â€–2â€‹âˆ‚xâ€‹xÎ¾â€‹(t,x,y)+12â€‹(ÏƒYâ€‹(t,y))2â€‹âˆ‚yâ€‹yÎ¾â€‹(t,x,y)\displaystyle\quad+\dfrac{1}{2}\left\lVert\sigma\_{X}(t,x,y)\right\rVert^{2}\partial\_{xx}\xi(t,x,y)+\dfrac{1}{2}\left(\sigma\_{Y}(t,y)\right)^{2}\partial\_{yy}\xi(t,x,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +ÏƒX,1â€‹(t,x,Ï€â€‹(t,x,y))â€‹ÏƒYâ€‹(t,y)â€‹âˆ‚xâ€‹yÎ¾â€‹(t,x,y),\displaystyle\quad+\sigma\_{X,1}(t,x,\pi(t,x,y))\sigma\_{Y}(t,y)\partial\_{xy}\xi(t,x,y), |  |

where âˆ‚x,âˆ‚y,âˆ‚xâ€‹x,âˆ‚xâ€‹y,âˆ‚yâ€‹y\partial\_{x},\partial\_{y},\partial\_{xx},\partial\_{xy},\partial\_{yy} denote the corresponding partial derivatives.

Analogously, we define the controlled differential operator ğ’ŸÂ¯Ï€\overline{\mathcal{D}}^{\pi} under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}} as follows:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’ŸÂ¯Ï€â€‹Î¾â€‹(t,x,y)\displaystyle\overline{\mathcal{D}}^{\pi}\xi(t,x,y) | =âˆ‚tÎ¾â€‹(t,x,y)+Î¼Â¯Xâ€‹(t,x,Ï€â€‹(t,x,y))â€‹âˆ‚xÎ¾â€‹(t,x,y)+Î¼Â¯Yâ€‹(t,y)â€‹âˆ‚yÎ¾â€‹(t,x,y)\displaystyle=\partial\_{t}\xi(t,x,y)+\overline{\mu}\_{X}(t,x,\pi(t,x,y))\partial\_{x}\xi(t,x,y)+\overline{\mu}\_{Y}(t,y)\partial\_{y}\xi(t,x,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +12â€‹â€–ÏƒÂ¯Xâ€‹(t,x,y)â€–2â€‹âˆ‚xâ€‹xÎ¾â€‹(t,x,y)+12â€‹(ÏƒÂ¯Yâ€‹(t,y))2â€‹âˆ‚yâ€‹yÎ¾â€‹(t,x,y)\displaystyle\quad+\dfrac{1}{2}\left\lVert\overline{\sigma}\_{X}(t,x,y)\right\rVert^{2}\partial\_{xx}\xi(t,x,y)+\dfrac{1}{2}\left(\overline{\sigma}\_{Y}(t,y)\right)^{2}\partial\_{yy}\xi(t,x,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +ÏƒÂ¯X,1â€‹(t,x,Ï€â€‹(t,x,y))â€‹ÏƒÂ¯Yâ€‹(t,y)â€‹âˆ‚xâ€‹yÎ¾â€‹(t,x,y).\displaystyle\quad+\overline{\sigma}\_{X,1}(t,x,\pi(t,x,y))\overline{\sigma}\_{Y}(t,y)\partial\_{xy}\xi(t,x,y). |  |

For a constant control Ï€\pi, the operators are defined in the same way.

### 3.2 Heuristic derivation of the eHJB

The reward functional ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) does not fall directly within the general framework of BjoerkKhapkoMurgoci2021:TICT (henceforth, BKM21), Section 15.5, whose most general objective (in our notation) when the dimensionality of the state process is n=2n=2 has the form

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | ğ”¼t,x,yâ€‹[âˆ«tTHâ€‹(t,x,y,s,XsÏ€,Ys,Ï€â€‹(s,XsÏ€,Ys))â€‹ğ‘‘s]\displaystyle\mathbb{E}\_{t,x,y}\Bigg[\int\_{t}^{T}H(t,x,y,s,X^{\pi}\_{s},Y\_{s},\pi(s,X^{\pi}\_{s},Y\_{s}))\,ds\Bigg] |  | (3.6) |
|  |  | +ğ”¼t,x,yâ€‹[Fâ€‹(t,x,y,XTÏ€,YT)]+Gâ€‹(t,x,y,ğ”¼t,x,yâ€‹[XTÏ€],ğ”¼t,x,yâ€‹[YT]),\displaystyle+\mathbb{E}\_{t,x,y}\Big[F\big(t,x,y,X^{\pi}\_{T},Y\_{T}\big)\Big]+G\Big(t,x,y,\mathbb{E}\_{t,x,y}[X^{\pi}\_{T}],\mathbb{E}\_{t,x,y}[Y\_{T}]\Big), |  |

for possibly nonlinear functions F,G,HF,G,H; cf. Eq. (15.13) therein. (In Section [3.4](https://arxiv.org/html/2512.21149v1#S3.SS4 "3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"), we return to this reward functional and discuss the corresponding eHJB.)

Two structural features of our preferences ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) prevent a direct embedding into (LABEL:eq:reward\_functional\_general\_BKM2021):

1. (a)

   the objective involves expectations conditional on a fixed terminal state, YT=yÂ¯Y\_{T}=\overline{y}, inside a nonlinear function of the expectation of the terminal state;
2. (b)

   the nonlinear function of the expectation of terminal state involves a continuum of terms Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€)])\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi}\_{T}\right)\right]\right), rather than one expectation of terminal state.

In what follows, we then explain how to generalize (LABEL:eq:reward\_functional\_general\_BKM2021) to a form that includes ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). Feature (a) is addressed by using Lemma [3.1](https://arxiv.org/html/2512.21149v1#S3.Thmtheorem1 "Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"), which describes the dynamics of (XÏ€,Y)(X^{\pi},Y) under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}. Feature (b), on the other hand, requires more work. Specifically, we need to approximate ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) as a finite sum of different GG-terms in (LABEL:eq:reward\_functional\_general\_BKM2021), where we use the label â€œGG-termâ€ to refer to any nonlinear function of the expectation(s) of function(s) of the terminal value of the state process.

In the simplest case of a sum consisting of just one element, the approximating reward functional resembles (LABEL:eq:reward\_functional\_general\_BKM2021) with Fâ‰¡0F\equiv 0, Hâ‰¡0H\equiv 0 and one suitable Gâ‰¢0G\not\equiv 0, with a minor difference that under the expectation operator there is a function of the terminal value of the state process (instead of just the terminal value of the state process itself). Therefore, for the heuristic derivation of the eHJB for our reward functional, we use the following reward functional as a starting point:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Gâ€‹(t,x,y,ğ”¼t,x,yâ€‹[XTÏ€],ğ”¼t,x,yâ€‹[YT]).G\Big(t,x,y,\mathbb{E}\_{t,x,y}[X^{\pi}\_{T}],\mathbb{E}\_{t,x,y}[Y\_{T}]\Big). |  | (3.7) |

As we explain in detail in Section [3.4](https://arxiv.org/html/2512.21149v1#S3.SS4 "3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"), the extended system characterizing an equilibrium control for ([3.7](https://arxiv.org/html/2512.21149v1#S3.E7 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) involves an auxiliary function gâ€‹(t,x,y)=(g1â€‹(t,x,y),g2â€‹(t,x,y))g(t,x,y)=(g\_{1}(t,x,y),g\_{2}(t,x,y)), where g1,g2:ğ’¯Ã—ğ’³Ã—ğ’´â†’â„g\_{1},g\_{2}:\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}, and uses the following notation:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Gâ‹„g)â€‹(t,x,y):=Gâ€‹(t,x,y,g1â€‹(t,x,y),g2â€‹(t,x,y)),â„‹Ï€â€‹gâ€‹(t,x,y):=Gx~â€‹(t,x,y,g1â€‹(t,x,y),g2â€‹(t,x,y))â€‹ğ’ŸÏ€â€‹g1â€‹(t,x,y)+Gy~â€‹(t,x,y,g1â€‹(t,x,y),g2â€‹(t,x,y))â€‹ğ’ŸÏ€â€‹g2â€‹(t,x,y),ğ’ŸÏ€^â€‹gâ€‹(t,x,y):=(ğ’ŸÏ€^â€‹g1â€‹(t,x,y),ğ’ŸÏ€^â€‹g2â€‹(t,x,y)).\begin{split}(G\diamond g)(t,x,y)&:=G(t,x,y,g\_{1}(t,x,y),g\_{2}(t,x,y)),\\[5.69046pt] \mathcal{H}^{\pi}g(t,x,y)&:=G\_{\tilde{x}}(t,x,y,g\_{1}(t,x,y),g\_{2}(t,x,y))\ \mathcal{D}^{\pi}g\_{1}(t,x,y)\\ &\quad+G\_{\tilde{y}}(t,x,y,g\_{1}(t,x,y),g\_{2}(t,x,y))\,\mathcal{D}^{\pi}g\_{2}(t,x,y),\\ \mathcal{D}^{\widehat{\pi}}g(t,x,y)&:=\left(\mathcal{D}^{\widehat{\pi}}g\_{1}(t,x,y),\mathcal{D}^{\widehat{\pi}}g\_{2}(t,x,y)\right).\end{split} |  | (3.8) |

The eHJB is then given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆˆğ’œâ€‹(t,x,y){ğ’ŸÏ€â€‹Vâ€‹(t,x,y)âˆ’ğ’ŸÏ€â€‹(Gâ‹„g)â€‹(t,x,y)+â„‹Ï€â€‹gâ€‹(t,x,y)},\displaystyle=\sup\_{\pi\in\mathcal{A}(t,x,y)}\Big\{\mathcal{D}^{\pi}V(t,x,y)-\mathcal{D}^{\pi}(G\diamond g)(t,x,y)+\mathcal{H}^{\pi}g(t,x,y)\Big\}, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | (0,0)\displaystyle(0,0) | =ğ’ŸÏ€^â€‹gâ€‹(t,x,y),\displaystyle=\mathcal{D}^{\widehat{\pi}}g(t,x,y), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Vâ€‹(T,x,y)\displaystyle V(T,x,y) | =Gâ€‹(T,x,y,x,y),\displaystyle=G(T,x,y,x,y), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | gâ€‹(T,x,y)\displaystyle g(T,x,y) | =(x,y),\displaystyle=(x,y), |  |

where Ï€^\widehat{\pi} denotes the control law that realizes the supremum in the first equation of the system; for more details, see Section [3.4](https://arxiv.org/html/2512.21149v1#S3.SS4 "3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty").

As stated in Section 16.3 of BKM21, it is possible to generalize the above eHJB to the case of

|  |  |  |
| --- | --- | --- |
|  | G1â€‹(t,x,y,ğ”¼t,x,yâ€‹[k11â€‹(XTÏ€)],ğ”¼t,x,yâ€‹[k12â€‹(YT)]),G\_{1}\Big(t,x,y,\mathbb{E}\_{t,x,y}[k\_{1}^{1}(X^{\pi}\_{T})],\mathbb{E}\_{t,x,y}[k\_{1}^{2}(Y\_{T})]\Big), |  |

for some functions k11:ğ’³â†’â„k\_{1}^{1}:\mathcal{X}\rightarrow\mathbb{R} and k12:ğ’´â†’â„k\_{1}^{2}:\mathcal{Y}\rightarrow\mathbb{R}, where the superscript refers to the dimension of the state process (XÏ€,Y)(X^{\pi},Y) and the subscript refers to the number of expectations of a function of the terminal state process value.

For a one-dimensional state process XÏ€X^{\pi}, another generalization is studied in KrygerNordfangSteffensen2020:MMRO, where the eHJB is established for the case where the GG-term depends on the conditional expectations of two different functions of the terminal state:

|  |  |  |
| --- | --- | --- |
|  | G2â€‹(t,x,ğ”¼t,xâ€‹[k1â€‹(XTÏ€)],ğ”¼t,xâ€‹[k2â€‹(XTÏ€)]),G\_{2}\Big(t,x,\mathbb{E}\_{t,x}[k\_{1}(X^{\pi}\_{T})],\mathbb{E}\_{t,x}[k\_{2}(X^{\pi}\_{T})]\Big), |  |

for k1,k2:ğ’³â†’â„k\_{1},k\_{2}:\mathcal{X}\rightarrow\mathbb{R}.

In Remark 2 of the same paper, it is stated (yet not shown) that one can similarly obtain the eHJB for the case with n>2n>2 different functions ki:ğ’³â†’â„k\_{i}:\mathcal{X}\rightarrow\mathbb{R}, i=1,â€¦â€‹ni=1,\dots n:

|  |  |  |
| --- | --- | --- |
|  | Gnâ€‹(t,x,ğ”¼t,xâ€‹[k1â€‹(XTÏ€)],â€¦,ğ”¼t,xâ€‹[knâ€‹(XTÏ€)]).G\_{n}\Big(t,x,\mathbb{E}\_{t,x}[k\_{1}(X^{\pi}\_{T})],\dots,\mathbb{E}\_{t,x}[k\_{n}(X^{\pi}\_{T})]\Big). |  |

The function GnG\_{n} can be interpreted as an nn-term finite aggregator of conditional expectations. Since finite sums provide natural discrete approximations of integrals, the expression above represents a tractable discretization of the continuum aggregation appearing in ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). In our problem, the integral averages certainty equivalents across the entire distribution of future preference states. By choosing the functions kik\_{i} and the structure of GnG\_{n} appropriately, the sequence of discretized problems (Pn)(P\_{n}) can approximate the original problem with continuous aggregation arbitrarily well. This observation allows us to construct the eHJB for our full objective by first analyzing the finite-dimensional case and then passing to the limit.

We proceed in two steps:

1. 1.

   We construct a sequence of auxiliary problems (Pn)(P\_{n}) that approximate the equilibrium investment problem associated with ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). Each problem (Pn)(P\_{n}) replaces the integral aggregation over future preference states by a finite sum, enabling us to heuristically derive the eHJB in the finite-dimensional case (Pn)(P\_{n}).
2. 2.

   We then let nâ†’âˆn\to\infty and interpret the integral in ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) as the limit of these discrete approximations. In doing so, we obtain the eHJB for the original problem as the limiting case of the systems associated with (Pn)(P\_{n}).

Step 1: Sequence of approximating problems (Pn)(P\_{n})

Fix an arbitrary point (t,x,y)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´(t,x,y)\in[0,T)\times\mathcal{X}\times\mathcal{Y}. For any nâˆˆâ„•n\in\mathbb{N}, let ğ’«ğ’´:={yÂ¯0,yÂ¯1,â€¦,yÂ¯n}\mathcal{P}\_{\mathcal{Y}}:=\left\{\overline{y}\_{0},\overline{y}\_{1},\dots,\overline{y}\_{n}\right\} be an arbitrarily chosen partition of ğ’´\mathcal{Y}, with yÂ¯iâˆˆâ„Â¯\overline{y}\_{i}\in\overline{\mathbb{R}}\, for every iâˆˆ{0,1,â€¦,n}i\in\left\{0,1,\dots,n\right\}, where â„Â¯:=â„âˆª{âˆ’âˆ,âˆ}\overline{\mathbb{R}}:=\mathbb{R}\cup\left\{-\infty,\infty\right\}. Define Î”â€‹Fiâ€‹(t,y):=FYTâ€‹(yÂ¯i+1;t,y)âˆ’FYTâ€‹(yÂ¯i;t,y)\Delta F\_{i}(t,y):=F\_{Y\_{T}}(\overline{y}\_{i+1};t,y)-F\_{Y\_{T}}(\overline{y}\_{i};t,y).
Then, we can approximate the integral as a finite sum as follows:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | JÏ€â€‹(t,x,y)\displaystyle J^{\pi}(t,x,y) | â‰ˆâˆ‘i=1nÏ†yÂ¯iâˆ’1â€‹(ğ”¼t,x,y,yÂ¯iâˆ’1â€‹[uÎ³â€‹(yÂ¯iâˆ’1)â€‹(XTÏ€)])â€‹Î”â€‹Fiâˆ’1â€‹(t,y)\displaystyle\approx\sum\limits\_{i=1}^{n}\varphi^{\overline{y}\_{i-1}}\Big(\mathbb{E}\_{t,x,y,\overline{y}\_{i-1}}\left[u^{\gamma(\overline{y}\_{i-1})}\left(X^{\pi}\_{T}\right)\right]\Big)\Delta F\_{i-1}(t,y) |  | (3.9) |
|  |  | =:Gn(t,y,ğ”¼t,x,y,yÂ¯0[uÎ³â€‹(yÂ¯0)(XTÏ€)],â€¦,ğ”¼t,x,y,yÂ¯nâˆ’1[uÎ³â€‹(yÂ¯nâˆ’1)(XTÏ€)]),\displaystyle=:G\_{n}\Big(t,y,\mathbb{E}\_{t,x,y,\overline{y}\_{0}}\left[u^{\gamma(\overline{y}\_{0})}\left(X^{\pi}\_{T}\right)\right],\dots,\mathbb{E}\_{t,x,y,\overline{y}\_{n-1}}\left[u^{\gamma(\overline{y}\_{n-1})}\left(X^{\pi}\_{T}\right)\right]\Big), |  |

where GnG\_{n} above does not have xx as its argument, though the derivation below can easily be extended to this case.

We define the nn-th approximating problem (Pn)(P\_{n}) as the one for which the reward functional is given by

|  |  |  |
| --- | --- | --- |
|  | JnÏ€â€‹(t,x,y):=Gnâ€‹(t,y,ğ”¼t,x,y,yÂ¯0â€‹[uÎ³â€‹(yÂ¯0)â€‹(XTÏ€)],â€¦,ğ”¼t,x,y,yÂ¯nâˆ’1â€‹[uÎ³â€‹(yÂ¯nâˆ’1)â€‹(XTÏ€)]).J^{\pi}\_{n}(t,x,y):=G\_{n}\Big(t,y,\mathbb{E}\_{t,x,y,\overline{y}\_{0}}\left[u^{\gamma(\overline{y}\_{0})}\left(X^{\pi}\_{T}\right)\right],\dots,\mathbb{E}\_{t,x,y,\overline{y}\_{n-1}}\left[u^{\gamma(\overline{y}\_{n-1})}\left(X^{\pi}\_{T}\right)\right]\Big). |  |

Denote by Ï€^n\widehat{\pi}\_{n} an equilibrium investment strategy for (Pn)(P\_{n}) and by V^nâ€‹(t,x,y)\widehat{V}\_{n}(t,x,y) the respective equilibrium value function.

Let us derive the eHJB for the simplest case of (P1)(P\_{1}). Choose an arbitrary partition ğ’«ğ’´={yÂ¯0,yÂ¯1}\mathcal{P}\_{\mathcal{Y}}=\left\{\overline{y}\_{0},\overline{y}\_{1}\right\}, i.e., yÂ¯0\overline{y}\_{0} is such that FYTâ€‹(yÂ¯0;t,y)=0F\_{Y\_{T}}(\overline{y}\_{0};t,y)=0 and yÂ¯1\overline{y}\_{1} is such that FYTâ€‹(yÂ¯1;t,y)=1F\_{Y\_{T}}(\overline{y}\_{1};t,y)=1. Then, Î”â€‹F0â€‹(t,y)=1\Delta F\_{0}(t,y)=1 and (P1)(P\_{1}) has the reward functional

|  |  |  |  |
| --- | --- | --- | --- |
|  | J1Ï€â€‹(t,x,y)=Ï†yÂ¯0â€‹(ğ”¼t,x,y,yÂ¯0â€‹[uÎ³â€‹(yÂ¯0)â€‹(XTÏ€)])â€‹Î”â€‹F0â€‹(t,y)=G1â€‹(t,y,ğ”¼t,x,y,yÂ¯0â€‹[uÎ³â€‹(yÂ¯0)â€‹(XTÏ€)]).\begin{split}J^{\pi}\_{1}(t,x,y)&=\varphi^{\overline{y}\_{0}}\left(\mathbb{E}\_{t,x,y,\overline{y}\_{0}}\left[u^{\gamma(\overline{y}\_{0})}\left(X^{\pi}\_{T}\right)\right]\right)\Delta F\_{0}(t,y)\\ &=G\_{1}\left(t,y,\mathbb{E}\_{t,x,y,\overline{y}\_{0}}\left[u^{\gamma(\overline{y}\_{0})}\left(X^{\pi}\_{T}\right)\right]\right).\end{split} |  | (3.10) |

Comparing ([3.10](https://arxiv.org/html/2512.21149v1#S3.E10 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) with ([3.7](https://arxiv.org/html/2512.21149v1#S3.E7 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we observe that the two formulations are nearly identical, with only two conceptual differences. First, the appearance of the nonlinear function uÎ³â€‹(yÂ¯0)u^{\gamma(\overline{y}\_{0})} inside the expectation, which poses no structural difficulty; as noted in Section 16.3 of BKM21 and in KrygerNordfangSteffensen2020:MMRO, such a modification can be incorporated simply by adjusting the terminal condition for the auxiliary function in the extended HJB system. Second, because the expectation in ([3.7](https://arxiv.org/html/2512.21149v1#S3.E7 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) is also conditional on YT=yÂ¯Y\_{T}=\overline{y}, the relevant state dynamics â€“and hence the differential operator appearing in the HJBâ€“ must be taken under the conditional measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}} rather than â„™t,x,y\mathbb{P}\_{t,x,y}. Apart from this change of measure, the overall structure remains fully aligned with the framework of BKM21. (For completeness, we note that G1G\_{1} in ([3.10](https://arxiv.org/html/2512.21149v1#S3.E10 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) does not depend on xx and the conditional expectation of YTY\_{T}, in contrast to ([3.7](https://arxiv.org/html/2512.21149v1#S3.E7 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). If G1G\_{1} were to explicitly depend on these two objects, the arguments of this section could easily be adjusted to account for such dependence.)

Building on these observations, we now derive the eHJB for (P1)(P\_{1}). We begin by introducing the following notation:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (G1â‹„g1yÂ¯0)â€‹(t,x,y)\displaystyle\left(G\_{1}\diamond g\_{1}^{\overline{y}\_{0}}\right)(t,x,y) | :=G1â€‹(t,y,g1yÂ¯0â€‹(t,x,y))=Ï†yÂ¯0â€‹(g1yÂ¯0â€‹(t,x,y))â€‹Î”â€‹F0â€‹(t,y),\displaystyle:=G\_{1}\big(t,y,g\_{1}^{\overline{y}\_{0}}(t,x,y)\big)=\varphi^{\overline{y}\_{0}}\left(g\_{1}^{\overline{y}\_{0}}(t,x,y)\right)\Delta F\_{0}(t,y), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | â„‹Â¯1Ï€â€‹g1yÂ¯0â€‹(t,x,y)\displaystyle\overline{\mathcal{H}}^{\pi}\_{1}g\_{1}^{\overline{y}\_{0}}(t,x,y) | :=âˆ‚z1G1â€‹(t,y,g1yÂ¯0â€‹(t,x,y))â€‹ğ’ŸÂ¯Ï€â€‹g1yÂ¯0â€‹(t,x,y),\displaystyle:=\partial\_{z\_{1}}G\_{1}\big(t,y,g\_{1}^{\overline{y}\_{0}}(t,x,y)\big)\,\overline{\mathcal{D}}^{\pi}g\_{1}^{\overline{y}\_{0}}(t,x,y), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(Ï†yÂ¯0)â€²â€‹(g1yÂ¯0â€‹(t,x,y))â€‹ğ’ŸÂ¯Ï€â€‹g1yÂ¯0â€‹(t,x,y)â€‹Î”â€‹F0â€‹(t,y).\displaystyle=\left(\varphi^{\overline{y}\_{0}}\right)^{\prime}\left(g\_{1}^{\overline{y}\_{0}}(t,x,y)\right)\,\overline{\mathcal{D}}^{\pi}g\_{1}^{\overline{y}\_{0}}(t,x,y)\,\Delta F\_{0}(t,y). |  |

With this notation in place, the eHJB for (P1)(P\_{1}) takes the form

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0=supÏ€âˆˆğ’œâ€‹(t,x,y){ğ’ŸÏ€â€‹V1â€‹(t,x,y)âˆ’ğ’ŸÏ€â€‹(G1â‹„g1yÂ¯0)â€‹(t,x,y)+â„‹Â¯1Ï€â€‹g1yÂ¯0â€‹(t,x,y)},0=ğ’ŸÂ¯Ï€^1â€‹g1yÂ¯0â€‹(t,x,y),V1â€‹(T,x,y)=vâ€‹(x),g1yÂ¯0â€‹(T,x,y)=uÎ³â€‹(yÂ¯0)â€‹(x),\begin{split}0&=\sup\_{\pi\in\mathcal{A}(t,x,y)}\Big\{\mathcal{D}^{\pi}V\_{1}(t,x,y)-\mathcal{D}^{\pi}\left(G\_{1}\diamond g\_{1}^{\overline{y}\_{0}}\right)(t,x,y)+\overline{\mathcal{H}}^{\pi}\_{1}g\_{1}^{\overline{y}\_{0}}(t,x,y)\Big\},\\[5.69046pt] 0&=\overline{\mathcal{D}}^{\widehat{\pi}\_{1}}g\_{1}^{\overline{y}\_{0}}(t,x,y),\\[5.69046pt] V\_{1}(T,x,y)&=v(x),\\ g\_{1}^{\overline{y}\_{0}}(T,x,y)&=u^{\gamma(\overline{y}\_{0})}(x),\end{split} |  | (3.11) |

where Ï€^1\widehat{\pi}\_{1} realizes the supremum in the first equation of ([3.11](https://arxiv.org/html/2512.21149v1#S3.E11 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). A slight modification of Theorem 15.2 in BKM21 verifies that, under certain regularity conditions, Ï€^1\widehat{\pi}\_{1} solving the above extended system is indeed an equilibrium control for (P1)(P\_{1}).

Applying similar heuristic reasoning as in Section 15.3.1 of BKM21 to the problem (Pn)(P\_{n}), whose reward functional is given by ([3.9](https://arxiv.org/html/2512.21149v1#S3.E9 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we obtain the natural extension of the system derived for (P1)(P\_{1}). To express this compactly, we introduce the notation

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Gnâ‹„(g1yÂ¯0,â€¦,gnyÂ¯nâˆ’1))â€‹(t,x,y)\displaystyle\left(G\_{n}\diamond\left(g\_{1}^{\overline{y}\_{0}},\dots,g\_{n}^{\overline{y}\_{n-1}}\right)\right)\left(t,x,y\right) | :=Gnâ€‹(t,y,g1yÂ¯0â€‹(t,x,y),â€¦,gnyÂ¯nâˆ’1â€‹(t,x,y))\displaystyle:=G\_{n}\left(t,y,g^{\overline{y}\_{0}}\_{1}\left(t,x,y\right),\dots,g^{\overline{y}\_{n-1}}\_{n}\left(t,x,y\right)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ‘i=1nÏ†yÂ¯iâˆ’1(giyÂ¯iâˆ’1(t,x,y)))Î”Fiâˆ’1(t,y),\displaystyle=\sum\limits\_{i=1}^{n}\varphi^{\overline{y}\_{i-1}}\left(g\_{i}^{\overline{y}\_{i-1}}(t,x,y))\right)\Delta F\_{i-1}(t,y), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | â„‹Â¯nÏ€â€‹((giyÂ¯iâˆ’1)i=1,â€¦,n)â€‹(t,x,y)\displaystyle\overline{\mathcal{H}}^{\pi}\_{n}\left(\left(g\_{i}^{\overline{y}\_{i-1}}\right)\_{i=1,\dots,n}\right)(t,x,y) | :=âˆ‘i=1n(Ï†yÂ¯iâˆ’1)â€²(giyÂ¯iâˆ’1(t,x,y)))\displaystyle:=\sum\limits\_{i=1}^{n}\left(\varphi^{\overline{y}\_{i-1}}\right)^{\prime}\left(g\_{i}^{\overline{y}\_{i-1}}(t,x,y))\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | Ã—ğ’ŸÂ¯Ï€â€‹giyÂ¯iâˆ’1â€‹(t,x,y)â€‹Î”â€‹Fiâˆ’1â€‹(t,y).\displaystyle\qquad\times\overline{\mathcal{D}}^{\pi}g\_{i}^{\overline{y}\_{i-1}}(t,x,y)\,\Delta F\_{i-1}(t,y). |  |

These expressions parallel exactly the one-component case, except that each discrete preference scenario contributes its own auxiliary function giyÂ¯iâˆ’1g\_{i}^{\overline{y}\_{i-1}} and sensitivity term weighted by the corresponding probability mass Î”â€‹Fiâˆ’1â€‹(t,y)\Delta F\_{i-1}(t,y).

With this notation in place, the eHJB for (Pn)(P\_{n}) takes the form

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆˆğ’œâ€‹(t,x,y){ğ’ŸÏ€Vn(t,x,y)âˆ’ğ’ŸÏ€(Gnâ‹„(g1yÂ¯0,â€¦,gnyÂ¯nâˆ’1))(t,x,y)\displaystyle=\sup\_{\pi\in\mathcal{A}(t,x,y)}\Bigg\{\mathcal{D}^{\pi}V\_{n}(t,x,y)-\mathcal{D}^{\pi}\left(G\_{n}\diamond\left(g\_{1}^{\overline{y}\_{0}},\dots,g\_{n}^{\overline{y}\_{n-1}}\right)\right)\left(t,x,y\right)\Bigg. |  | (3.12) |
|  |  | +â„‹Â¯nÏ€((giyÂ¯iâˆ’1)i=1,â€¦,n)(t,x,y)},\displaystyle\qquad\qquad\qquad\Bigg.+\overline{\mathcal{H}}^{\pi}\_{n}\left(\left(g\_{i}^{\overline{y}\_{i-1}}\right)\_{i=1,\dots,n}\right)(t,x,y)\Bigg\}, |  |
|  | 0\displaystyle 0 | =ğ’ŸÂ¯Ï€^nâ€‹giyÂ¯iâˆ’1â€‹(t,x,y),iâˆˆ{1,â€¦,n},\displaystyle=\overline{\mathcal{D}}^{\widehat{\pi}\_{n}}g\_{i}^{\overline{y}\_{i-1}}(t,x,y),\qquad i\in\left\{1,\dots,n\right\}, |  |
|  | Vnâ€‹(T,x,y)\displaystyle V\_{n}(T,x,y) | =vâ€‹(x),\displaystyle=v(x), |  |
|  | giyÂ¯iâˆ’1â€‹(T,x,y)\displaystyle g\_{i}^{\overline{y}\_{i-1}}(T,x,y) | =uÎ³â€‹(yÂ¯iâˆ’1)â€‹(x),iâˆˆ{1,â€¦,n},\displaystyle=u^{\gamma(\overline{y}\_{i-1})}(x),\,\qquad i\in\left\{1,\dots,n\right\}, |  |

where Ï€^n\widehat{\pi}\_{n} realizes the supremum in the first equation of ([3.12](https://arxiv.org/html/2512.21149v1#S3.E12 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). Once more, an appropriate adaptation of the verification argument in BKM21 shows that, under suitable smoothness and integrability conditions, the control Ï€^n\widehat{\pi}\_{n} obtained from this system constitutes an equilibrium control for (Pn)(P\_{n}).

Step 2: eHJB for the limiting case

To obtain the eHJB associated with the original objective functional ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we now pass from the discrete problems (Pn)(P\_{n}) to their continuous counterpart. This motivates introducing the limiting objects

|  |  |  |  |
| --- | --- | --- | --- |
|  | Gâˆâ€‹(t,x,y)\displaystyle G\_{\infty}(t,x,y) | :=limnâ†’âˆ(Gnâ‹„(g1yÂ¯0,â€¦,gnyÂ¯nâˆ’1))â€‹(t,x,y)\displaystyle:=\lim\_{n\to\infty}\left(G\_{n}\diamond\left(g\_{1}^{\overline{y}\_{0}},\dots,g\_{n}^{\overline{y}\_{n-1}}\right)\right)\left(t,x,y\right) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y),\displaystyle=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)dF\_{Y\_{T}}(\overline{y};t,y), |  | (3.13) |
|  |  |  |  |
| --- | --- | --- | --- |
|  | â„‹Â¯Ï€â€‹((gyÂ¯)yÂ¯âˆˆğ’´)â€‹(t,x,y)\displaystyle\overline{\mathcal{H}}^{\pi}\left(\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right)(t,x,y) | :=limnâ†’âˆâ„‹Â¯nÏ€â€‹((giyÂ¯iâˆ’1)i=1,â€¦,n)â€‹(t,x,y)\displaystyle:=\lim\_{n\to\infty}\overline{\mathcal{H}}^{\pi}\_{n}\left(\left(g\_{i}^{\overline{y}\_{i-1}}\right)\_{i=1,\dots,n}\right)(t,x,y) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =âˆ«ğ’´(Ï†yÂ¯)â€²â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ’ŸÂ¯Ï€â€‹gyÂ¯â€‹(t,x,y)â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y).\displaystyle=\int\_{\mathcal{Y}}\left(\varphi^{\overline{y}}\right)^{\prime}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,\overline{\mathcal{D}}^{\pi}g^{\overline{y}}\left(t,x,y\right)\,dF\_{Y\_{T}}(\overline{y};t,y). |  | (3.14) |

We are now equipped to write down the eHJB characterizing an equilibrium control for the original, infinite-dimensional aggregation problem.

#### The extended HJB system.

The system consists of the following coupled relations:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆˆğ’œâ€‹(t,x,y){ğ’ŸÏ€â€‹Vâ€‹(t,x,y)âˆ’ğ’ŸÏ€â€‹Gâˆâ€‹(t,x,y)+â„‹Â¯Ï€â€‹((gyÂ¯)yÂ¯âˆˆğ’´)â€‹(t,x,y)},\displaystyle=\sup\_{\pi\in\mathcal{A}(t,x,y)}\Bigg\{\mathcal{D}^{\pi}V(t,x,y)-\mathcal{D}^{\pi}G\_{\infty}(t,x,y)+\overline{\mathcal{H}}^{\pi}\left(\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right)(t,x,y)\Bigg\}, |  | (Sâ€‹1S1) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =ğ’ŸÂ¯Ï€^â€‹gyÂ¯â€‹(t,x,y),yÂ¯âˆˆğ’´,\displaystyle=\overline{\mathcal{D}}^{\widehat{\pi}}g^{\overline{y}}\left(t,x,y\right),\qquad\bar{y}\in\mathcal{Y}, |  | (Sâ€‹2S2) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | vâ€‹(x)\displaystyle v(x) | =Vâ€‹(T,x,y)\displaystyle=V(T,x,y) |  | (Sâ€‹3S3) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | uÎ³â€‹(yÂ¯)â€‹(x)\displaystyle u^{\gamma(\overline{y})}(x) | =gyÂ¯â€‹(T,x,y),yÂ¯âˆˆğ’´,\displaystyle=g^{\overline{y}}\left(T,x,y\right),\qquad\bar{y}\in\mathcal{Y}, |  | (Sâ€‹4S4) |

where Ï€^\widehat{\pi} realizes the supremum in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")).

The following section provides a verification theorem establishing that a solution of ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))-([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) indeed yields an equilibrium strategy.

### 3.3 Verification results

For the proof of the main theorem, we will require suitable integrability conditions. These are outlined in the following definition of an â„’2\mathcal{L}^{2} function space.

###### Definition 3.3.

Fix an arbitrary control Ï€âˆˆğ“\pi\in\bm{\mathcal{A}}. A function Î¾:ğ’¯Ã—ğ’³Ã—ğ’´â†’â„\xi:\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R} is said to belong to the space â„’2â€‹(XÏ€,Y)\mathcal{L}^{2}(X^{\pi},Y) if, for any (t,x,y)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´(t,x,y)\in[0,T)\times\mathcal{X}\times\mathcal{Y}, there exists a constant Î´Â¯âˆˆ(0,Tâˆ’t)\bar{\delta}\in(0,T-t) such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼t,x,y[sup0â‰¤Î´â‰¤Î´Â¯|âˆ«tt+Î´1Î´ğ’ŸÏ€Î¾(s,XsÏ€,Ys)ds|\displaystyle\mathbb{E}\_{t,x,y}\Bigg[\sup\_{0\leq\delta\leq\bar{\delta}}\Bigg|\int\_{t}^{t+\delta}\dfrac{1}{\delta}\mathcal{D}^{\pi}\xi(s,X^{\pi}\_{s},Y\_{s})ds\;\Bigg|\Bigg. |  |
|  |  |  |
| --- | --- | --- |
|  | +âˆ«tt+Î´Â¯â€–âˆ‚xÎ¾â€‹(s,XsÏ€,Ys)â€‹ÏƒXâ€‹(s,XsÏ€,Ï€â€‹(s))â€–2â€‹ğ‘‘s\displaystyle\hskip 56.9055pt\Bigg.+\int\_{t}^{t+\bar{\delta}}\left\lVert\partial\_{x}\xi(s,X^{\pi}\_{s},Y\_{s})\sigma\_{X}\left(s,X^{\pi}\_{s},\pi(s)\right)\right\rVert^{2}ds\Bigg. |  |
|  |  |  |
| --- | --- | --- |
|  | +âˆ«tt+Î´Â¯(âˆ‚yÎ¾(s,XsÏ€,Ys)ÏƒY(s,Ys))2ds]<âˆ.\displaystyle\hskip 56.9055pt\Bigg.+\int\_{t}^{t+\bar{\delta}}\Big(\partial\_{y}\xi(s,X^{\pi}\_{s},Y\_{s})\sigma\_{Y}\left(s,Y\_{s}\right)\Big)^{2}ds\Bigg]<\infty. |  |

Analogously, we say that Î¾:ğ’¯Ã—ğ’³Ã—ğ’´â†’â„\xi:\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R} belongs to the space â„’Â¯2â€‹(XÏ€,Y)\overline{\mathcal{L}}^{2}(X^{\pi},Y) if, for any (t,x,y)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´(t,x,y)\in[0,T)\times\mathcal{X}\times\mathcal{Y}, there exists a constant Î´Â¯âˆˆ(0,Tâˆ’t)\bar{\delta}\in(0,T-t) such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼t,x,y[sup0â‰¤Î´â‰¤Î´Â¯|âˆ«tt+Î´1Î´ğ’ŸÂ¯Ï€Î¾(s,XsÏ€,Ys)ds|\displaystyle\mathbb{E}\_{t,x,y}\Bigg[\sup\_{0\leq\delta\leq\bar{\delta}}\Bigg|\int\_{t}^{t+\delta}\dfrac{1}{\delta}\overline{\mathcal{D}}^{\pi}\xi(s,X^{\pi}\_{s},Y\_{s})ds\;\Bigg|\Bigg. |  |
|  |  |  |
| --- | --- | --- |
|  | +âˆ«tt+Î´Â¯â€–âˆ‚xÎ¾â€‹(s,XsÏ€,Ys)â€‹ÏƒÂ¯Xâ€‹(s,XsÏ€,Ï€â€‹(s))â€–2â€‹ğ‘‘s\displaystyle\hskip 56.9055pt\Bigg.+\int\_{t}^{t+\bar{\delta}}\left\lVert\partial\_{x}\xi(s,X^{\pi}\_{s},Y\_{s})\overline{\sigma}\_{X}\left(s,X^{\pi}\_{s},\pi(s)\right)\right\rVert^{2}ds\Bigg. |  |
|  |  |  |
| --- | --- | --- |
|  | +âˆ«tt+Î´Â¯(âˆ‚yÎ¾(s,XsÏ€,Ys)ÏƒÂ¯Y(s,Ys))2ds]<âˆ.\displaystyle\hskip 56.9055pt\Bigg.+\int\_{t}^{t+\bar{\delta}}\Big(\partial\_{y}\xi(s,X^{\pi}\_{s},Y\_{s})\overline{\sigma}\_{Y}\left(s,Y\_{s}\right)\Big)^{2}ds\Bigg]<\infty. |  |

We now introduce a family of auxiliary functions parameterized by yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | gÏ€;yÂ¯â€‹(t,x,y)=ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)],\displaystyle g^{\pi;\overline{y}}(t,x,y)=\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\,, |  | (3.15) |

where, by construction, yy and yÂ¯\overline{y} must coincide at t=Tt=T.

In the following lemma, we derive a recursive representation for each function in (gÏ€;yÂ¯)yÂ¯âˆˆğ’´\left(g^{\pi;\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}} and also characterize it via a PDE. Its proof follows the same steps as Lemma 3.5 in Lindensjoe2019:ORL or Lemma 3.7 in DeGennaroAquino2024equilibrium, with the only difference that we work here under the conditional measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}} instead of â„™t,x,y\mathbb{P}\_{t,x,y}.

###### Lemma 3.4.

For any admissible control Ï€âˆˆğ“\pi\in\bm{\mathcal{A}} and yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y}, for any Î´âˆˆ(0,Tâˆ’t]\delta\in(0,T-t], the function gÏ€;yÂ¯â€‹(t,x,y)g^{\pi;\overline{y}}(t,x,y) satisfies the recursive relation

|  |  |  |
| --- | --- | --- |
|  | gÏ€;yÂ¯â€‹(t,x,y)=ğ”¼t,x,y,yÂ¯â€‹[gÏ€;yÂ¯â€‹(t+Î´,XÏ€â€‹(t+Î´),Yâ€‹(t+Î´))],g^{\pi;\overline{y}}(t,x,y)=\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\pi;\overline{y}}\left(t+\delta,X^{\pi}(t+\delta),Y(t+\delta)\right)\right], |  |

and the terminal condition

|  |  |  |
| --- | --- | --- |
|  | gÏ€;yÂ¯â€‹(T,x,y)=uÎ³â€‹(yÂ¯)â€‹(x).g^{\pi;\overline{y}}(T,x,y)=u^{\gamma(\overline{y})}(x). |  |

Moreover, if gÏ€;yÂ¯âˆˆ\textgothâ€‹C1,2,1â€‹(ğ’¯Ã—â„Ã—â„)âˆ©â„’Â¯2â€‹(XÏ€,Y)g^{\pi;\overline{y}}\in\textgoth{C}^{1,2,1}\left(\mathcal{T}\times\mathbb{R}\times\mathbb{R}\right)\cap\overline{\mathcal{L}}^{2}\left(X^{\pi},Y\right), then, for tâˆˆ[0,T)t\in[0,T), gÏ€;yÂ¯â€‹(t,x,y)g^{\pi;\overline{y}}(t,x,y) satisfies the PDE

|  |  |  |
| --- | --- | --- |
|  | ğ’ŸÂ¯Ï€â€‹gÏ€;yÂ¯â€‹(t,x,y)=0.\overline{\mathcal{D}}^{\pi}g^{\pi;\overline{y}}(t,x,y)=0. |  |

We are now in a position to state our main result.

###### Theorem 3.5 (Verification theorem).

Assume that the functions Vâ€‹(t,x,y)V(t,x,y), Gâˆâ€‹(t,x,y)G\_{\infty}(t,x,y), and the family (gyÂ¯â€‹(t,x,y))yÂ¯âˆˆğ’´\left(g^{\overline{y}}\left(t,x,y\right)\right)\_{\overline{y}\in\mathcal{Y}} satisfy the following properties:

1. (C1)

   The arg sup in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) exists, is denoted by Ï€^\widehat{\pi}, and it is an admissible control.
2. (C2)

   The triplet (V,Gâˆ,(gyÂ¯)yÂ¯âˆˆğ’´)\left(V,G\_{\infty},\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right) solves the system ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))-([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")).
3. (C3)

   For every yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y},

   |  |  |  |
   | --- | --- | --- |
   |  | gyÂ¯âˆˆğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´)g^{\overline{y}}\in\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right) |  |

   and

   |  |  |  |
   | --- | --- | --- |
   |  | Vâˆˆğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´),Gâˆâˆˆğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´).V\in\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right),G\_{\infty}\in\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right). |  |
4. (C4)

   For every yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y} and Ï€âˆˆğ“\pi\in\bm{\mathcal{A}},

   |  |  |  |
   | --- | --- | --- |
   |  | gyÂ¯âˆˆâ„’Â¯2â€‹(XÏ€,YÏ€),g^{\overline{y}}\in\overline{\mathcal{L}}^{2}\left(X^{\pi},Y^{\pi}\right), |  |

   and for every Ï€âˆˆğ“\pi\in\bm{\mathcal{A}},

   |  |  |  |
   | --- | --- | --- |
   |  | Vâˆˆâ„’2â€‹(XÏ€,YÏ€),Gâˆâˆˆâ„’2â€‹(XÏ€,YÏ€).V\in\mathcal{L}^{2}\left(X^{\pi},Y^{\pi}\right),G\_{\infty}\in\mathcal{L}^{2}\left(X^{\pi},Y^{\pi}\right). |  |

Then:

1. (R1)

   gyÂ¯â€‹(t,x,y)=gÏ€^;yÂ¯â€‹(t,x,y)g^{\overline{y}}(t,x,y)=g^{\widehat{\pi};\overline{y}}(t,x,y), and admits the probabilistic representation

   |  |  |  |  |
   | --- | --- | --- | --- |
   |  | gyÂ¯â€‹(t,x,y)\displaystyle g^{\overline{y}}(t,x,y) | =ğ”¼â€‹[uÎ³â€‹(YT)â€‹(XTÏ€^)|XtÏ€^=x,Yt=y,YT=yÂ¯]\displaystyle=\mathbb{E}\left[u^{\gamma(Y\_{T})}\left(X^{\widehat{\pi}}\_{T}\right)|\,X^{\widehat{\pi}}\_{t}=x,Y\_{t}=y,Y\_{T}=\overline{y}\right] |  |
   |  |  |  |  |
   | --- | --- | --- | --- |
   |  |  | =ğ”¼â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€^)|XtÏ€^=x,Yt=y].\displaystyle=\mathbb{E}\left[u^{\gamma(\overline{y})}\left(X^{\widehat{\pi}}\_{T}\right)|\,X^{\widehat{\pi}}\_{t}=x,Y\_{t}=y\right]. |  |
2. (R2)

   For Ï€^\widehat{\pi} realizing the sup in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), the objective can be written as

   |  |  |  |
   | --- | --- | --- |
   |  | JÏ€^â€‹(t,x,y)=âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y).J^{\widehat{\pi}}(t,x,y)=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}(t,x,y)\right)\,dF\_{Y\_{T}}(\overline{y};t,y). |  |
3. (R3)

   Ï€^\widehat{\pi} is an equilibrium investment strategy.
4. (R4)

   The equilibrium value function is given by

   |  |  |  |
   | --- | --- | --- |
   |  | V^â€‹(t,x,y)=Vâ€‹(t,x,y)=âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y),\widehat{V}(t,x,y)=V(t,x,y)=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}(t,x,y)\right)\,dF\_{Y\_{T}}(\overline{y};t,y), |  |

   and admits the probabilistic representation ([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) for Ï€=Ï€^\pi=\widehat{\pi}.

Proof. See Appendix [A.2](https://arxiv.org/html/2512.21149v1#A1.SS2 "A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty").

The verification theorem allows us to simplify the eHJB ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))-([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) in a way analogous to what is done in Section 16.1 of BKM21. From (R4) and ([3.13](https://arxiv.org/html/2512.21149v1#S3.E13 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we in fact notice that

|  |  |  |
| --- | --- | --- |
|  | Vâ€‹(t,x,y)=Gâˆâ€‹(t,x,y).V(t,x,y)=G\_{\infty}(t,x,y). |  |

Therefore, the first two terms under the supremum in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) cancel out.

###### Corollary 3.6.

Using ([3.14](https://arxiv.org/html/2512.21149v1#S3.E14 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), the eHJB ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))-([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) can be written in the following equivalent form:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆˆğ’œâ€‹(t,x,y)â„‹Â¯Ï€â€‹((gyÂ¯)yÂ¯âˆˆğ’´)â€‹(t,x,y),\displaystyle=\sup\limits\_{\pi\in\mathcal{A}(t,x,y)}\overline{\mathcal{H}}^{\pi}\left(\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right)(t,x,y), |  | (Sâ€‹1Â¯\overline{S1}) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =ğ’ŸÂ¯Ï€^â€‹gyÂ¯â€‹(t,x,y),yÂ¯âˆˆğ’´,\displaystyle=\overline{\mathcal{D}}^{\widehat{\pi}}g^{\overline{y}}\left(t,x,y\right),\qquad\,\overline{y}\in\mathcal{Y}, |  | (Sâ€‹2Â¯\overline{S2}) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | uÎ³â€‹(yÂ¯)â€‹(x)\displaystyle u^{\gamma(\overline{y})}(x) | =gyÂ¯â€‹(T,x,y),yÂ¯âˆˆğ’´,\displaystyle=g^{\overline{y}}\left(T,x,y\right),\qquad\,\overline{y}\in\mathcal{Y}, |  | (Sâ€‹3Â¯\overline{S3}) |

where Ï€^\widehat{\pi} realizes the supremum in ([Sâ€‹1Â¯\overline{S1}](https://arxiv.org/html/2512.21149v1#S3.Ex47 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")).

### 3.4 Relation to existing formulations

To place our eHJB in context, we relate it to the general framework of time-inconsistent control developed by BKM21. We begin by recalling the eHJB associated with the objective function (LABEL:eq:reward\_functional\_general\_BKM2021), adapted to the case when the state space is two-dimensional. For clarity, we consistently translate their notation into ours.

For functions g=(g1,g2)g=(g\_{1},g\_{2}) and GG, recall the definitions used by BKM21 introduced in ([3.8](https://arxiv.org/html/2512.21149v1#S3.E8 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). In addition, for a function ff, they write

|  |  |  |
| --- | --- | --- |
|  | fsâ€‹x~â€‹y~â€‹(t,x,y):=fâ€‹(t,x,y,s,x~,y~),withÂ â€‹s,x~,y~â€‹Â seen as fixed values.f^{s\tilde{x}\tilde{y}}(t,x,y):=f(t,x,y,s,\tilde{x},\tilde{y}),\quad\mbox{with }s,\tilde{x},\tilde{y}\;\mbox{ seen as fixed values.} |  |

With these definitions, the full characterization of the value function VV, the family of auxiliary value functions fsâ€‹x~â€‹y~â€‹(t,x,y)f^{s\tilde{x}\tilde{y}}(t,x,y), and the function gg, takes the form:

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0=supÏ€âˆˆğ’œâ€‹(t,x,y){ğ’ŸÏ€V(t,x,y)+H(t,x,y,t,x,y,Ï€)âˆ’ğ’ŸÏ€f(t,x,y,t,x,y),+ğ’ŸÏ€ftâ€‹xâ€‹y(t,x,y)âˆ’ğ’ŸÏ€(Gâ‹„g)(t,x,y)+(â„‹Ï€g)(t,x,y)},0=ğ’ŸÏ€^â€‹fsâ€‹x~â€‹y~â€‹(t,x,y)+Hâ€‹(s,x~,y~,t,x,y,Ï€^),(s,x~,y~)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´,(0,0)=ğ’ŸÏ€^â€‹gâ€‹(t,x,y),Vâ€‹(T,x,y)=Fâ€‹(T,x,y,x,y)+Gâ€‹(T,x,y,x,y),fsâ€‹x~â€‹y~â€‹(T,x,y)=Fâ€‹(s,x~,y~,x,y),(s,x~,y~)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´,gâ€‹(T,x,y)=(x,y),\begin{split}0&=\sup\_{\pi\in\mathcal{A}(t,x,y)}\Big\{\mathcal{D}^{\pi}V(t,x,y)+H(t,x,y,t,x,y,\pi)-\mathcal{D}^{\pi}f(t,x,y,t,x,y),\\ &\hskip 42.67912pt+\mathcal{D}^{\pi}f^{txy}(t,x,y)-\mathcal{D}^{\pi}(G\diamond g)(t,x,y)+(\mathcal{H}^{\pi}g)(t,x,y)\Big\},\\ 0&=\mathcal{D}^{\widehat{\pi}}f^{s\tilde{x}\tilde{y}}(t,x,y)+H(s,\tilde{x},\tilde{y},t,x,y,\widehat{\pi}),\quad(s,\tilde{x},\tilde{y})\in[0,T)\times\mathcal{X}\times\mathcal{Y},\\ (0,0)&=\mathcal{D}^{\widehat{\pi}}g(t,x,y),\\ V(T,x,y)&=F(T,x,y,x,y)+G(T,x,y,x,y),\\ f^{s\tilde{x}\tilde{y}}(T,x,y)&=F(s,\tilde{x},\tilde{y},x,y),\quad(s,\tilde{x},\tilde{y})\in[0,T)\times\mathcal{X}\times\mathcal{Y},\\ g(T,x,y)&=(x,y),\end{split} |  | (3.16) |

where Ï€^\widehat{\pi} realizes the supremum in the first equation of ([3.16](https://arxiv.org/html/2512.21149v1#S3.E16 "In 3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")).

To understand how our system relates to the general framework presented above, we need to examine what happens when the general reward functional (LABEL:eq:reward\_functional\_general\_BKM2021) contains only the nonlinear GG-term corresponding to ([3.7](https://arxiv.org/html/2512.21149v1#S3.E7 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). This case arises by setting Hâ‰¡0H\equiv 0 and Fâ‰¡0F\equiv 0.

Under this restriction, several simplifications occur in the system ([3.16](https://arxiv.org/html/2512.21149v1#S3.E16 "In 3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")). Firstly, the second and fifth equations are redundant. Secondly, by noticing that V=Gâ‹„gV=G\diamond g, the two terms (ğ’ŸÏ€â€‹V)â€‹(t,x,y)(\mathcal{D}^{\pi}V)(t,x,y) and ğ’ŸÏ€â€‹(Gâ‹„g)â€‹(t,x,y)\mathcal{D}^{\pi}(G\diamond g)(t,x,y) become identical. This gives the system

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆˆğ’œâ€‹(t,x,y)(â„‹Ï€â€‹g)â€‹(t,x,y),\displaystyle=\sup\_{\pi\in\mathcal{A}(t,x,y)}(\mathcal{H}^{\pi}g)(t,x,y), |  | (3.17) |
|  | (0,0)\displaystyle(0,0) | =ğ’ŸÏ€^â€‹gâ€‹(t,x,y),\displaystyle=\mathcal{D}^{\widehat{\pi}}g(t,x,y), |  |
|  | gâ€‹(T,x,y)\displaystyle g(T,x,y) | =(x,y),\displaystyle=(x,y), |  |

which is structurally similar to ([Sâ€‹1Â¯\overline{S1}](https://arxiv.org/html/2512.21149v1#S3.Ex47 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))â€“([Sâ€‹3Â¯\overline{S3}](https://arxiv.org/html/2512.21149v1#S3.Ex49 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")).

As for the extended system in DesmettreSteffensen2023:MF, Theorem 3.5, observe that Utâ€‹(t,x)U\_{t}(t,x) and all the terms in the first two lines under the infimum in their Eq. (10) cancel out as a consequence of their Eq. (20). After these cancellations, their extended system can be rewritten in the following compact form:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 0\displaystyle 0 | =supÏ€âˆ«Î¹Î³â€‹(YÎ³â€‹(t,x))â€‹ğ’ŸÏ€â€‹YÎ³â€‹(t,x)â€‹dÎ“â€‹(Î³),\displaystyle=\sup\_{\pi}\int\iota^{\gamma}(Y^{\gamma}(t,x))\,\mathcal{D}^{\pi}Y^{\gamma}(t,x)\,\mathrm{d}\Gamma(\gamma), |  | (3.18) |
|  | 0\displaystyle 0 | =ğ’ŸÏ€^â€‹YÎ³â€‹(t,x),for each realization ofÂ â€‹Î³,\displaystyle=\mathcal{D}^{\widehat{\pi}}Y^{\gamma}(t,x),\qquad\text{for each realization of }\gamma, |  |
|  | uÎ³â€‹(x)\displaystyle u^{\gamma}(x) | =YÎ³â€‹(T,x),for each realization ofÂ â€‹Î³,\displaystyle=Y^{\gamma}(T,x),\qquad\text{for each realization of }\gamma, |  |

which is identical to our eHJB for vâ€‹(x)=xv(x)=x once we translate their notation into ours:

|  |  |  |
| --- | --- | --- |
|  | Î³â†’Î³â€‹(yÂ¯),Î¹Î³â†’(Ï†yÂ¯)â€²,YÎ³â€‹(t,x)â†’gyÂ¯â€‹(t,x,y),uÎ³â†’uÎ³â€‹(yÂ¯),dâ€‹Î“â€‹(Î³)â†’dâ€‹FYTâ€‹(yÂ¯;t,y).\begin{split}&\gamma\rightarrow\gamma(\overline{y}),\quad\iota^{\gamma}\rightarrow\left(\varphi^{\overline{y}}\right)^{\prime},\quad Y^{\gamma}(t,x)\rightarrow g^{\overline{y}}(t,x,y),\\ &u^{\gamma}\rightarrow u^{\gamma(\overline{y})},\quad d\Gamma(\gamma)\rightarrow dF\_{Y\_{T}}(\overline{y};t,y).\end{split} |  |

Finally, we relate our eHJB to the system in Eq. (9) of ChenGuanLiang2025, reported below:

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0=supÏ€âˆˆÎ {âˆ‘kâˆˆğ’®((uk)âˆ’1)â€²â€‹(fi,kâ€‹(t,x))â€‹ğ’œÏ€â€‹fi,kâ€‹(t,x)â€‹pâ€‹(t,i,k)}=0,0=ğ’œÏ€â€‹fi,jâ€‹(t,x)=0,jâˆˆğ’®,fi,jâ€‹(T,x)=ujâ€‹(x),jâˆˆğ’®.\begin{split}0&=\sup\_{\pi\in\Pi}\left\{\sum\_{k\in\mathcal{S}}\left((u^{k})^{-1}\right)^{\prime}\left(f^{i,k}(t,x)\right)\;\mathscr{A}^{\pi}f^{i,k}(t,x)\;p(t,i,k)\right\}=0,\\ 0&=\mathscr{A}^{\pi}f^{i,j}(t,x)=0,\qquad j\in\mathcal{S},\\ f^{i,j}(T,x)&=u^{j}(x),\qquad j\in\mathcal{S}.\end{split} |  | (3.19) |

Here ğ’®:={1,â€¦,n}\mathcal{S}:=\left\{1,\dots,n\right\}, with nâˆˆâ„•n\in\mathbb{N}, is the state space of the Markov chain Ïµ:=(Ïµt)tâˆˆğ’¯\epsilon:=\left(\epsilon\_{t}\right)\_{t\in\mathcal{T}} driving both risk aversion and market coefficients, pâ€‹(t,i,k)=â„™â€‹(ÏµT=k|Ïµt=i)p(t,i,k)=\mathbb{P}\left(\epsilon\_{T}=k\,|\ \epsilon\_{t}=i\right), for every tâˆˆğ’¯t\in\mathcal{T} and i,kâˆˆğ’®i,k\in\mathcal{S}, Î \Pi is the set of admissible strategies, and ğ’œÏ€\mathscr{A}^{\pi} is the controlled infinitesimal generator of the regime-switching diffusion. Naturally, ([3.19](https://arxiv.org/html/2512.21149v1#S3.E19 "In 3.4 Relation to existing formulations â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) corresponds to the special case of our ([Sâ€‹1Â¯\overline{S1}](https://arxiv.org/html/2512.21149v1#S3.Ex47 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) under vâ€‹(x)=x,Ï=0v(x)=x,\rho=0, and the dictionary

|  |  |  |
| --- | --- | --- |
|  | Î£â†’âˆ«,ğ’®â†’ğ’´,kâ†’yÂ¯,jâ†’yÂ¯,iâ†’y,(uk)âˆ’1â†’Ï†yÂ¯,pâ€‹(t,i,k)â†’dâ€‹FYTâ€‹(yÂ¯;t,y),fi,jâ€‹(t,x)â†’gyÂ¯â€‹(t,x,y).\begin{split}&\Sigma\rightarrow\int,\quad\mathcal{S}\rightarrow\mathcal{Y},\quad k\rightarrow\overline{y},\quad j\rightarrow\overline{y},\quad i\rightarrow y,\quad\left(u^{k}\right)^{-1}\rightarrow\varphi^{\overline{y}},\\ &p(t,i,k)\rightarrow dF\_{Y\_{T}}(\overline{y};t,y),\quad f^{i,j}(t,x)\rightarrow g^{\overline{y}}(t,x,y).\end{split} |  |

Due to the assumption of independence between the Markov chain Ïµ\epsilon and the Brownian motion driving the wealth process in ChenGuanLiang2025, conditioning on ÏµT=k\epsilon\_{T}=k, for some kâˆˆğ’®k\in\mathcal{S}, does not change the law of the wealth process. In contrast, our setting allows for arbitrary correlation between XX and YY via Ïâˆˆ[âˆ’1,1]\rho\in[-1,1]. Conditioning on YT=yÂ¯Y\_{T}=\overline{y} therefore changes the law of XX, which requires a change of the differential operator from ğ’Ÿ\mathcal{D} (under â„™t,x,y\mathbb{P}\_{t,x,y}) to ğ’ŸÂ¯\overline{\mathcal{D}} (under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}).

## 4 Application: state-dependent CRRA utility

In this section, we apply the general equilibrium framework developed in Sections [2](https://arxiv.org/html/2512.21149v1#S2 "2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty") and [3](https://arxiv.org/html/2512.21149v1#S3 "3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty") to a tractable case in which the investorâ€™s relative risk aversion is driven by an exogenous factor that follows an arithmetic Brownian motion.

First, we describe the preference specification and derive the specialized form of the eHJB. Second, we analyze the resulting equilibrium policy numerically and provide some intuition on the underlying economic mechanisms.

### 4.1 Preference specification and equilibrium investment

We consider preferences that are CRRA with a state-dependent relative risk aversion. The intertemporal variation in risk attitudes is driven by an exogenous factor, denoted by YY, which evolves according to the arithmetic Brownian motion

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Yt=Î¼Yâ€‹dâ€‹t+ÏƒYâ€‹dâ€‹Bt1,dY\_{t}=\mu\_{Y}dt+\sigma\_{Y}dB^{1}\_{t}, |  | (4.1) |

for constants Î¼Yâˆˆâ„\mu\_{Y}\in\mathbb{R} and ÏƒY>0\sigma\_{Y}>0, with slight abuse of notation compared to ([2.2](https://arxiv.org/html/2512.21149v1#S2.E2 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")).

For a fixed realization of YT=yÂ¯Y\_{T}=\overline{y}, we model the risk aversion coefficient by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î³â€‹(yÂ¯):=eyÂ¯,\gamma(\overline{y}):=e^{\overline{y}}, |  | (4.2) |

which induces the CRRA utility

|  |  |  |  |
| --- | --- | --- | --- |
|  | uÎ³â€‹(yÂ¯)â€‹(x)=x1âˆ’Î³â€‹(yÂ¯)1âˆ’Î³â€‹(yÂ¯).u^{\gamma(\overline{y})}(x)=\dfrac{x^{1-\gamma(\overline{y})}}{1-\gamma(\overline{y})}. |  | (4.3) |

Thus, the investor behaves as a standard CRRA agent along the wealth dimension, while changes in YY alter her effective risk aversion over time.

The corresponding evaluation of a portfolio strategy Ï€\pi is recalled here for convenience:

|  |  |  |
| --- | --- | --- |
|  | JÏ€â€‹(t,x,y)=âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€)])â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯.J^{\pi}(t,x,y)=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\!\left(\mathbb{E}\_{t,x,y,\bar{y}}\big[u^{\gamma(\bar{y})}(X^{\pi}\_{T})\big]\right)f\_{Y\_{T}}(\bar{y};t,y)\,d\bar{y}. |  |

In the general framework of Section [3](https://arxiv.org/html/2512.21149v1#S3 "3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"), vv is an arbitrary increasing, concave, and differentiable function. Here, we adopt the logarithmic form

|  |  |  |  |
| --- | --- | --- | --- |
|  | vâ€‹(x)=lnâ¡(x),v(x)=\ln(x), |  | (4.4) |

which is helpful for tractability reasons as it naturally aligns with the multiplicative structure of CRRA preferences. (This form of aggregator for certainty equivalents is also used in BS21, albeit in a different context.)

In addition, recall that the density fYTâ€‹(yÂ¯;t,y)f\_{Y\_{T}}(\bar{y};t,y) is the PDF of YTY\_{T} conditional on Yt=yY\_{t}=y, which is Gaussian, since ([4.1](https://arxiv.org/html/2512.21149v1#S4.E1 "In 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) implies

|  |  |  |
| --- | --- | --- |
|  | YT|Yt=yâˆ¼ğ’©â€‹(y+Î¼Yâ€‹(Tâˆ’t),ÏƒY2â€‹(Tâˆ’t)).Y\_{T}\,|\,Y\_{t}=y\sim\mathcal{N}\left(y+\mu\_{Y}(T-t),\sigma\_{Y}^{2}(T-t)\right). |  |

To construct the equilibrium policy, we next adapt the general eHJB from Section [3](https://arxiv.org/html/2512.21149v1#S3 "3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty") to this CRRA setting. The first step is to identify the dynamics of the state process (XÏ€,Y)(X^{\pi},Y) under the family of conditional measures appearing in the equilibrium equations. The next result follows from LemmaÂ [3.1](https://arxiv.org/html/2512.21149v1#S3.Thmtheorem1 "Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty") upon inserting the diffusion specification for YY.

###### Corollary 4.1.

Let BÂ¯1\overline{B}^{1} and BÂ¯2\overline{B}^{2} be two standard Brownian motions under the conditional measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}. Then, for sâˆˆ[t,T)s\in[t,T):

* â€¢

  The preference factor YY satisfies

  |  |  |  |
  | --- | --- | --- |
  |  | dâ€‹Ys=yÂ¯âˆ’YsTâˆ’sâ€‹dâ€‹s+ÏƒYâ€‹dâ€‹BÂ¯s1,dY\_{s}=\frac{\overline{y}-Y\_{s}}{T-s}ds+\sigma\_{Y}d\overline{B}^{1}\_{s}, |  |

  with Yt=yY\_{t}=y and YT=yÂ¯Y\_{T}=\overline{y}.
* â€¢

  The wealth process XÏ€X^{\pi} satisfies

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | dâ€‹XsÏ€\displaystyle dX^{\pi}\_{s} | =XsÏ€â€‹(r+Ï€â€‹(s)â€‹(Î¼Sâˆ’r)+Ï€â€‹(s)â€‹Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’Ysâˆ’Î¼Yâ€‹(Tâˆ’s)Tâˆ’s)â€‹dâ€‹s\displaystyle=X^{\pi}\_{s}\left(r+\pi(s)(\mu\_{S}-r)+\pi(s)\rho\frac{\sigma\_{S}}{\sigma\_{Y}}\frac{\overline{y}-Y\_{s}-\mu\_{Y}(T-s)}{T-s}\right)ds |  |
  |  |  |  |  |
  | --- | --- | --- | --- |
  |  |  | +XsÏ€â€‹Ï€â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2),\displaystyle\qquad+X^{\pi}\_{s}\pi(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right), |  |

  with XtÏ€=xX^{\pi}\_{t}=x and XTÏ€=limtâ†’TXtÏ€X^{\pi}\_{T}=\lim\_{t\to T}X^{\pi}\_{t}.

Proof. See Appendix [A.3](https://arxiv.org/html/2512.21149v1#A1.SS3 "A.3 Proof of Corollary 4.1 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty").

The process YY thus becomes an arithmetic Brownian bridge under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, whereas XÏ€X^{\pi} carries an additional drift adjustment reflecting both the conditioning on YT=yÂ¯Y\_{T}=\bar{y} and the correlation between the underlying shocks.

The following proposition provides the semi-explicit representation of an equilibrium policy. Its expression depends on a family of auxiliary functions hyÂ¯â€‹(t,y)h^{\bar{y}}(t,y) which solve a coupled nonlinear PIDE.

###### Proposition 4.2.

For a reward functional of the form in ([2.3](https://arxiv.org/html/2512.21149v1#S2.E3 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty")), consider a CRRA specification ([4.2](https://arxiv.org/html/2512.21149v1#S4.E2 "In 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty"))-([4.3](https://arxiv.org/html/2512.21149v1#S4.E3 "In 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) with logarithmic certainty equivalent aggregator ([4.4](https://arxiv.org/html/2512.21149v1#S4.E4 "In 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")). In this setting, the equilibrium investment policy depends only on (t,y)(t,y) and is given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï€^â€‹(t,y)=Î¼Sâˆ’r+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹âˆ«ğ’´âˆ‚yhyÂ¯â€‹(t,y)hyÂ¯â€‹(t,y)â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯ÏƒS2â€‹expâ¡(y+Î¼Yâ€‹(Tâˆ’t)+12â€‹ÏƒY2â€‹(Tâˆ’t)),\begin{split}\widehat{\pi}(t,y)&=\dfrac{\mu\_{S}-r+\rho\sigma\_{S}\sigma\_{Y}\displaystyle{\int\_{\mathcal{Y}}\dfrac{\partial\_{y}h^{\bar{y}}(t,y)}{h^{\bar{y}}(t,y)}f\_{Y\_{T}}(\bar{y};t,y)d\bar{y}}}{\sigma\_{S}^{2}\exp\left(y+\mu\_{Y}(T-t)+\dfrac{1}{2}\sigma\_{Y}^{2}(T-t)\right)},\end{split} |  | (4.5) |

where, for each yÂ¯âˆˆğ’´\bar{y}\in\mathcal{Y}, the function hyÂ¯h^{\bar{y}} solves

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0=âˆ‚thyÂ¯â€‹(t,y)+(yÂ¯âˆ’yTâˆ’t+Ïâ€‹Ï€^â€‹ÏƒSâ€‹ÏƒYâ€‹(1âˆ’eyÂ¯))â€‹âˆ‚yhyÂ¯â€‹(t,y)+12â€‹ÏƒY2â€‹âˆ‚yâ€‹yhyÂ¯â€‹(t,y)+(r+Ï€^â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹(yÂ¯âˆ’yTâˆ’tâˆ’Î¼Y))âˆ’12â€‹Ï€^2â€‹ÏƒS2â€‹eyÂ¯)â€‹(1âˆ’eyÂ¯)â€‹hyÂ¯â€‹(t,y),hyÂ¯â€‹(T,y)=1.\begin{split}0&=\partial\_{t}h^{\bar{y}}(t,y)+\left(\dfrac{\bar{y}-y}{T-t}+\rho\widehat{\pi}\sigma\_{S}\sigma\_{Y}\big(1-e^{\bar{y}}\big)\right)\partial\_{y}h^{\bar{y}}(t,y)+\dfrac{1}{2}\sigma\_{Y}^{2}\partial\_{yy}h^{\bar{y}}(t,y)\\ &+\left(r+\widehat{\pi}\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\left(\dfrac{\bar{y}-y}{T-t}-\mu\_{Y}\right)\right)-\dfrac{1}{2}\widehat{\pi}^{2}\sigma\_{S}^{2}\,e^{\bar{y}}\right)\big(1-e^{\bar{y}}\big)h^{\bar{y}}(t,y),\\ h^{\bar{y}}(T,y)&=1.\end{split} |  | (4.6) |

Proof. See Appendix [A.4](https://arxiv.org/html/2512.21149v1#A1.SS4 "A.4 Proof of Proposition 4.2 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty").

The relation defining the equilibrium control in ([4.5](https://arxiv.org/html/2512.21149v1#S4.E5 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) and the PIDE for hyÂ¯h^{\bar{y}} in ([4.6](https://arxiv.org/html/2512.21149v1#S4.E6 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) are jointly nonlinear and fully coupled, except in the special case Ï=0\rho=0. The numerical computations reported below are based on solving this forward-backward system.

### 4.2 Interpretation and numerical analysis

Let us comment on the equilibrium investment policy in ([4.5](https://arxiv.org/html/2512.21149v1#S4.E5 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")). Since the exponential factor appearing in the denominator equals the conditional expectation of Î³â€‹(YT)\gamma(Y\_{T}) given Yt=yY\_{t}=y, we may rewrite Ï€^â€‹(t,y)\widehat{\pi}(t,y) as

|  |  |  |
| --- | --- | --- |
|  | Ï€^â€‹(t,y)=Î¼Sâˆ’rÏƒS2â€‹ğ”¼t,yâ€‹[Î³â€‹(YT)]+Ïâ€‹ÏƒYÏƒSâ€‹ğ”¼t,yâ€‹[Î³â€‹(YT)]â€‹âˆ«ğ’´âˆ‚yhyÂ¯â€‹(t,y)hyÂ¯â€‹(t,y)â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯.\widehat{\pi}(t,y)=\dfrac{\mu\_{S}-r}{\sigma\_{S}^{2}\mathbb{E}\_{t,y}\left[\gamma(Y\_{T})\right]}+\dfrac{\rho\sigma\_{Y}}{\sigma\_{S}\mathbb{E}\_{t,y}\left[\gamma(Y\_{T})\right]}\int\_{\mathcal{Y}}\frac{\partial\_{y}h^{\bar{y}}(t,y)}{h^{\bar{y}}(t,y)}f\_{Y\_{T}}(\bar{y};t,y)\,d\bar{y}. |  |

The first term is the familiar myopic (Merton-type) demand, but with the constant risk aversion coefficient replaced by the conditional expectation of its terminal realization. The second term is what we call a preference-hedging demand,
for it captures the agentâ€™s intention to adjust todayâ€™s exposure in anticipation of how her future risk aversion may evolve. Crucially, this hedging term depends not only on preference dynamics but also on how these dynamics interact with the market. When Ïâ‰ 0\rho\neq 0, preference shocks and asset return shocks are partially correlated, giving the investor a channel to hedge the stochastic evolution of her own future risk attitudes. When Ï=0\rho=0, this channel is absent and the hedging component vanishes entirely, yielding a solution that resembles the one found in Eq. (19) of BS21.

The integral term itself involves the elasticity âˆ‚yhyÂ¯â€‹(t,y)hyÂ¯â€‹(t,y)\frac{\partial\_{y}h^{\bar{y}}(t,y)}{h^{\bar{y}}(t,y)}, where the function hyÂ¯h^{\bar{y}} solves the PIDE in ([4.6](https://arxiv.org/html/2512.21149v1#S4.E6 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")). As shown in the proof of Proposition [4.2](https://arxiv.org/html/2512.21149v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty") in Appendix [A.4](https://arxiv.org/html/2512.21149v1#A1.SS4 "A.4 Proof of Proposition 4.2 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty"), this function is tied to the value function of the problem (specifically, to the continuation value), so the hedging demand reflects the sensitivity of future continuation value to the current preference state.

A notable feature of this representation is that, despite the complexity of the underlying dynamic inconsistency, the equilibrium policy does not depend on wealth. This property, of course, follows from the homothetic structure of CRRA preferences and is preserved here even in the presence of evolving risk attitudes. It is worth contrasting this with the findings of KrausslLucasSiegman2012:FinResearchLetters, who â€“working with a different model for preferencesâ€“ show that uncertainty about risk aversion can instead generate a positive relation between wealth and risk taking.

![Refer to caption](eqpolicy_positive_muy_positive_rho.png)


(a)

![Refer to caption](eqpolicy_negative_muy_positive_rho.png)


(b)

![Refer to caption](prefhedging_positive_muy_positive_rho.png)


(c)

![Refer to caption](prefhedging_negative_muy_positive_rho.png)


(d)

Figure 1: Equilibrium policy Ï€^â€‹(t,y)\widehat{\pi}(t,y) and preference hedging demand for Î¼Y=0.02\mu\_{Y}=0.02 (left column) and Î¼Y=âˆ’0.02\mu\_{Y}=-0.02 (right column). Other parameters: (r,Î¼S,ÏƒS,ÏƒY,Ï,expâ¡(y0))=(0.02,â€‰0.07,â€‰0.2,â€‰0.04,â€‰0.6,â€‰2)(r,\mu\_{S},\sigma\_{S},\sigma\_{Y},\rho,\exp(y\_{0}))=(0.02,\,0.07,\,0.2,\,0.04,\,0.6,\,2).

Figures [1](https://arxiv.org/html/2512.21149v1#S4.F1 "Figure 1 â€£ 4.2 Interpretation and numerical analysis â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty") (a)-(b) show the equilibrium policy for Î¼Y={âˆ’0.02,0.02}\mu\_{Y}=\{-0.02,0.02\}, while Figures [1](https://arxiv.org/html/2512.21149v1#S4.F1 "Figure 1 â€£ 4.2 Interpretation and numerical analysis â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty") (c)-(d) display the corresponding preference hedging demand. Other parameters in the computations are set as follows: (r,Î¼S,ÏƒS,ÏƒY,Ï,expâ¡(y0))=(0.02,â€‰0.07,â€‰0.2,â€‰0.04,â€‰0.6,â€‰2)(r,\mu\_{S},\sigma\_{S},\sigma\_{Y},\rho,\exp(y\_{0}))=(0.02,\,0.07,\,0.2,\,0.04,\,0.6,\,2).

A first observation is the asymmetry between positive and negative Î¼Y\mu\_{Y}. When Î¼Y=0.02\mu\_{Y}=0.02, the expected drift of future risk aversion is positive. For a fixed current state yy, the agent behaves more conservatively at early dates, and the equilibrium policy increases over time. The associated preference-hedging demand is positive but small and decays quickly. Its economic role is to partially counteract the conservative initial attitude, although quantitatively the effect is minor.

When Î¼Y=âˆ’0.02\mu\_{Y}=-0.02, the expected drift of future risk aversion is negative. The agent initially invests more aggressively, anticipating a less risk-averse future self, and the equilibrium policy decreases over time. Here, the hedging demand reinforces the agentâ€™s initial behavior and is larger in magnitude. A plausible explanation is that the distribution of YTY\_{T} shifts towards regions where hyÂ¯h^{\bar{y}} is more sensitive in yy, leading to a higher weighted elasticity.

It is important to emphasize that, in standard models of time-inconsistent preferences, agents may foresee changes in utility, but equilibrium strategies typically do not feature an explicit hedging motive against such preference shifts. In our setting, however, a hedging component arises endogenously from the sensitivity structure of the continuation value with respect to the preference factor YY.

Additional numerical results, including tables, are provided in Appendix [B](https://arxiv.org/html/2512.21149v1#A2 "Appendix B Additional numerical results â€£ Equilibrium investment under dynamic preference uncertainty"). The pseudocode for the computational procedure is given in Appendix [C](https://arxiv.org/html/2512.21149v1#A3 "Appendix C Pseudocodes â€£ Equilibrium investment under dynamic preference uncertainty").

## 5 Conclusion

We developed a continuous-time investment framework in which risk preferences evolve endogenously with an observable state variable. By evaluating payoffs through conditional certainty equivalents and aggregating them across future preference states, we obtained a reward functional that is inherently time-inconsistent. This required refining existing equilibrium methods for time-inconsistent control problems and deriving a new one suited to our setting.

Specializing to CRRA preferences, we let the underlying preference factor follow an arithmetic Brownian motion and define relative risk aversion as its exponential â€“yielding de facto a geometric Brownian motion for risk aversion itself. Under this specification, we showed that the equilibrium system reduces to a coupled nonlinear PIDE indexed by terminal preference states. The resulting semi-explicit equilibrium portfolio rule features a novel hedging component that captures incentives to adjust current exposure in the risky asset in anticipation of future changes in risk attitudes.

Possible avenues for future work include expanding the market environment (for instance, by introducing incompleteness), incorporating intermediate evaluation of consumption, and allowing for path dependence in the evolution of preferences over time.

## Acknowledgements

We gratefully thank the institutions at which parts of this work were carried out. Luca De Gennaro Aquino acknowledges the University of Copenhagen, the Johannes Kepler University Linz, and the University of Lausanne for their support and hospitality. Sascha Desmettre is grateful to the University of Copenhagen and to the University of Lausanne for supporting the respective research visits. Yevhen Havrylenko acknowledges the financial support from the PRIME program (<https://www.daad.de/en/studying-in-germany/scholarships/daad-funding-programmes/prime/prime-fellows-202324/>) of the German Academic Exchange Service (DAAD, <https://ror.org/039djdh30>), funded by the German Federal Ministry of Education and Research (BMBF). He further acknowledges the generous support of the University of Copenhagen and Ulm University, where parts of this research were done, and the Johannes Kepler University Linz for its hospitality during his research visit.

## Appendices

## Appendix A Proofs

### A.1 Proof of Lemma [3.1](https://arxiv.org/html/2512.21149v1#S3.Thmtheorem1 "Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")

To derive the dynamics of YY under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}} (i.e., under the condition YT=yÂ¯Y\_{T}=\overline{y}), we can directly use the theory of conditional diffusion processes; see Delyon2006.

To derive the dynamics of XÏ€X^{\pi}, again under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, we first note that, by Girsanovâ€™s theorem, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹â„™t,x,y,yÂ¯dâ€‹â„™t,x,y|â„±T=exp(\displaystyle\left.\frac{d\mathbb{P}\_{t,x,y,\overline{y}}}{d\mathbb{P}\_{t,x,y}}\right|\_{\mathcal{F}\_{T}}=\exp\Biggl( | âˆ’âˆ«tTÎ½s1dBs1âˆ’âˆ«tTÎ½s2dBs2âˆ’12âˆ«tT(Î½s1)2dsâˆ’12âˆ«tT(Î½s2)2ds),\displaystyle-\int\_{t}^{T}\nu^{1}\_{s}dB^{1}\_{s}-\int\_{t}^{T}\nu^{2}\_{s}dB^{2}\_{s}-\frac{1}{2}\int\_{t}^{T}(\nu^{1}\_{s})^{2}ds-\frac{1}{2}\int\_{t}^{T}(\nu^{2}\_{s})^{2}ds\Biggr), |  |

where Î½1\nu^{1} and Î½2\nu^{2} are square-integrable processes characterizing the change of measure. Also, the SDEs of standard Brownian motions under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}} are given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹BÂ¯s1=dâ€‹Bs1+Î½s1â€‹dâ€‹s,dâ€‹BÂ¯s2=dâ€‹Bs2+Î½s2â€‹dâ€‹s.d\overline{B}^{1}\_{s}=dB^{1}\_{s}+\nu^{1}\_{s}ds,\qquad\,d\overline{B}^{2}\_{s}=dB^{2}\_{s}+\nu^{2}\_{s}ds. |  | (A.1) |

Since conditioning on YT=yÂ¯Y\_{T}=\overline{y} influences only B1B^{1}, and B1âŸ‚B2B^{1}\perp B^{2}, we deduce that the dynamics of B2B^{2} remains unchanged under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}. Therefore, for a standard Brownian motion BÂ¯2\overline{B}^{2} under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, we have dâ€‹BÂ¯s2=dâ€‹Bs2d\overline{B}^{2}\_{s}=dB^{2}\_{s} and Î½s2=0\nu^{2}\_{s}=0, for all sâˆˆ[t,T]s\in[t,T]. To find the correct Î½1\nu\_{1}, we insert ([A.1](https://arxiv.org/html/2512.21149v1#A1.E1 "In A.1 Proof of Lemma 3.1 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) in ([3.5](https://arxiv.org/html/2512.21149v1#S3.E5 "In 2nd item â€£ Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) and get

|  |  |  |
| --- | --- | --- |
|  | dâ€‹Ys=(Î¼Yâ€‹(s,Ys)+ÏƒY2â€‹(s,Ys)â€‹âˆ‚ylnâ¡(pYâ€‹(s,Ys;T,yÂ¯))+ÏƒYâ€‹(s,Ys)â€‹Î½s1)â€‹dâ€‹s+ÏƒYâ€‹(s,Ys)â€‹dâ€‹Bs1.\displaystyle dY\_{s}=\Big(\mu\_{Y}(s,Y\_{s})+\sigma\_{Y}^{2}(s,Y\_{s})\partial\_{y}\ln\big(p\_{Y}(s,Y\_{s};{T},\overline{y})\big)+\sigma\_{Y}(s,Y\_{s})\nu^{1}\_{s}\Big)ds+\sigma\_{Y}(s,Y\_{s})dB^{1}\_{s}. |  |

As the drift must be equal to Î¼Yâ€‹(s,Ys)\mu\_{Y}(s,Y\_{s}) under â„™t,x,y\mathbb{P}\_{t,x,y}, and ÏƒYâ€‹(s,Ys)â‰ 0\sigma\_{Y}(s,Y\_{s})\neq 0 almost surely, for all sâˆˆ[t,T]s\in[t,T], we conclude that

|  |  |  |
| --- | --- | --- |
|  | Î½s1=âˆ’ÏƒYâ€‹(s,Ys)â€‹âˆ‚ylnâ¡(pYâ€‹(s,Ys;T,yÂ¯)).\nu^{1}\_{s}=-\sigma\_{Y}(s,Y\_{s})\partial\_{y}\ln\big(p\_{Y}(s,Y\_{s};{T},\overline{y})\big). |  |

Inserting ([A.1](https://arxiv.org/html/2512.21149v1#A1.E1 "In A.1 Proof of Lemma 3.1 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) in the SDE ([3.4](https://arxiv.org/html/2512.21149v1#S3.E4 "In 1st item â€£ Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) for XÏ€X^{\pi} under â„™t,x,y\mathbb{P}\_{t,x,y} and using the above form of Î½1\nu\_{1} specifying the change of measure, we obtain the SDE of XÏ€X^{\pi} under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹XsÏ€\displaystyle dX^{\pi}\_{s} | =XsÏ€â€‹(r+Ï€â€‹(s)â€‹(Î¼Sâˆ’r))â€‹dâ€‹s+XsÏ€â€‹Ï€â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹(dâ€‹BÂ¯s1âˆ’Î½s1â€‹dâ€‹s)+1âˆ’Ï2â€‹dâ€‹BÂ¯s2)\displaystyle=X^{\pi}\_{s}(r+\pi(s)(\mu\_{S}-r))ds+X^{\pi}\_{s}\pi(s)\sigma\_{S}\left(\rho\left(d\overline{B}^{1}\_{s}-\nu^{1}\_{s}ds\right)+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =XsÏ€â€‹(r+Ï€â€‹(s)â€‹(Î¼Sâˆ’r)+Ï€â€‹(s)â€‹ÏƒSâ€‹Ïâ€‹ÏƒYâ€‹(s,Ys)â€‹âˆ‚ylnâ¡(pYâ€‹(s,Ys;T,yÂ¯)))â€‹dâ€‹s\displaystyle=X^{\pi}\_{s}\Big(r+\pi(s)(\mu\_{S}-r)+\pi(s)\sigma\_{S}\rho\,\sigma\_{Y}(s,Y\_{s})\,\partial\_{y}\ln\big(p\_{Y}(s,Y\_{s};{T},\overline{y})\big)\Big)ds |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +XsÏ€â€‹Ï€â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2).\displaystyle\quad+X^{\pi}\_{s}\pi(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right). |  |

âˆ

### A.2 Proof of Theorem [3.5](https://arxiv.org/html/2512.21149v1#S3.Thmtheorem5 "Theorem 3.5 (Verification theorem). â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")

Proof of (R1). Choose an arbitrary but fixed yÂ¯âˆˆğ’´\overline{y}\in\mathcal{Y} and (t,x,y)âˆˆ[0,T)Ã—ğ’³Ã—ğ’´(t,x,y)\in[0,T)\times\mathcal{X}\times\mathcal{Y}. Let Ï€^\widehat{\pi} be the argâ€‹sup\arg\sup in ([3.11](https://arxiv.org/html/2512.21149v1#S3.E11 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), which exists by assumption (C1). Applying ItÃ´â€™s lemma to the function gyÂ¯g^{\overline{y}} (which belongs to ğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´)\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right) by assumption (C3)) and the state process (XÏ€^,Y)(X^{\widehat{\pi}},Y) under the measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, we get

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | gyÂ¯â€‹(T,XTÏ€^,YT)\displaystyle g^{\overline{y}}\left(T,X^{\widehat{\pi}}\_{T},Y\_{T}\right) | =gyÂ¯â€‹(t,XtÏ€^,Yt)+âˆ«tTğ’ŸÂ¯Ï€^â€‹gyÂ¯â€‹(s,XsÏ€^,Ys)â€‹ğ‘‘s\displaystyle=g^{\overline{y}}\left(t,X^{\widehat{\pi}}\_{t},Y\_{t}\right)+\int\limits\_{t}^{T}\overline{\mathcal{D}}^{\widehat{\pi}}g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\,ds |  | (A.2) |
|  |  | +âˆ«tTâˆ‚xgyÂ¯â€‹(s,XsÏ€^,Ys)â€‹Ï€^â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2)\displaystyle\quad+\int\limits\_{t}^{T}\partial\_{x}g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\widehat{\pi}(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right) |  |
|  |  | +âˆ«tTâˆ‚ygyÂ¯â€‹(s,XsÏ€^,Ys)â€‹ÏƒYâ€‹dâ€‹BÂ¯s1.\displaystyle\quad+\int\limits\_{t}^{T}\partial\_{y}g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\sigma\_{Y}d\overline{B}^{1}\_{s}. |  |

Taking the expectation on both sides of ([A.2](https://arxiv.org/html/2512.21149v1#A1.E2 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")), and using the fact that gyÂ¯â€‹(t,x,y)g^{\overline{y}}\left(t,x,y\right) satisfies ([Sâ€‹2S2](https://arxiv.org/html/2512.21149v1#S3.Ex26 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) by assumption (C2), as well as gyÂ¯â€‹(t,x,y)âˆˆâ„’2â€‹(XÏ€^,Y)g^{\overline{y}}\left(t,x,y\right)\in\mathcal{L}^{2}\left(X^{\widehat{\pi}},Y\right) by assumption (C4), gives

|  |  |  |
| --- | --- | --- |
|  | ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(T,XTÏ€^,YT)]=ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(t,XtÏ€^,Yt)].\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(T,X^{\widehat{\pi}}\_{T},Y\_{T}\right)\right]=\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t,X^{\widehat{\pi}}\_{t},Y\_{t}\right)\right]. |  |

Thus, since gyÂ¯â€‹(T,x,y)g^{\overline{y}}\left(T,x,y\right) solves ([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) (again by (C2)), we have

|  |  |  |
| --- | --- | --- |
|  | gyÂ¯â€‹(t,x,y)=ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(T,XTÏ€^,YT)]=ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€^)],g^{\overline{y}}\left(t,x,y\right)=\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(T,X^{\widehat{\pi}}\_{T},Y\_{T}\right)\right]=\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}\left(X^{\widehat{\pi}}\_{T}\right)\right], |  |

which proves (R1).

Proof of (R2). Plugging Ï€^\widehat{\pi} in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | 0\displaystyle 0 | =ğ’ŸÏ€^â€‹Vâ€‹(t,x,y)âˆ’ğ’ŸÏ€^â€‹âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle=\mathcal{D}^{\widehat{\pi}}V(t,x,y)-\mathcal{D}^{\widehat{\pi}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +âˆ«ğ’´(Ï†yÂ¯)â€²â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ’ŸÂ¯Ï€^â€‹gyÂ¯â€‹(t,x,y)â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y).\displaystyle\qquad\qquad\qquad+\int\_{\mathcal{Y}}\left(\varphi^{\overline{y}}\right)^{\prime}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,\overline{\mathcal{D}}^{\widehat{\pi}}g^{\overline{y}}\left(t,x,y\right)\,dF\_{Y\_{T}}(\overline{y};t,y). |  |

Since ([Sâ€‹2S2](https://arxiv.org/html/2512.21149v1#S3.Ex26 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) holds, the last term in the above PDE is zero. Thus,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’ŸÏ€^â€‹Vâ€‹(t,x,y)=ğ’ŸÏ€^â€‹âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y).\mathcal{D}^{\widehat{\pi}}V(t,x,y)=\mathcal{D}^{\widehat{\pi}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)dF\_{Y\_{T}}(\overline{y};t,y). |  | (A.3) |

Due to (C3), Vâˆˆğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´)V\in\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right). Applying ItÃ´â€™s lemma to Vâ€‹(t,XtÏ€^,Yt)V(t,X^{\widehat{\pi}}\_{t},Y\_{t}) on [t,T][t,T] under the measure â„™t,x,y\mathbb{P}\_{t,x,y}, and then taking the expectation on both sides of the equality, we derive that

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼t,x,y\displaystyle\mathbb{E}\_{t,x,y} | [Vâ€‹(T,XTÏ€^,YT)]=Vâ€‹(t,x,y)+ğ”¼t,x,yâ€‹[âˆ«tTğ’ŸÏ€^â€‹Vâ€‹(s,XsÏ€^,Ys)â€‹ğ‘‘s]\displaystyle\left[V(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right]=V(t,x,y)+\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\mathcal{D}^{\widehat{\pi}}V(s,X^{\widehat{\pi}}\_{s},Y\_{s})\,ds\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +ğ”¼t,x,yâ€‹[âˆ«tTâˆ‚xVâ€‹(s,XsÏ€^,Ys)â€‹Ï€^â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹Bs1+1âˆ’Ï2â€‹dâ€‹Bs2)]\displaystyle+\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\partial\_{x}V(s,X^{\widehat{\pi}}\_{s},Y\_{s})\widehat{\pi}(s)\sigma\_{S}\left(\rho dB^{1}\_{s}+\sqrt{1-\rho^{2}}dB^{2}\_{s}\right)\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +ğ”¼t,x,yâ€‹[âˆ«tTâˆ‚yVâ€‹(s,XsÏ€^,Ys)â€‹ÏƒYâ€‹dâ€‹Bs1]\displaystyle+\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\partial\_{y}V(s,X^{\widehat{\pi}}\_{s},Y\_{s})\sigma\_{Y}dB^{1}\_{s}\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(Câ€‹4)Vâ€‹(t,x,y)+ğ”¼t,x,yâ€‹[âˆ«tTğ’ŸÏ€^â€‹Vâ€‹(s,XsÏ€^,Ys)â€‹ğ‘‘s]\displaystyle\mathrel{{\mathop{=}\limits^{(C4)}}}V(t,x,y)+\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\mathcal{D}^{\widehat{\pi}}V(s,X^{\widehat{\pi}}\_{s},Y\_{s})\,ds\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =([A.3](https://arxiv.org/html/2512.21149v1#A1.E3 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty"))Vâ€‹(t,x,y)+ğ”¼t,x,yâ€‹[âˆ«tTğ’ŸÏ€^â€‹(âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(s,XsÏ€^,Ys))â€‹ğ‘‘FYTâ€‹(yÂ¯;s,Ys))â€‹ğ‘‘s].\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:equal\_terms\_in\_HJB\_PDE}}}}V(t,x,y)+\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\mathcal{D}^{\widehat{\pi}}\left(\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\right)dF\_{Y\_{T}}\left(\overline{y};s,Y\_{s}\right)\right)ds\right]. |  |

Using the notation for Gâˆâ€‹(t,x,y)G\_{\infty}(t,x,y) in ([3.13](https://arxiv.org/html/2512.21149v1#S3.E13 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")),
we consider the process

|  |  |  |
| --- | --- | --- |
|  | Gâˆâ€‹(s,XsÏ€^,Ys)=âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(s,XsÏ€^,Ys))â€‹ğ‘‘FYTâ€‹(yÂ¯;s,Ys).G\_{\infty}(s,X^{\widehat{\pi}}\_{s},Y\_{s})=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\right)dF\_{Y\_{T}}\left(\overline{y};s,Y\_{s}\right). |  |

Due to (C3), Gâˆâˆˆğ’1,2,2â€‹(ğ’¯Ã—ğ’³Ã—ğ’´)G\_{\infty}\in\mathcal{C}^{1,2,2}\left(\mathcal{T}\times\mathcal{X}\times\mathcal{Y}\right). Applying ItÃ´â€™s lemma to GâˆG\_{\infty} under â„™t,x,y\mathbb{P}\_{t,x,y}, taking the expectation and using that Gâˆâˆˆâ„’2â€‹(XÏ€^,Y)G\_{\infty}\in\mathcal{L}^{2}\left(X^{\widehat{\pi}},Y\right) (again by (C4)), we get

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼t,x,y\displaystyle\mathbb{E}\_{t,x,y} | [Gâˆâ€‹(T,XTÏ€^,YT)]âˆ’ğ”¼t,x,yâ€‹[Gâˆâ€‹(t,XtÏ€^,Yt)]\displaystyle\left[G\_{\infty}(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right]-\mathbb{E}\_{t,x,y}\left[G\_{\infty}(t,X^{\widehat{\pi}}\_{t},Y\_{t})\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =ğ”¼t,x,yâ€‹[âˆ«tTğ’ŸÏ€^â€‹(âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(s,XsÏ€^,Ys))â€‹ğ‘‘FYTâ€‹(yÂ¯;s,Ys))â€‹ğ‘‘s].\displaystyle=\mathbb{E}\_{t,x,y}\left[\int\limits\_{t}^{T}\mathcal{D}^{\widehat{\pi}}\left(\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(s,X^{\widehat{\pi}}\_{s},Y\_{s}\right)\right)dF\_{Y\_{T}}\left(\overline{y};s,Y\_{s}\right)\right)ds\right]. |  |

Therefore,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼t,x,yâ€‹[Vâ€‹(T,XTÏ€^,YT)]\displaystyle\mathbb{E}\_{t,x,y}\left[V(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right] | =Vâ€‹(t,x,y)+ğ”¼t,x,yâ€‹[Gâˆâ€‹(T,XTÏ€^,YT)]âˆ’Gâˆâ€‹(t,XtÏ€^,Yt).\displaystyle=V(t,x,y)+\mathbb{E}\_{t,x,y}\left[G\_{\infty}(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right]-G\_{\infty}(t,X^{\widehat{\pi}}\_{t},Y\_{t}). |  |

Due to ([Sâ€‹3S3](https://arxiv.org/html/2512.21149v1#S3.Ex27 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) and ([Sâ€‹4S4](https://arxiv.org/html/2512.21149v1#S3.Ex28 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")),
ğ”¼t,x,yâ€‹[Vâ€‹(T,XTÏ€^,YT)]=ğ”¼t,x,yâ€‹[Gâˆâ€‹(T,XTÏ€^,YT)]\mathbb{E}\_{t,x,y}\left[V(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right]=\mathbb{E}\_{t,x,y}\left[G\_{\infty}(T,X^{\widehat{\pi}}\_{T},Y\_{T})\right]. Thus,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Vâ€‹(t,x,y)\displaystyle V(t,x,y) | =Gâˆâ€‹(t,x,y)=âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle=G\_{\infty}(t,x,y)=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)dF\_{Y\_{T}}\left(\overline{y};t,y\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(Râ€‹1)âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€^)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle\mathrel{{\mathop{=}\limits^{(R1)}}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}\left(X^{\widehat{\pi}}\_{T}\right)\right]\right)dF\_{Y\_{T}}\left(\overline{y};t,y\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =ğ”¼t,x,yâ€‹[vâˆ˜(uÎ³â€‹(YT))âˆ’1â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(YT)â€‹(XTÏ€)])]\displaystyle=\mathbb{E}\_{t,x,y}\left[v\circ\left(u^{\gamma(Y\_{T})}\right)^{-1}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(Y\_{T})}(X^{\pi}\_{T})\right]\right)\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =([2.3](https://arxiv.org/html/2512.21149v1#S2.E3 "In 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"))JÏ€â€‹(t,x,y),\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:reward\_functional}}}}J^{\pi}(t,x,y), |  |

which proves (R2).

Proof of (R3). First, we derive a recursive representation of gyÂ¯â€‹(t,x,y)g^{\overline{y}}\left(t,x,y\right) and JÏ€Î´â€‹(t,x,y)J^{\pi\_{\delta}}(t,x,y) for an arbitrary but fixed Ï€Î´\pi\_{\delta}. Similarly to ([A.2](https://arxiv.org/html/2512.21149v1#A1.E2 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")), under the measure â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, we can apply ItÃ´â€™s lemma to the process gyÂ¯â€‹(s,XsÏ€Î´,Ys)g^{\overline{y}}\left(s,X^{\pi\_{\delta}}\_{s},Y\_{s}\right) on the time interval [t+Î´,T][t+\delta,T]:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | gyÂ¯â€‹(T,XTÏ€Î´,YT)\displaystyle g^{\overline{y}}\left(T,X^{\pi\_{\delta}}\_{T},Y\_{T}\right) | =gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))+âˆ«t+Î´TDÂ¯Ï€Î´â€‹gyÂ¯â€‹(s,XsÏ€Î´,Ys)â€‹ğ‘‘s\displaystyle=g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)+\int\limits\_{t+\delta}^{T}\overline{D}^{\pi\_{\delta}}g^{\overline{y}}\left(s,X^{\pi\_{\delta}}\_{s},Y\_{s}\right)\,ds |  | (A.4) |
|  |  | +âˆ«t+Î´Tâˆ‚xgyÂ¯â€‹(s,XsÏ€Î´,Ys)â€‹Ï€Î´â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2)\displaystyle\quad+\int\limits\_{t+\delta}^{T}\partial\_{x}g^{\overline{y}}\left(s,X^{\pi\_{\delta}}\_{s},Y\_{s}\right)\pi\_{\delta}(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right) |  |
|  |  | +âˆ«t+Î´Tâˆ‚ygyÂ¯â€‹(s,XsÏ€Î´,Ys)â€‹ÏƒYâ€‹dâ€‹BÂ¯s1.\displaystyle\quad+\int\limits\_{t+\delta}^{T}\partial\_{y}g^{\overline{y}}\left(s,X^{\pi\_{\delta}}\_{s},Y\_{s}\right)\sigma\_{Y}d\overline{B}^{1}\_{s}. |  |

Taking the expectation and using Ï€Î´â€‹(s)=Ï€^â€‹(s)\pi\_{\delta}(s)=\widehat{\pi}(s) , for every sâˆˆ[t+Î´,T]s\in[t+\delta,T], together with assumptions (C2) and (C4), we get

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]=ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)].\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]=\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right]. |  | (A.5) |

Furthermore, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€Î´â€‹(t,x,y)\displaystyle J^{\pi\_{\delta}}(t,x,y) | =([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:reward\_functional\_explicit}}}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  | (A.6) |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +Vâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))âˆ’JÏ€Î´â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´)),\displaystyle\quad+V(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))-J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)), |  |

where the difference between the last two terms is zero due to Ï€Î´â€‹(s)=Ï€^â€‹(s),sâˆˆ[t+Î´,T]\pi\_{\delta}(s)=\widehat{\pi}(s),s\in[t+\delta,T]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€Î´â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))\displaystyle J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)) | =JÏ€^â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))\displaystyle\;=J^{\widehat{\pi}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(R2)Vâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´)).\displaystyle\mathrel{{\mathop{=}\limits^{\textit{(R2)}}}}V(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)). |  |

Taking the expectation under the measure â„™t,x,y\mathbb{P}\_{t,x,y} in ([A.6](https://arxiv.org/html/2512.21149v1#A1.E6 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) yields

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | JÏ€Î´â€‹(t,x,y)\displaystyle J^{\pi\_{\delta}}(t,x,y) | =âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle=\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  | (A.7) |
|  |  | +ğ”¼t,x,yâ€‹[Vâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]\displaystyle\quad+\mathbb{E}\_{t,x,y}\left[V(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right] |  |
|  |  | âˆ’ğ”¼t,x,yâ€‹[JÏ€Î´â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))].\displaystyle\quad-\mathbb{E}\_{t,x,y}\left[J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right]. |  |

Therefore,

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€^â€‹(t,x,y)âˆ’JÏ€Î´â€‹(t,x,y)\displaystyle J^{\widehat{\pi}}(t,x,y)-J^{\pi\_{\delta}}(t,x,y) | =([A.7](https://arxiv.org/html/2512.21149v1#A1.E7 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty"))+(R2)Vâ€‹(t,x,y)âˆ’ğ”¼t,x,yâ€‹[Vâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:R3\_proof\_J\_pih\_recursion\_after\_E}+\textit{(R2)}}}}V(t,x,y)-\mathbb{E}\_{t,x,y}\left[V(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle\quad-\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +ğ”¼t,x,yâ€‹[JÏ€Î´â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]\displaystyle\quad+\mathbb{E}\_{t,x,y}\left[J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ’(ğ”¼t,x,yâ€‹[Vâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]âˆ’Vâ€‹(t,x,y))\displaystyle=-\left(\mathbb{E}\_{t,x,y}\left[V(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right]-V(t,x,y)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’(âˆ«ğ’´Ï†yÂ¯(ğ”¼t,x,y,yÂ¯[gyÂ¯(t+Î´,XÏ€Î´(t+Î´),Y(t+Î´))])dFYT(yÂ¯;t,y)\displaystyle\quad-\Bigl(\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’âˆ«ğ’´Ï†yÂ¯(gyÂ¯(t,x,y))dFYT(yÂ¯;t,y))\displaystyle\quad\quad-\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,dF\_{Y\_{T}}(\overline{y};t,y)\Bigr) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +(ğ”¼t,x,y[JÏ€Î´(t+Î´,XÏ€Î´(t+Î´),Y(t+Î´))]\displaystyle\quad+\Bigl(\mathbb{E}\_{t,x,y}\left[J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’âˆ«ğ’´Ï†yÂ¯(gyÂ¯(t,x,y))dFYT(yÂ¯;t,y))\displaystyle\quad\quad-\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,dF\_{Y\_{T}}(\overline{y};t,y)\Bigr) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =:âˆ’Î”1(Î´)âˆ’Î”2(Î´)+Î”3(Î´),\displaystyle=:-\Delta\_{1}(\delta)-\Delta\_{2}(\delta)+\Delta\_{3}(\delta), |  | (A.8) |

where in the second equality we add and subtract the same term and use ([A.5](https://arxiv.org/html/2512.21149v1#A1.E5 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) for ğ”¼t,x,y,yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€Î´)]\mathbb{E}\_{t,x,y,\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi\_{\delta}}\_{T}\right)\right].

To prove that Ï€^\widehat{\pi} is an equilibrium control according to Definition [2.4](https://arxiv.org/html/2512.21149v1#S2.Thmtheorem4 "Definition 2.4 (Equilibrium control law; cf. Def. 15.3 in BjoerkKhapkoMurgoci2021:TICT). â€£ 2 Problem formulation â€£ Equilibrium investment under dynamic preference uncertainty"), we need to compute the following limit:

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim infÎ´â†“0\displaystyle\liminf\_{\delta\downarrow 0} | JÏ€^â€‹(t,x,y)âˆ’JÏ€Î´â€‹(t,x,y)Î´=([A.8](https://arxiv.org/html/2512.21149v1#A1.E8 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty"))lim infÎ´â†“01Î´â€‹(âˆ’Î”1â€‹(Î´)âˆ’Î”2â€‹(Î´)+Î”3â€‹(Î´))\displaystyle\frac{J^{\hat{\pi}}(t,x,y)-J^{\pi\_{\delta}}(t,x,y)}{\delta}\mathrel{{\mathop{=}\limits^{\eqref{eq:R3\_proof\_def\_delta\_terms}}}}\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\left(-\Delta\_{1}(\delta)-\Delta\_{2}(\delta)+\Delta\_{3}(\delta)\right) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =âˆ’(lim supÎ´â†“01Î´â€‹Î”1â€‹(Î´)+lim supÎ´â†“01Î´â€‹Î”2â€‹(Î´)âˆ’lim infÎ´â†“01Î´â€‹Î”3â€‹(Î´)),\displaystyle=-\left(\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{1}(\delta)+\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{2}(\delta)-\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{3}(\delta)\right), |  | (A.9) |

where we use the linearity of the limit and the relation between lim sup\limsup and lim inf\liminf.

Using standard arguments, we can show that

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim supÎ´â†“01Î´â€‹Î”1â€‹(Î´)=ğ’ŸÏ€â€‹Vâ€‹(t,x,y).\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{1}(\delta)=\mathcal{D}^{\pi}V(t,x,y). |  | (A.10) |

Furthermore, we get

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim supÎ´â†“0\displaystyle\limsup\_{\delta\downarrow 0} | 1Î´Î”2(Î´)=lim supÎ´â†“01Î´(âˆ«ğ’´Ï†yÂ¯(ğ”¼t,x,y,yÂ¯[gyÂ¯(t+Î´,XÏ€Î´(t+Î´),Y(t+Î´))])dFYT(yÂ¯;t,y)\displaystyle\frac{1}{\delta}\Delta\_{2}(\delta)=\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Biggl(\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’âˆ«ğ’´Ï†yÂ¯(gyÂ¯(t,x,y))dFYT(yÂ¯;t,y))\displaystyle\quad\quad-\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,dF\_{Y\_{T}}(\overline{y};t,y)\Biggr) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ«ğ’´lim supÎ´â†“01Î´(Ï†yÂ¯(ğ”¼t,x,y,yÂ¯[gyÂ¯(t+Î´,XÏ€Î´(t+Î´),Y(t+Î´))])\displaystyle=\int\_{\mathcal{Y}}\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Biggl(\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’Ï†yÂ¯(gyÂ¯(t,x,y)))dFYT(yÂ¯;t,y)\displaystyle\quad\quad-\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)\Biggr)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ«ğ’´lim supÎ´â†“0(Ï†yÂ¯â€‹(ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))])âˆ’Ï†yÂ¯â€‹(gyÂ¯â€‹(t,x,y))ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]âˆ’gyÂ¯â€‹(t,x,y)\displaystyle=\int\_{\mathcal{Y}}\limsup\_{\delta\downarrow 0}\Biggl(\frac{\varphi^{\overline{y}}\left(\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]\right)-\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)}{\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]-g^{\overline{y}}\left(t,x,y\right)} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‹…ğ”¼t,x,y,yÂ¯â€‹[gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]âˆ’gyÂ¯â€‹(t,x,y)Î´)dFYT(yÂ¯;t,y)\displaystyle\quad\quad\cdot\frac{\mathbb{E}\_{t,x,y,\overline{y}}\left[g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right]-g^{\overline{y}}\left(t,x,y\right)}{\delta}\Biggr)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ«ğ’´(Ï†yÂ¯)â€²â€‹(gyÂ¯â€‹(t,x,y))â€‹ğ’ŸÂ¯Ï€â€‹gyÂ¯â€‹(t,x,y)â€‹ğ‘‘FYTâ€‹(yÂ¯;t,y)\displaystyle=\int\_{\mathcal{Y}}\left(\varphi^{\overline{y}}\right)^{\prime}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,\overline{\mathcal{D}}^{\pi}g^{\overline{y}}\left(t,x,y\right)\,dF\_{Y\_{T}}(\overline{y};t,y) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =([3.14](https://arxiv.org/html/2512.21149v1#S3.E14 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))â„‹Â¯Ï€â€‹((gyÂ¯)yÂ¯âˆˆğ’´)â€‹(t,x,y),\displaystyle\hskip-5.69046pt\mathrel{{\mathop{=}\limits^{\eqref{eq:barH\_pi}}}}\overline{\mathcal{H}}^{\pi}\left(\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right)(t,x,y), |  | (A.11) |

where in the second equality we use regularity conditions (C4) to exchange lim inf\liminf and integral, in the third equality we multiply and divide by the same non-zero term, and in the fourth equality we use the definition of a derivative for the first term, the definition of the differential operator under â„™t,x,y,yÂ¯\mathbb{P}\_{t,x,y,\overline{y}}, the assumption that Ï†yÂ¯\varphi^{\overline{y}} is differentiable, the condition that gyÂ¯âˆˆâ„’Â¯2â€‹(XÏ€,Y)g^{\overline{y}}\in\overline{\mathcal{L}}^{2}(X^{\pi},Y) as per (C4), and the product rule for limits.

Finally, observing that

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏ€Î´\displaystyle J^{\pi\_{\delta}} | (t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))\displaystyle(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =([3.2](https://arxiv.org/html/2512.21149v1#S3.E2 "In 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))âˆ«ğ’´Ï†yÂ¯â€‹(ğ”¼t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´),yÂ¯â€‹[uÎ³â€‹(yÂ¯)â€‹(XTÏ€)])â€‹ğ‘‘FYTâ€‹(yÂ¯;t+Î´,Yâ€‹(t+Î´))\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:reward\_functional\_explicit}}}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(\mathbb{E}\_{t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta),\overline{y}}\left[u^{\gamma(\overline{y})}\left(X^{\pi}\_{T}\right)\right]\right)\,dF\_{Y\_{T}}(\overline{y};t+\delta,Y(t+\delta)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(Râ€‹1)âˆ«ğ’´Ï†yÂ¯â€‹(gyÂ¯â€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´)))â€‹ğ‘‘FYTâ€‹(yÂ¯;t+Î´,Yâ€‹(t+Î´))\displaystyle\mathrel{{\mathop{=}\limits^{(R1)}}}\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)\right)\right)\,dF\_{Y\_{T}}(\overline{y};t+\delta,Y(t+\delta)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =([3.13](https://arxiv.org/html/2512.21149v1#S3.E13 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))Gâˆâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´)),\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:G\_infty}}}}G\_{\infty}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta)), |  |

we compute

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim infÎ´â†“01Î´â€‹Î”3â€‹(Î´)\displaystyle\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{3}(\delta) | =lim infÎ´â†“01Î´(ğ”¼t,x,y[JÏ€Î´(t+Î´,XÏ€Î´(t+Î´),Y(t+Î´))]\displaystyle=\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\Biggl(\mathbb{E}\_{t,x,y}\left[J^{\pi\_{\delta}}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ’âˆ«ğ’´Ï†yÂ¯(gyÂ¯(t,x,y))dFYT(yÂ¯;t,y))\displaystyle\quad\quad-\int\_{\mathcal{Y}}\varphi^{\overline{y}}\left(g^{\overline{y}}\left(t,x,y\right)\right)\,dF\_{Y\_{T}}(\overline{y};t,y)\Biggr) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =([3.13](https://arxiv.org/html/2512.21149v1#S3.E13 "In 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))lim infÎ´â†“01Î´â€‹(ğ”¼t,x,yâ€‹[Gâˆâ€‹(t+Î´,XÏ€Î´â€‹(t+Î´),Yâ€‹(t+Î´))]âˆ’Gâˆâ€‹(t,x,y))\displaystyle\mathrel{{\mathop{=}\limits^{\eqref{eq:G\_infty}}}}\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\Biggl(\mathbb{E}\_{t,x,y}\left[G\_{\infty}(t+\delta,X^{\pi\_{\delta}}(t+\delta),Y(t+\delta))\right]-G\_{\infty}(t,x,y)\Biggr) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =ğ’ŸÏ€â€‹Gâˆâ€‹(t,x,y).\displaystyle\mathrel{{\mathop{=}\limits}}\mathcal{D}^{\pi}G\_{\infty}(t,x,y). |  | (A.12) |

Using ([A.8](https://arxiv.org/html/2512.21149v1#A1.E8 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) and the convergence results in ([A.10](https://arxiv.org/html/2512.21149v1#A1.E10 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty"))-([A.12](https://arxiv.org/html/2512.21149v1#A1.E12 "In A.2 Proof of Theorem 3.5 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")), we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | lim infÎ´â†“0\displaystyle\liminf\_{\delta\downarrow 0}\, | JÏ€^â€‹(t,x,y)âˆ’JÏ€Î´â€‹(t,x,y)Î´\displaystyle\frac{J^{\hat{\pi}}(t,x,y)-J^{\pi\_{\delta}}(t,x,y)}{\delta} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ’(lim supÎ´â†“01Î´â€‹Î”1â€‹(Î´)+lim supÎ´â†“01Î´â€‹Î”2â€‹(Î´)âˆ’lim infÎ´â†“01Î´â€‹Î”3â€‹(Î´))\displaystyle=-\left(\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{1}(\delta)+\limsup\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{2}(\delta)-\liminf\_{\delta\downarrow 0}\frac{1}{\delta}\Delta\_{3}(\delta)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ’(ğ’ŸÏ€â€‹Vâ€‹(t,x,y)+â„‹Â¯Ï€â€‹((gyÂ¯)yÂ¯âˆˆğ’´)â€‹(t,x,y)âˆ’ğ’ŸÏ€â€‹Gâˆâ€‹(t,x,y))\displaystyle=-\left(\mathcal{D}^{\pi}V(t,x,y)+\overline{\mathcal{H}}^{\pi}\left(\left(g^{\overline{y}}\right)\_{\overline{y}\in\mathcal{Y}}\right)(t,x,y)-\mathcal{D}^{\pi}G\_{\infty}(t,x,y)\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¥0,\displaystyle\geq 0, |  |

where the inequality follows from the fact that Ï€^\widehat{\pi} realizes the supremum in ([Sâ€‹1S1](https://arxiv.org/html/2512.21149v1#S3.Ex25 "In The extended HJB system. â€£ 3.2 Heuristic derivation of the eHJB â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) as per (C1). Therefore, Ï€^\widehat{\pi} is an equilibrium control, which proves (R3).

Proof of (R4).
We conclude that Vâ€‹(t,x,y)V(t,x,y) is indeed the equilibrium value function, i.e., V^â€‹(t,x,y)=Vâ€‹(t,x,y)\widehat{V}(t,x,y)=V(t,x,y), since Vâ€‹(t,x,y)=JÏ€^â€‹(t,x,y)V(t,x,y)=J^{\widehat{\pi}}(t,x,y) by (R2) and Ï€^\widehat{\pi} is an equilibrium control by (R3). This proves (R4) and completes the proof of the verification theorem. âˆ

### A.3 Proof of Corollary [4.1](https://arxiv.org/html/2512.21149v1#S4.Thmtheorem1 "Corollary 4.1. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")

First, it is straightforward to verify that

|  |  |  |
| --- | --- | --- |
|  | fYTâ€‹(yÂ¯;t,y)=12â€‹Ï€â€‹ÏƒY2â€‹(Tâˆ’t)â€‹expâ¡(âˆ’(yÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t))22â€‹ÏƒY2â€‹(Tâˆ’t)).f\_{Y\_{T}}(\overline{y};t,y)=\frac{1}{\sqrt{2\uppi\sigma\_{Y}^{2}(T-t)}}\exp\left(-\frac{\left(\overline{y}-y-\mu\_{Y}(T-t)\right)^{2}}{2\sigma\_{Y}^{2}(T-t)}\right). |  |

(Note that Ï€\uppi in the conditional PDF above denotes the mathematical constant pi, so it should not be confused with the control (investment strategy) denoted by Ï€\pi.)

Thus, for YT|Ys=yY\_{T}|Y\_{s}=y, we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‚ylnâ¡(pYâ€‹(s,y;T,yÂ¯))=âˆ‚ylnâ¡(12â€‹Ï€â€‹ÏƒY2â€‹(Tâˆ’s)â€‹expâ¡(âˆ’(yÂ¯âˆ’(y+Î¼Yâ€‹(Tâˆ’s)))22â€‹ÏƒY2â€‹(Tâˆ’s)))=âˆ’yÂ¯âˆ’(y+Î¼Yâ€‹(Tâˆ’s))ÏƒY2â€‹(Tâˆ’s).\begin{split}\partial\_{y}\ln\big(p\_{Y}(s,y;T,\overline{y})\big)&=\partial\_{y}\ln\left(\frac{1}{\sqrt{2\uppi\sigma\_{Y}^{2}(T-s)}}\exp\left(-\frac{\left(\overline{y}-(y+\mu\_{Y}(T-s))\right)^{2}}{2\sigma\_{Y}^{2}(T-s)}\right)\right)\\ &=-\frac{\overline{y}-(y+\mu\_{Y}(T-s))}{\sigma\_{Y}^{2}(T-s)}.\end{split} |  | (A.13) |

Plugging this result in ([3.5](https://arxiv.org/html/2512.21149v1#S3.E5 "In 2nd item â€£ Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), we obtain the SDE for (Ys)sâˆˆ[t,T)\left(Y\_{s}\right)\_{s\in[t,T)} under the condition YT=yÂ¯Y\_{T}=\overline{y}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Ys\displaystyle dY\_{s} | =(Î¼Yâ€‹dâ€‹s+ÏƒY2â€‹(âˆ’yÂ¯âˆ’(y+Î¼Yâ€‹(Tâˆ’s))ÏƒY2â€‹(Tâˆ’s)))â€‹dâ€‹s+ÏƒYâ€‹dâ€‹Bs1\displaystyle=\left(\mu\_{Y}ds+\sigma\_{Y}^{2}\left(-\frac{\overline{y}-(y+\mu\_{Y}(T-s))}{\sigma\_{Y}^{2}(T-s)}\right)\right)ds+\sigma\_{Y}dB^{1}\_{s} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =yÂ¯âˆ’YsTâˆ’sâ€‹dâ€‹s+ÏƒYâ€‹dâ€‹BÂ¯s1,\displaystyle=\frac{\overline{y}-Y\_{s}}{T-s}ds+\sigma\_{Y}d\overline{B}^{1}\_{s}, |  |

with Yt=yY\_{t}=y.

Similarly, inserting ([A.13](https://arxiv.org/html/2512.21149v1#A1.E13 "In A.3 Proof of Corollary 4.1 â€£ Appendix A Proofs â€£ Equilibrium investment under dynamic preference uncertainty")) into ([3.4](https://arxiv.org/html/2512.21149v1#S3.E4 "In 1st item â€£ Lemma 3.1. â€£ 3.1 Preliminary definitions and state process dynamics under conditional measures â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")), using that ÏƒYâ€‹(s,YS)=ÏƒY\sigma\_{Y}(s,Y\_{S})=\sigma\_{Y}, and simplifying, we obtain the SDE for (XÏ€)sâˆˆ[t,T)(X^{\pi})\_{s\in[t,T)}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹XsÏ€\displaystyle dX^{\pi}\_{s} | =XsÏ€â€‹(r+Ï€â€‹(s)â€‹(Î¼Sâˆ’r)+Ï€â€‹(s)â€‹Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’Ysâˆ’Î¼Yâ€‹(Tâˆ’s)Tâˆ’s)â€‹dâ€‹s\displaystyle=X^{\pi}\_{s}\left(r+\pi(s)(\mu\_{S}-r)+\pi(s)\rho\frac{\sigma\_{S}}{\sigma\_{Y}}\frac{\overline{y}-Y\_{s}-\mu\_{Y}(T-s)}{T-s}\right)ds |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +XsÏ€â€‹Ï€â€‹(s)â€‹ÏƒSâ€‹(Ïâ€‹dâ€‹BÂ¯s1+1âˆ’Ï2â€‹dâ€‹BÂ¯s2),\displaystyle\qquad+X^{\pi}\_{s}\pi(s)\sigma\_{S}\left(\rho d\overline{B}^{1}\_{s}+\sqrt{1-\rho^{2}}d\overline{B}^{2}\_{s}\right), |  |

with XtÏ€=xX^{\pi}\_{t}=x and XTÏ€=limtâ†’TXtÏ€X^{\pi}\_{T}=\lim\_{t\to T}X^{\pi}\_{t}.
âˆ

### A.4 Proof of Proposition [4.2](https://arxiv.org/html/2512.21149v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")

Recall our choice of the CRRA specification uyÂ¯â€‹(x)=11âˆ’Î³â€‹(yÂ¯)â€‹x1âˆ’Î³â€‹(yÂ¯)u^{\overline{y}}(x)=\frac{1}{1-\gamma(\overline{y})}x^{1-\gamma(\overline{y})} and the aggregator vâ€‹(x)=lnâ¡(x)v(x)=\ln(x). The inverse utility and certainty equivalent transform then satisfy

|  |  |  |  |
| --- | --- | --- | --- |
|  | (uyÂ¯)âˆ’1â€‹(x)\displaystyle\left(u^{\overline{y}}\right)^{-1}(x) | =((1âˆ’Î³â€‹(yÂ¯))â€‹x)11âˆ’Î³â€‹(yÂ¯),\displaystyle=\big(\left(1-\gamma(\overline{y})\right)x\big)^{\frac{1}{1-\gamma(\overline{y})}}, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï†yÂ¯â€‹(x)\displaystyle\varphi^{\overline{y}}(x) | =lnâ¡(((1âˆ’Î³â€‹(yÂ¯))â€‹x)11âˆ’Î³â€‹(yÂ¯))=11âˆ’Î³â€‹(yÂ¯)â€‹(lnâ¡(1âˆ’Î³â€‹(yÂ¯))+lnâ¡(x)),\displaystyle=\ln\left(\big(\left(1-\gamma(\overline{y})\right)x\big)^{\frac{1}{1-\gamma(\overline{y})}}\right)=\frac{1}{1-\gamma(\overline{y})}\big(\ln\left(1-\gamma(\overline{y})\right)+\ln(x)\big), |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | (Ï†yÂ¯)â€²â€‹(x)\displaystyle\left(\varphi^{\overline{y}}\right)^{\prime}(x) | =1xâ€‹(1âˆ’Î³â€‹(yÂ¯)).\displaystyle=\frac{1}{x\left(1-\gamma(\overline{y})\right)}. |  |

Using these expressions and the evolution of (XÏ€,Y)(X^{\pi},Y), the in ([Sâ€‹1Â¯\overline{S1}](https://arxiv.org/html/2512.21149v1#S3.Ex47 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty"))-([Sâ€‹3Â¯\overline{S3}](https://arxiv.org/html/2512.21149v1#S3.Ex49 "In Corollary 3.6. â€£ 3.3 Verification results â€£ 3 Derivation of equilibrium controls â€£ Equilibrium investment under dynamic preference uncertainty")) takes the form

|  |  |  |
| --- | --- | --- |
|  | 0=supÏ€âˆ«ğ’´1gyÂ¯â€‹(t,x,y)â€‹(1âˆ’Î³â€‹(yÂ¯))(âˆ‚tgyÂ¯(t,x,y)+xâ€‹(r+Ï€â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)Tâˆ’t))â€‹âˆ‚xgyÂ¯â€‹(t,x,y)+yÂ¯âˆ’yTâˆ’tâ€‹âˆ‚ygyÂ¯â€‹(t,x,y)+12â€‹x2â€‹Ï€2â€‹ÏƒS2â€‹âˆ‚xâ€‹xgyÂ¯â€‹(t,x,y)+12â€‹ÏƒY2â€‹âˆ‚yâ€‹ygyÂ¯â€‹(t,x,y)+ÏxÏ€ÏƒSÏƒYâˆ‚xâ€‹ygyÂ¯(t,x,y))fYT(yÂ¯;t,y)dyÂ¯,0=âˆ‚tgyÂ¯â€‹(t,x,y)+xâ€‹(r+Ï€^â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)Tâˆ’t))â€‹âˆ‚xgyÂ¯â€‹(t,x,y)+yÂ¯âˆ’yTâˆ’tâ€‹âˆ‚ygyÂ¯â€‹(t,x,y)+12â€‹x2â€‹Ï€^2â€‹ÏƒS2â€‹âˆ‚xâ€‹xgyÂ¯â€‹(t,x,y)+12â€‹ÏƒY2â€‹âˆ‚yâ€‹ygyÂ¯â€‹(t,x,y)+Ïâ€‹xâ€‹Ï€^â€‹ÏƒSâ€‹ÏƒYâ€‹âˆ‚xâ€‹ygyÂ¯â€‹(t,x,y),uÎ³â€‹(yÂ¯)â€‹(x)=gyÂ¯â€‹(T,x,y).\begin{split}&0=\sup\_{\pi}\int\_{\mathcal{Y}}\dfrac{1}{g^{\overline{y}}(t,x,y)(1-\gamma(\bar{y}))}\Bigg(\partial\_{t}g^{\overline{y}}(t,x,y)\Bigg.\\ &\hskip 56.9055pt+x\left(r+\pi\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\dfrac{\bar{y}-y-\mu\_{Y}(T-t)}{T-t}\right)\right)\partial\_{x}g^{\overline{y}}(t,x,y)\\ &\hskip 56.9055pt+\dfrac{\bar{y}-y}{T-t}\partial\_{y}g^{\overline{y}}(t,x,y)+\dfrac{1}{2}x^{2}\pi^{2}\sigma\_{S}^{2}\partial\_{xx}g^{\overline{y}}(t,x,y)+\dfrac{1}{2}\sigma\_{Y}^{2}\partial\_{yy}g^{\overline{y}}(t,x,y)\\ &\hskip 56.9055pt\Bigg.+\rho x\pi\sigma\_{S}\sigma\_{Y}\partial\_{xy}g^{\overline{y}}(t,x,y)\Bigg)f\_{Y\_{T}}(\bar{y};t,y)d\bar{y},\\ &0=\partial\_{t}g^{\overline{y}}(t,x,y)+x\left(r+\widehat{\pi}\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\dfrac{\bar{y}-y-\mu\_{Y}(T-t)}{T-t}\right)\right)\partial\_{x}g^{\overline{y}}(t,x,y)\\ &\qquad+\dfrac{\bar{y}-y}{T-t}\partial\_{y}g^{\overline{y}}(t,x,y)+\dfrac{1}{2}x^{2}\widehat{\pi}^{2}\sigma\_{S}^{2}\partial\_{xx}g^{\overline{y}}(t,x,y)+\dfrac{1}{2}\sigma\_{Y}^{2}\partial\_{yy}g^{\overline{y}}(t,x,y)\\ &\qquad+\rho x\widehat{\pi}\sigma\_{S}\sigma\_{Y}\partial\_{xy}g^{\overline{y}}(t,x,y),\\ u^{\gamma(\bar{y})}(x)&=g^{\overline{y}}(T,x,y).\end{split} |  |

The first order condition for Ï€\pi gives

|  |  |  |
| --- | --- | --- |
|  | Ï€^(t,x,y)=1ÏƒS2â€‹x2âˆ«ğ’´1gyÂ¯â€‹(t,x,y)â€‹(1âˆ’Î³â€‹(yÂ¯))((âˆ’Î¼S+râˆ’ÏÏƒSÏƒYyÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)Tâˆ’t)âˆ‚xgyÂ¯(t,x,y)âˆ’ÏÏƒSÏƒYâˆ‚xâ€‹ygyÂ¯(t,x,y))fYT(yÂ¯;t,y)dyÂ¯Ã—(âˆ«ğ’´1gyÂ¯â€‹(t,x,y)â€‹(1âˆ’Î³â€‹(yÂ¯))â€‹âˆ‚xâ€‹xgyÂ¯â€‹(t,x,y)â€‹fYTâ€‹(yÂ¯;t,y)â€‹dâ€‹yÂ¯)âˆ’1.\begin{split}&\widehat{\pi}(t,x,y)=\dfrac{1}{\sigma\_{S}^{2}x^{2}}\int\_{\mathcal{Y}}\dfrac{1}{g^{\overline{y}}(t,x,y)\big(1-\gamma(\bar{y})\big)}\bigg(\left(-\mu\_{S}+r-\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\dfrac{\bar{y}-y-\mu\_{Y}(T-t)}{T-t}\right)\partial\_{x}g^{\overline{y}}(t,x,y)\bigg.\Bigg.\\ &\Bigg.\bigg.\hskip 113.81102pt-\rho\sigma\_{S}\sigma\_{Y}\partial\_{xy}g^{\overline{y}}(t,x,y)\bigg)f\_{Y\_{T}}(\bar{y};t,y)d\bar{y}\\ &\hskip 56.9055pt\times\Bigg(\int\_{\mathcal{Y}}\dfrac{1}{g^{\overline{y}}(t,x,y)\big(1-\gamma(\bar{y})\big)}\partial\_{xx}g^{\overline{y}}(t,x,y)f\_{Y\_{T}}(\bar{y};t,y)d\bar{y}\Bigg)^{-1}.\end{split} |  |

We now apply the ansatz

|  |  |  |
| --- | --- | --- |
|  | gyÂ¯â€‹(t,x,y)=11âˆ’Î³â€‹(yÂ¯)â€‹hyÂ¯â€‹(t,y)â€‹x1âˆ’Î³â€‹(yÂ¯),g^{\bar{y}}(t,x,y)=\dfrac{1}{1-\gamma(\bar{y})}h^{\bar{y}}(t,y)x^{1-\gamma(\bar{y})}, |  |

which leads to the following PIDE:

|  |  |  |
| --- | --- | --- |
|  | 0=11âˆ’Î³â€‹(yÂ¯)â€‹x1âˆ’Î³â€‹(yÂ¯)â€‹âˆ‚thyÂ¯â€‹(t,y)+xâ€‹(r+Ï€^â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)Tâˆ’t))â€‹xâˆ’Î³â€‹(yÂ¯)â€‹hyÂ¯â€‹(t,y)+yÂ¯âˆ’yTâˆ’tâ€‹(11âˆ’Î³â€‹(yÂ¯)â€‹x1âˆ’Î³â€‹(yÂ¯))â€‹âˆ‚yhyÂ¯â€‹(t,y)âˆ’12â€‹x2â€‹Ï€^2â€‹ÏƒS2â€‹Î³â€‹(yÂ¯)â€‹xâˆ’Î³â€‹(yÂ¯)âˆ’1â€‹hyÂ¯â€‹(t,y)+12â€‹ÏƒY2â€‹(11âˆ’Î³â€‹(yÂ¯)â€‹x1âˆ’Î³â€‹(yÂ¯))â€‹âˆ‚yâ€‹yhyÂ¯â€‹(t,y)+Ïâ€‹xâ€‹Ï€^â€‹ÏƒSâ€‹ÏƒYâ€‹xâˆ’Î³â€‹(yÂ¯)â€‹âˆ‚yhyÂ¯â€‹(t,y),\begin{split}0&=\dfrac{1}{1-\gamma(\bar{y})}x^{1-\gamma(\bar{y})}\partial\_{t}h^{\bar{y}}(t,y)\\ &+x\left(r+\widehat{\pi}\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\dfrac{\bar{y}-y-\mu\_{Y}(T-t)}{T-t}\right)\right)x^{-\gamma(\bar{y})}h^{\bar{y}}(t,y)\\ &\qquad+\dfrac{\bar{y}-y}{T-t}\left(\dfrac{1}{1-\gamma(\bar{y})}x^{1-\gamma(\bar{y})}\right)\partial\_{y}h^{\bar{y}}(t,y)-\dfrac{1}{2}x^{2}\widehat{\pi}^{2}\sigma\_{S}^{2}\,\gamma(\bar{y})x^{-\gamma(\bar{y})-1}h^{\bar{y}}(t,y)\\ &\qquad+\dfrac{1}{2}\sigma\_{Y}^{2}\left(\dfrac{1}{1-\gamma(\bar{y})}x^{1-\gamma(\bar{y})}\right)\partial\_{yy}h^{\bar{y}}(t,y)+\rho x\widehat{\pi}\sigma\_{S}\sigma\_{Y}x^{-\gamma(\bar{y})}\partial\_{y}h^{\bar{y}}(t,y),\end{split} |  |

with terminal condition hyÂ¯â€‹(T,y)=1.h^{\bar{y}}(T,y)=1.

Simplifying with respect to xx (which cancels out entirely), this reduces to

|  |  |  |
| --- | --- | --- |
|  | 0=âˆ‚thyÂ¯â€‹(t,y)+(r+Ï€^â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹yÂ¯âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)Tâˆ’t))â€‹(1âˆ’Î³â€‹(yÂ¯))â€‹hyÂ¯â€‹(t,y)+yÂ¯âˆ’yTâˆ’tâ€‹âˆ‚yhyÂ¯â€‹(t,y)âˆ’12â€‹Ï€^2â€‹ÏƒS2â€‹Î³â€‹(yÂ¯)â€‹(1âˆ’Î³â€‹(yÂ¯))â€‹hyÂ¯â€‹(t,y)+12â€‹ÏƒY2â€‹âˆ‚yâ€‹yhyÂ¯â€‹(t,y)+Ïâ€‹Ï€^â€‹ÏƒSâ€‹ÏƒYâ€‹(1âˆ’Î³â€‹(yÂ¯))â€‹âˆ‚yhyÂ¯â€‹(t,y).\begin{split}&0=\partial\_{t}h^{\bar{y}}(t,y)+\left(r+\widehat{\pi}\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\dfrac{\bar{y}-y-\mu\_{Y}(T-t)}{T-t}\right)\right)\big(1-\gamma(\bar{y})\big)h^{\bar{y}}(t,y)\\ &\qquad+\dfrac{\bar{y}-y}{T-t}\partial\_{y}h^{\bar{y}}(t,y)-\dfrac{1}{2}\widehat{\pi}^{2}\sigma\_{S}^{2}\,\gamma(\bar{y})\big(1-\gamma(\bar{y})\big)h^{\bar{y}}(t,y)+\dfrac{1}{2}\sigma\_{Y}^{2}\partial\_{yy}h^{\bar{y}}(t,y)\\ &\qquad+\rho\widehat{\pi}\sigma\_{S}\sigma\_{Y}\big(1-\gamma(\bar{y})\big)\partial\_{y}h^{\bar{y}}(t,y).\end{split} |  |

Collecting terms near partial derivatives, we then have

|  |  |  |
| --- | --- | --- |
|  | 0=âˆ‚thyÂ¯â€‹(t,y)+(yÂ¯âˆ’yTâˆ’t+Ïâ€‹Ï€^â€‹ÏƒSâ€‹ÏƒYâ€‹(1âˆ’Î³â€‹(yÂ¯)))â€‹âˆ‚yhyÂ¯â€‹(t,y)+12â€‹ÏƒY2â€‹âˆ‚yâ€‹yhyÂ¯â€‹(t,y)+(r+Ï€^â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹(yÂ¯âˆ’yTâˆ’tâˆ’Î¼Y))âˆ’12â€‹Ï€^2â€‹ÏƒS2â€‹Î³â€‹(yÂ¯))â€‹(1âˆ’Î³â€‹(yÂ¯))â€‹hyÂ¯â€‹(t,y).\begin{split}&0=\partial\_{t}h^{\bar{y}}(t,y)+\left(\dfrac{\bar{y}-y}{T-t}+\rho\widehat{\pi}\sigma\_{S}\sigma\_{Y}\big(1-\gamma(\bar{y})\big)\right)\partial\_{y}h^{\bar{y}}(t,y)+\dfrac{1}{2}\sigma\_{Y}^{2}\partial\_{yy}h^{\bar{y}}(t,y)\\ &+\left(r+\widehat{\pi}\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\left(\dfrac{\bar{y}-y}{T-t}-\mu\_{Y}\right)\right)-\dfrac{1}{2}\widehat{\pi}^{2}\sigma\_{S}^{2}\gamma(\bar{y})\right)\big(1-\gamma(\bar{y})\big)h^{\bar{y}}(t,y).\end{split} |  |

Finally, using Î³â€‹(yÂ¯)=expâ¡(yÂ¯)\gamma(\bar{y})=\exp(\bar{y}), we obtain the equilibrium policy

|  |  |  |
| --- | --- | --- |
|  | Ï€^â€‹(t,y)=1ÏƒS2â€‹ğ”¼t,yâ€‹[Î³â€‹(YT)]â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹âˆ«ğ’´âˆ‚yhyÂ¯â€‹(t,y)hyÂ¯â€‹(t,y)â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯)=Î¼Sâˆ’r+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹âˆ«ğ’´âˆ‚yhyÂ¯â€‹(t,y)hyÂ¯â€‹(t,y)â€‹fYTâ€‹(yÂ¯;t,y)â€‹ğ‘‘yÂ¯ÏƒS2â€‹expâ¡(y+Î¼Yâ€‹(Tâˆ’t)+12â€‹ÏƒY2â€‹(Tâˆ’t)),\begin{split}\widehat{\pi}(t,y)&=\dfrac{1}{\sigma\_{S}^{2}\mathbb{E}\_{t,y}\left[\gamma(Y\_{T})\right]}\left(\mu\_{S}-r+\rho\sigma\_{S}\sigma\_{Y}\int\_{\mathcal{Y}}\dfrac{\partial\_{y}h^{\bar{y}}(t,y)}{h^{\bar{y}}(t,y)}f\_{Y\_{T}}(\bar{y};t,y)d\bar{y}\right)\\ &=\dfrac{\mu\_{S}-r+\rho\sigma\_{S}\sigma\_{Y}\int\_{\mathcal{Y}}\dfrac{\partial\_{y}h^{\bar{y}}(t,y)}{h^{\bar{y}}(t,y)}f\_{Y\_{T}}(\bar{y};t,y)d\bar{y}}{\sigma\_{S}^{2}\exp\left(y+\mu\_{Y}(T-t)+\dfrac{1}{2}\sigma\_{Y}^{2}(T-t)\right)},\end{split} |  |

which is independent of the current wealth level.
âˆ

## Appendix B Additional numerical results

In this appendix, we provide supplementary numerics that complement the analysis in Section [4](https://arxiv.org/html/2512.21149v1#S4 "4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty").

First, Figures [2](https://arxiv.org/html/2512.21149v1#A2.F2 "Figure 2 â€£ Appendix B Additional numerical results â€£ Equilibrium investment under dynamic preference uncertainty") (a)-(b) display the functions hyÂ¯â€‹(t,y)h^{\bar{y}}(t,y) solving the PIDE ([4.6](https://arxiv.org/html/2512.21149v1#S4.E6 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) for a fixed value of yÂ¯=YT=lnâ¡(2)\bar{y}=Y\_{T}=\ln(2).

![Refer to caption](hfunction_positive_muy_positive_rho.png)


(a)

![Refer to caption](hfunction_negative_muy_positive_rho.png)


(b)

Figure 2: Intertemporal continuation value hyÂ¯â€‹(t,y)h^{\bar{y}}(t,y) for Î¼Y=0.02\mu\_{Y}=0.02 (left) and Î¼Y=âˆ’0.02\mu\_{Y}=-0.02 (right), fixing yT=lnâ¡(2)y\_{T}=\ln(2). Other parameters: (r,Î¼S,ÏƒS,ÏƒY,Ï,expâ¡(y0))=(0.02,0.07,0.2,0.04,0.6,2)(r,\mu\_{S},\sigma\_{S},\sigma\_{Y},\rho,\exp(y\_{0}))=(0.02,0.07,0.2,0.04,0.6,2).

Second, Figure [3](https://arxiv.org/html/2512.21149v1#A2.F3 "Figure 3 â€£ Appendix B Additional numerical results â€£ Equilibrium investment under dynamic preference uncertainty") shows the equilibrium investment policy in the special case Î¼Y=0.5â€‹ÏƒY2\mu\_{Y}=0.5\sigma\_{Y}^{2}. Under this specification, the exponential factor in the denominator of ([4.5](https://arxiv.org/html/2512.21149v1#S4.E5 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) becomes time-invariant, leading to an equilibrium policy that is static in tt.

![Refer to caption](eqpolicy_special_muy_positive_rho.png)


Figure 3: Equilibrium policy for Î¼Y=0.5â€‹ÏƒY2\mu\_{Y}=0.5\sigma\_{Y}^{2}. Other parameters: (r,Î¼S,ÏƒS,ÏƒY,Ï)=(0.02,0.07,0.2,0.03,0.6)(r,\mu\_{S},\sigma\_{S},\sigma\_{Y},\rho)=(0.02,0.07,0.2,0.03,0.6).

To conclude, Table LABEL:tab:policy\_values reports equilibrium allocations for a range of parameter combinations in Î¼Y\mu\_{Y} and Ï\rho. All remaining parameters are as specified above.

Table 1: Equilibrium policy Ï€^â€‹(y,t)\hat{\pi}(y,t) for selected values of (y,t)(y,t).
Other parameters: (r,Î¼S,ÏƒS,ÏƒY,Î³â€‹(y0))=(0.02,0.07,0.2,0.04,2)(r,\mu\_{S},\sigma\_{S},\sigma\_{Y},\gamma(y\_{0}))=(0.02,0.07,0.2,0.04,2).

| Î¼Y,Ï\mu\_{Y},\rho | expâ¡(y)\exp(y) | t=0t=0 | t=7t=7 | t=14t=14 | t=21t=21 | t=28t=28 | t=35t=35 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 0.02,0.60.02,0.6 | 2 | 0.272 | 0.315 | 0.364 | 0.421 | 0.487 | 0.563 |
| 3 | 0.182 | 0.21 | 0.243 | 0.281 | 0.325 | 0.376 |
| 4 | 0.136 | 0.157 | 0.182 | 0.211 | 0.244 | 0.282 |
| 7 | 0.078 | 0.09 | 0.104 | 0.120 | 0.139 | 0.161 |
| 10 | 0.054 | 0.063 | 0.073 | 0.084 | 0.097 | 0.113 |
| 0.02,âˆ’0.60.02,-0.6 | 2 | 0.272 | 0.315 | 0.364 | 0.421 | 0.487 | 0.563 |
| 3 | 0.181 | 0.21 | 0.243 | 0.281 | 0.325 | 0.376 |
| 4 | 0.136 | 0.157 | 0.182 | 0.21 | 0.243 | 0.281 |
| 7 | 0.078 | 0.09 | 0.104 | 0.12 | 0.139 | 0.161 |
| 10 | 0.054 | 0.063 | 0.073 | 0.084 | 0.097 | 0.113 |
| âˆ’0.02,0.6-0.02,0.6 | 0.8 | 3.48 | 2.946 | 2.574 | 2.251 | 1.967 | 1.72 |
| 1.2 | 2.328 | 1.963 | 1.716 | 1.5 | 1.312 | 1.147 |
| 1.6 | 1.724 | 1.472 | 1.287 | 1.125 | 0.984 | 0.86 |
| 2 | 1.365 | 1.178 | 1.03 | 0.9 | 0.787 | 0.688 |
| 2.4 | 1.13 | 0.981 | 0.858 | 0.75 | 0.656 | 0.573 |
| âˆ’0.02,âˆ’0.6-0.02,-0.6 | 0.8 | 3.384 | 2.93 | 2.573 | 2.25 | 1.967 | 1.72 |
| 1.2 | 2.257 | 1.948 | 1.716 | 1.5 | 1.312 | 1.147 |
| 1.6 | 1.692 | 1.462 | 1.287 | 1.125 | 0.984 | 0.86 |
| 2 | 1.353 | 1.171 | 1.029 | 0.9 | 0.787 | 0.688 |
| 2.4 | 1.128 | 0.976 | 0.858 | 0.75 | 0.656 | 0.573 |
| 0.5â€‹ÏƒY2,0.60.5\sigma\_{Y}^{2},0.6 | 1 | 1.172 | 1.186 | 1.199 | 1.213 | 1.226 | 1.24 |
| 2 | 0.586 | 0.593 | 0.599 | 0.606 | 0.613 | 0.62 |
| 3 | 0.391 | 0.395 | 0.4 | 0.404 | 0.409 | 0.413 |
| 4 | 0.293 | 0.296 | 0.3 | 0.303 | 0.307 | 0.31 |
| 5 | 0.235 | 0.237 | 0.24 | 0.243 | 0.245 | 0.248 |
| 0.5â€‹ÏƒY2,âˆ’0.60.5\sigma\_{Y}^{2},-0.6 | 1 | 1.171 | 1.186 | 1.199 | 1.213 | 1.227 | 1.24 |
| 2 | 0.586 | 0.593 | 0.599 | 0.606 | 0.613 | 0.62 |
| 3 | 0.391 | 0.395 | 0.4 | 0.404 | 0.409 | 0.413 |
| 4 | 0.293 | 0.296 | 0.3 | 0.303 | 0.307 | 0.31 |
| 5 | 0.234 | 0.237 | 0.24 | 0.243 | 0.245 | 0.248 |
| 0.02,10.02,1 | 2 | 0.272 | 0.315 | 0.364 | 0.421 | 0.487 | 0.563 |
| 3 | 0.181 | 0.21 | 0.243 | 0.281 | 0.325 | 0.376 |
| 4 | 0.136 | 0.157 | 0.182 | 0.21 | 0.243 | 0.282 |
| 7 | 0.078 | 0.09 | 0.104 | 0.12 | 0.139 | 0.161 |
| 10 | 0.054 | 0.063 | 0.073 | 0.084 | 0.097 | 0.113 |
| 0.02,âˆ’10.02,-1 | 2 | 0.272 | 0.315 | 0.364 | 0.421 | 0.487 | 0.563 |
| 3 | 0.181 | 0.21 | 0.243 | 0.281 | 0.325 | 0.376 |
| 4 | 0.136 | 0.157 | 0.182 | 0.21 | 0.243 | 0.282 |
| 7 | 0.078 | 0.09 | 0.104 | 0.12 | 0.139 | 0.161 |
| 10 | 0.054 | 0.063 | 0.073 | 0.084 | 0.097 | 0.113 |
| âˆ’0.02,1-0.02,1 | 0.8 | 3.446 | 3.027 | 2.578 | 2.251 | 1.967 | 1.72 |
| 1.2 | 2.34 | 2.008 | 1.717 | 1.5 | 1.312 | 1.467 |
| 1.6 | 1.767 | 1.43 | 1.287 | 1.125 | 0.984 | 0.86 |
| 2 | 1.419 | 1.188 | 1.03 | 0.9 | 0.787 | 0.688 |
| 2.4 | 1.185 | 0.986 | 0.858 | 0.75 | 0.656 | 0.573 |
| âˆ’0.02,âˆ’1-0.02,-1 | 0.8 | 3.49 | 2.942 | 2.574 | 2.251 | 1.968 | 1.72 |
| 1.2 | 2.387 | 1.962 | 1.716 | 1.5 | 1.312 | 1.147 |
| 1.6 | 1.794 | 1.471 | 1.287 | 1.125 | 0.984 | 0.86 |
| 2 | 1.424 | 1.177 | 1.03 | 0.9 | 0.787 | 0.688 |
| 2.4 | 1.174 | 0.981 | 0.858 | 0.75 | 0.656 | 0.573 |
| 0.02,00.02,0 | 2 | 0.272 | 0.315 | 0.3634 | 0.421 | 0.487 | 0.563 |
| 3 | 0.181 | 0.21 | 0.243 | 0.281 | 0.325 | 0.376 |
| 4 | 0.136 | 0.157 | 0.182 | 0.21 | 0.243 | 0.282 |
| 7 | 0.078 | 0.09 | 0.104 | 0.12 | 0.139 | 0.161 |
| 10 | 0.054 | 0.063 | 0.073 | 0.084 | 0.097 | 0.113 |
| âˆ’0.02,0-0.02,0 | 0.8 | 3.368 | 2.946 | 2.574 | 2.25 | 1.968 | 1.72 |
| 1.2 | 2.245 | 1.963 | 1.716 | 1.5 | 1.312 | 1.147 |
| 1.6 | 1.684 | 1.472 | 1.287 | 1.125 | 0.984 | 0.86 |
| 2 | 1.347 | 1.178 | 1.03 | 0.9 | 0.787 | 0.688 |
| 2.4 | 1.123 | 0.981 | 0.858 | 0.75 | 0.656 | 0.573 |

## Appendix C Pseudocodes

To compute the equilibrium policy numerically, we solve the coupled system ([4.5](https://arxiv.org/html/2512.21149v1#S4.E5 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty"))-([4.6](https://arxiv.org/html/2512.21149v1#S4.E6 "In Proposition 4.2. â€£ 4.1 Preference specification and equilibrium investment â€£ 4 Application: state-dependent CRRA utility â€£ Equilibrium investment under dynamic preference uncertainty")) using a neural network-based approach. The key idea is to approximate each function hyÂ¯â€‹(t,y)h^{\bar{y}}(t,y) by a neural network and to enforce the PIDE through a physics-informed loss that penalizes deviations from the differential equation, the boundary condition, and the coupling with Ï€^â€‹(t,y)\widehat{\pi}(t,y). The equilibrium policy is updated iteratively: given an estimate of hyÂ¯h^{\bar{y}}, we compute Ï€^\widehat{\pi}; this updated policy is then fed back into the PIDE, and the networks are trained until a fixed point is reached.

1EvaluatePiHat(*hÎ¸h\_{\theta}, current state yy, time tt*)

Input :Â Trained model hÎ¸h\_{\theta}, grid size Ngâ€‹râ€‹iâ€‹dN\_{grid} for yTy\_{T} integration

Output :Â Estimated policy Ï€^â€‹(t,y)\widehat{\pi}(t,y)

2

3Construct grid {yT(j)}j=1Ngâ€‹râ€‹iâ€‹d\{y\_{T}^{(j)}\}\_{j=1}^{N\_{grid}} over support of yTy\_{T};

4
for *j=1j=1 to Ngâ€‹râ€‹iâ€‹dN\_{grid}* do

5â€‚Â â€ƒCompute hj=hÎ¸â€‹(t,y,yT(j))h\_{j}=h\_{\theta}(t,y,y\_{T}^{(j)});

6â€‚Â â€ƒ
Compute partial derivative âˆ‚yhjâ€‹(t,y,yT(j));\partial\_{y}h\_{j}(t,y,y\_{T}^{(j)})\;;

7â€‚Â â€ƒCompute ratio:

|  |  |  |
| --- | --- | --- |
|  | rj=âˆ‚yhjhj+Îµ;r\_{j}=\frac{\partial\_{y}h\_{j}}{h\_{j}+\varepsilon}\;; |  |

8â€‚Â â€ƒUsing the conditional distribution of the arithmetic Brownian motion, YT|Yt=yâˆ¼ğ’©â€‹(y+Î¼Yâ€‹(Tâˆ’t),ÏƒY2â€‹(Tâˆ’t))Y\_{T}\,|\,Y\_{t}=y\sim\mathcal{N}\big(y+\mu\_{Y}(T-t),\sigma\_{Y}^{2}(T-t)\big), compute CDF weights:

|  |  |  |
| --- | --- | --- |
|  | wj=Î¦â€‹(yT(j)âˆ’yâˆ’Î¼Yâ€‹(Tâˆ’t)ÏƒYâ€‹Tâˆ’t).w\_{j}=\Phi\left(\frac{y\_{T}^{(j)}-y-\mu\_{Y}(T-t)}{\sigma\_{Y}\sqrt{T-t}}\right)\;. |  |

9

10Compute integral using trapezoidal rule:

|  |  |  |
| --- | --- | --- |
|  | I=âˆ‘j=1Ngâ€‹râ€‹iâ€‹drjâ‹…wjâ‹…Î”â€‹yT;I=\sum\_{j=1}^{N\_{grid}}r\_{j}\cdot w\_{j}\cdot\Delta y\_{T}\;; |  |

Return:

|  |  |  |
| --- | --- | --- |
|  | Ï€^â€‹(t,y)=Î¼Sâˆ’r+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹IÏƒS2â€‹ğ”¼t,yâ€‹[Î³â€‹(yT)]=Î¼Sâˆ’r+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹IÏƒS2â€‹expâ¡(y+Î¼Yâ€‹(Tâˆ’t)+12â€‹ÏƒY2â€‹(Tâˆ’t)).\widehat{\pi}(t,y)=\frac{\mu\_{S}-r+\rho\sigma\_{S}\sigma\_{Y}I}{\sigma\_{S}^{2}\,\mathbb{E}\_{t,y}\left[\gamma(y\_{T})\right]}=\frac{\mu\_{S}-r+\rho\sigma\_{S}\sigma\_{Y}I}{\sigma\_{S}^{2}\,\exp\left(y+\mu\_{Y}(T-t)+\frac{1}{2}\sigma\_{Y}^{2}(T-t)\right)}. |  |

AlgorithmÂ 1 Evaluate equilibrium policy Ï€^â€‹(t,y)\widehat{\pi}(t,y)



1TrainHModel(*Î¸\theta (NN parameters), terminal time TT, initial state Y0Y\_{0}*)

Input :Â Learning rate Î·\eta, number of iterations NiterN\_{\text{iter}}, batch size Nbâ€‹aâ€‹tâ€‹câ€‹hN\_{batch}, sample size Npâ€‹aâ€‹tâ€‹hâ€‹sN\_{paths}, boundary loss weight Î»bâ€‹c\lambda\_{bc}

Output :Â Trained model hÎ¸â€‹(t,y,yT)h\_{\theta}(t,y,y\_{T})

2

3Initialize neural network hÎ¸:(t,y,yT)â†¦â„+h\_{\theta}\colon(t,y,y\_{T})\mapsto\mathbb{R}\_{+};

4
for *k=1k=1 to Niâ€‹tâ€‹eâ€‹rN\_{iter}* do

5â€‚Â â€ƒ
Sample training batch {(ti,yi,yT(i))}i=1Nbâ€‹aâ€‹tâ€‹câ€‹h\{(t\_{i},y\_{i},y\_{T}^{(i)})\}\_{i=1}^{N\_{batch}} from training domain;

6â€‚Â â€ƒ
for *i=1i=1 to Nbâ€‹aâ€‹tâ€‹câ€‹hN\_{batch}* do

7â€‚Â â€ƒâ€‚Â â€ƒ
Compute model output hi=hÎ¸â€‹(ti,yi,yT(i))h\_{i}=h\_{\theta}(t\_{i},y\_{i},y\_{T}^{(i)});

8â€‚Â â€ƒâ€‚Â â€ƒ
Compute partial derivatives âˆ‚thi,âˆ‚yhi,âˆ‚yâ€‹yhi\partial\_{t}h\_{i},\,\partial\_{y}h\_{i},\,\partial\_{yy}h\_{i} with autograd;

9

10â€‚Â â€ƒâ€‚Â â€ƒCompute Ï€=Ï€^â€‹(yi,ti)\pi=\widehat{\pi}(y\_{i},t\_{i}) using Algorithm [1](https://arxiv.org/html/2512.21149v1#algorithm1 "In Appendix C Pseudocodes â€£ Equilibrium investment under dynamic preference uncertainty");

11

12â€‚Â â€ƒâ€‚Â â€ƒCompute PIDE coefficient functions Pi=Pâ€‹(ti,yi,yT(i)),Qi=Qâ€‹(ti,yi,yT(i)),P\_{i}=P(t\_{i},y\_{i},y\_{T}^{(i)}),Q\_{i}=Q(t\_{i},y\_{i},y\_{T}^{(i)}), Ri=Râ€‹(ti,yi,yT(i))R\_{i}=R(t\_{i},y\_{i},y\_{T}^{(i)}):

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Pi\displaystyle P\_{i} | =\displaystyle= | (r+Ï€â€‹(Î¼Sâˆ’r+Ïâ€‹ÏƒSÏƒYâ€‹(yT(i)âˆ’yiTâˆ’tiâˆ’Î¼Y))âˆ’12â€‹Ï€2â€‹ÏƒS2â€‹Î³â€‹(yT(i)))â€‹(1âˆ’Î³â€‹(yT(i))),\displaystyle\left(r+\pi\left(\mu\_{S}-r+\rho\dfrac{\sigma\_{S}}{\sigma\_{Y}}\left(\dfrac{y\_{T}^{(i)}-y\_{i}}{T-t\_{i}}-\mu\_{Y}\right)\right)-\dfrac{1}{2}\pi^{2}\sigma\_{S}^{2}\gamma(y\_{T}^{(i)})\right)(1-\gamma(y\_{T}^{(i)}))\;, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Qi\displaystyle Q\_{i} | =\displaystyle= | yT(i)âˆ’yiTâˆ’ti+Ïâ€‹ÏƒSâ€‹ÏƒYâ€‹(1âˆ’Î³â€‹(yT(i))),Ri=12â€‹ÏƒY2;\displaystyle\dfrac{y\_{T}^{(i)}-y\_{i}}{T-t\_{i}}+\rho\sigma\_{S}\sigma\_{Y}(1-\gamma(y\_{T}^{(i)}))\;,\quad R\_{i}=\dfrac{1}{2}\sigma\_{Y}^{2}\;; |  |

13â€‚Â â€ƒâ€‚Â â€ƒEvaluate PIDE residual:

|  |  |  |
| --- | --- | --- |
|  | residuali=âˆ‚thi+Pâ€‹(ti,yi,yT(i))â€‹hi+Qâ€‹(ti,yi,yT(i))â€‹âˆ‚yhi+Râ€‹(ti,yi,yT(i))â€‹âˆ‚yâ€‹yhi;\text{residual}\_{i}=\partial\_{t}h\_{i}+P(t\_{i},y\_{i},y\_{T}^{(i)})h\_{i}+Q(t\_{i},y\_{i},y\_{T}^{(i)})\partial\_{y}h\_{i}+R(t\_{i},y\_{i},y\_{T}^{(i)})\partial\_{yy}h\_{i}\;; |  |

14

15â€‚Â â€ƒCompute PIDE loss:

|  |  |  |
| --- | --- | --- |
|  | Lpâ€‹iâ€‹dâ€‹e=1Nbâ€‹aâ€‹tâ€‹câ€‹hâ€‹âˆ‘i=1Nbâ€‹aâ€‹tâ€‹câ€‹h(residuali)2;L\_{pide}=\frac{1}{N\_{batch}}\sum\_{i=1}^{N\_{batch}}(\text{residual}\_{i})^{2}\;; |  |

16â€‚Â â€ƒSample boundary points {(T,yT(j),yT(j))}j=1Npâ€‹aâ€‹tâ€‹hâ€‹s\{(T,y\_{T}^{(j)},y\_{T}^{(j)})\}\_{j=1}^{N\_{paths}};

17â€‚Â â€ƒ
Compute terminal condition loss:

|  |  |  |
| --- | --- | --- |
|  | Lbc=1Npâ€‹aâ€‹tâ€‹hâ€‹sâ€‹âˆ‘j=1Npâ€‹aâ€‹tâ€‹hâ€‹s(hÎ¸â€‹(T,yT(j),yT(j))âˆ’1)2;L\_{\text{bc}}=\frac{1}{N\_{paths}}\sum\_{j=1}^{N\_{paths}}\left(h\_{\theta}(T,y\_{T}^{(j)},y\_{T}^{(j)})-1\right)^{2}\;; |  |

18â€‚Â â€ƒCompute total loss: L=Lpâ€‹iâ€‹dâ€‹e+Î»bcâ€‹Lbc;\quad L=L\_{pide}+\lambda\_{\text{bc}}L\_{\text{bc}};

19â€‚Â â€ƒUpdate parameters: Î¸â†Î¸âˆ’Î·â€‹âˆ‡Î¸L;\quad\theta\leftarrow\theta-\eta\nabla\_{\theta}L\;;

return hÎ¸.h\_{\theta}\;.

AlgorithmÂ 2 Training the NN solution hâ€‹(t,y,yT)h(t,y,y\_{T})