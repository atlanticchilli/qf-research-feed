---
authors:
- Jose Blanchet
- Jiayi Cheng
- Hao Liu
- Yang Liu
doc_id: arxiv:2512.01408v1
family_id: arxiv:2512.01408
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein
  Projections
url_abs: http://arxiv.org/abs/2512.01408v1
url_html: https://arxiv.org/html/2512.01408v1
venue: arXiv q-fin
version: 1
year: 2025
---


Jose Blanchet
Stanford University, CA 94305, US. Email: jose.blanchet@stanford.edu
â€ƒâ€ƒ
Jiayi Cheng
New York University, NY 10003, US. Email: jiayicheng@nyu.edu
â€ƒâ€ƒ
Hao Liu
Stanford University, CA 94305, US. Email: haoliu20@stanford.edu
â€ƒâ€ƒ
Yang Liu
The Chinese University of Hong Kong, Shenzhen, Guangdong 518172, China. Email: yangliu16@cuhk.edu.cn

###### Abstract

We revisit Mertonâ€™s continuous-time portfolio selection through a data-driven, distributionally robust lens. Our aim is to tap the benefits of frequent trading over short horizons while acknowledging that drift is hard to pin down, whereas volatility can be screened using realized or implied measures for appropriately selected assets. Rather than time-rectangular distributional robust controlâ€”which replenishes adversarial power at every instant and induces over-pessimismâ€”we place a single ambiguity set on the drift prior within a Bayesian Merton model. This prior-level ambiguity preserves learning and tractability: a minimax swap reduces the robust control to optimizing a nonlinear functional of the prior, enabling Karatzas and Zhao [KZ98]-typeâ€™s closed-form evaluation for each candidate prior. We then characterize small-radius worst-case priors under Wasserstein uncertainty via an explicit asymptotically optimal pushforward of the nominal prior, and we calibrate the ambiguity radius through a nonlinear Wasserstein projection tailored to the Merton functional. Synthetic and real-data studies demonstrate reduced pessimism relative to DRC and improved performance over myopic DROâ€“Markowitz under frequent rebalancing.

MSC 2020 subject classifications:
Primary 49K45; Secondary 49Q22, 91G10, 90C31.

Keywords: Portfolio selection, distributionally robust stochastic control, reduction of over-pessimism, constrained distributional optimization, nonlinear Wasserstein projection

## 1 Introduction

This paper revisits Mertonâ€™s classical continuous-time portfolio selection model through a data-driven, distributionally robust lens. Our goal is to tap the benefits of frequent trading over short horizons (days to weeks) while acknowledging that drift is difficult to pin down over such horizons. In contrast, volatility can often be stabilized by screening via realized or implied measures appropriately chosen assets111We acknowledge that this screening can limit the investing universe; we discuss ways to incorporate volatility uncertainty in the conclusion.. We therefore focus on the robustness of the drift and explicitly separate uncertainty modeling: we treat volatility as pre-estimated (e.g., realized/implied volatility) within the Bayesian filtering setup, and we robustify only the drift by placing a single ambiguity set on the drift prior.

Our starting point is the observation that, while data-driven robust portfolio selection performs competitively, it is static and myopic; it does not leverage the value of frequent rebalancing that Mertonâ€™s continuous-time model affords. In particular, for example, myopic DROâ€“Markowitz policies do not capitalize on information revealed over time except through rolling re-estimation. At first sight, it may be surprising that DROâ€“Markowitz often outperforms dynamic investment strategies in practice (as illustrated in [BlanchetChenZhou2021]). As explained there, sophisticated dynamic decisions rely heavily on model assumptions; when these are violated, errors compound over time, undermining dynamic strategiesâ€”especially under unpredictable non-stationarities. By contrast, the Merton framework provides a principled way to exploit frequent tradingâ€”provided we handle model uncertainty in a way that does not induce excessive pessimism.

The robust control literature (DRC/DRMDP) places time-rectangular ambiguity on the data-generating process and derives policies via dynamic programming; see, e.g., [HansenSargent2001, hansen2008robustness, RB1, RB2] and subsequent developments in DRMDP/DRRL [NianSi, wang2022policy, Wang2023, Liu2022, Zhou2021, lu2024drrl]. Rectangularity replenishes the adversaryâ€™s power at every time step, often yielding over-conservative allocations when applied to portfolio choice with short horizons. Intuitively, in a one-dimensional drift-shift toy example, a rectangular adversary can depress the drift at each instant, compounding pessimism over time; by contrast, a prior-level ambiguity perturbs the drift distribution once. Nevertheless, rectangularity is widely used because it preserves time consistency and the dynamic-programming structure (Bellman equations), which confers strong tractability and algorithmic scalabilityâ€”the very benefit delivered by the â€œreplenishingâ€ mechanism. Our design choice is different: instead of time-rectangular uncertainty, we adopt a â€‰*prior-level* ambiguity in a Bayesian Merton model. We place a single ambiguity set around the drift prior - primarily a Wasserstein ball, though KL balls are also covered. The volatility is assumed to be constant and therefore easy to estimate in continuous-time. This *distributionally robust Bayesian control* (DRBC) design reduces pessimism and preserves the learning structure of the Bayesian Merton formulation.

Technically, an important tractability lever is a minimax swap (Sion-type) that holds for broad prior-level ambiguity sets (including Wasserstein and KL). This swap allows us to evaluate, for any fixed prior in the ambiguity set, the optimal Bayesian Merton value and policy in closed form using the formulas of [KZ98]. As a result, the DRBC game reduces to a constrained distributional optimization over the drift prior: we optimize a nonlinear functional of the prior that arises from Karatzas and Zhao [KZ98]â€™s expression. The reduction holds under mild conditions standard in the Bayesian Merton literature. 222Even if the minimax swap is difficult to justify, one may start with the formulation in which the adversary moves first. While this is not the most natural formulation (because the adversary typically models an environment that occurs after the manager makes its decision), still, it may still be a pragmatic way to induce robustness while mitigate overconservative policies.

Optimizing over a Wasserstein ball is subtle here because the resulting objective is highly nonlinear in the prior; standard Wasserstein DRO tools do not apply off-the-shelf. We derive small-radius asymptotics for non-linear functionals and apply these results to the worst-case prior. We obtain a *constructive* approximation: an explicit asymptotically optimal pushforward perturbation of the nominal prior that realizes the first-order effect. Beyond optimization, we also address calibration: we select the ambiguity radius by general *nonlinear Wasserstein projections*. Then, we tailor these general results to the Merton functional, extending linear RWPI-style projection ideas to this nonlinear setting. We highlight that this nonlinear projection perspective may be of independent interest, given the broad and growing use of Wasserstein projections [SiMurthyBlanchetNguyen2021, Blanchet2021WassersteinDRO].

We complement the theory with evidence in synthetic and real-data settings. In synthetic experiments, we simulate an environment consistent with Mertonâ€™s assumptions: volatilities are known (or well-estimated), while asset drifts are unknown but deterministic and time-varying, generated from sinusoidal bases spanning a wide range of oscillatory frequencies. We compare two empirical strategies to construct the nominal drift prior from data: (i) batched, disjoint time windows (e.g., days or weeks) that form an empirical prior from window-level average returns; and (ii) day-of-week aggregation within larger windows (e.g., averages of â€œMondays,â€ â€œTuesdays,â€ etc.). Perhaps surprisingly, the batched-window prior performs slightly better even under periodic drifts, and we adopt it in our real-data study. Across both synthetic and real data, DRBC exhibits reduced pessimism compared to DRC under matched radii and improves performance over myopic DROâ€“Markowitz when frequent rebalancing is possible.

##### Contributions.

Our main contributions are as follows.

* â€¢

  Duality for prior-level ambiguity. We prove a minimax swap for drift-prior ambiguity sets (Wasserstein and KL), reducing DRBCâ€“Merton to optimizing a nonlinear functional of the prior while preserving closed-form evaluation via [KZ98].
* â€¢

  Constructive worst-case prior sensitivity under Wasserstein and non-linear functionals. For small ambiguity radii, we derive a first-order expansion of the robust objective and give an explicit asymptotically optimal push-forward perturbation of the nominal prior. These results are of independent interest since they are derived for the evaluation of worst-case non-linear functions of probabilities.
* â€¢

  Calibration via nonlinear Wasserstein projection. We introduce a projection-based, data-driven method to select the ambiguity radius tailored to the Merton functional, generalizing linear RWPI-style projections to a nonlinear manifold. Again, the results involve general nonlinear projections in Wasserstein geometry which are of independent interest.
* â€¢

  Empirical validation and reduced pessimism. Synthetic and real-data experiments demonstrate reduced over-conservatism relative to DRC and improved performance over myopic DROâ€“Markowitz under frequent rebalancing.

In the end, we emphasize that our contributions can still be interpreted within a Bayesian lens. What we offer is a systematic approach to infuse robustness and tractability in the choice of the prior, situating our framework within the scope of contemporary tools of distributionally robust decision making. From this perspective, the statistician may note that the priorâ€™s choice may induce a bias that is relatively small as time increases. But this is not the environment we have in mind. In our setting, the investment horizon (which we denote as TT) is fixed. This time horizon is long enough so that the manager may take advantage of multi-stage, even frequent, decisions but short enough that the volatility and drift are roughly constant. With this in mind, volatility can be set fixed and drift is unknown, so a Bayesian setting is natural but with a prior that requires robust calibration. This is precisely the mindset that motivates our development.

##### Related work.

Distributionally robust optimization (DRO) has been extensively studied in statistics and machine learning, including Wasserstein DRO [Blanchet2021WassersteinDRO, Blanchet2024DRO] and surveys [rahimian2019distributionally, Bayraksan2015, ksw\_2024\_dro]. In control, DRC or DRMDP (Distributionally Robust Markov Decision Processes) typically adopt a time-rectangular ambiguity that preserves Bellman dynamic programming and tractability, but can be conservative because the adversary constantly replenishes its power [HansenSargent2001, hansen2008robustness, wkr\_2013\_rmdp, RB1, RB2, NianSi, wang2022policy, Wang2023, Liu2022, Zhou2021, lu2024drrl]. We instead place a single ambiguity set on the drift prior in a Bayesian Merton model, enabling closed-form evaluation while tempering pessimism. Our approach relates to Bayesian DRO in static settings [doi:10.1137/21M1465548] and differs from DRBO [pmlr-v108-kirschner20a]: beyond being online and discrete-time, DRBO does not robustify within a stochastic control framework (it is closer to rolling-horizon risk minimization) and provides limited guidance for selecting the ambiguity size.

On the sensitivity-analysis side, our work builds on the Wasserstein-DRO expansions of [BartlDrapeauOblojWiesel2021], who develop first-order asymptotics and optimal perturbations under Wasserstein balls, and to subsequent statistical analyses of Wasserstein estimators such as [BKW19, Blanchet2021WassersteinDRO, BMZ21]. A parallel line of work studies divergence-based robustness, most notably the KL- and Ï•\phi-divergence sensitivity framework of [Lam2016] and the RÃ©nyi-divergence bounds of [AtarChowdharyDupuis2015]. In contrast to these approachesâ€”which focus on linear or convex performance measuresâ€”we analyze the sensitivity of a highly non-linear Merton value functional in Wasserstein geometry and use its first-order expansion to construct problem-specific worst-case priors in continuous-time Bayesian control models. A broader robustness and sensitivity literature, ranging from ambiguity-averse portfolio selection [PflugWozabal2007] to distributionally robust SAA, stochastic programming, and adversarial training and hedging [AndersonPhilpott2019, Dupacova1990, BonnansShapiro2013, ArmacostFiacco1974, AraujoEtAl2019, GaoKleywegt2016, sauldubois\_touzi\_2024], provides useful context but tackles problems of a different structural form.

On the projection side, most existing results focus on linear or convex functionals and thus differ from the non-linear, Merton-specific projection problem studied here. Linear optimal transport projections have been extensively analyzed in the optimal-transport DRO literature, including recent developments on small-sample behavior [LinBlanchetGlynnNguyen2024], unifying OT-based DRO reformulations [BlanchetKuhnLiTaskesen2023], and stability evaluations via distributional perturbations [BlanchetCuiLiLiu2024]. Related projection methodologies also arise in confidence-region construction [BlanchetMurthySi2022], fairness testing through OT projections [SiMurthyBlanchetNguyen2021, TaskesenBlanchetKuhnNguyen2021], and martingale projections under adapted Wasserstein distances [BlanchetWieselZhangZhang2024]. Unlike these worksâ€”which center on linear expectation functionals or convex risk measuresâ€”we analyze a fully non-linear projection defined by the Merton value functional and derive a problem-specific first-order expansion that yields constructive worst-case priors tailored to continuous-time Bayesian control.

##### Organization.

Section [2](https://arxiv.org/html/2512.01408v1#S2 "2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") reviews the classical and Bayesian Merton formulations. Section [3](https://arxiv.org/html/2512.01408v1#S3 "3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") introduces the DRBC model, establishes the minimax swap enabling closed-form evaluation, and gives the small-radius Wasserstein approximations for worst-case priors. Section [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") presents our data-driven construction of the drift prior and develops a nonlinear Wasserstein projection for ambiguity calibration. Sections [5](https://arxiv.org/html/2512.01408v1#S5 "5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [6](https://arxiv.org/html/2512.01408v1#S6 "6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") report synthetic and real-data experiments, respectively. Additional experimental details are deferred to the Appendix. Due to space constraints and to ease the exposition, we focus on compactly supported adversarial priors. We provide an online supplementary section dealing with more general priors in the important power-utility setting.

## 2 Preliminaries

In this section we review the classical and Bayesian formulations of Mertonâ€™s portfolio selection problem and set the notation used throughout. W=(W1,â€¦,Wd)âŠ¤W=\left(W\_{1},\ldots,W\_{d}\right)^{\top} is an â„d\mathbb{R}^{d}-valued Brownian motion under a complete filtered probability space (Î©,â„±,{â„±â€‹(t)}tâˆˆ[0,T],â„™)(\Omega,\mathcal{F},\{\mathcal{F}(t)\}\_{t\in[0,T]},\mathbb{P}). The risk-free asset is given by S0â€‹(0)=s0>0S\_{0}(0)=s\_{0}>0 and

|  |  |  |
| --- | --- | --- |
|  | dâ€‹S0â€‹(t)=râ€‹S0â€‹(t)â€‹dâ€‹t,â€„â€„0â‰¤tâ‰¤T,dS\_{0}(t)=rS\_{0}(t)dt,\;\;0\leq t\leq T, |  |

with risk-free rate r>0r>0 and dd risky assets are represented by the vector S=(S1,â€¦,Sd)âŠ¤S=\left(S\_{1},\ldots,S\_{d}\right)^{\top}. The dynamics of the risky assets follow the geometric Brownian motion: for i=1,â€¦,di=1,\ldots,d, Siâ€‹(0)>0S\_{i}(0)>0 and

|  |  |  |
| --- | --- | --- |
|  | dâ€‹Siâ€‹(t)=Siâ€‹(t)â€‹[biâ€‹dâ€‹t+âˆ‘j=1dÏƒiâ€‹jâ€‹dâ€‹Wjâ€‹(t)],â€„â€„0â‰¤tâ‰¤T.dS\_{i}(t)=S\_{i}(t)\left[b\_{i}dt+\sum\_{j=1}^{d}\sigma\_{ij}dW\_{j}(t)\right],\;\;0\leq t\leq T. |  |

A portfolio (or control, or policy) is a stochastic process Ï€={Ï€â€‹(t)}tâˆˆ[0,T]\pi=\{\pi(t)\}\_{t\in[0,T]} such that for a fixed tâˆˆ[0,T]t\in[0,T], Ï€â€‹(t)=(Ï€1â€‹(t),â€¦,Ï€dâ€‹(t))âŠ¤\pi(t)=\left(\pi\_{1}(t),\ldots,\pi\_{d}(t)\right)^{\top} and Ï€iâ€‹(t)\pi\_{i}(t) represents the amount of money invested in the iith stock at time tt. This induces the dynamics of a controlled wealth process with Xâ€‹(0)=x0X(0)=x\_{0} (we simplify the notation so that XÏ€X^{\pi} is written as XX)

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Xâ€‹(t)=râ€‹Xâ€‹(t)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹(bâˆ’râ€‹ğŸ)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹Ïƒâ€‹dâ€‹Wâ€‹(t),dX(t)=rX(t)dt+\pi(t)^{\top}\left(b-r\mathbf{1}\right)dt+\pi(t)^{\top}\sigma dW(t), |  | (1) |

where ğŸ=(1,â€¦,1)âŠ¤\mathbf{1}=\left(1,\ldots,1\right)^{\top} is the vector of all 1.
We call an â„±\mathcal{F}-progressively measurable (under â„™\mathbb{P} up to â„™\mathbb{P}-null sets) stochastic processes (control) Ï€={Ï€â€‹(t)}tâˆˆ[0,T]\pi=\{\pi(t)\}\_{t\in[0,T]} admissible if Xâ€‹(0)=x0X(0)=x\_{0}, âˆ«0Tâ€–Ï€â€‹(t)â€–22â€‹ğ‘‘t<âˆ\int\_{0}^{T}\left\|\pi(t)\right\|\_{2}^{2}dt<\infty â„™\mathbb{P}-almost surely, and
Equation ([1](https://arxiv.org/html/2512.01408v1#S2.E1 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) admits a unique strong solution with Xâ€‹(t)>0X(t)>0 for any tâˆˆ[0,T]t\in[0,T]. The collection of all admissible controls is denoted by ğ’œâ€‹(x0)\mathcal{A}(x\_{0}).

The objective function of Mertonâ€™s problem is Vâ€‹(x0)=supÏ€âˆˆğ’œâ€‹(x0)ğ”¼â„™â€‹[Uâ€‹(Xâ€‹(T))],V(x\_{0})=\sup\_{\pi\in\mathcal{A}(x\_{0})}\mathbb{E}\_{\mathbb{P}}\left[U(X(T))\right],
where UU is the utility function. We will specify the utility in Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") later. Using techniques from dynamic programming, Mertonâ€™s problem admits a closed-form formula of the optimal strategy Ï€\pi. In practice, the parameters bb and Ïƒ\sigma are estimated from the market data with statistical techniques (e.g., maximum likelihood estimation), and then these estimations are plugged into the closed-form solutions.

However, in practice, estimating bb is difficult at the horizons of interest. To address this, [KZ98] introduces a partially observed Bayesian variant: we keep the same probability space but model the instantaneous return as an unobservable random vector B:Î©â†’â„dB:\Omega\to\mathbb{R}^{d}, independent of WW under â„™\mathbb{P}, with prior distribution Î¼\mu. The price dynamics become the same SDE with bb replaced by BB:

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Siâ€‹(t)=Siâ€‹(t)â€‹[Biâ€‹dâ€‹t+âˆ‘j=1dÏƒiâ€‹jâ€‹dâ€‹Wjâ€‹(t)],â€„â€„0â‰¤tâ‰¤T,dS\_{i}(t)=S\_{i}(t)\left[B\_{i}dt+\sum\_{j=1}^{d}\sigma\_{ij}dW\_{j}(t)\right],\;\;0\leq t\leq T, |  | (2) |

Equivalently, under â„™\mathbb{P}, Bâˆ¼Î¼B\sim\mu (some probability measure) and BB is independent of WW; we refer to Î¼\mu as the prior. We write ğ’©â€‹(m,Î£)\mathcal{N}(m,\Sigma) for a Gaussian law with mean mm and covariance Î£\Sigma, and Ï†s\varphi\_{s} for the density of ğ’©â€‹(0,sâ€‹Id)\mathcal{N}(0,sI\_{d}).

We denote the natural filtration of the process SS by â„±S\mathcal{F}^{S} and denote the â„™\mathbb{P}-augmentation of â„±S\mathcal{F}^{S} by â„±â„™S\mathcal{F}^{S}\_{\mathbb{P}} and this right-continuous and completion is the observation filtration. The decisions are made based on only information from stocks. That is, in this case, the admissible controls are restricted to those that are â„±â„™S\mathcal{F}^{S}\_{\mathbb{P}}-progressively measurable and satisfy the same assumptions of integrability and SDE as before.

The full information of the Brownian motion and the random vector is encoded in the â„™\mathbb{P}-augmentation of the enlarged filtration ğ’¢B,W={ğ’¢B,Wâ€‹(t)}tâ‰¥0\mathcal{G}^{B,W}=\{\mathcal{G}^{B,W}(t)\}\_{t\geq 0} with

|  |  |  |
| --- | --- | --- |
|  | ğ’¢B,Wâ€‹(t)=Ïƒâ€‹(B,Wâ€‹(s),0â‰¤sâ‰¤t)=Ïƒâ€‹(B)âˆ¨â„±Wâ€‹(t),\mathcal{G}^{B,W}(t)=\sigma\left(B,W(s),0\leq s\leq t\right)=\sigma(B)\vee\mathcal{F}^{W}(t), |  |

where we denote this augmentation as ğ’¢\mathcal{G}.
Therefore, for each tâ‰¥0,â„±â„™Sâ€‹(t)âŠ‚ğ’¢â€‹(t)t\geq 0,\mathcal{F}^{S}\_{\mathbb{P}}(t)\subset\mathcal{G}(t), where the inclusion can be strict. The wealth dynamic is

|  |  |  |  |
| --- | --- | --- | --- |
|  | dâ€‹Xâ€‹(t)=râ€‹Xâ€‹(t)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹(Bâˆ’râ€‹ğŸ)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹Ïƒâ€‹dâ€‹Wâ€‹(t).dX(t)=rX(t)dt+\pi(t)^{\top}\left(B-r\mathbf{1}\right)dt+\pi(t)^{\top}\sigma dW(t). |  | (3) |

We call an â„±â„™S\mathcal{F}^{S}\_{\mathbb{P}}-progressively measurable (under â„™\mathbb{P} up to â„™\mathbb{P}-null sets) stochastic processes (control) Ï€={Ï€â€‹(t)}tâˆˆ[0,T]\pi=\{\pi(t)\}\_{t\in[0,T]} admissible if Xâ€‹(0)=x0X(0)=x\_{0}, âˆ«0Tâ€–Ï€â€‹(t)â€–22â€‹ğ‘‘t<âˆ\int\_{0}^{T}\left\|\pi(t)\right\|\_{2}^{2}dt<\infty â„™\mathbb{P}-almost surely, and
Equation ([3](https://arxiv.org/html/2512.01408v1#S2.E3 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) admits a unique strong solution with Xâ€‹(t)>0X(t)>0 for any tâˆˆ[0,T]t\in[0,T]. The collection of all admissible controls is denoted as ğ’œâ€‹(x0)\mathcal{A}(x\_{0}).
The Bayesian diffusion control problem is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Vâ€‹(x0)=supÏ€âˆˆğ’œâ€‹(x0)ğ”¼â„™â€‹[Uâ€‹(Xâ€‹(T))].V(x\_{0})=\sup\_{\pi\in\mathcal{A}(x\_{0})}\mathbb{E}\_{\mathbb{P}}\left[U(X(T))\right]. |  | (4) |

We will study a general utility family shown in Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

###### Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]).

(1) The utility function U:(0,âˆ)â†’â„U:(0,\infty)\to\mathbb{R} is twice continuously differentiable,
strictly concave, strictly increasing, and satisfies a polynomial growth condition:
there exist constants CU>0C\_{U}>0 and pU>0p\_{U}>0 such that

|  |  |  |
| --- | --- | --- |
|  | |U(x)|â‰¤CU(1+max{x,xâˆ’1}pU),x>0.|U(x)|\;\leq\;C\_{U}\Bigl(1+\max\{x,\,x^{-1}\}^{p\_{U}}\Bigr),\qquad x>0. |  |

(2) Define the conjugate function Iâ€‹(â‹…)=(Uâ€²)âˆ’1â€‹(â‹…)I(\cdot)=(U^{\prime})^{-1}(\cdot), which is strictly convex and decreasing.
We assume that II and its derivative satisfy a twoâ€“sided polynomial growth bound, and that
II does not decay too fast at infinity: there exist constants CI>0C\_{I}>0, cI>0c\_{I}>0, and pI>0p\_{I}>0 such that

|  |  |  |
| --- | --- | --- |
|  | |I(y)|+|Iâ€²(y)|â‰¤CI(1+max{y,yâˆ’1}pI),y>0,|I(y)|+|I^{\prime}(y)|\;\leq\;C\_{I}\Bigl(1+\max\{y,\,y^{-1}\}^{p\_{I}}\Bigr),\qquad y>0, |  |

and

|  |  |  |
| --- | --- | --- |
|  | Iâ€‹(y)â‰¥cIâ€‹yâˆ’pI,y>0.I(y)\;\geq\;c\_{I}\,y^{-p\_{I}},\qquad y>0. |  |

###### Remark 1.

The growth conditions for UU and for I=(Uâ€²)âˆ’1I=(U^{\prime})^{-1} are stated separately because
bounds on UU do not in general imply corresponding bounds on Uâ€²U^{\prime} or on II.
Nevertheless, for all standard utility functions used in applications
(such as power/CRRA and logarithmic utility), both parts of
Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") are satisfied.

We now introduce the objects needed to state the Bayesian solution. Define
Fâ€‹(t,y):=FÎ¼â€‹(t,y):=âˆ«â„dLtâ€‹(b,y)â€‹Î¼â€‹(dâ€‹b)=ğ”¼Î¼â€‹[LTâ€‹(B,y)]F(t,y):=F\_{\mu}(t,y):=\int\_{\mathbb{R}^{d}}L\_{t}(b,y)\mu(db)=\mathbb{E}\_{\mu}[L\_{T}(B,y)]
with

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ltâ€‹(b,y)=expâ¡(âŸ¨Ïƒâˆ’1â€‹(bâˆ’râ€‹ğŸ),yâŸ©âˆ’12â€‹â€–Ïƒâˆ’1â€‹(bâˆ’râ€‹ğŸ)â€–2â€‹t),tâˆˆ(0,âˆ),bâˆˆâ„d,yâˆˆâ„d.L\_{t}(b,y)=\exp\left(\langle\sigma^{-1}(b-r\mathbf{1}),y\rangle-\frac{1}{2}\|\sigma^{-1}(b-r\mathbf{1})\|^{2}t\right),\;\;t\in(0,\infty),\;b\in\mathbb{R}^{d},\;y\in\mathbb{R}^{d}. |  | (5) |

For k>0k>0, sâˆˆ[0,T]s\in[0,T], and yâˆˆâ„dy\in\mathbb{R}^{d}, set

|  |  |  |  |
| --- | --- | --- | --- |
|  | Lâ€‹(k;s,y):={eâˆ’râ€‹sâ€‹âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹TFâ€‹(T,y+z))â€‹Ï†sâ€‹(z)â€‹ğ‘‘z,s>0,Iâ€‹(kâ€‹eâˆ’râ€‹TFâ€‹(T,y)),s=0.L(k;s,y):=\begin{cases}e^{-rs}\displaystyle\int\_{\mathbb{R}^{d}}I\!\left(\frac{ke^{-rT}}{F(T,y+z)}\right)\varphi\_{s}(z)\,dz,&s>0,\\[11.99998pt] I\!\left(\frac{ke^{-rT}}{F(T,y)}\right),&s=0.\end{cases} |  | (6) |

To simplify tedious technical discussions, we assume that the drift variable BB is compactly supported (Assumption [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). We provide more technical discussions under specific utilities with relaxed concentration assumptions of BB in supplementary materials.

###### Assumption 2 (Compact Support for BB).

The random variable BB is compactly supported in Mertonâ€™s model. Specifically, there exists a compact set KâŠ‚â„dK\subset\mathbb{R}^{d} such that Î¼â€‹(BâˆˆK)=1\mu(B\in K)=1 for all possible Î¼\mu.

Under this setting, a standard Gaussian integral computation yields the following lemma.

###### Lemma 1.

Under Assumptions [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the map LL in ([6](https://arxiv.org/html/2512.01408v1#S2.E6 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is finite for all (k,s,y)âˆˆ(0,âˆ)Ã—[0,T]Ã—â„d(k,s,y)\in(0,\infty)\times[0,T]\times\mathbb{R}^{d}, continuously differentiable in (k,s,y)(k,s,y) on (0,âˆ)Ã—(0,T]Ã—â„d(0,\infty)\times(0,T]\times\mathbb{R}^{d}, and twice continuously differentiable in (k,y)(k,y) on (0,âˆ)Ã—[0,T]Ã—â„d(0,\infty)\times[0,T]\times\mathbb{R}^{d}.

According to [KZ98], under Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the strictly decreasing function

|  |  |  |  |
| --- | --- | --- | --- |
|  | kâ†¦eâˆ’râ€‹Tâ€‹âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹TFâ€‹(T,z))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z=Lâ€‹(k;T,0)\displaystyle k\mapsto e^{-rT}\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{F(T,z)}\right)\varphi\_{T}(z)dz=L(k;T,0) |  | (7) |

is continuous and maps (0,âˆ)(0,\infty) onto itself. Thus, the equation Lâ€‹(k;T,0)=x0L(k;T,0)=x\_{0} is satisfied for a unique constant ğ’¦â€‹(x0)âˆˆ(0,âˆ)\mathcal{K}(x\_{0})\in(0,\infty).

The optimal solution is summarized in the following two results, first for the value function and later for the optimal strategy (i.e., the portfolio weights at every point in time); these results restate the characterization in [KZ98] in our notation and compact form, and will be used repeatedly in our development.

###### Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution).

Suppose that Assumptions [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") hold.

(1) The optimal value function of Problem ([4](https://arxiv.org/html/2512.01408v1#S2.E4 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is given by

|  |  |  |
| --- | --- | --- |
|  | Vâ€‹(x0)=âˆ«â„dFâ€‹(T,z)â€‹Uâ€‹(Iâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z)))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z,V(x\_{0})=\int\_{\mathbb{R}^{d}}F(T,z)U\left(I\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z)}\right)\right)\varphi\_{T}(z)dz, |  |

where ğ’¦â€‹(x0)>0\mathcal{K}(x\_{0})>0 is the unique solution to the budget constraint:

|  |  |  |  |
| --- | --- | --- | --- |
|  | x0â€‹erâ€‹T=âˆ«â„dIâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z.x\_{0}e^{rT}=\int\_{\mathbb{R}^{d}}I\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z)}\right)\varphi\_{T}(z)dz. |  | (8) |

In particular, for power utility Uâ€‹(x)=xÎ±/Î±U(x)=x^{\alpha}/\alpha, this reduces to the classical Karatzasâ€“Zhao [KZ98]â€™s formula:

|  |  |  |
| --- | --- | --- |
|  | Vâ€‹(x0)=(x0â€‹erâ€‹T)Î±Î±â€‹(âˆ«â„dFâ€‹(T,z)11âˆ’Î±â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z)1âˆ’Î±.V(x\_{0})=\frac{(x\_{0}e^{rT})^{\alpha}}{\alpha}\left(\int\_{\mathbb{R}^{d}}F(T,z)^{\frac{1}{1-\alpha}}\varphi\_{T}(z)dz\right)^{1-\alpha}. |  |

(2) The optimal fractions invested in each stock at time tâˆˆ[0,T]t\in[0,T] are given by the vector

|  |  |  |
| --- | --- | --- |
|  | Ï€âˆ—â€‹(t)Xâˆ—â€‹(t)=(ÏƒâŠ¤)âˆ’1â€‹(âˆ’ğ’¦â€‹(x0))â€‹eâˆ’râ€‹Tâ‹…âˆ«â„dâˆ‡zFâ€‹(T,z+Yâ€‹(t))Fâ€‹(T,z+Yâ€‹(t))2â‹…Iâ€²â€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+Yâ€‹(t)))â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘zâˆ«â„dIâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+Yâ€‹(t)))â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘z,\frac{\pi^{\*}(t)}{X^{\*}(t)}={\left(\sigma^{\top}\right)}^{-1}(-\mathcal{K}(x\_{0}))e^{-rT}\cdot\frac{\int\_{\mathbb{R}^{d}}\frac{\nabla\_{z}F\left(T,z+Y(t)\right)}{F\left(T,z+Y(t)\right)^{2}}\cdot I^{\prime}\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+Y(t))}\right)\varphi\_{T-t}(z)dz}{\int\_{\mathbb{R}^{d}}I\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+Y(t))}\right)\varphi\_{T-t}(z)dz}, |  |

where Yâ€‹(t)=Ïƒâˆ’1â€‹(Bâˆ’râ€‹ğŸ)â€‹t+Wâ€‹(t)Y(t)=\sigma^{-1}(B-r\mathbf{1})t+W(t), tâˆˆ[0,T]t\in[0,T]. Note that the filtration generated by {Yâ€‹(t)}tâˆˆ[0,T]\{Y(t)\}\_{t\in[0,T]} is equal to â„±S\mathcal{F}^{S} under â„™\mathbb{P}.

In particular, for power utility Uâ€‹(x)=xÎ±/Î±U(x)=x^{\alpha}/\alpha, this reduces to the classical formula:

|  |  |  |
| --- | --- | --- |
|  | Ï€âˆ—â€‹(t)Xâˆ—â€‹(t)=(ÏƒâŠ¤)âˆ’1â‹…âˆ«â„dâˆ‡zFâ€‹(T,z+Yâ€‹(t))â‹…Fâ€‹(T,z+Yâ€‹(t))Î±1âˆ’Î±â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘z(1âˆ’Î±)â€‹âˆ«â„dFâ€‹(T,z+Yâ€‹(t))11âˆ’Î±â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘z.\frac{\pi^{\*}(t)}{X^{\*}(t)}={\left(\sigma^{\top}\right)}^{-1}\cdot\frac{\int\_{\mathbb{R}^{d}}\nabla\_{z}F\left(T,z+Y(t)\right)\cdot F\left(T,z+Y(t)\right)^{\frac{\alpha}{1-\alpha}}\varphi\_{T-t}(z)dz}{(1-\alpha)\int\_{\mathbb{R}^{d}}F\left(T,z+Y(t)\right)^{\frac{1}{1-\alpha}}\varphi\_{T-t}(z)dz}. |  |

In practice, the prior distribution is chosen by experts and other available information, and the fraction of investment into risky assets is computed via the formula provided by Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") plugging in the observations of stock prices, normalizing the weight to maintain self-financing.

## 3 Formulation and Main Structural Results

In this section, we introduce our formulation of distributionally robust Bayesian control (DRBC) of Mertonâ€™s problem, compare it with the classical distributionally robust control (DRC) methods, and show the tractability of the DRBC formulation. We focus on optimal transport based uncertainty sets and, as mentioned in the Introduction, we will revisit Ï•\phi-divergence extensions in a later section. The work of [Blanchet2025Duality] considers duality results for DRBC with Ï•\phi-divergence uncertainty. In this setting, the admissible controls are still defined as â„±â„™0S\mathcal{F}^{S}\_{\mathbb{P}\_{0}}-progressively measurable since all other probability measures â„š\mathbb{Q} in the uncertainty set are absolutely continuous to â„™0\mathbb{P}\_{0}, and thus the formulation is still well-defined. However, this is not immediate in the Wasserstein uncertainty case that we study here, so some care is needed to handle this.

We use DcD\_{c} to denote the optimal transport discrepancy generated by cc (equivalent to the Wasserstein distance when cc is a metric), as we now describe. Precisely, let
ğ’«â€‹(â„dÃ—â„d)\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}) be the space of Borel
probability measures supported on â„dÃ—â„d\mathbb{R}^{d}\times\mathbb{R}^{d}. A
given element Ï…âˆˆğ’«â€‹(â„dÃ—â„d)\upsilon\in\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}) is
associated to a random vector (U,V)\left(U,V\right), where Uâˆˆâ„dU\in\mathbb{R}^{d} and Vâˆˆâ„dV\in\mathbb{R}^{d}, in the following way: Ï…Uâ€‹(A)=Ï…â€‹(AÃ—â„d)\upsilon\_{U}\left(A\right)=\upsilon\left(A\times\mathbb{R}^{d}\right) and Ï…Vâ€‹(A)=Ï…â€‹(â„dÃ—A)\upsilon\_{V}\left(A\right)=\upsilon\left(\mathbb{R}^{d}\times A\right) for every
Borel set AâŠ‚â„dA\subset\mathbb{R}^{d}, where Ï…U\upsilon\_{U} and Ï…V\upsilon\_{V}
respectively denote the mariginal distributions of UU and VV under Ï…\upsilon.

To define DcD\_{c}, we need to introduce a cost function c:â„dÃ—â„dâ†’[0,âˆ]c:\mathbb{R}^{d}\times\mathbb{R}^{d}\rightarrow[0,\infty], which we shall assume to be lower
semicontinuous and such that câ€‹(u,u)=0c\left(u,u\right)=0 for any uâˆˆâ„du\in\mathbb{R}^{d}. Finally, given two probability distribution â„™\mathbb{P} and â„š\mathbb{Q} supported on
â„d\mathbb{R}^{d} and a cost function cc, define

|  |  |  |  |
| --- | --- | --- | --- |
|  | Dcâ€‹(â„™,â„š):=inf{ğ”¼Ï…â€‹[câ€‹(U,V)]:Ï…âˆˆğ’«â€‹(â„dÃ—â„d),Ï…U=â„™,Ï…V=â„š},D\_{c}(\mathbb{P},\mathbb{Q}):=\inf\{\mathbb{E}\_{\upsilon}[c(U,V)]:\upsilon\in\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}),\upsilon\_{U}=\mathbb{P},\upsilon\_{V}=\mathbb{Q}\}, |  | (9) |

which can be interpreted as the optimal (minimal) transportation cost of
moving the mass from â„™\mathbb{P} into the mass of â„š\mathbb{Q} under a cost câ€‹(x,y)c\left(x,y\right) per unit of mass transported from xx to yy. If for a given
Ïâ‰¥1\rho\geq 1, c1/Ïâ€‹(â‹…)c^{1/\rho}\left(\cdot\right) is a metric, then Dc1/ÏD\_{c}^{1/\rho} defines a metric on probability measures (the Wasserstein distance of order Ï\rho); see [villani2008optimal].
Throughout the rest of the paper, we will choose cost
function câ€‹(u,v)=â€–vâˆ’uâ€–22c(u,v)=||v-u||\_{2}^{2} when BB is compactly supported. The discussion of other choices of the cost functions will be discussed in supplementary materials.

To rigorously define the DRBC formulation, we need to make sure only the distribution of BB is changed and all other problem structures (e.g., the adaptedness of the controls, the distribution of the other sources of randomness, independence structures, and integrability conditions) are kept the same.
To preserve the structure of the original partial observation problem, we keep track only of the joint law of (B,W)(B,W) and maintain their independence. We place the model on the canonical product space Î©=â„dÃ—Câ€‹([0,T];â„d)\Omega=\mathbb{R}^{d}\times C([0,T];\mathbb{R}^{d}) equipped with the Borel Ïƒ\sigma-algebra â„¬â€‹(Î©)\mathcal{B}(\Omega), with canonical coordinates (B,W)(B,W) and write S=Sâ€‹(B,W)S=S(B,W) for the price process. We let â„™W\mathbb{P}\_{W} be the Wiener measure on the space Câ€‹([0,T];â„d)C\left([0,T];\mathbb{R}^{d}\right) and denote the prior distribution of BB as â„™0\mathbb{P}\_{0} (satisfying Assumption [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). The observation filtration is fixed once and for all as

|  |  |  |
| --- | --- | --- |
|  | â„±S(t):=Ïƒ(S(u):0â‰¤uâ‰¤t)âˆ¨ğ’©,\mathcal{F}^{S}(t):=\sigma\big(S(u):0\leq u\leq t\big)\vee\mathcal{N}, |  |

where ğ’©\mathcal{N} collects the null sets, and it does not depend on the choice of the nominal prior â„™0\mathbb{P}\_{0} (nor on Î¼\mu in the ambiguity set). The reason is that the distributions of Yâ€‹(t;b)=bâ€‹t+Ïƒâˆ’1â€‹Wâ€‹(t)Y(t;b)=bt+\sigma^{-1}W(t) share the same sets of measure zero for each bb in the canonical space. Admissible controls are processes that are progressively measurable with respect to {â„±Sâ€‹(t)}tâˆˆ[0,T]\{\mathcal{F}^{S}(t)\}\_{t\in[0,T]} and satisfy the usual integrability/positivity conditions. This setup ensures that robustness only changes the prior on BB while leaving the information structure unchanged.

Now we define â„™:=â„™0âŠ—â„™W\mathbb{P}:=\mathbb{P}\_{0}\otimes\mathbb{P}\_{W}.
The Wasserstein uncertainty set with a radius Î´>0\delta>0 is defined as:

|  |  |  |
| --- | --- | --- |
|  | ğ’°Î´OTâ€‹(â„™0):={â„š=Î¼âŠ—â„™W:Dcâ€‹(Î¼,â„™0)â‰¤Î´â€‹Â andÂ Î¼Â satisfies AssumptionÂ [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")},\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}):=\left\{\mathbb{Q}=\mu\otimes\mathbb{P}\_{W}:D\_{c}(\mu,\mathbb{P}\_{0})\leq\delta\text{ and $\mu$ satisfies Assumption \ref{ass:compact\_B}}\right\}, |  |

where we assume in the following that the prior measure and all adversarial measures have a compact support.
We now define the admissible controls by the stochastic process Ï€:[0,T]Ã—Î©â†’â„d\pi:[0,T]\times\Omega\to\mathbb{R}^{d} such that

* â€¢

  (a) Ï€\pi is â„±S\mathcal{F}^{S}-progressively measurable with cÃ dlÃ g paths.
* â€¢

  (b) The SDE

  |  |  |  |
  | --- | --- | --- |
  |  | dâ€‹Xâ€‹(t)=râ€‹Xâ€‹(t)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹(Bâˆ’râ€‹ğŸ)â€‹dâ€‹t+Ï€â€‹(t)âŠ¤â€‹Ïƒâ€‹dâ€‹Wâ€‹(t)dX(t)=rX(t)dt+\pi(t)^{\top}\left(B-r\mathbf{1}\right)dt+\pi(t)^{\top}\sigma dW(t) |  |

  admits a unique weak solution such that Xâ€‹(t)>0X(t)>0 for any tâˆˆ[0,T]t\in[0,T].
* â€¢

  (c) âˆ«0Tâ€–Ï€â€‹(t)â€–22â€‹ğ‘‘t<âˆ\int\_{0}^{T}\|\pi(t)\|\_{2}^{2}dt<\infty â„™\mathbb{P}-a.s.

The collection of all admissible controls is denoted as ğ’œâ€‹(x0)\mathcal{A}(x\_{0}) for the case when Xâ€‹(0)=x0X(0)=x\_{0}. The DRBC problem is defined by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Vâ€‹(x0)=supÏ€âˆˆğ’œâ€‹(x0)infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[UÏ€â€‹(Xâ€‹(T))]V(x\_{0})=\sup\_{\pi\in\mathcal{A}(x\_{0})}\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}\left[U^{\pi}(X(T))\right] |  | (10) |

and denote the optimal solution of Problem ([10](https://arxiv.org/html/2512.01408v1#S3.E10 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) as Ï€DRBC\pi\_{\text{DRBC}}.

As discussed in [Blanchet2025Duality], Problem ([10](https://arxiv.org/html/2512.01408v1#S3.E10 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is typically not directly tractable in its original form. To solve the problem, [Blanchet2025Duality] discusses several techniques, such as discretizing the prior distribution in the context of KL-uncertainty sets or applying simulation techniques that may be time-consuming. However, exploiting the special structure of the Merton problem, under reasonable assumptions, we can derive the following theorem, which will significantly simplify approximating the solution to Problem ([10](https://arxiv.org/html/2512.01408v1#S3.E10 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")).

###### Theorem 2 (Min-Max Equality).

Under Assumptions [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), for any initial wealth x0>0x\_{0}>0, the following min-max equality holds:

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’œâ€‹(x0)infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]=infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supÏ€âˆˆğ’œâ€‹(x0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))].\sup\_{\pi\in\mathcal{A}(x\_{0})}\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]=\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\sup\_{\pi\in\mathcal{A}(x\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]. |  |

###### Proof.

We prove the theorem in four steps, leveraging the compact support of BB and the structure of the utility function.

Step 1: Weak duality. The inequality supÏ€infâ„šâ‰¤infâ„šsupÏ€\sup\_{\pi}\inf\_{\mathbb{Q}}\leq\inf\_{\mathbb{Q}}\sup\_{\pi} holds by definition (weak duality). To upgrade the reverse inequality, we introduce the subset

|  |  |  |
| --- | --- | --- |
|  | ğ’œâ€²â€‹(x0):={Ï€âˆˆğ’œâ€‹(x0):dâ€‹(Ï€,0)<âˆ},Â whereÂ â€‹dâ€‹(Ï€,Ï€â€²):=supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)(ğ”¼â„šâ€‹[âˆ«0Tâ€–Ï€â€‹(t)âˆ’Ï€â€²â€‹(t)â€–2â€‹ğ‘‘t])1/2,\mathcal{A}^{\prime}(x\_{0}):=\Big\{\pi\in\mathcal{A}(x\_{0}):d(\pi,0)<\infty\Big\},\text{ where }d(\pi,\pi^{\prime}):=\sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\left(\mathbb{E}\_{\mathbb{Q}}\left[\int\_{0}^{T}\|\pi(t)-\pi^{\prime}(t)\|^{2}dt\right]\right)^{1/2}, |  |

which equips the class of L2L^{2}-admissible policies with the topology induced by the L2L^{2}-norm. As ğ’œâ€²â€‹(x0)âŠ‚ğ’œâ€‹(x0)\mathcal{A}^{\prime}(x\_{0})\subset\mathcal{A}(x\_{0}), we have

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’œâ€‹(x0)infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]â‰¥supÏ€âˆˆğ’œâ€²â€‹(x0)infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))].\sup\_{\pi\in\mathcal{A}(x\_{0})}\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]\;\geq\;\sup\_{\pi\in\mathcal{A}^{\prime}(x\_{0})}\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]. |  |

In the next steps, we establish the corresponding reverse inequality for ğ’œâ€²â€‹(x0)\mathcal{A}^{\prime}(x\_{0}). The final step (discussed later) will verify that the optimizer obtained at the end of the analysis belongs to ğ’œâ€²â€‹(x0)\mathcal{A}^{\prime}(x\_{0}), thereby closing the gap.

Step 2: Variation of constants and continuity in the model.
Let KâŠ‚â„dK\subset\mathbb{R}^{d} be the compact support guaranteed by Assumption [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), fix Ï€âˆˆğ’œâ€²â€‹(x0)\pi\in\mathcal{A}^{\prime}(x\_{0}), and note that the linear wealth dynamics yield the variation-of-constants formula

|  |  |  |  |
| --- | --- | --- | --- |
|  | XÏ€â€‹(T;b,W)=x0â€‹erâ€‹T+erâ€‹Tâ€‹âˆ«0Teâˆ’râ€‹sâ€‹Ï€â€‹(s)âŠ¤â€‹(bâˆ’râ€‹ğŸ)â€‹ğ‘‘s+erâ€‹Tâ€‹âˆ«0Teâˆ’râ€‹sâ€‹Ï€â€‹(s)âŠ¤â€‹Ïƒâ€‹ğ‘‘Wâ€‹(s),X^{\pi}(T;b,W)=x\_{0}e^{rT}+e^{rT}\int\_{0}^{T}e^{-rs}\pi(s)^{\top}(b-r\mathbf{1})\,ds+e^{rT}\int\_{0}^{T}e^{-rs}\pi(s)^{\top}\sigma\,dW(s), |  | (11) |

which is affine in bb for every realization of WW.
For bâˆˆKb\in K, define

|  |  |  |
| --- | --- | --- |
|  | gÏ€â€‹(b):=ğ”¼â„™Wâ€‹[Uâ€‹(XÏ€â€‹(T))âˆ£B=b],g\_{\pi}(b):=\mathbb{E}\_{\mathbb{P}^{W}}\left[U\left(X^{\pi}(T)\right)\mid B=b\right], |  |

where the conditional expectation is taken only with respect to the Brownian motion WW.
Equation ([11](https://arxiv.org/html/2512.01408v1#S3.E11 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) shows bâ†¦XÏ€â€‹(T;b,Wâ€‹(Ï‰))b\mapsto X^{\pi}(T;b,W(\omega)) is continuous for every Ï‰\omega, and therefore the same holds for bâ†¦Uâ€‹(XÏ€â€‹(T;b,Wâ€‹(Ï‰)))b\mapsto U(X^{\pi}(T;b,W(\omega))).

We now justify interchanging limit and expectation. Because Ï€âˆˆğ’œâ€²â€‹(x0)\pi\in\mathcal{A}^{\prime}(x\_{0}), there exists MÏ€<âˆM\_{\pi}<\infty such that supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[âˆ«0Tâ€–Ï€â€‹(s)â€–2â€‹ğ‘‘s]â‰¤MÏ€.\sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}\!\left[\int\_{0}^{T}\|\pi(s)\|^{2}ds\right]\leq M\_{\pi}.
Using the variation-of-constants formula ([11](https://arxiv.org/html/2512.01408v1#S3.E11 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), Jensenâ€™s inequality, and ItÃ´â€™s isometry, we obtain a constant CÏ€>0C\_{\pi}>0, independent of bâˆˆKb\in K, such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â„šâ€‹[|XÏ€â€‹(T;b,W)|2+Îµ]â‰¤CÏ€for someÂ â€‹Îµ>0,\mathbb{E}\_{\mathbb{Q}}\!\left[\left|X^{\pi}(T;b,W)\right|^{2+\varepsilon}\right]\leq C\_{\pi}\qquad\text{for some }\varepsilon>0, |  | (12) |

uniformly over â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}) and bâˆˆKb\in K. The compactness of KK ensures
supbâˆˆKâ€–bâˆ’râ€‹ğŸâ€–<âˆ\sup\_{b\in K}\|b-r\mathbf{1}\|<\infty, so the deterministic term in ([11](https://arxiv.org/html/2512.01408v1#S3.E11 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is uniformly controlled in bb, while the stochastic integral does not depend on bb. Moreover, since the wealth dynamics are linear with bounded coefficients (in view of Assumption [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), standard estimates for linear SDEs imply that, for any m>0m>0, there exists CÏ€,m<âˆC\_{\pi,m}<\infty such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supbâˆˆKğ”¼â„šâ€‹[(XÏ€â€‹(T;b,W))âˆ’m]â‰¤CÏ€,m.\sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\ \sup\_{b\in K}\ \mathbb{E}\_{\mathbb{Q}}\!\left[\bigl(X^{\pi}(T;b,W)\bigr)^{-m}\right]\leq C\_{\pi,m}. |  | (13) |

In particular, combining ([12](https://arxiv.org/html/2512.01408v1#S3.E12 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) and ([13](https://arxiv.org/html/2512.01408v1#S3.E13 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) with the max-type growth in Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we may choose p>0p>0 and a constant CU>0C\_{U}>0 such that

|  |  |  |
| --- | --- | --- |
|  | |Uâ€‹(x)|â‰¤CUâ€‹(1+xp+xâˆ’p),x>0,|U(x)|\leq C\_{U}\bigl(1+x^{p}+x^{-p}\bigr),\qquad x>0, |  |

and hence there exists an integrable random variable YÏ€Y\_{\pi} (depending on Ï€\pi but not on bb) with

|  |  |  |
| --- | --- | --- |
|  | |Uâ€‹(XÏ€â€‹(T;b,W))|â‰¤YÏ€for allÂ â€‹bâˆˆK,â„šâˆˆğ’°Î´OTâ€‹(â„™0).|U\bigl(X^{\pi}(T;b,W)\bigr)|\leq Y\_{\pi}\qquad\text{for all }b\in K,\ \mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}). |  |

Therefore, if bnâ†’bb\_{n}\to b in KK, the pointwise continuity of bâ†¦XÏ€â€‹(T;b,W)b\mapsto X^{\pi}(T;b,W) and the dominated convergence theorem yield

|  |  |  |
| --- | --- | --- |
|  | gÏ€â€‹(bn)=ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T;bn,W))âˆ£B=bn]âŸ¶gÏ€â€‹(b)=ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T;b,W))âˆ£B=b].g\_{\pi}(b\_{n})\;=\;\mathbb{E}\_{\mathbb{Q}}\!\left[U\bigl(X^{\pi}(T;b\_{n},W)\bigr)\mid B=b\_{n}\right]\;\longrightarrow\;g\_{\pi}(b)\;=\;\mathbb{E}\_{\mathbb{Q}}\!\left[U\bigl(X^{\pi}(T;b,W)\bigr)\mid B=b\right]. |  |

Thus gÏ€g\_{\pi} is continuous on the compact set KK.
Every â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}) shares the same law for WW and has a marginal distribution of BB supported in KK. Hence, for fixed Ï€\pi,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]=âˆ«KgÏ€â€‹(b)â€‹â„šBâ€‹(dâ€‹b),\mathbb{E}\_{\mathbb{Q}}\!\left[U(X^{\pi}(T))\right]=\int\_{K}g\_{\pi}(b)\,\mathbb{Q}\_{B}(db), |  |

and the right-hand side depends continuously on â„šB\mathbb{Q}\_{B} under the weak topology because gÏ€g\_{\pi} is continuous and bounded on KK.
This proves the desired continuity in the model variable.

Step 3: Concavity and continuity in the control.
For fixed â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}), the map
Ï€â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\pi\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is concave because UU is concave
and the state equation is affine in Ï€\pi.

To show continuity on (ğ’œâ€²â€‹(x0),d)(\mathcal{A}^{\prime}(x\_{0}),d), let Ï€nâ†’Ï€\pi\_{n}\to\pi in the topology
induced by dd, and set Î”â€‹Ï€â€‹(t)=Ï€nâ€‹(t)âˆ’Ï€â€‹(t)\Delta\pi(t)=\pi\_{n}(t)-\pi(t). Subtracting the
representations ([11](https://arxiv.org/html/2512.01408v1#S3.E11 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) for Ï€n\pi\_{n} and Ï€\pi, taking quadratic moments,
and using (a1+a2)2â‰¤2â€‹a12+2â€‹a22(a\_{1}+a\_{2})^{2}\leq 2a\_{1}^{2}+2a\_{2}^{2}, we obtain

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„šâ€‹[|XÏ€nâ€‹(T)âˆ’XÏ€â€‹(T)|2]â‰¤Câ€‹ğ”¼â„šâ€‹[âˆ«0Tâ€–Î”â€‹Ï€â€‹(s)â€–2â€‹ğ‘‘s],\mathbb{E}\_{\mathbb{Q}}\!\big[|X^{\pi\_{n}}(T)-X^{\pi}(T)|^{2}\big]\;\leq\;C\,\mathbb{E}\_{\mathbb{Q}}\!\left[\int\_{0}^{T}\|\Delta\pi(s)\|^{2}ds\right], |  |

where C=2â€‹e2â€‹râ€‹Tâ€‹(Tâ€‹supbâˆˆKâ€–bâˆ’râ€‹ğŸâ€–2+â€–Ïƒâ€‹ÏƒâŠ¤â€–op)C=2e^{2rT}\Big(T\sup\_{b\in K}\|b-r\mathbf{1}\|^{2}\;+\;\|\sigma\sigma^{\top}\|\_{\mathrm{op}}\Big)
is independent of â„š\mathbb{Q}. Since dâ€‹(Ï€n,Ï€)â†’0d(\pi\_{n},\pi)\to 0, the right-hand side
converges to zero uniformly over â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}).
Hence XÏ€nâ€‹(T)â†’XÏ€â€‹(T)inÂ â€‹L2â€‹(â„š)X^{\pi\_{n}}(T)\to X^{\pi}(T)\quad\text{in }L^{2}(\mathbb{Q}) (and thus in probability)
uniformly over â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}).

Next we establish uniform integrability.
Because Ï€âˆˆğ’œâ€²â€‹(x0)\pi\in\mathcal{A}^{\prime}(x\_{0}) and dâ€‹(Ï€n,Ï€)â†’0d(\pi\_{n},\pi)\to 0, there exists
M<âˆM<\infty such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | supnâ‰¥1supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[âˆ«0Tâ€–Ï€nâ€‹(s)â€–2â€‹ğ‘‘s]â‰¤M.\sup\_{n\geq 1}\ \sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}\!\left[\int\_{0}^{T}\|\pi\_{n}(s)\|^{2}ds\right]\leq M. |  | (14) |

Indeed, for each nn,

|  |  |  |
| --- | --- | --- |
|  | âˆ«0Tâ€–Ï€nâ€‹(s)â€–2â€‹ğ‘‘sâ‰¤â€„2â€‹âˆ«0Tâ€–Ï€â€‹(s)â€–2â€‹ğ‘‘s+â€„2â€‹âˆ«0Tâ€–Î”â€‹Ï€â€‹(s)â€–2â€‹ğ‘‘s,\int\_{0}^{T}\|\pi\_{n}(s)\|^{2}ds\;\leq\;2\int\_{0}^{T}\|\pi(s)\|^{2}ds\;+\;2\int\_{0}^{T}\|\Delta\pi(s)\|^{2}ds, |  |

and the two terms on the right-hand side are uniformly bounded in â„š\mathbb{Q},
with the second one vanishing as nâ†’âˆn\to\infty by the definition of dd.
Using ([14](https://arxiv.org/html/2512.01408v1#S3.E14 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), the compactness of KK, and the linear
wealth dynamics ([11](https://arxiv.org/html/2512.01408v1#S3.E11 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), standard estimates for linear SDEs with bounded
coefficients yield the existence of Îµ>0\varepsilon>0 and, for each m>0m>0,
constants C+,m,Câˆ’,m<âˆC\_{+,m},C\_{-,m}<\infty such that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | supnâ‰¥1supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supbâˆˆKğ”¼â„šâ€‹[|XÏ€nâ€‹(T;b,W)|2+Îµ]\displaystyle\sup\_{n\geq 1}\ \sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\ \sup\_{b\in K}\mathbb{E}\_{\mathbb{Q}}\!\big[|X^{\pi\_{n}}(T;b,W)|^{2+\varepsilon}\big] | â‰¤C+,2+Îµ,\displaystyle\leq C\_{+,2+\varepsilon}, |  | (15) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | supnâ‰¥1supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supbâˆˆKğ”¼â„šâ€‹[(XÏ€nâ€‹(T;b,W))âˆ’m]\displaystyle\sup\_{n\geq 1}\ \sup\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\ \sup\_{b\in K}\mathbb{E}\_{\mathbb{Q}}\!\big[(X^{\pi\_{n}}(T;b,W))^{-m}\big] | â‰¤Câˆ’,m.\displaystyle\leq C\_{-,m}. |  | (16) |

In particular, by the max-type growth in Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), there
exist p>0p>0 and CU>0C\_{U}>0 such that

|  |  |  |
| --- | --- | --- |
|  | |Uâ€‹(x)|â‰¤CUâ€‹(1+xp+xâˆ’p),x>0,|U(x)|\leq C\_{U}\big(1+x^{p}+x^{-p}\big),\qquad x>0, |  |

and combining this with ([15](https://arxiv.org/html/2512.01408v1#S3.E15 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"))â€“([16](https://arxiv.org/html/2512.01408v1#S3.E16 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"))
shows that the family {Uâ€‹(XÏ€nâ€‹(T)):nâ‰¥1}\{U(X^{\pi\_{n}}(T)):n\geq 1\} is uniformly integrable
under every â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}).
Since XÏ€nâ€‹(T)â†’XÏ€â€‹(T)X^{\pi\_{n}}(T)\to X^{\pi}(T) in probability and {Uâ€‹(XÏ€nâ€‹(T))}nâ‰¥1\{U(X^{\pi\_{n}}(T))\}\_{n\geq 1}
is uniformly integrable, the continuity of UU implies
ğ”¼â„šâ€‹[Uâ€‹(XÏ€nâ€‹(T))]âŸ¶ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi\_{n}}(T))]\;\longrightarrow\;\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))], âˆ€â„šâˆˆğ’°Î´OTâ€‹(â„™0).\forall\,\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}).
Thus, for each fixed â„š\mathbb{Q}, the map
Ï€â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\pi\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is continuous on
(ğ’œâ€²â€‹(x0),d)(\mathcal{A}^{\prime}(x\_{0}),d).

Step 4: Apply Sionâ€™s min-max theorem on ğ’œâ€²â€‹(x0)\mathcal{A}^{\prime}(x\_{0}). The space ğ’œâ€²â€‹(x0)\mathcal{A}^{\prime}(x\_{0}) is convex because the wealth dynamics are linear in Ï€\pi, and ğ’°Î´OTâ€‹(â„™0)\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}) is weakly compact since each admissible BB-marginal is supported in the compact set KK and the Wasserstein/KL balls are weakly closed (Prokhorovâ€™s theorem).
Moreover, the map (Ï€,â„š)â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))](\pi,\mathbb{Q})\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] satisfies:

* â€¢

  Concavity in Ï€\pi: For fixed â„š\mathbb{Q}, Ï€â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\pi\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is concave by the previous step.
* â€¢

  Convexity in â„š\mathbb{Q}: For fixed Ï€\pi, â„šâ†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\mathbb{Q}\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is linear (hence convex).
* â€¢

  Continuity in Ï€\pi: For fixed â„š\mathbb{Q}, Ï€â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\pi\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is continuous on (ğ’œâ€²â€‹(x0),d)(\mathcal{A}^{\prime}(x\_{0}),d) (Step 3).
* â€¢

  Continuity in â„š\mathbb{Q}: For fixed Ï€\pi, â„šâ†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]\mathbb{Q}\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))] is continuous under the weak topology on ğ’°Î´OTâ€‹(â„™0)\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}) by the argument in Step 2.

By Sionâ€™s min-max theorem applied to ğ’œâ€²â€‹(x0)Ã—ğ’°Î´OTâ€‹(â„™0)\mathcal{A}^{\prime}(x\_{0})\times\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0}), we conclude:

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’œâ€²â€‹(x0)infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]=infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supÏ€âˆˆğ’œâ€²â€‹(x0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))].\sup\_{\pi\in\mathcal{A}^{\prime}(x\_{0})}\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]=\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\sup\_{\pi\in\mathcal{A}^{\prime}(x\_{0})}\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))]. |  |

Step 5: Return to ğ’œâ€‹(x0)\mathcal{A}(x\_{0}).
Fix bâˆˆKb\in K and consider the optimal policy Ï€âˆ—,b\pi^{\*,b} supplied by
Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") when the prior is the Dirac mass at bb.
Writing Ybâ€‹(t)=Ïƒâˆ’1â€‹(bâˆ’râ€‹ğŸ)â€‹t+Wâ€‹(t)Y^{b}(t)=\sigma^{-1}(b-r\mathbf{1})t+W(t) and

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î˜â€‹(t,y)\displaystyle\Theta(t,y) | =âˆ«â„dIâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+y))â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘z,\displaystyle=\int\_{\mathbb{R}^{d}}I\!\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+y)}\right)\,\varphi\_{T-t}(z)\,dz, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Îâ€‹(t,y)\displaystyle\Xi(t,y) | =âˆ«â„dâˆ‡zFâ€‹(T,z+y)Fâ€‹(T,z+y)2â€‹Iâ€²â€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+y))â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘z,\displaystyle=\int\_{\mathbb{R}^{d}}\frac{\nabla\_{z}F(T,z+y)}{F(T,z+y)^{2}}\,I^{\prime}\!\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+y)}\right)\,\varphi\_{T-t}(z)\,dz, |  |

the optimal fraction from Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") reads

|  |  |  |
| --- | --- | --- |
|  | Ï€âˆ—,bâ€‹(t)Xâˆ—,bâ€‹(t)=(ÏƒâŠ¤)âˆ’1â€‹(âˆ’ğ’¦â€‹(x0)â€‹eâˆ’râ€‹T)â€‹Îâ€‹(t,Ybâ€‹(t))Î˜â€‹(t,Ybâ€‹(t)).\frac{\pi^{\*,b}(t)}{X^{\*,b}(t)}=\left(\sigma^{\top}\right)^{-1}(-\mathcal{K}(x\_{0})e^{-rT})\,\frac{\Xi(t,Y^{b}(t))}{\Theta(t,Y^{b}(t))}. |  |

To bound the ratio, note that for any uâˆˆâ„du\in\mathbb{R}^{d},

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(T,u)=âˆ«KLTâ€‹(b~,u)â€‹Î¼â€‹(dâ€‹b~),âˆ‡uFâ€‹(T,u)=âˆ«KÏƒâˆ’âŠ¤â€‹(b~âˆ’râ€‹ğŸ)â€‹LTâ€‹(b~,u)â€‹Î¼â€‹(dâ€‹b~).F(T,u)=\int\_{K}L\_{T}(\tilde{b},u)\,\mu(d\tilde{b}),\qquad\nabla\_{u}F(T,u)=\int\_{K}\sigma^{-\top}(\tilde{b}-r\mathbf{1})L\_{T}(\tilde{b},u)\,\mu(d\tilde{b}). |  |

Because KK is compact and Ïƒâˆ’âŠ¤â€‹(b~âˆ’râ€‹ğŸ)\sigma^{-\top}(\tilde{b}-r\mathbf{1}) is continuous in b~\tilde{b},
there exists CK>0C\_{K}>0 such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–âˆ‡uFâ€‹(T,u)Fâ€‹(T,u)â€–â‰¤CKâˆ€uâˆˆâ„d.\left\|\frac{\nabla\_{u}F(T,u)}{F(T,u)}\right\|\leq C\_{K}\qquad\forall u\in\mathbb{R}^{d}. |  | (17) |

Moreover, LTâ€‹(b~,u)L\_{T}(\tilde{b},u) is bounded from above and below by two-sided exponentials in
â€–uâ€–\|u\|, uniformly in b~âˆˆK\tilde{b}\in K, so there exists c0>0c\_{0}>0 with

|  |  |  |  |
| --- | --- | --- | --- |
|  | c0âˆ’1â€‹eâˆ’c0â€‹â€–uâ€–â‰¤Fâ€‹(T,u)â‰¤c0â€‹ec0â€‹â€–uâ€–,|1Fâ€‹(T,u)|â‰¤c0â€‹ec0â€‹â€–uâ€–.c\_{0}^{-1}e^{-c\_{0}\|u\|}\;\leq\;F(T,u)\;\leq\;c\_{0}e^{c\_{0}\|u\|},\qquad\left|\frac{1}{F(T,u)}\right|\leq c\_{0}e^{c\_{0}\|u\|}. |  | (18) |

Recall that
Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") guarantees that for some CI,pI>0C\_{I},p\_{I}>0 and cI>0c\_{I}>0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Iâ€‹(x)|+|Iâ€²â€‹(x)|â‰¤CIâ€‹(1+xpI+xâˆ’pI),Iâ€‹(x)â‰¥cIâ€‹xâˆ’pI,x>0.|I(x)|+|I^{\prime}(x)|\;\leq\;C\_{I}\bigl(1+x^{p\_{I}}+x^{-p\_{I}}\bigr),\qquad I(x)\;\geq\;c\_{I}x^{-p\_{I}},\qquad x>0. |  | (19) |

Applying ([19](https://arxiv.org/html/2512.01408v1#S3.E19 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) to
x=ğ’¦â€‹(x0)â€‹eâˆ’râ€‹T/Fâ€‹(T,z+y)x=\mathcal{K}(x\_{0})e^{-rT}/F(T,z+y)
and using ([18](https://arxiv.org/html/2512.01408v1#S3.E18 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) yields exponential bounds

|  |  |  |
| --- | --- | --- |
|  | |Iâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+y))|+|Iâ€²â€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+y))|â‰¤Câ€²â€‹ecâ€²â€‹â€–z+yâ€–,\Big|I\!\left(\tfrac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+y)}\right)\Big|+\Big|I^{\prime}\!\left(\tfrac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+y)}\right)\Big|\;\leq\;C^{\prime}e^{c^{\prime}\|z+y\|}, |  |

and crucially, the *lower bound*

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î˜â€‹(t,y)=âˆ«â„dIâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z+y))â€‹Ï†Tâˆ’tâ€‹(z)â€‹ğ‘‘zâ‰¥câ€²â€‹expâ¡(âˆ’câ€²â€²â€‹â€–yâ€–)\Theta(t,y)=\int\_{\mathbb{R}^{d}}I\!\left(\tfrac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z+y)}\right)\varphi\_{T-t}(z)\,dz\;\geq\;c^{\prime}\,\exp\!\bigl(-c^{\prime\prime}\|y\|\bigr) |  | (20) |

for suitable constants câ€²,câ€²â€²>0c^{\prime},c^{\prime\prime}>0 (using Iâ€‹(x)â‰¥cIâ€‹xâˆ’pII(x)\geq c\_{I}x^{-p\_{I}} and the Gaussian tail of Ï†Tâˆ’t\varphi\_{T-t}).

Similarly,

|  |  |  |
| --- | --- | --- |
|  | |Îâ€‹(t,y)|â‰¤C2â€‹ec2â€‹â€–yâ€–|\Xi(t,y)|\leq C\_{2}e^{c\_{2}\|y\|} |  |

for constants C2,c2>0C\_{2},c\_{2}>0.

Combining these,

|  |  |  |
| --- | --- | --- |
|  | â€–Îâ€‹(t,y)Î˜â€‹(t,y)â€–â‰¤aâ€‹ecâ€‹â€–yâ€–(t,y)âˆˆ[0,T]Ã—â„d.\left\|\frac{\Xi(t,y)}{\Theta(t,y)}\right\|\;\leq\;a\,e^{c\|y\|}\qquad(t,y)\in[0,T]\times\mathbb{R}^{d}. |  |

Because YbY^{b} has continuous paths,
sup0â‰¤tâ‰¤Tâ€–Ybâ€‹(t)â€–<âˆ\sup\_{0\leq t\leq T}\|Y^{b}(t)\|<\infty
a.s. Since YbY^{b} is a Brownian motion with bounded drift,
sup0â‰¤tâ‰¤Tâ€–Ybâ€‹(t)â€–\sup\_{0\leq t\leq T}\|Y^{b}(t)\|
admits finite exponential moments. Therefore,

|  |  |  |
| --- | --- | --- |
|  | sup0â‰¤tâ‰¤Tâ€–Ï€âˆ—,bâ€‹(t)Xâˆ—,bâ€‹(t)â€–â‰¤aâ€‹expâ¡(câ€‹sup0â‰¤tâ‰¤Tâ€–Ybâ€‹(t)â€–)<âˆâ„™â€‹-a.s.\sup\_{0\leq t\leq T}\left\|\frac{\pi^{\*,b}(t)}{X^{\*,b}(t)}\right\|\;\leq\;a\exp\!\left(c\sup\_{0\leq t\leq T}\|Y^{b}(t)\|\right)<\infty\qquad\mathbb{P}\text{-a.s.} |  |

Finally, Xâˆ—,bX^{\*,b} has continuous paths and is strictly positive, so
sup0â‰¤tâ‰¤Tâ€–Ï€âˆ—,bâ€‹(t)â€–<âˆ\sup\_{0\leq t\leq T}\|\pi^{\*,b}(t)\|<\infty
a.s., and hence
âˆ«0Tâ€–Ï€âˆ—,bâ€‹(t)â€–2â€‹ğ‘‘t<âˆ\int\_{0}^{T}\|\pi^{\*,b}(t)\|^{2}dt<\infty
a.s.
The constants above are uniform in bâˆˆKb\in K, and thus for every
â„šâˆˆğ’°Î´OTâ€‹(â„™0)\mathbb{Q}\in\mathcal{U}\_{\delta}^{\mathrm{OT}}(\mathbb{P}\_{0}),

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„šâ€‹[(âˆ«0Tâ€–Ï€âˆ—â€‹(t)â€–2â€‹ğ‘‘t)1/2]<âˆ.\mathbb{E}\_{\mathbb{Q}}\left[\left(\int\_{0}^{T}\|\pi^{\*}(t)\|^{2}dt\right)^{1/2}\right]<\infty. |  |

This proves Ï€âˆ—âˆˆğ’œâ€²â€‹(x0)âŠ‚ğ’œâ€‹(x0)\pi^{\*}\in\mathcal{A}^{\prime}(x\_{0})\subset\mathcal{A}(x\_{0}).
Together with the inequalities at the beginning of the proof, this yields the
desired minâ€“max equality on ğ’œâ€‹(x0)\mathcal{A}(x\_{0}).

âˆ

The value of Theorem [2](https://arxiv.org/html/2512.01408v1#Thmtheorem2 "Theorem 2 (Min-Max Equality). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") is that for a fixed probability measure â„š\mathbb{Q}, by Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the inner problem supÏ€âˆˆğ’œâ€‹(x0)ğ”¼â„šâ€‹[Uâ€‹(Xâ€‹(T))]\sup\_{\pi\in\mathcal{A}(x\_{0})}\mathbb{E}\_{\mathbb{Q}}\left[U(X(T))\right] has a closed-form solution in terms of the distribution of the drift BB.
In other words, the DRBC problem is equivalent to solving a constrained distributional optimization problem

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)supÏ€âˆˆğ’œâ€‹(x0)ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))]=infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)âˆ«â„dFâ€‹(T,z)â€‹Uâ€‹(Iâ€‹(ğ’¦â€‹(x0)â€‹eâˆ’râ€‹TFâ€‹(T,z)))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z,\displaystyle\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\sup\_{\pi\in\mathcal{A}(x\_{0})}\mathbb{E}\_{\mathbb{Q}}\left[U(X^{\pi}(T))\right]=\inf\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}\int\_{\mathbb{R}^{d}}F(T,z)U\left(I\left(\frac{\mathcal{K}(x\_{0})e^{-rT}}{F(T,z)}\right)\right)\varphi\_{T}(z)dz, |  | (21) |

where
ğ’°Î´OTâ€‹(â„™0)\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})
is the uncertainty set that is only concerned with the distribution of BB since the objective function in ([21](https://arxiv.org/html/2512.01408v1#S3.E21 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) no longer contains the Brownian motion WW. Hence, it suffices to optimize over the nonlinear functional and obtain the extreme probability measure â„šâˆ—\mathbb{Q}^{\*} (denote the functional on the right-hand side of Eq. ([21](https://arxiv.org/html/2512.01408v1#S3.E21 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) by a specific Jâ€‹(â„š)J(\mathbb{Q}); see Corollary [1](https://arxiv.org/html/2512.01408v1#Thmcorollary1 "Corollary 1 (Asymptotic non-linear optimal perturbation under Wasserstein distance). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") for details):

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„šâˆ—=argâ¡minâ„šâˆˆğ’°Î´OTâ€‹(â„™0)â¡Jâ€‹(â„š).\displaystyle\mathbb{Q}^{\*}=\arg\min\_{\mathbb{Q}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{0})}{J}(\mathbb{Q}). |  | (22) |

We will first give a sensitivity analysis of this distributional optimization problem in greater generality for JJ, and then Problem ([22](https://arxiv.org/html/2512.01408v1#S3.E22 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) can be solved easily in an approximate sense by the following Corollary [1](https://arxiv.org/html/2512.01408v1#Thmcorollary1 "Corollary 1 (Asymptotic non-linear optimal perturbation under Wasserstein distance). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

###### Theorem 3 (Nonlinear optimal perturbations).

Fix 1<q<âˆ1<q<\infty and let pp be its HÃ¶lder conjugate.
Let âˆ¥â‹…âˆ¥q\|\cdot\|\_{q} be a norm on â„d\mathbb{R}^{d} and âˆ¥â‹…âˆ¥p\|\cdot\|\_{p} be its dual norm.
Consider the quadratic transport cost câ€‹(xâ€²âˆ’x):=Ï„â€‹â€–xâ€²âˆ’xâ€–q2c(x^{\prime}-x):=\tau\,\|x^{\prime}-x\|\_{q}^{2} with Ï„>0\tau>0
and let DcD\_{c} denote the corresponding optimal-transport divergence

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î¼,Î½):=infÏ€âˆˆÎ â€‹(Î¼,Î½)ğ”¼Ï€â€‹[câ€‹(Xâ€²âˆ’X)].D\_{c}(\mu,\nu):=\inf\_{\pi\in\Pi(\mu,\nu)}\mathbb{E}\_{\pi}\big[c(X^{\prime}-X)\big]. |  |

For Î´>0\delta>0, set VÎ´:=supDcâ€‹(Î¼,Î½)â‰¤Î´Jâ€‹(Î¼)V\_{\delta}:=\sup\_{D\_{c}(\mu,\nu)\leq\delta}J(\mu), where the functional
J:ğ’«â€‹(â„d)â†’â„J:\mathcal{P}(\mathbb{R}^{d})\to\mathbb{R} satisfies:

* (i)

  For all Î¼\mu in a neighbourhood of Î½\nu, there exists a measurable
  JÎ¼â€²:â„dâ†’â„J^{\prime}\_{\mu}:\mathbb{R}^{d}\to\mathbb{R}, differentiable in xx with gradient âˆ‡JÎ¼â€²â€‹(x)\nabla J^{\prime}\_{\mu}(x),
  such that for every coupling Ï€\pi of (Xâ€²,X)âˆ¼(Î¼,Î½)(X^{\prime},X)\sim(\mu,\nu) and
  Î½t:=(1âˆ’t)â€‹Î½+tâ€‹Î¼\nu\_{t}:=(1-t)\nu+t\mu,

  |  |  |  |
  | --- | --- | --- |
  |  | Jâ€‹(Î¼)âˆ’Jâ€‹(Î½)=âˆ«01ğ”¼Ï€â€‹[JÎ½tâ€²â€‹(Xâ€²)âˆ’JÎ½tâ€²â€‹(X)]â€‹ğ‘‘t.J(\mu)-J(\nu)=\int\_{0}^{1}\mathbb{E}\_{\pi}\big[J^{\prime}\_{\nu\_{t}}(X^{\prime})-J^{\prime}\_{\nu\_{t}}(X)\big]\,dt. |  |
* (ii)

  (Regularity and growth of the Wasserstein gradient)
  The map (Î¼,x)â†¦âˆ‡JÎ¼â€²â€‹(x)(\mu,x)\mapsto\nabla J^{\prime}\_{\mu}(x) is jointly continuous in the product
  topology (weak topology on Î¼\mu, Euclidean on xx) in a neighbourhood
  of (Î½,â‹…)(\nu,\cdot).
  Moreover, there exist 1â‰¤râ‰¤21\leq r\leq 2 and C>0C>0 such that for all such Î¼\mu and all xâˆˆâ„dx\in\mathbb{R}^{d},

  |  |  |  |
  | --- | --- | --- |
  |  | â€–âˆ‡JÎ¼â€²â€‹(x)â€–pâ‰¤Câ€‹(1+â€–xâ€–râˆ’1),\|\nabla J^{\prime}\_{\mu}(x)\|\_{p}\leq C\big(1+\|x\|^{r-1}\big), |  |

  and the reference law Î½\nu has finite 2â€‹r2r-moment:

  |  |  |  |
  | --- | --- | --- |
  |  | ğ”¼Î½â€‹â€–Xâ€–2â€‹r<âˆ.\mathbb{E}\_{\nu}\|X\|^{2r}<\infty. |  |

Let gâ€‹(x):=âˆ‡JÎ½â€²â€‹(x)g(x):=\nabla J^{\prime}\_{\nu}(x) and assume
ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2<âˆ\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}<\infty.
Then, as Î´â†“0\delta\downarrow 0,

|  |  |  |
| --- | --- | --- |
|  | VÎ´=Jâ€‹(Î½)+Î´Ï„â€‹(ğ”¼Î½â€‹[â€–gâ€‹(X)â€–p2])1/2+oâ€‹(Î´).V\_{\delta}=J(\nu)+\sqrt{\frac{\delta}{\tau}}\,\Big(\mathbb{E}\_{\nu}\big[\|g(X)\|\_{p}^{2}\big]\Big)^{1/2}+o(\sqrt{\delta}). |  |

Moreover, there exists an asymptotically optimal Monge-type perturbation
TÎ´T\_{\delta} of the form

|  |  |  |
| --- | --- | --- |
|  | TÎ´â€‹(X)=X+Î´Ï„â€‹Î”Â¯â€‹(X)â€‹(1+opâ€‹(1)),T\_{\delta}(X)=X+\sqrt{\frac{\delta}{\tau}}\,\bar{\Delta}(X)\,\big(1+o\_{p}(1)\big), |  |

where for each xx with gâ€‹(x)â‰ 0g(x)\neq 0, we choose

|  |  |  |
| --- | --- | --- |
|  | uâ€‹(x)âˆˆargâ¡maxâ€–uâ€–q=1â¡gâ€‹(x)â‹…u,u(x)\in\arg\max\_{\|u\|\_{q}=1}g(x)\cdot u, |  |

and define

|  |  |  |
| --- | --- | --- |
|  | Î”Â¯â€‹(x):=â€–gâ€‹(x)â€–pKâ€‹uâ€‹(x),K:=(ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2)1/2,\bar{\Delta}(x):=\frac{\|g(x)\|\_{p}}{K}\,u(x),\qquad K:=\Big(\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}\Big)^{1/2}, |  |

with Î”Â¯â€‹(x):=0\bar{\Delta}(x):=0 when gâ€‹(x)=0g(x)=0.

###### Proof.

Write gâ€‹(x):=âˆ‡JÎ½â€²â€‹(x)g(x):=\nabla J^{\prime}\_{\nu}(x) and

|  |  |  |
| --- | --- | --- |
|  | K:=(ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2)1/2.K:=\Big(\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}\Big)^{1/2}. |  |

If K=0K=0, then gâ€‹(X)=0g(X)=0 Î½\nu-a.s. and ([27](https://arxiv.org/html/2512.01408v1#S3.E27 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) below implies
VÎ´âˆ’Jâ€‹(Î½)=oâ€‹(Î´)V\_{\delta}-J(\nu)=o(\sqrt{\delta}), so the claim holds with the identity map.
Hence we henceforth assume K>0K>0.
We will mimic the proof of [BartlDrapeauOblojWiesel2021].

Step 1: Coupling class ğ’Î´\mathcal{C}\_{\delta} and L2L^{2}â€“scaling.
For Î´>0\delta>0, define the class of couplings

|  |  |  |
| --- | --- | --- |
|  | ğ’Î´:={Ï€âˆˆğ’«â€‹(â„dÃ—â„d):Ï€â€‹(â„d,â‹…)=Î½,ğ”¼Ï€â€‹[câ€‹(Xâ€²âˆ’X)]â‰¤Î´}.\mathcal{C}\_{\delta}:=\Big\{\pi\in\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}):\pi(\mathbb{R}^{d},\cdot)=\nu,\;\mathbb{E}\_{\pi}\big[c(X^{\prime}-X)\big]\leq\delta\Big\}. |  |

Write Î”:=Xâ€²âˆ’X\Delta:=X^{\prime}-X and note that for Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta},

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼Ï€â€‹â€–Î”â€–q2â‰¤Î´Ï„,â€–Î”â€–L2â€‹(Ï€):=(ğ”¼Ï€â€‹â€–Î”â€–q2)1/2â‰¤Î´Ï„.\mathbb{E}\_{\pi}\|\Delta\|\_{q}^{2}\;\leq\;\frac{\delta}{\tau},\qquad\|\Delta\|\_{L^{2}(\pi)}:=\big(\mathbb{E}\_{\pi}\|\Delta\|\_{q}^{2}\big)^{1/2}\;\leq\;\sqrt{\frac{\delta}{\tau}}. |  | (23) |

In particular, if Î´nâ†“0\delta\_{n}\downarrow 0 and Ï€nâˆˆğ’Î´n\pi\_{n}\in\mathcal{C}\_{\delta\_{n}}, then
â€–Î”nâ€–L2â€‹(Ï€n)â†’0\|\Delta\_{n}\|\_{L^{2}(\pi\_{n})}\to 0, and since â€–Î”nâ€–q2â‰¥0\|\Delta\_{n}\|\_{q}^{2}\geq 0 and
ğ”¼â€‹â€–Î”nâ€–q2â†’0\mathbb{E}\|\Delta\_{n}\|\_{q}^{2}\to 0, the family {â€–Î”nâ€–q2}n\{\|\Delta\_{n}\|\_{q}^{2}\}\_{n} is uniformly integrable.

Moreover, for any Î¼\mu with Dcâ€‹(Î¼,Î½)â‰¤Î´D\_{c}(\mu,\nu)\leq\delta, there exists at least one coupling
Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta} with first marginal Î¼\mu (an optimal transport plan);
conversely, every Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta}
has some first marginal Î¼\mu with Dcâ€‹(Î¼,Î½)â‰¤Î´D\_{c}(\mu,\nu)\leq\delta.
Thus

|  |  |  |
| --- | --- | --- |
|  | VÎ´âˆ’Jâ€‹(Î½)=supÎ¼:Dcâ€‹(Î¼,Î½)â‰¤Î´(Jâ€‹(Î¼)âˆ’Jâ€‹(Î½))=supÏ€âˆˆğ’Î´(Jâ€‹(Î¼Ï€)âˆ’Jâ€‹(Î½)),V\_{\delta}-J(\nu)=\sup\_{\begin{subarray}{c}\mu:\,D\_{c}(\mu,\nu)\leq\delta\end{subarray}}\big(J(\mu)-J(\nu)\big)=\sup\_{\pi\in\mathcal{C}\_{\delta}}\big(J(\mu\_{\pi})-J(\nu)\big), |  |

where Î¼Ï€\mu\_{\pi} denotes the first marginal of Ï€\pi.

Step 2: Path identity, Taylor expansion, and linearization.
Fix Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta} with first marginal Î¼\mu and displacement Î”=Xâ€²âˆ’X\Delta=X^{\prime}-X.
For tâˆˆ[0,1]t\in[0,1], set Î½t:=(1âˆ’t)â€‹Î½+tâ€‹Î¼\nu\_{t}:=(1-t)\nu+t\mu. By Assumption (i),

|  |  |  |  |
| --- | --- | --- | --- |
|  | Jâ€‹(Î¼)âˆ’Jâ€‹(Î½)=âˆ«01ğ”¼Ï€â€‹[JÎ½tâ€²â€‹(Xâ€²)âˆ’JÎ½tâ€²â€‹(X)]â€‹ğ‘‘t.J(\mu)-J(\nu)=\int\_{0}^{1}\mathbb{E}\_{\pi}\big[J^{\prime}\_{\nu\_{t}}(X^{\prime})-J^{\prime}\_{\nu\_{t}}(X)\big]\,dt. |  | (24) |

For each fixed tt, the map xâ†¦JÎ½tâ€²â€‹(x)x\mapsto J^{\prime}\_{\nu\_{t}}(x) is differentiable with gradient
âˆ‡JÎ½tâ€²â€‹(x)\nabla J^{\prime}\_{\nu\_{t}}(x). Using the fundamental theorem of calculus along the segment
X+sâ€‹Î”X+s\Delta, sâˆˆ[0,1]s\in[0,1], we obtain

|  |  |  |
| --- | --- | --- |
|  | JÎ½tâ€²â€‹(X+Î”)âˆ’JÎ½tâ€²â€‹(X)=âˆ«01âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)â‹…Î”â€‹ğ‘‘s.J^{\prime}\_{\nu\_{t}}(X+\Delta)-J^{\prime}\_{\nu\_{t}}(X)=\int\_{0}^{1}\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)\cdot\Delta\,ds. |  |

Subtract âˆ‡JÎ½tâ€²â€‹(X)â‹…Î”\nabla J^{\prime}\_{\nu\_{t}}(X)\cdot\Delta and define the remainder

|  |  |  |
| --- | --- | --- |
|  | RÎ´,t:=âˆ«01(âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X))â‹…Î”â€‹ğ‘‘s.R\_{\delta,t}:=\int\_{0}^{1}\big(\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\big)\cdot\Delta\,ds. |  |

Then

|  |  |  |  |
| --- | --- | --- | --- |
|  | Jâ€‹(Î¼)âˆ’Jâ€‹(Î½)=âˆ«01ğ”¼Ï€â€‹[âˆ‡JÎ½tâ€²â€‹(X)â‹…Î”]â€‹ğ‘‘t+âˆ«01ğ”¼Ï€â€‹[RÎ´,t]â€‹ğ‘‘t.J(\mu)-J(\nu)=\int\_{0}^{1}\mathbb{E}\_{\pi}\big[\nabla J^{\prime}\_{\nu\_{t}}(X)\cdot\Delta\big]\,dt\;+\;\int\_{0}^{1}\mathbb{E}\_{\pi}\big[R\_{\delta,t}\big]\,dt. |  | (25) |

We now show that the remainder term is oâ€‹(Î´)o(\sqrt{\delta}), *uniformly* over
Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta} and tâˆˆ[0,1]t\in[0,1].

By Cauchyâ€“Schwarz in L2â€‹(Ï€)L^{2}(\pi) and HÃ¶lder in â„d\mathbb{R}^{d},

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼Ï€â€‹|RÎ´,t|\displaystyle\mathbb{E}\_{\pi}|R\_{\delta,t}| | â‰¤âˆ«01ğ”¼Ï€â€‹[â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X)â€–pâ€‹â€–Î”â€–q]â€‹ğ‘‘s\displaystyle\leq\int\_{0}^{1}\mathbb{E}\_{\pi}\big[\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\|\_{p}\,\|\Delta\|\_{q}\big]\,ds |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ«01â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X)â€–L2â€‹(Ï€)â€‹â€–Î”â€–L2â€‹(Ï€)â€‹ğ‘‘s.\displaystyle\leq\int\_{0}^{1}\big\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\big\|\_{L^{2}(\pi)}\,\|\Delta\|\_{L^{2}(\pi)}\,ds. |  |

Using ([23](https://arxiv.org/html/2512.01408v1#S3.E23 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")),

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Ï€â€‹|RÎ´,t|â‰¤Î´Ï„â€‹supsâˆˆ[0,1]â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X)â€–L2â€‹(Ï€).\mathbb{E}\_{\pi}|R\_{\delta,t}|\leq\sqrt{\frac{\delta}{\tau}}\,\sup\_{s\in[0,1]}\big\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\big\|\_{L^{2}(\pi)}. |  |

*Uniform L2L^{2} bounds via polynomial growth.*
By Assumption (ii), there exist 1â‰¤râ‰¤21\leq r\leq 2 and C>0C>0 such that

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡JÎ½tâ€²â€‹(x)â€–pâ‰¤Câ€‹(1+â€–xâ€–râˆ’1),xâˆˆâ„d,tâˆˆ[0,1],\|\nabla J^{\prime}\_{\nu\_{t}}(x)\|\_{p}\leq C\big(1+\|x\|^{r-1}\big),\qquad x\in\mathbb{R}^{d},\ t\in[0,1], |  |

for all Î¼\mu in a neighbourhood of Î½\nu; in particular this holds for all interpolants
Î½t=(1âˆ’t)â€‹Î½+tâ€‹Î¼\nu\_{t}=(1-t)\nu+t\mu with Dcâ€‹(Î¼,Î½)D\_{c}(\mu,\nu) small. Let (Xâ€²,X)âˆ¼Ï€âˆˆğ’Î´0(X^{\prime},X)\sim\pi\in\mathcal{C}\_{\delta\_{0}}.
Then, by the triangle inequality and the fact that 2â€‹(râˆ’1)â‰¤22(r-1)\leq 2,

|  |  |  |
| --- | --- | --- |
|  | â€–X+sâ€‹Î”â€–2â€‹(râˆ’1)â‰¤Câ€²â€‹(â€–Xâ€–2â€‹(râˆ’1)+â€–Î”â€–2â€‹(râˆ’1)),sâˆˆ[0,1],\|X+s\Delta\|^{2(r-1)}\leq C^{\prime}\big(\|X\|^{2(r-1)}+\|\Delta\|^{2(r-1)}\big),\qquad s\in[0,1], |  |

for some Câ€²>0C^{\prime}>0. Since 2â€‹(râˆ’1)â‰¤22(r-1)\leq 2 and ğ”¼Ï€â€‹â€–Î”â€–2â‰¤Î´0/Ï„\mathbb{E}\_{\pi}\|\Delta\|^{2}\leq\delta\_{0}/\tau, Jensenâ€™s
inequality yields

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´0ğ”¼Ï€â€‹â€–Î”â€–2â€‹(râˆ’1)<âˆ,\sup\_{\pi\in\mathcal{C}\_{\delta\_{0}}}\mathbb{E}\_{\pi}\|\Delta\|^{2(r-1)}<\infty, |  |

and ğ”¼Î½â€‹â€–Xâ€–2â€‹r<âˆ\mathbb{E}\_{\nu}\|X\|^{2r}<\infty implies ğ”¼Î½â€‹â€–Xâ€–2â€‹(râˆ’1)<âˆ\mathbb{E}\_{\nu}\|X\|^{2(r-1)}<\infty, so

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´0supsâˆˆ[0,1]ğ”¼Ï€â€‹â€–X+sâ€‹Î”â€–2â€‹(râˆ’1)<âˆ.\sup\_{\pi\in\mathcal{C}\_{\delta\_{0}}}\sup\_{s\in[0,1]}\mathbb{E}\_{\pi}\|X+s\Delta\|^{2(r-1)}<\infty. |  |

Using the growth bound

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)â€–p2â‰¤Câ€²â€²â€‹(1+â€–X+sâ€‹Î”â€–2â€‹(râˆ’1)),\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)\|\_{p}^{2}\leq C^{\prime\prime}\big(1+\|X+s\Delta\|^{2(r-1)}\big), |  |

we obtain

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´0suptâˆˆ[0,1],sâˆˆ[0,1]ğ”¼Ï€â€‹[â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)â€–p2]<âˆ,\sup\_{\pi\in\mathcal{C}\_{\delta\_{0}}}\sup\_{t\in[0,1],\,s\in[0,1]}\mathbb{E}\_{\pi}\big[\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)\|\_{p}^{2}\big]<\infty, |  |

and likewise

|  |  |  |
| --- | --- | --- |
|  | suptâˆˆ[0,1]ğ”¼Î½â€‹[â€–âˆ‡JÎ½tâ€²â€‹(X)â€–p2]<âˆ.\sup\_{t\in[0,1]}\mathbb{E}\_{\nu}\big[\|\nabla J^{\prime}\_{\nu\_{t}}(X)\|\_{p}^{2}\big]<\infty. |  |

Thus the family {âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”):Ï€âˆˆğ’Î´0,t,sâˆˆ[0,1]}\{\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta):\pi\in\mathcal{C}\_{\delta\_{0}},t,s\in[0,1]\}
is uniformly square-integrable.

*Spatial term.*
For the spatial part, set

|  |  |  |
| --- | --- | --- |
|  | AÎ´,t,s:=â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X)â€–L2â€‹(Ï€).A\_{\delta,t,s}:=\big\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\big\|\_{L^{2}(\pi)}. |  |

By joint continuity of (Î¼,x)â†¦âˆ‡JÎ¼â€²â€‹(x)(\mu,x)\mapsto\nabla J^{\prime}\_{\mu}(x) and the fact that
â€–Î”â€–L2â€‹(Ï€)â†’0\|\Delta\|\_{L^{2}(\pi)}\to 0 uniformly over Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta} as Î´â†“0\delta\downarrow 0,
we have âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)â†’âˆ‡JÎ½tâ€²â€‹(X)\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)\to\nabla J^{\prime}\_{\nu\_{t}}(X) in probability.
Together with the uniform L2L^{2}-bound just proved and uniform integrability of
â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)â€–p2\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)\|\_{p}^{2}, Vitaliâ€™s theorem yields

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´suptâˆˆ[0,1],sâˆˆ[0,1]AÎ´,t,s=oâ€‹(1),Î´â†“0.\sup\_{\pi\in\mathcal{C}\_{\delta}}\sup\_{t\in[0,1],\,s\in[0,1]}A\_{\delta,t,s}\;=\;o(1),\qquad\delta\downarrow 0. |  |

*Measure term.*
For the measure part, consider

|  |  |  |
| --- | --- | --- |
|  | BÎ´,t:=âˆ¥âˆ‡JÎ½tâ€²(X)âˆ’g(X)âˆ¥L2â€‹(Ï€).B\_{\delta,t}:=\big\|\nabla J^{\prime}\_{\nu\_{t}}(X)-g(X)\big\|\_{L^{2}(\pi)}. |  |

Since XX has law Î½\nu under any Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta}, this is

|  |  |  |
| --- | --- | --- |
|  | BÎ´,t=(ğ”¼Î½â€‹[â€–âˆ‡JÎ½tâ€²â€‹(X)âˆ’gâ€‹(X)â€–p2])1/2.B\_{\delta,t}=\Big(\mathbb{E}\_{\nu}\big[\|\nabla J^{\prime}\_{\nu\_{t}}(X)-g(X)\|\_{p}^{2}\big]\Big)^{1/2}. |  |

By joint continuity of (Î¼,x)â†¦âˆ‡JÎ¼â€²â€‹(x)(\mu,x)\mapsto\nabla J^{\prime}\_{\mu}(x) and the uniform L2L^{2}-bound
from the growth condition, the map
Î¼â†¦âˆ‡JÎ¼â€²\mu\mapsto\nabla J^{\prime}\_{\mu} is continuous in L2â€‹(Î½)L^{2}(\nu) near Î½\nu.
Moreover, for Î¼\mu with Dcâ€‹(Î¼,Î½)â‰¤Î´0D\_{c}(\mu,\nu)\leq\delta\_{0}, all interpolants
Î½t=(1âˆ’t)â€‹Î½+tâ€‹Î¼\nu\_{t}=(1-t)\nu+t\mu also satisfy Dcâ€‹(Î½t,Î½)â‰¤Î´0D\_{c}(\nu\_{t},\nu)\leq\delta\_{0}, so the same
uniform bound applies. Since Î½tâ†’Î½\nu\_{t}\to\nu weakly and the family is uniformly
square-integrable, Vitaliâ€™s theorem yields

|  |  |  |
| --- | --- | --- |
|  | supÎ¼:Dcâ€‹(Î¼,Î½)â‰¤Î´0,tâˆˆ[0,1]BÎ´,t=oâ€‹(1),\sup\_{\begin{subarray}{c}\mu:D\_{c}(\mu,\nu)\leq\delta\_{0},\\ t\in[0,1]\end{subarray}}B\_{\delta,t}=o(1), |  |

as Î¼â†’Î½\mu\to\nu (hence Î½tâ†’Î½\nu\_{t}\to\nu in the weak topology). Since here
we are only considering Î¼\mu with Dcâ€‹(Î¼,Î½)â‰¤Î´D\_{c}(\mu,\nu)\leq\delta and Î´â†“0\delta\downarrow 0,
this implies

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´suptâˆˆ[0,1]BÎ´,t=oâ€‹(1).\sup\_{\pi\in\mathcal{C}\_{\delta}}\sup\_{t\in[0,1]}B\_{\delta,t}\;=\;o(1). |  |

Putting the spatial and measure parts together and using the triangle inequality, we obtain

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´suptâˆˆ[0,1]supsâˆˆ[0,1]â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’gâ€‹(X)â€–L2â€‹(Ï€)=oâ€‹(1),Î´â†“0.\sup\_{\pi\in\mathcal{C}\_{\delta}}\sup\_{t\in[0,1]}\sup\_{s\in[0,1]}\big\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-g(X)\big\|\_{L^{2}(\pi)}=o(1),\qquad\delta\downarrow 0. |  |

In particular,

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´suptâˆˆ[0,1]supsâˆˆ[0,1]â€–âˆ‡JÎ½tâ€²â€‹(X+sâ€‹Î”)âˆ’âˆ‡JÎ½tâ€²â€‹(X)â€–L2â€‹(Ï€)=oâ€‹(1),Î´â†“0.\sup\_{\pi\in\mathcal{C}\_{\delta}}\sup\_{t\in[0,1]}\sup\_{s\in[0,1]}\big\|\nabla J^{\prime}\_{\nu\_{t}}(X+s\Delta)-\nabla J^{\prime}\_{\nu\_{t}}(X)\big\|\_{L^{2}(\pi)}=o(1),\qquad\delta\downarrow 0. |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´suptâˆˆ[0,1]ğ”¼Ï€â€‹|RÎ´,t|â‰¤Î´Ï„â‹…oâ€‹(1)=oâ€‹(Î´),\sup\_{\pi\in\mathcal{C}\_{\delta}}\sup\_{t\in[0,1]}\mathbb{E}\_{\pi}|R\_{\delta,t}|\;\leq\;\sqrt{\frac{\delta}{\tau}}\cdot o(1)=o(\sqrt{\delta}), |  |

and integrating over tâˆˆ[0,1]t\in[0,1],

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´|âˆ«01ğ”¼Ï€â€‹[RÎ´,t]â€‹ğ‘‘t|=oâ€‹(Î´),Î´â†“0.\sup\_{\pi\in\mathcal{C}\_{\delta}}\left|\int\_{0}^{1}\mathbb{E}\_{\pi}[R\_{\delta,t}]\,dt\right|=o(\sqrt{\delta}),\qquad\delta\downarrow 0. |  |

Next, by the same Vitali-type argument (now without the ss-shift),

|  |  |  |
| --- | --- | --- |
|  | âˆ«01ğ”¼Ï€â€‹[âˆ‡JÎ½tâ€²â€‹(X)â‹…Î”]â€‹ğ‘‘t=ğ”¼Ï€â€‹[gâ€‹(X)â‹…Î”]+oâ€‹(Î´),\int\_{0}^{1}\mathbb{E}\_{\pi}\big[\nabla J^{\prime}\_{\nu\_{t}}(X)\cdot\Delta\big]\,dt=\mathbb{E}\_{\pi}[g(X)\cdot\Delta]+o(\sqrt{\delta}), |  |

uniformly over Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta}. Combining this with
([25](https://arxiv.org/html/2512.01408v1#S3.E25 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), we conclude that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Jâ€‹(Î¼)âˆ’Jâ€‹(Î½)=ğ”¼Ï€â€‹[gâ€‹(X)â‹…Î”]+oâ€‹(Î´),J(\mu)-J(\nu)=\mathbb{E}\_{\pi}[g(X)\cdot\Delta]+o(\sqrt{\delta}), |  | (26) |

with the oâ€‹(Î´)o(\sqrt{\delta}) term uniform over Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta} (hence over all
feasible Î¼\mu with Dcâ€‹(Î¼,Î½)â‰¤Î´D\_{c}(\mu,\nu)\leq\delta).

Taking the supremum over Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta},

|  |  |  |  |
| --- | --- | --- | --- |
|  | VÎ´âˆ’Jâ€‹(Î½)=supÏ€âˆˆğ’Î´ğ”¼Ï€â€‹[gâ€‹(X)â‹…Î”]+oâ€‹(Î´),Î´â†“0.V\_{\delta}-J(\nu)=\sup\_{\pi\in\mathcal{C}\_{\delta}}\mathbb{E}\_{\pi}[g(X)\cdot\Delta]\;+\;o(\sqrt{\delta}),\qquad\delta\downarrow 0. |  | (27) |

Step 3: Upper bound via HÃ¶lder and Cauchyâ€“Schwarz.
For any Ï€âˆˆğ’Î´\pi\in\mathcal{C}\_{\delta},

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼Ï€â€‹[gâ€‹(X)â‹…Î”]\displaystyle\mathbb{E}\_{\pi}[g(X)\cdot\Delta] | â‰¤ğ”¼Ï€â€‹[â€–gâ€‹(X)â€–pâ€‹â€–Î”â€–q]â€‹(ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2)1/2â€‹(ğ”¼Ï€â€‹â€–Î”â€–q2)1/2â‰¤Kâ€‹Î´Ï„,\displaystyle\leq\mathbb{E}\_{\pi}\big[\|g(X)\|\_{p}\,\|\Delta\|\_{q}\big]\Big(\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}\Big)^{1/2}\Big(\mathbb{E}\_{\pi}\|\Delta\|\_{q}^{2}\Big)^{1/2}\leq K\,\sqrt{\frac{\delta}{\tau}}, |  |

where we used that Xâˆ¼Î½X\sim\nu under Ï€\pi and ([23](https://arxiv.org/html/2512.01408v1#S3.E23 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")).
Thus,

|  |  |  |
| --- | --- | --- |
|  | supÏ€âˆˆğ’Î´ğ”¼Ï€â€‹[gâ€‹(X)â‹…Î”]â‰¤Kâ€‹Î´Ï„,\sup\_{\pi\in\mathcal{C}\_{\delta}}\mathbb{E}\_{\pi}[g(X)\cdot\Delta]\leq K\,\sqrt{\frac{\delta}{\tau}}, |  |

and ([27](https://arxiv.org/html/2512.01408v1#S3.E27 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) yields

|  |  |  |
| --- | --- | --- |
|  | VÎ´âˆ’Jâ€‹(Î½)â‰¤Î´Ï„â€‹K+oâ€‹(Î´).V\_{\delta}-J(\nu)\leq\sqrt{\frac{\delta}{\tau}}\,K+o(\sqrt{\delta}). |  |

Step 4: Lower bound via a deterministic extremal Monge map.
For each xx with gâ€‹(x)â‰ 0g(x)\neq 0, choose

|  |  |  |
| --- | --- | --- |
|  | uâ€‹(x)âˆˆargâ¡maxâ€–uâ€–q=1â¡gâ€‹(x)â‹…u,u(x)\in\arg\max\_{\|u\|\_{q}=1}g(x)\cdot u, |  |

and define

|  |  |  |
| --- | --- | --- |
|  | Î”Â¯â€‹(x):=â€–gâ€‹(x)â€–pKâ€‹uâ€‹(x),Î”Â¯â€‹(x):=0â€‹Â ifÂ â€‹gâ€‹(x)=0.\bar{\Delta}(x):=\frac{\|g(x)\|\_{p}}{K}\,u(x),\qquad\bar{\Delta}(x):=0\text{ if }g(x)=0. |  |

Then

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹â€–Î”Â¯â€‹(X)â€–q2=1K2â€‹ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2=1,\mathbb{E}\_{\nu}\|\bar{\Delta}(X)\|\_{q}^{2}=\frac{1}{K^{2}}\,\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}=1, |  |

and

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹[gâ€‹(X)â‹…Î”Â¯â€‹(X)]=1Kâ€‹ğ”¼Î½â€‹[â€–gâ€‹(X)â€–pâ€‹gâ€‹(X)â‹…uâ€‹(X)]=1Kâ€‹ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2=K.\mathbb{E}\_{\nu}[g(X)\cdot\bar{\Delta}(X)]=\frac{1}{K}\,\mathbb{E}\_{\nu}\big[\|g(X)\|\_{p}\,g(X)\cdot u(X)\big]=\frac{1}{K}\,\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}=K. |  |

Define the Monge map

|  |  |  |
| --- | --- | --- |
|  | TÎ´â€‹(x):=x+Î´Ï„â€‹Î”Â¯â€‹(x),Î¼Î´:=TÎ´â€‹#â€‹Î½,T\_{\delta}(x):=x+\sqrt{\frac{\delta}{\tau}}\,\bar{\Delta}(x),\qquad\mu\_{\delta}:=T\_{\delta\#}\nu, |  |

and let Ï€Î´\pi\_{\delta} be the coupling (Xâ€²,X)=(TÎ´â€‹(X),X)(X^{\prime},X)=(T\_{\delta}(X),X) with Xâˆ¼Î½X\sim\nu.
Then

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Ï€Î´â€‹â€–Xâ€²âˆ’Xâ€–q2=Î´Ï„â€‹ğ”¼Î½â€‹â€–Î”Â¯â€‹(X)â€–q2=Î´Ï„,\mathbb{E}\_{\pi\_{\delta}}\|X^{\prime}-X\|\_{q}^{2}=\frac{\delta}{\tau}\,\mathbb{E}\_{\nu}\|\bar{\Delta}(X)\|\_{q}^{2}=\frac{\delta}{\tau}, |  |

so

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î¼Î´,Î½)â‰¤ğ”¼Ï€Î´â€‹câ€‹(Xâ€²âˆ’X)=Ï„â€‹ğ”¼Ï€Î´â€‹â€–Xâ€²âˆ’Xâ€–q2=Î´,D\_{c}(\mu\_{\delta},\nu)\leq\mathbb{E}\_{\pi\_{\delta}}c(X^{\prime}-X)=\tau\,\mathbb{E}\_{\pi\_{\delta}}\|X^{\prime}-X\|\_{q}^{2}=\delta, |  |

and hence Ï€Î´âˆˆğ’Î´\pi\_{\delta}\in\mathcal{C}\_{\delta} and Î¼Î´\mu\_{\delta} is feasible.

Applying ([26](https://arxiv.org/html/2512.01408v1#S3.E26 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) with Ï€Î´\pi\_{\delta},

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(Î¼Î´)âˆ’Jâ€‹(Î½)=ğ”¼Ï€Î´â€‹[gâ€‹(X)â‹…Î”]+oâ€‹(Î´)=Î´Ï„â€‹ğ”¼Î½â€‹[gâ€‹(X)â‹…Î”Â¯â€‹(X)]+oâ€‹(Î´)=Î´Ï„â€‹K+oâ€‹(Î´).J(\mu\_{\delta})-J(\nu)=\mathbb{E}\_{\pi\_{\delta}}[g(X)\cdot\Delta]+o(\sqrt{\delta})=\sqrt{\frac{\delta}{\tau}}\,\mathbb{E}\_{\nu}[g(X)\cdot\bar{\Delta}(X)]+o(\sqrt{\delta})=\sqrt{\frac{\delta}{\tau}}\,K+o(\sqrt{\delta}). |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | lim infÎ´â†“0VÎ´âˆ’Jâ€‹(Î½)Î´â‰¥1Ï„â€‹K.\liminf\_{\delta\downarrow 0}\frac{V\_{\delta}-J(\nu)}{\sqrt{\delta}}\geq\sqrt{\frac{1}{\tau}}\,K. |  |

Step 5: Conclusion.
Combining the upper bound from Step 3 with the lower bound from Step 4,

|  |  |  |
| --- | --- | --- |
|  | 1Ï„â€‹Kâ‰¤lim infÎ´â†“0VÎ´âˆ’Jâ€‹(Î½)Î´â‰¤lim supÎ´â†“0VÎ´âˆ’Jâ€‹(Î½)Î´â‰¤1Ï„â€‹K.\sqrt{\frac{1}{\tau}}\,K\leq\liminf\_{\delta\downarrow 0}\frac{V\_{\delta}-J(\nu)}{\sqrt{\delta}}\leq\limsup\_{\delta\downarrow 0}\frac{V\_{\delta}-J(\nu)}{\sqrt{\delta}}\leq\sqrt{\frac{1}{\tau}}\,K. |  |

Hence

|  |  |  |
| --- | --- | --- |
|  | VÎ´=Jâ€‹(Î½)+Î´Ï„â€‹K+oâ€‹(Î´)=Jâ€‹(Î½)+Î´Ï„â€‹(ğ”¼Î½â€‹â€–gâ€‹(X)â€–p2)1/2+oâ€‹(Î´),V\_{\delta}=J(\nu)+\sqrt{\frac{\delta}{\tau}}\,K+o(\sqrt{\delta})=J(\nu)+\sqrt{\frac{\delta}{\tau}}\,\Big(\mathbb{E}\_{\nu}\|g(X)\|\_{p}^{2}\Big)^{1/2}+o(\sqrt{\delta}), |  |

and the Monge map TÎ´T\_{\delta} constructed in Step 4 is asymptotically optimal
and of the stated form.
âˆ

When applied to the specific Problem ([22](https://arxiv.org/html/2512.01408v1#S3.E22 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), the proof reduces to explicitly computing the Wasserstein derivative and the checking the regularity conditions.

###### Corollary 1 (Asymptotic non-linear optimal perturbation under Wasserstein distance).

Suppose Assumptions [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") hold. Define the functional

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(â„š)=âˆ«â„dFâ„šâ€‹(T,z)â€‹Uâ€‹(Iâ€‹(ğ’¦â„šâ€‹(x0)â€‹eâˆ’râ€‹TFâ„šâ€‹(T,z)))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z,â„šâˆˆğ’°Î´OTâ€‹(â„™0),J(\mathbb{Q})=\int\_{\mathbb{R}^{d}}F\_{\mathbb{Q}}(T,z)\,U\!\left(I\!\left(\frac{\mathcal{K}\_{\mathbb{Q}}(x\_{0})e^{-rT}}{F\_{\mathbb{Q}}(T,z)}\right)\right)\varphi\_{T}(z)\,dz,\qquad\mathbb{Q}\in\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0}), |  |

where Fâ„šâ€‹(T,z)=ğ”¼â„šâ€‹[LTâ€‹(B,z)]F\_{\mathbb{Q}}(T,z)=\mathbb{E}\_{\mathbb{Q}}[L\_{T}(B,z)] and the uncertainty set
ğ’°Î´OTâ€‹(â„™0)={â„š:Dcâ€‹(â„š,â„™0)â‰¤Î´}\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0})=\{\mathbb{Q}:D\_{c}(\mathbb{Q},\mathbb{P}\_{0})\leq\delta\}
is the 2-Wasserstein ball with quadratic cost câ€‹(bâ€²âˆ’b)=â€–bâ€²âˆ’bâ€–22c(b^{\prime}-b)=\|b^{\prime}-b\|\_{2}^{2}.
Define the influence function H:â„dâ†’â„dH:\mathbb{R}^{d}\to\mathbb{R}^{d} by

|  |  |  |
| --- | --- | --- |
|  | Hâ€‹(b):=âˆ‡Jâ„™0â€²â€‹(b)=âˆ«â„dâˆ‡bLTâ€‹(b,z)â€‹(ğ’¦â„™0â€‹(x0)â€‹eâˆ’râ€‹TFâ„™0â€‹(T,z))2â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z,H(b):=\nabla J^{\prime}\_{\mathbb{P}\_{0}}(b)=\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(b,z)\,\left(\frac{\mathcal{K}\_{\mathbb{P}\_{0}}(x\_{0})e^{-rT}}{F\_{\mathbb{P}\_{0}}(T,z)}\right)^{2}\varphi\_{T}(z)\,dz, |  |

where ğ’¦â„™0â€‹(x0)\mathcal{K}\_{\mathbb{P}\_{0}}(x\_{0}) is the unique solution to the budget constraint under â„™0\mathbb{P}\_{0}. Let

|  |  |  |
| --- | --- | --- |
|  | â€–Hâ€–L2â€‹(â„™0):=(ğ”¼â„™0â€‹[â€–Hâ€‹(B)â€–22])1/2.\|H\|\_{L^{2}(\mathbb{P}\_{0})}:=\left(\mathbb{E}\_{\mathbb{P}\_{0}}\big[\|H(B)\|\_{2}^{2}\big]\right)^{1/2}. |  |

Then, as Î´â†’0\delta\to 0, an asymptotically optimal adversarial perturbation is given by the pushforward â„šÎ´âˆ—=(I+Î”Î´âˆ—)#â€‹â„™0\mathbb{Q}^{\*}\_{\delta}=(I+\Delta^{\*}\_{\delta})\_{\#}\mathbb{P}\_{0}, where

|  |  |  |
| --- | --- | --- |
|  | Î”Î´âˆ—â€‹(b)=âˆ’Î´â€‹Hâ€‹(b)â€–Hâ€–L2â€‹(â„™0)+oâ€‹(Î´)inÂ â€‹L2â€‹(â„™0).\Delta\_{\delta}^{\*}(b)=-\sqrt{\delta}\,\frac{H(b)}{\|H\|\_{L^{2}(\mathbb{P}\_{0})}}+o(\sqrt{\delta})\quad\text{in }L^{2}(\mathbb{P}\_{0}). |  |

Furthermore, the corresponding asymptotically optimal value is

|  |  |  |
| --- | --- | --- |
|  | infâ„šâˆˆğ’°Î´OTâ€‹(â„™0)Jâ€‹(â„š)=Jâ€‹(â„™0)âˆ’Î´â€‹â€–Hâ€–L2â€‹(â„™0)+oâ€‹(Î´).\inf\_{\mathbb{Q}\in\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0})}J(\mathbb{Q})=J(\mathbb{P}\_{0})-\sqrt{\delta}\,\|H\|\_{L^{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}). |  |

###### Proof.

We show that JJ satisfies the assumptions of Theorem [3](https://arxiv.org/html/2512.01408v1#Thmtheorem3 "Theorem 3 (Nonlinear optimal perturbations). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")
with q=p=2q=p=2, compute the Wasserstein gradient at â„™0\mathbb{P}\_{0}, and then apply the theorem
to the functional âˆ’J-J to obtain the stated expansion.

Step 1: Computation of the Wasserstein derivative at â„™0\mathbb{P}\_{0}.
Consider the perturbation â„™Ïµ=(1âˆ’Ïµ)â€‹â„™0+Ïµâ€‹Î´b\mathbb{P}^{\epsilon}=(1-\epsilon)\mathbb{P}\_{0}+\epsilon\delta\_{b} and write
kÏµ=ğ’¦â„™Ïµâ€‹(x0)k^{\epsilon}=\mathcal{K}\_{\mathbb{P}^{\epsilon}}(x\_{0}), FÏµâ€‹(z)=Fâ„™Ïµâ€‹(T,z)F^{\epsilon}(z)=F\_{\mathbb{P}^{\epsilon}}(T,z), and

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(â„™Ïµ)=âˆ«â„dFÏµâ€‹(z)â€‹Uâ€‹(Iâ€‹(kÏµâ€‹eâˆ’râ€‹TFÏµâ€‹(z)))â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z.J(\mathbb{P}^{\epsilon})=\int\_{\mathbb{R}^{d}}F^{\epsilon}(z)\,U\!\left(I\!\left(\frac{k^{\epsilon}e^{-rT}}{F^{\epsilon}(z)}\right)\right)\varphi\_{T}(z)\,dz. |  |

Since FÏµâ€‹(z)=(1âˆ’Ïµ)â€‹F0â€‹(z)+Ïµâ€‹LTâ€‹(b,z)F^{\epsilon}(z)=(1-\epsilon)F\_{0}(z)+\epsilon L\_{T}(b,z) and all integrands are dominated by
expâ¡(câ€‹â€–zâ€–)â€‹Ï†Tâ€‹(z)\exp(c\|z\|)\varphi\_{T}(z) (by Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and compactness of BB),
the dominated convergence theorem applies, allowing differentiation under the integral.

Differentiating Jâ€‹(â„™Ïµ)J(\mathbb{P}^{\epsilon}) at Ïµ=0\epsilon=0, and using
Uâ€²â€‹(Iâ€‹(y))=yU^{\prime}(I(y))=y, Iâ€²â€‹(y)=1/Uâ€²â€²â€‹(Iâ€‹(y))I^{\prime}(y)=1/U^{\prime\prime}(I(y)), and the fact that the term containing
kË™=dâ€‹kÏµdâ€‹Ïµ|Ïµ=0\dot{k}=\frac{dk^{\epsilon}}{d\epsilon}|\_{\epsilon=0} cancels by an envelope-theorem argument,
one obtains the first variation

|  |  |  |
| --- | --- | --- |
|  | Î´â€‹JÎ´â€‹â„™0â€‹(b)=(k0â€‹eâˆ’râ€‹T)2â€‹âˆ«â„dLTâ€‹(b,z)F0â€‹(z)2â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z.\frac{\delta J}{\delta\mathbb{P}\_{0}}(b)=(k^{0}e^{-rT})^{2}\int\_{\mathbb{R}^{d}}\frac{L\_{T}(b,z)}{F\_{0}(z)^{2}}\varphi\_{T}(z)\,dz. |  |

Taking the spatial gradient yields the Wasserstein gradient

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‡Jâ„™0â€²(b)=âˆ«â„dâˆ‡bLT(b,z)(ğ’¦â„™0â€‹(x0)â€‹eâˆ’râ€‹TFâ„™0â€‹(T,z))2Ï†T(z)dz=:H(b),\nabla J^{\prime}\_{\mathbb{P}\_{0}}(b)=\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(b,z)\left(\frac{\mathcal{K}\_{\mathbb{P}\_{0}}(x\_{0})e^{-rT}}{F\_{\mathbb{P}\_{0}}(T,z)}\right)^{2}\varphi\_{T}(z)\,dz=:H(b), |  | (28) |

matching exactly the influence function stated in the corollary.

Step 2: Verifying regularity and applying Theorem [3](https://arxiv.org/html/2512.01408v1#Thmtheorem3 "Theorem 3 (Nonlinear optimal perturbations). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").
All remaining assumptions of Theorem [3](https://arxiv.org/html/2512.01408v1#Thmtheorem3 "Theorem 3 (Nonlinear optimal perturbations). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") follow immediately
from the compact support of BB (Assumption [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), the exponential bounds
on LTL\_{T} and âˆ‡bLT\nabla\_{b}L\_{T} from Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), and the continuity of
â„šâ†¦Fâ„š\mathbb{Q}\mapsto F\_{\mathbb{Q}} and â„šâ†¦ğ’¦â„šâ€‹(x0)\mathbb{Q}\mapsto\mathcal{K}\_{\mathbb{Q}}(x\_{0}) under weak convergence.
In particular:

(i) HâˆˆL2â€‹(â„™0)H\in L^{2}(\mathbb{P}\_{0}) by the uniform exponential bound in ([28](https://arxiv.org/html/2512.01408v1#S3.E28 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"));
(ii) (â„š,b)â†¦âˆ‡Jâ„šâ€²â€‹(b)(\mathbb{Q},b)\mapsto\nabla J^{\prime}\_{\mathbb{Q}}(b) is jointly continuous, again by dominated convergence;
(iii) JJ is GÃ¢teaux differentiable along quadratic-cost interpolations, so the linearization formula required by the theorem holds.

Thus, the hypotheses of Theorem [3](https://arxiv.org/html/2512.01408v1#Thmtheorem3 "Theorem 3 (Nonlinear optimal perturbations). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") hold with q=p=2q=p=2 and r=1r=1.

Applying the theorem to J~â€‹(â„š)=âˆ’Jâ€‹(â„š)\widetilde{J}(\mathbb{Q})=-J(\mathbb{Q}) (so that âˆ‡J~â„™0â€²=âˆ’H\nabla\widetilde{J}^{\prime}\_{\mathbb{P}\_{0}}=-H)
gives, as Î´â†’0\delta\to 0,

|  |  |  |
| --- | --- | --- |
|  | supâ„š:Dcâ€‹(â„š,â„™0)â‰¤Î´J~â€‹(â„š)=J~â€‹(â„™0)+Î´â€‹â€–Hâ€–L2â€‹(â„™0)+oâ€‹(Î´),\sup\_{\mathbb{Q}:D\_{c}(\mathbb{Q},\mathbb{P}\_{0})\leq\delta}\widetilde{J}(\mathbb{Q})=\widetilde{J}(\mathbb{P}\_{0})+\sqrt{\delta}\,\|H\|\_{L^{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}), |  |

which is equivalent to

|  |  |  |
| --- | --- | --- |
|  | infâ„š:Dcâ€‹(â„š,â„™0)â‰¤Î´Jâ€‹(â„š)=Jâ€‹(â„™0)âˆ’Î´â€‹â€–Hâ€–L2â€‹(â„™0)+oâ€‹(Î´).\inf\_{\mathbb{Q}:D\_{c}(\mathbb{Q},\mathbb{P}\_{0})\leq\delta}J(\mathbb{Q})=J(\mathbb{P}\_{0})-\sqrt{\delta}\,\|H\|\_{L^{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}). |  |

The optimal perturbation is the Monge map

|  |  |  |
| --- | --- | --- |
|  | Î”Î´â€‹(b)=âˆ’Î´â€‹Hâ€‹(b)â€–Hâ€–L2â€‹(â„™0)+oâ€‹(Î´)inÂ â€‹L2â€‹(â„™0),\Delta\_{\delta}(b)=-\sqrt{\delta}\,\frac{H(b)}{\|H\|\_{L^{2}(\mathbb{P}\_{0})}}+o(\sqrt{\delta})\quad\text{in }L^{2}(\mathbb{P}\_{0}), |  |

as asserted. This completes the proof.
âˆ

###### Remark 2 (Connection to Dual Problem).

The conjugate function Iâ€‹(y)=(Uâ€²)âˆ’1â€‹(y)I(y)=(U^{\prime})^{-1}(y) appears naturally in the dual formulation of the robust optimization problem. In particular, the optimal density tilt under
KL divergence is proportional to Iâ€‹(Î»â€‹LTâ€‹(b,y))I(\lambda L\_{T}(b,y)) for some Lagrange multiplier Î»\lambda. However, under Wasserstein distance and compact support, we do not need to solve the dual â€” the first-order condition suffices.

If â„™0=â„™n\mathbb{P}\_{0}=\mathbb{P}\_{n} for some empirical measure, then we can compute Î”âˆ—\Delta^{\*} by replacing â„™0\mathbb{P}\_{0} by â„™n\mathbb{P}\_{n} conditioned on these samples, rather than viewing them as random measures. We are going to construct i.i.d. samples of B(k)B^{(k)} in Section [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), and then we construct the optimal measure for the original problem via the perturbed empirical measure

|  |  |  |
| --- | --- | --- |
|  | â„™nâ€‹(dâ€‹x)=1nâ€‹âˆ‘k=1nÎ´C(k)â€‹(dâ€‹x),\mathbb{P}\_{n}(dx)\;=\;\frac{1}{n}\sum\_{k=1}^{n}\delta\_{C^{(k)}}(dx), |  |

where for each kk, C(k)=B(k)+Î”âˆ—C^{(k)}=B^{(k)}+\Delta^{\*}. Therefore, this gives a way of solving the Wasserstein constrained distributional optimization problem when Î´>0\delta>0 is small.

## 4 Data-Driven Formulation and Choice of Model Parameters

In this section, we first describe the data-driven version of the DRBC formulation of the stochastic control problem since it is natural to inform the choice of the prior â„™0\mathbb{P}\_{0} from the data, and an appropriate empirical measure is the natural candidate. Next, we provide the prescription to choose an uncertainty radius Î´\delta using an asymptotically optimal (as data collected increases) approach. The idea is that this choice should also be based on observed data. We calibrate the distributional ambiguity set to the smallest size that makes the oracle-optimal portfolio (i.e., the one chosen if the true distribution were known) statistically plausible at the desired confidence level. The prescription is then obtained from an asymptotical statistical result with projecting Wasserstein distance on a nonlinear manifold.

Recall that we assume each asset follows a geometric Brownian motion with random drift:

|  |  |  |
| --- | --- | --- |
|  | dâ€‹Siâ€‹(t)Siâ€‹(t)=Biâ€‹dâ€‹t+âˆ‘j=1dÏƒiâ€‹jâ€‹dâ€‹Wjâ€‹(t),i=1,â€¦,d.\frac{dS\_{i}(t)}{S\_{i}(t)}\;=\;B\_{i}\,dt\;+\;\sum\_{j=1}^{d}\sigma\_{ij}\,dW\_{j}(t),\qquad i=1,\dots,d. |  |

Therefore, we have the explicit closed-form formula

|  |  |  |
| --- | --- | --- |
|  | logâ¡Siâ€‹(t)âˆ’logâ¡Siâ€‹(0)=(Biâˆ’12â€‹â€–Ïƒiâ£â‹…â€–2)â€‹t+âˆ‘j=1dÏƒiâ€‹jâ€‹Wjâ€‹(t),\log S\_{i}(t)-\log S\_{i}(0)=\Big(B\_{i}-\tfrac{1}{2}\|\sigma\_{i\cdot}\|^{2}\Big)\,t\;+\;\sum\_{j=1}^{d}\sigma\_{ij}\,W\_{j}(t), |  |

where â€–Ïƒiâ£â‹…â€–2:=âˆ‘j=1dÏƒiâ€‹j2\|\sigma\_{i\cdot}\|^{2}:=\sum\_{j=1}^{d}\sigma\_{ij}^{2}.

We adopt a data-driven approximation in which the ground-truth distribution of BB is fixed, but at the beginning of the kk-th nonoverlapping window of length t~\tilde{t}, the realization B(k)B^{(k)} of return vectors is redrawn i.i.d. from such ground-truth distribution and constant during the window. Within the kk-th window, we observe prices of the stock SS on a grid 0,h,2â€‹h,â€¦,mâ€‹h=t~0,h,2h,\dots,mh=\tilde{t}.

Asset ii in window kk has return Bi(k)B\_{i}^{(k)}. An unbiased estimator of Bi(k)B\_{i}^{(k)} (conditional on B(k)B^{(k)}) is obtained from the endpoint log-return:

|  |  |  |
| --- | --- | --- |
|  | B^i(k)=logâ¡Si(k)â€‹(t~)âˆ’logâ¡Si(k)â€‹(0)t~+12âˆ¥Ïƒiâ£â‹…âˆ¥2,ğ”¼[B^i(k)|B(k)]=Bi(k).\widehat{B}^{(k)}\_{i}\;=\;\frac{\log S\_{i}^{(k)}(\tilde{t})-\log S\_{i}^{(k)}(0)}{\tilde{t}}\;+\;\tfrac{1}{2}\|\sigma\_{i\cdot}\|^{2},\qquad\mathbb{E}\!\left[\widehat{B}^{(k)}\_{i}\,\middle|\,B^{(k)}\right]=B^{(k)}\_{i}. |  |

Equivalently, averaging one-step log-returns over the window yields

|  |  |  |
| --- | --- | --- |
|  | B^i(k)=1mâ€‹hâ€‹âˆ‘â„“=0mâˆ’1logâ¡(Si(k)â€‹((â„“+1)â€‹h)Si(k)â€‹(â„“â€‹h))+12â€‹â€–Ïƒiâ£â‹…â€–2.\widehat{B}^{(k)}\_{i}\;=\;\frac{1}{mh}\sum\_{\ell=0}^{m-1}\log\!\left(\frac{S\_{i}^{(k)}((\ell+1)h)}{S\_{i}^{(k)}(\ell h)}\right)\;+\;\tfrac{1}{2}\|\sigma\_{i\cdot}\|^{2}. |  |

Collecting kâˆˆ{1,â€¦,n}k\in\{1,...,n\} windows yields i.i.d. estimates B(1),â€¦,B(n)âˆˆâ„dB^{(1)},\dots,B^{(n)}\in\mathbb{R}^{d}. We are abusing notation here because the estimates that we obtained are not exactly the realized B(k)B^{(k)}â€™s but noisy versions. Strictly speaking, we should apply a deconvolution method, which we did but the results did not change significantly and this approach is much easier to implement. The distributional robustness should absorb the noise that is still present in our estimate of B(k)B^{(k)} and in case t~\tilde{t} is hard to estimate. So, ultimately, we take the nominal prior as the empirical measure

|  |  |  |
| --- | --- | --- |
|  | â„™nâ€‹(dâ€‹x)=1nâ€‹âˆ‘k=1nÎ´B(k)â€‹(dâ€‹x).\mathbb{P}\_{n}(dx)\;=\;\frac{1}{n}\sum\_{k=1}^{n}\delta\_{B^{(k)}}(dx). |  |

The choice of the key parameter Î´\delta is crucial. If Î´\delta is too large, there is too much model ambiguity, and the available data becomes less relevant. If Î´\delta is too small, the effect of robustification is negligible. Therefore, the choice of Î´\delta should not be exogenously defined; rather, it should be endogenously informed by the data. Before presenting the methodology, we first present some technical assumptions. We denote kâˆ—=ğ’¦â€‹(x0)k^{\*}=\mathcal{K}(x\_{0}) as the optimal Lagrangian multiplier in Eq. ([8](https://arxiv.org/html/2512.01408v1#S2.E8 "In Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")).

In order to choose an appropriate Î´=Î´n\delta=\delta\_{n}, here we follow the idea behind the RWPI approach introduced in [BKW19]. Intuitively, Î´\delta should be chosen such that the set ğ’°Î´OTâ€‹(â„™n)\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{n}) contains all the probability measures that are plausible variations of the data represented by â„™n\mathbb{P}\_{n}.
According to Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and the assumption that the real underlying ground-truth is â„™âˆ—\mathbb{P}^{\*}, we have that the formula for such an optimal policy is unique with a Lagrangian multiplier kâˆ—k^{\*} as a pre-committed strategy. We restate here (real optimal policy Ï€âˆ—\pi^{\*} and Xâˆ—â€‹(T)X^{\*}(T) has one-to-one correspondence)

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[Î›^â€‹(T)â€‹Xâˆ—â€‹(T)]=âˆ«â„dIâ€‹(kâˆ—â€‹eâˆ’râ€‹Tğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T.\mathbb{E}\_{\mathbb{P}^{\*}}\left[\hat{\Lambda}(T)X^{\*}(T)\right]=\int\_{\mathbb{R}^{d}}I\left(\frac{k^{\*}e^{-rT}}{\mathbb{E}\_{\mathbb{P}^{\*}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}. |  |

We can see that the optimal policy Ï€âˆ—\pi^{\*} and the Lagrangian multiplier kâˆ—k^{\*} also have a one-to-one correspondence. Thus, without loss of generality, we assume k>0k>0 is the decision variable and choose the optimal Î´\delta based on whether the optimal kâˆ—k^{\*} is covered. Similar to the notation in [BKW19], we define

|  |  |  |
| --- | --- | --- |
|  | â„±k={â„™:âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T}.\mathcal{F}\_{k}=\left\{\mathbb{P}:\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}\right\}. |  |

Now, for a fixed â„™âˆˆğ’°Î´OTâ€‹(â„™n)\mathbb{P}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{n}), the set {k>0:â„™âˆˆâ„±k}\left\{k>0:\mathbb{P}\in\mathcal{F}\_{k}\right\} contains all parameter choices that are optimal from the decision makerâ€™s point of view. This motivates the definition of the following set

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î›Î´â€‹(â„™n)\displaystyle\Lambda\_{\delta}(\mathbb{P}\_{n}) | ={k>0:â„±kâˆ©ğ’°Î´OTâ€‹(â„™n)â‰ âˆ…}\displaystyle=\left\{k>0:\mathcal{F}\_{k}\cap\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{n})\neq\varnothing\right\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | ={k>0:there existsÂ â€‹â„™âˆˆğ’°Î´OTâ€‹(â„™n)â€‹Â such thatÂ â€‹âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T},\displaystyle=\left\{k>0:\text{there exists }\mathbb{P}\in\mathcal{U}^{\text{OT}}\_{\delta}(\mathbb{P}\_{n})\text{ such that }\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}\right\}, |  |

which corresponds to all the plausible estimates of kâˆ—k^{\*}. Thus, it includes all the parameter choices that are collected by the decision maker as optimal for some distribution in the uncertainty set. As a result, Î›Î´â€‹(â„™n)\Lambda\_{\delta}(\mathbb{P}\_{n}) is a natural confidence region for kâˆ—k^{\*}. Therefore, Î´>0\delta>0 should be chosen as the smallest Î´nâˆ—\delta^{\*}\_{n} such that kâˆ—k^{\*} belongs to this region with a given confidence interval. Namely,

|  |  |  |
| --- | --- | --- |
|  | Î´nâˆ—=minâ¡{Î´>0:â„™âˆ—â€‹(kâˆ—âˆˆÎ›Î´â€‹(â„™n))â‰¥1âˆ’Î´0},\delta^{\*}\_{n}=\min\left\{\delta>0:\mathbb{P}^{\*}\left(k^{\*}\in\Lambda\_{\delta}(\mathbb{P}\_{n})\right)\geq 1-\delta\_{0}\right\}, |  |

where Î´0\delta\_{0} is the user-defined confidence level (typically Î´0=0.05\delta\_{0}=0.05).

However, by the mere definition, it is hard to compute Î´nâˆ—\delta^{\*}\_{n}. We now provide a simpler representation for Î´nâˆ—\delta^{\*}\_{n} via an auxiliary function called the robust Wasserstein profile (RWP) function:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Rnâ€‹(k)\displaystyle R\_{n}(k) | :=infâ„™âˆˆâ„±kDcâ€‹(â„™,â„™n)\displaystyle:=\inf\_{\mathbb{P}\in\mathcal{F}\_{k}}D\_{c}(\mathbb{P},\mathbb{P}\_{n}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =inf{Dcâ€‹(â„™,â„™n):âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T}.\displaystyle=\inf\left\{D\_{c}(\mathbb{P},\mathbb{P}\_{n}):\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}\right\}. |  |

Compared with the linear projection in [BKW19], here the RWP function is defined as a projection of the empirical measure to a nonlinear manifold, so the behavior of the nonlinear RWP function is much complicated.

In the following theorem, we derive the nonlinear projection asymptotics with great generality, and the specific choice of the uncertainty radius can be obtained by a corollary.

###### Theorem 4 (Non-linear projection asymptotics).

Let Î½\nu be a probability measure on â„d\mathbb{R}^{d}, and let
Îº:ğ’«2â€‹(â„d)â†’â„\kappa:\mathcal{P}\_{2}(\mathbb{R}^{d})\to\mathbb{R} be a functional with Îºâ€‹(Î½)=0\kappa(\nu)=0.
Assume that Îº\kappa admits a first variation ÎºÎ¼â€²:â„dâ†’â„\kappa^{\prime}\_{\mu}:\mathbb{R}^{d}\to\mathbb{R}
such that:

* â€¢

  For any probability measure Î¼\mu and any coupling
  (Xâ€²,X)âˆ¼(Î¼,Î½)(X^{\prime},X)\sim(\mu,\nu), with the linear interpolation
  Î½t:=(1âˆ’t)â€‹Î½+tâ€‹Î¼\nu\_{t}:=(1-t)\nu+t\mu, we have

  |  |  |  |
  | --- | --- | --- |
  |  | Îºâ€‹(Î¼)âˆ’Îºâ€‹(Î½)=âˆ«01ğ”¼â€‹[ÎºÎ½tâ€²â€‹(Xâ€²)âˆ’ÎºÎ½tâ€²â€‹(X)]â€‹ğ‘‘t.\kappa(\mu)-\kappa(\nu)=\int\_{0}^{1}\mathbb{E}\!\left[\kappa^{\prime}\_{\nu\_{t}}(X^{\prime})-\kappa^{\prime}\_{\nu\_{t}}(X)\right]\,dt. |  |
* â€¢

  For Î¼\mu in a neighborhood of Î½\nu, the map
  xâ†¦ÎºÎ¼â€²â€‹(x)x\mapsto\kappa^{\prime}\_{\mu}(x) is C1C^{1}, and its gradient
  gÎ¼â€‹(x):=âˆ‡xÎºÎ¼â€²â€‹(x)g\_{\mu}(x):=\nabla\_{x}\kappa^{\prime}\_{\mu}(x) is jointly continuous
  in (Î¼,x)(\mu,x) near (Î½,â‹…)(\nu,\cdot). Moreover, there exists
  an envelope GâˆˆL2â€‹(Î½)G\in L^{2}(\nu) such that

  |  |  |  |
  | --- | --- | --- |
  |  | â€–gÎ¼â€‹(x)â€–2â‰¤Gâ€‹(x)for allÂ Î¼Â in a neighborhood ofÂ Î½Â and allÂ â€‹xâˆˆâ„d,\|g\_{\mu}(x)\|\_{2}\leq G(x)\quad\text{for all $\mu$ in a neighborhood of $\nu$ and all }x\in\mathbb{R}^{d}, |  |

  and

  |  |  |  |
  | --- | --- | --- |
  |  | gÎ½âˆˆL2â€‹(Î½;â„d),â€–gÎ½â€–L2â€‹(Î½)>0.g\_{\nu}\in L^{2}(\nu;\mathbb{R}^{d}),\qquad\|g\_{\nu}\|\_{L^{2}(\nu)}>0. |  |

Let c:â„dÃ—â„dâ†’[0,âˆ]c:\mathbb{R}^{d}\times\mathbb{R}^{d}\to[0,\infty] be a transport cost satisfying:

* (i)

  There exist Ï„>0\tau>0, r0>0r\_{0}>0
  and a function Î·:(0,r0]â†’[0,âˆ)\eta:(0,r\_{0}]\to[0,\infty) with Î·â€‹(r)â†’0\eta(r)\to 0 as râ†’0r\to 0 such that

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | |câ€‹(x,y)âˆ’Ï„â€‹â€–xâˆ’yâ€–22|â‰¤Î·â€‹(â€–xâˆ’yâ€–2)â€‹â€–xâˆ’yâ€–22wheneverÂ â€‹â€–xâˆ’yâ€–2â‰¤r0.\bigl|c(x,y)-\tau\|x-y\|\_{2}^{2}\bigr|\;\leq\;\eta(\|x-y\|\_{2})\,\|x-y\|\_{2}^{2}\qquad\text{whenever }\|x-y\|\_{2}\leq r\_{0}. |  | (29) |
* (ii)

  There exist constants C1>0C\_{1}>0, C2â‰¥0C\_{2}\geq 0, R>0R>0
  such that

  |  |  |  |
  | --- | --- | --- |
  |  | câ€‹(x,y)â‰¥C1â€‹â€–xâˆ’yâ€–22âˆ’C2wheneverÂ â€‹â€–xâˆ’yâ€–2â‰¥R.c(x,y)\;\geq\;C\_{1}\|x-y\|\_{2}^{2}-C\_{2}\qquad\text{whenever }\|x-y\|\_{2}\geq R. |  |

Let

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î½,Î¼):=infÏ€âˆˆÎ â€‹(Î½,Î¼)âˆ«â„dÃ—â„dcâ€‹(x,y)â€‹Ï€â€‹(dâ€‹x,dâ€‹y)D\_{c}(\nu,\mu):=\inf\_{\pi\in\Pi(\nu,\mu)}\int\_{\mathbb{R}^{d}\times\mathbb{R}^{d}}c(x,y)\,\pi(dx,dy) |  |

denote the optimal transport divergence induced by cc. For zz in a neighborhood
of 0, define the projection cost

|  |  |  |
| --- | --- | --- |
|  | Râ€‹(z):=infÎ¼:Îºâ€‹(Î¼)=zDcâ€‹(Î½,Î¼).R(z):=\inf\_{\mu:\kappa(\mu)=z}D\_{c}(\nu,\mu). |  |

Then, as zâ†’0z\to 0,

|  |  |  |
| --- | --- | --- |
|  | Râ€‹(z)=Ï„â€‹z2ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]+oâ€‹(z2)=Ï„â€‹z2ğ”¼Î½â€‹[â€–âˆ‡ÎºÎ½â€²â€‹(X)â€–22]+oâ€‹(z2).R(z)=\frac{\tau z^{2}}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}+o(z^{2})=\frac{\tau z^{2}}{\mathbb{E}\_{\nu}[\|\nabla\kappa^{\prime}\_{\nu}(X)\|\_{2}^{2}]}+o(z^{2}). |  |

Moreover, there exists an asymptotically optimal Monge-type perturbation
of the form

|  |  |  |
| --- | --- | --- |
|  | Tzâ€‹(x)=x+Î”zâ€‹(x),Î”zâ€‹(x)=zğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]â€‹gÎ½â€‹(x)+oâ€‹(z)inÂ â€‹L2â€‹(Î½),T\_{z}(x)=x+\Delta\_{z}(x),\qquad\Delta\_{z}(x)=\frac{z}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}\,g\_{\nu}(x)+o(z)\quad\text{in }L^{2}(\nu), |  |

which satisfies Îºâ€‹(Tzâ€‹#â€‹Î½)=z+oâ€‹(z)\kappa(T\_{z\#}\nu)=z+o(z) and attains the above
cost up to oâ€‹(z2)o(z^{2}).

###### Proof.

Fix Î½\nu with Îºâ€‹(Î½)=0\kappa(\nu)=0. For zz small, we seek Î¼\mu such that
Îºâ€‹(Î¼)=z\kappa(\mu)=z and Dcâ€‹(Î½,Î¼)D\_{c}(\nu,\mu) is minimal.

Step 1: Linearization of the constraint.
By the assumptions on the first variation and the regularity of
ÎºÎ¼â€²\kappa^{\prime}\_{\mu}, one obtains that Îº\kappa is W2W\_{2}â€“differentiable
at Î½\nu with derivative gÎ½g\_{\nu}. In particular, for any small
Î”âˆˆL2â€‹(Î½)\Delta\in L^{2}(\nu), letting Î¼=(I+Î”)#â€‹Î½\mu=(I+\Delta)\_{\#}\nu,

|  |  |  |
| --- | --- | --- |
|  | Îºâ€‹(Î¼)âˆ’Îºâ€‹(Î½)=ğ”¼Î½â€‹[âŸ¨gÎ½â€‹(X),Î”â€‹(X)âŸ©]+oâ€‹(â€–Î”â€–L2â€‹(Î½)).\kappa(\mu)-\kappa(\nu)=\mathbb{E}\_{\nu}\!\left[\langle g\_{\nu}(X),\Delta(X)\rangle\right]+o\bigl(\|\Delta\|\_{L^{2}(\nu)}\bigr). |  |

Imposing the constraint Îºâ€‹(Î¼)=z\kappa(\mu)=z and recalling Îºâ€‹(Î½)=0\kappa(\nu)=0, we
obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼Î½â€‹[âŸ¨gÎ½â€‹(X),Î”â€‹(X)âŸ©]=z+oâ€‹(â€–Î”â€–L2â€‹(Î½)).\mathbb{E}\_{\nu}\!\left[\langle g\_{\nu}(X),\Delta(X)\rangle\right]=z+o\bigl(\|\Delta\|\_{L^{2}(\nu)}\bigr). |  | (30) |

In particular, any admissible perturbation satisfies
â€–Î”â€–L2â€‹(Î½)=Oâ€‹(|z|)\|\Delta\|\_{L^{2}(\nu)}=O(|z|) as zâ†’0z\to 0.

Step 2: Quadratic approximation of the cost.
For Î¼=(I+Î”)#â€‹Î½\mu=(I+\Delta)\_{\#}\nu, consider the coupling
(Xâ€²,X)=(X+Î”â€‹(X),X)(X^{\prime},X)=(X+\Delta(X),X) with Xâˆ¼Î½X\sim\nu. Then

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î½,Î¼)â‰¤ğ”¼Î½â€‹[câ€‹(X,X+Î”â€‹(X))].D\_{c}(\nu,\mu)\leq\mathbb{E}\_{\nu}\!\big[c\big(X,X+\Delta(X)\big)\big]. |  |

By the uniform local expansion ([29](https://arxiv.org/html/2512.01408v1#S4.E29 "In item (i) â€£ Theorem 4 (Non-linear projection asymptotics). â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")),

|  |  |  |
| --- | --- | --- |
|  | câ€‹(X,X+Î”â€‹(X))=Ï„â€‹â€–Î”â€‹(X)â€–22+râ€‹(Î”â€‹(X)),c\big(X,X+\Delta(X)\big)=\tau\|\Delta(X)\|\_{2}^{2}+r(\Delta(X)), |  |

where

|  |  |  |
| --- | --- | --- |
|  | |râ€‹(h)|â‰¤Î·â€‹(â€–hâ€–2)â€‹â€–hâ€–22,Î·â€‹(r)â†’0â€‹Â asÂ â€‹râ†’0.|r(h)|\leq\eta(\|h\|\_{2})\,\|h\|\_{2}^{2},\qquad\eta(r)\to 0\text{ as }r\to 0. |  |

Since â€–Î”â€–L2â€‹(Î½)=Oâ€‹(|z|)\|\Delta\|\_{L^{2}(\nu)}=O(|z|), we have
ğ”¼Î½â€‹[â€–Î”â€‹(X)â€–22]=Oâ€‹(z2)\mathbb{E}\_{\nu}[\|\Delta(X)\|\_{2}^{2}]=O(z^{2}) and â€–Î”â€‹(X)â€–â†’0\|\Delta(X)\|\to 0 in probability.
Using the uniform bound, we obtain

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹[|râ€‹(Î”â€‹(X))|]â‰¤(supâ€–hâ€–â‰¤r0Î·â€‹(â€–hâ€–))â€‹ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22=oâ€‹(ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22)=oâ€‹(z2).\mathbb{E}\_{\nu}[\,|r(\Delta(X))|\,]\;\leq\;\left(\sup\_{\|h\|\leq r\_{0}}\eta(\|h\|)\right)\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}=o\bigl(\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}\bigr)=o(z^{2}). |  |

Thus

|  |  |  |  |
| --- | --- | --- | --- |
|  | Dcâ€‹(Î½,Î¼)â‰¤Ï„â€‹ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22+oâ€‹(z2).D\_{c}(\nu,\mu)\leq\tau\,\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}+o(z^{2}). |  | (31) |

Next, we prove the lower bound.
Let Î¼\mu satisfy Îºâ€‹(Î¼)=z\kappa(\mu)=z, and let Ï€\pi be an optimal coupling
between Î½\nu and Î¼\mu, with (X,Y)âˆ¼Ï€(X,Y)\sim\pi and displacement D:=Yâˆ’XD:=Y-X.
By the first-variation representation and the envelope bound on gÎ¼g\_{\mu},

|  |  |  |
| --- | --- | --- |
|  | z=ğ”¼Ï€â€‹[âŸ¨gÎ½â€‹(X),DâŸ©]+oâ€‹(â€–Dâ€–L2â€‹(Ï€)).z=\mathbb{E}\_{\pi}\!\left[\langle g\_{\nu}(X),D\rangle\right]+o\bigl(\|D\|\_{L^{2}(\pi)}\bigr). |  |

Hence â€–Dâ€–L2â€‹(Ï€)=Oâ€‹(|z|)\|D\|\_{L^{2}(\pi)}=O(|z|).

By the local expansion ([29](https://arxiv.org/html/2512.01408v1#S4.E29 "In item (i) â€£ Theorem 4 (Non-linear projection asymptotics). â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), for â€–Dâ€–â‰¤r0\|D\|\leq r\_{0},

|  |  |  |
| --- | --- | --- |
|  | câ€‹(X,Y)=Ï„â€‹â€–Dâ€–22+râ€‹(D),|râ€‹(D)|â‰¤Î·â€‹(â€–Dâ€–)â€‹â€–Dâ€–22,c(X,Y)=\tau\|D\|\_{2}^{2}+r(D),\qquad|r(D)|\leq\eta(\|D\|)\|D\|\_{2}^{2}, |  |

while for â€–Dâ€–>r0\|D\|>r\_{0}, the quadratic coercivity (ii) yields

|  |  |  |
| --- | --- | --- |
|  | câ€‹(X,Y)â‰¥C1â€‹â€–Dâ€–22âˆ’C2.c(X,Y)\;\geq\;C\_{1}\|D\|\_{2}^{2}-C\_{2}. |  |

As â€–Dâ€–L2=Oâ€‹(|z|)\|D\|\_{L^{2}}=O(|z|), the region {â€–Dâ€–>r0}\{\|D\|>r\_{0}\} has probability
Oâ€‹(z2)O(z^{2}) by Markovâ€™s inequality. Combining these bounds,

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î½,Î¼)=ğ”¼Ï€â€‹[câ€‹(X,Y)]â‰¥Ï„â€‹ğ”¼Ï€â€‹â€–Dâ€–22âˆ’oâ€‹(ğ”¼Ï€â€‹â€–Dâ€–22)=Ï„â€‹ğ”¼Ï€â€‹â€–Dâ€–22+oâ€‹(z2).D\_{c}(\nu,\mu)=\mathbb{E}\_{\pi}[c(X,Y)]\;\geq\;\tau\,\mathbb{E}\_{\pi}\|D\|\_{2}^{2}-o\!\bigl(\mathbb{E}\_{\pi}\|D\|\_{2}^{2}\bigr)=\tau\,\mathbb{E}\_{\pi}\|D\|\_{2}^{2}+o(z^{2}). |  |

Next define the conditional mean displacement
Î”â€‹(x):=ğ”¼â€‹[Dâˆ£X=x]\Delta(x):=\mathbb{E}[D\mid X=x]. Then

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Ï€â€‹âŸ¨gÎ½â€‹(X),DâŸ©=ğ”¼Î½â€‹âŸ¨gÎ½â€‹(X),Î”â€‹(X)âŸ©,ğ”¼Ï€â€‹â€–Dâ€–22â‰¥ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22.\mathbb{E}\_{\pi}\langle g\_{\nu}(X),D\rangle=\mathbb{E}\_{\nu}\langle g\_{\nu}(X),\Delta(X)\rangle,\qquad\mathbb{E}\_{\pi}\|D\|\_{2}^{2}\;\geq\;\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}. |  |

Thus every admissible Î¼\mu induces a perturbation
Î”âˆˆL2â€‹(Î½)\Delta\in L^{2}(\nu) with

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹âŸ¨gÎ½â€‹(X),Î”â€‹(X)âŸ©=z+oâ€‹(z),Dcâ€‹(Î½,Î¼)â‰¥Ï„â€‹ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22+oâ€‹(z2).\mathbb{E}\_{\nu}\langle g\_{\nu}(X),\Delta(X)\rangle=z+o(z),\qquad D\_{c}(\nu,\mu)\geq\tau\,\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}+o(z^{2}). |  |

Hence we conclude that
for admissible Î¼\mu,

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(Î½,Î¼)=Ï„â€‹ğ”¼Î½â€‹â€–Î”â€‹(X)â€–22+oâ€‹(z2).D\_{c}(\nu,\mu)=\tau\,\mathbb{E}\_{\nu}\|\Delta(X)\|\_{2}^{2}+o(z^{2}). |  |

Step 3: Solving the quadratic optimization problem.
The leading-order problem is therefore

|  |  |  |
| --- | --- | --- |
|  | infÎ”âˆˆL2â€‹(Î½;â„d){Ï„ğ”¼Î½[âˆ¥Î”(X)âˆ¥22]:ğ”¼Î½[âŸ¨gÎ½(X),Î”(X)âŸ©]=z},\inf\_{\Delta\in L^{2}(\nu;\mathbb{R}^{d})}\Bigl\{\tau\,\mathbb{E}\_{\nu}[\|\Delta(X)\|\_{2}^{2}]:\mathbb{E}\_{\nu}[\langle g\_{\nu}(X),\Delta(X)\rangle]=z\Bigr\}, |  |

where we may ignore the oâ€‹(â€–Î”â€–L2)o(\|\Delta\|\_{L^{2}}) term in
([30](https://arxiv.org/html/2512.01408v1#S4.E30 "In 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) at order z2z^{2}. This is a convex quadratic
optimization with a single linear constraint in the Hilbert space
L2â€‹(Î½;â„d)L^{2}(\nu;\mathbb{R}^{d}). The Lagrangian is

|  |  |  |
| --- | --- | --- |
|  | â„’â€‹(Î”,Î»)=Ï„â€‹ğ”¼Î½â€‹[â€–Î”â€‹(X)â€–22]+Î»â€‹(zâˆ’ğ”¼Î½â€‹[âŸ¨gÎ½â€‹(X),Î”â€‹(X)âŸ©]).\mathcal{L}(\Delta,\lambda)=\tau\,\mathbb{E}\_{\nu}[\|\Delta(X)\|\_{2}^{2}]+\lambda\Bigl(z-\mathbb{E}\_{\nu}[\langle g\_{\nu}(X),\Delta(X)\rangle]\Bigr). |  |

Taking the variational derivative with respect to Î”\Delta and setting
it to zero gives, for Î½\nu-a.e. xx,

|  |  |  |
| --- | --- | --- |
|  | 2â€‹Ï„â€‹Î”â€‹(x)âˆ’Î»â€‹gÎ½â€‹(x)=0âŸ¹Î”â€‹(x)=Î»2â€‹Ï„â€‹gÎ½â€‹(x).2\tau\,\Delta(x)-\lambda g\_{\nu}(x)=0\quad\Longrightarrow\quad\Delta(x)=\frac{\lambda}{2\tau}\,g\_{\nu}(x). |  |

Substituting into the constraint,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹[âŸ¨gÎ½â€‹(X),Î»2â€‹Ï„â€‹gÎ½â€‹(X)âŸ©]=Î»2â€‹Ï„â€‹ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]=z,\mathbb{E}\_{\nu}\!\left[\Big\langle g\_{\nu}(X),\frac{\lambda}{2\tau}g\_{\nu}(X)\Big\rangle\right]=\frac{\lambda}{2\tau}\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]=z, |  |

so

|  |  |  |
| --- | --- | --- |
|  | Î»=2â€‹Ï„â€‹zğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22].\lambda=\frac{2\tau z}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}. |  |

Thus the optimal perturbation at leading order is

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î”zâ€‹(x)=Î»2â€‹Ï„â€‹gÎ½â€‹(x)=zğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]â€‹gÎ½â€‹(x).\Delta\_{z}(x)=\frac{\lambda}{2\tau}\,g\_{\nu}(x)=\frac{z}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}\,g\_{\nu}(x). |  | (32) |

Clearly â€–Î”zâ€–L2â€‹(Î½)=Oâ€‹(|z|)\|\Delta\_{z}\|\_{L^{2}(\nu)}=O(|z|), so the linearization error in
([30](https://arxiv.org/html/2512.01408v1#S4.E30 "In 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is oâ€‹(|z|)o(|z|), and
Îºâ€‹((I+Î”z)#â€‹Î½)=z+oâ€‹(z)\kappa((I+\Delta\_{z})\_{\#}\nu)=z+o(z).

Step 4: Computing the minimal cost.
Plugging ([32](https://arxiv.org/html/2512.01408v1#S4.E32 "In 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) into the quadratic cost term,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î½â€‹[â€–Î”zâ€‹(X)â€–22]=z2(ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22])2â€‹ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]=z2ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22].\mathbb{E}\_{\nu}[\|\Delta\_{z}(X)\|\_{2}^{2}]=\frac{z^{2}}{\bigl(\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]\bigr)^{2}}\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]=\frac{z^{2}}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}. |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | Râ€‹(z)=Ï„â€‹ğ”¼Î½â€‹[â€–Î”zâ€‹(X)â€–22]+oâ€‹(z2)=Ï„â€‹z2ğ”¼Î½â€‹[â€–gÎ½â€‹(X)â€–22]+oâ€‹(z2),R(z)=\tau\,\mathbb{E}\_{\nu}[\|\Delta\_{z}(X)\|\_{2}^{2}]+o(z^{2})=\frac{\tau z^{2}}{\mathbb{E}\_{\nu}[\|g\_{\nu}(X)\|\_{2}^{2}]}+o(z^{2}), |  |

which is the desired expansion. The Monge map Tzâ€‹(x)=x+Î”zâ€‹(x)T\_{z}(x)=x+\Delta\_{z}(x)
is asymptotically optimal and satisfies Îºâ€‹(Tzâ€‹#â€‹Î½)=z+oâ€‹(z)\kappa(T\_{z\#}\nu)=z+o(z),
as claimed.
âˆ

In the following corollary, we provide an asymptotic result nâ€‹Rnâ€‹(kâˆ—)â‡’Î¥nR\_{n}(k^{\*})\Rightarrow\Upsilon, so that

|  |  |  |
| --- | --- | --- |
|  | limnâ†’âˆâ„™âˆ—â€‹(Rnâ€‹(kâˆ—)â‰¤Î·1âˆ’Î´0n)=limnâ†’âˆâ„™âˆ—â€‹(nâ€‹Rnâ€‹(kâˆ—)â‰¤Î·1âˆ’Î´0)=â„™âˆ—â€‹(Î¥â‰¤Î·1âˆ’Î´0)=1âˆ’Î´0,\lim\_{n\to\infty}\mathbb{P}^{\*}\left(R\_{n}(k^{\*})\leq\frac{\eta\_{1-\delta\_{0}}}{n}\right)=\lim\_{n\to\infty}\mathbb{P}^{\*}\left(nR\_{n}(k^{\*})\leq\eta\_{1-\delta\_{0}}\right)=\mathbb{P}^{\*}\left(\Upsilon\leq\eta\_{1-\delta\_{0}}\right)=1-\delta\_{0}, |  |

where we define Î·1âˆ’Î´0\eta\_{1-\delta\_{0}} is the (1âˆ’Î´0)(1-\delta\_{0})-quantile of Î¥\Upsilon.

###### Corollary 2.

Suppose Assumption [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") hold. Define the RWP function for the Merton budget constraint as

|  |  |  |
| --- | --- | --- |
|  | Rnâ€‹(k)=inf{Dcâ€‹(â„™n,â„™):âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T}.R\_{n}(k)=\inf\left\{D\_{c}(\mathbb{P}\_{n},\mathbb{P}):\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}}[L\_{T}(B,y)]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}\right\}. |  |

Then with the cost function câ€‹(x,y)=â€–xâˆ’yâ€–22c(x,y)=||x-y||\_{2}^{2},

|  |  |  |
| --- | --- | --- |
|  | nâ€‹Rnâ€‹(kâˆ—)â‡’Î¥,asÂ â€‹nâ†’âˆ,nR\_{n}(k^{\*})\Rightarrow\Upsilon,\quad\text{as }n\to\infty, |  |

where Î¥\Upsilon is a non-negative random variable given by

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î¥=Z2ğ”¼â„™âˆ—â€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22],\Upsilon=\frac{Z^{2}}{\mathbb{E}\_{\mathbb{P}^{\*}}[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}]}, |  | (33) |

with Zâˆ¼ğ’©â€‹(0,Ïƒ2)Z\sim\mathcal{N}(0,\sigma^{2}) and

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ïƒ2=Varâ„™âˆ—â€‹(âˆ«â„dgâ€²â€‹(Fâ€‹(y))â€‹LTâ€‹(B,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y),\sigma^{2}=\text{Var}\_{\mathbb{P}^{\*}}\left(\int\_{\mathbb{R}^{d}}g^{\prime}(F(y))L\_{T}(B,y)\varphi\_{T}(y)dy\right), |  | (34) |

where Fâ€‹(y)=ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)]F(y)=\mathbb{E}\_{\mathbb{P}^{\*}}[L\_{T}(B,y)],

|  |  |  |
| --- | --- | --- |
|  | gâ€²â€‹(F)=âˆ’Iâ€²â€‹(kâˆ—â€‹eâˆ’râ€‹TF)â€‹kâˆ—â€‹eâˆ’râ€‹TF2,g^{\prime}(F)=-I^{\prime}\!\left(\frac{k^{\*}e^{-rT}}{F}\right)\frac{k^{\*}e^{-rT}}{F^{2}}, |  |

and

|  |  |  |
| --- | --- | --- |
|  | âˆ‡Îºâ„™âˆ—â€²â€‹(b)=âˆ’âˆ«â„dIâ€²â€‹(kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y))â‹…kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y)2â‹…âˆ‡bLTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(b)=-\int\_{\mathbb{R}^{d}}I^{\prime}\left(\frac{k^{\*}e^{-rT}}{F(y)}\right)\cdot\frac{k^{\*}e^{-rT}}{F(y)^{2}}\cdot\nabla\_{b}L\_{T}(b,y)\varphi\_{T}(y)dy. |  |

###### Proof.

We apply Theorem [4](https://arxiv.org/html/2512.01408v1#Thmtheorem4 "Theorem 4 (Non-linear projection asymptotics). â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") to the DRBC Merton setting.
Recall

|  |  |  |
| --- | --- | --- |
|  | Îºkâ€‹(â„™)=âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâˆ’x0â€‹erâ€‹T,â„±k={â„™:Îºkâ€‹(â„™)=0},\kappa\_{k}(\mathbb{P})=\int\_{\mathbb{R}^{d}}I\!\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}}[L\_{T}(B,y)]}\right)\varphi\_{T}(y)\,dy-x\_{0}e^{rT},\qquad\mathcal{F}\_{k}=\{\mathbb{P}:\kappa\_{k}(\mathbb{P})=0\}, |  |

and

|  |  |  |
| --- | --- | --- |
|  | Rnâ€‹(k)=inf{Dcâ€‹(â„™n,â„™):â„™âˆˆâ„±k}.R\_{n}(k)=\inf\{D\_{c}(\mathbb{P}\_{n},\mathbb{P}):\mathbb{P}\in\mathcal{F}\_{k}\}. |  |

Let â„™âˆ—\mathbb{P}^{\*} be the true model and kâˆ—k^{\*} the associated multiplier with
Îºkâˆ—â€‹(â„™âˆ—)=0\kappa\_{k^{\*}}(\mathbb{P}^{\*})=0.

Step 1: Wasserstein derivative of Îºkâˆ—\kappa\_{k^{\*}}.
As in Corollary 1, consider â„™Ïµ=(1âˆ’Ïµ)â€‹â„™âˆ—+Ïµâ€‹Î´b\mathbb{P}^{\epsilon}=(1-\epsilon)\mathbb{P}^{\*}+\epsilon\delta\_{b} and write
Fâ€‹(y)=ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)]F(y)=\mathbb{E}\_{\mathbb{P}^{\*}}[L\_{T}(B,y)].
Differentiating under the integral (justified by Assumptions [1](https://arxiv.org/html/2512.01408v1#Thmassumption1 "Assumption 1 (Utility Function; refinement of Assumption 3.1 of [KZ98]). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")â€“[2](https://arxiv.org/html/2512.01408v1#Thmassumption2 "Assumption 2 (Compact Support for ğµ). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) yields

|  |  |  |
| --- | --- | --- |
|  | Î´â€‹Îºkâˆ—Î´â€‹â„™âˆ—â€‹(b)=âˆ’âˆ«â„dIâ€²â€‹(kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y))â€‹kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y)2â€‹LTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,\frac{\delta\kappa\_{k^{\*}}}{\delta\mathbb{P}^{\*}}(b)=-\int\_{\mathbb{R}^{d}}I^{\prime}\!\left(\frac{k^{\*}e^{-rT}}{F(y)}\right)\frac{k^{\*}e^{-rT}}{F(y)^{2}}L\_{T}(b,y)\,\varphi\_{T}(y)\,dy, |  |

and therefore the Wasserstein gradient is

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‡Îºâ„™âˆ—â€²â€‹(b)=âˆ’âˆ«â„dIâ€²â€‹(kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y))â€‹kâˆ—â€‹eâˆ’râ€‹TFâ€‹(y)2â€‹âˆ‡bLTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(b)=-\int\_{\mathbb{R}^{d}}I^{\prime}\!\left(\frac{k^{\*}e^{-rT}}{F(y)}\right)\frac{k^{\*}e^{-rT}}{F(y)^{2}}\,\nabla\_{b}L\_{T}(b,y)\,\varphi\_{T}(y)\,dy. |  | (35) |

Step 2: Linearization and CLT for Îºkâˆ—â€‹(â„™n)\kappa\_{k^{\*}}(\mathbb{P}\_{n}).
Since â„™â†¦Îºkâˆ—â€‹(â„™)\mathbb{P}\mapsto\kappa\_{k^{\*}}(\mathbb{P}) is Wasserstein differentiable at â„™âˆ—\mathbb{P}^{\*}, the
functional delta method gives

|  |  |  |
| --- | --- | --- |
|  | nâ€‹(Îºkâˆ—â€‹(â„™n)âˆ’Îºkâˆ—â€‹(â„™âˆ—))=1nâ€‹âˆ‘i=1nÎ´â€‹Îºkâˆ—Î´â€‹â„™âˆ—â€‹(B(i))+oPâ€‹(1)â‡’Z,\sqrt{n}\big(\kappa\_{k^{\*}}(\mathbb{P}\_{n})-\kappa\_{k^{\*}}(\mathbb{P}^{\*})\big)=\frac{1}{\sqrt{n}}\sum\_{i=1}^{n}\frac{\delta\kappa\_{k^{\*}}}{\delta\mathbb{P}^{\*}}(B^{(i)})+o\_{P}(1)\Rightarrow Z, |  |

where Zâˆ¼ğ’©â€‹(0,Ïƒ2)Z\sim\mathcal{N}(0,\sigma^{2}) with

|  |  |  |
| --- | --- | --- |
|  | Ïƒ2=Varâ„™âˆ—â€‹(âˆ«â„dgâ€²â€‹(Fâ€‹(y))â€‹LTâ€‹(B,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y),gâ€²â€‹(F)=âˆ’Iâ€²â€‹(kâˆ—â€‹eâˆ’râ€‹TF)â€‹kâˆ—â€‹eâˆ’râ€‹TF2.\sigma^{2}=\text{Var}\_{\mathbb{P}^{\*}}\!\left(\int\_{\mathbb{R}^{d}}g^{\prime}(F(y))\,L\_{T}(B,y)\,\varphi\_{T}(y)\,dy\right),\qquad g^{\prime}(F)=-I^{\prime}\!\left(\frac{k^{\*}e^{-rT}}{F}\right)\frac{k^{\*}e^{-rT}}{F^{2}}. |  |

Write

|  |  |  |
| --- | --- | --- |
|  | zn:=Îºkâˆ—â€‹(â„™n)=Zn+oPâ€‹(1/n).z\_{n}:=\kappa\_{k^{\*}}(\mathbb{P}\_{n})=\frac{Z}{\sqrt{n}}+o\_{P}(1/\sqrt{n}). |  |

Step 3: Application of the local projection law.
Theorem [4](https://arxiv.org/html/2512.01408v1#Thmtheorem4 "Theorem 4 (Non-linear projection asymptotics). â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") gives, for any Î½\nu near â„™âˆ—\mathbb{P}^{\*} with Îºkâˆ—â€‹(Î½)=z\kappa\_{k^{\*}}(\nu)=z,

|  |  |  |
| --- | --- | --- |
|  | Râ€‹(z)=z2ğ”¼â„™âˆ—â€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22]+oâ€‹(z2).R(z)=\frac{z^{2}}{\mathbb{E}\_{\mathbb{P}^{\*}}\!\big[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}\big]}+o(z^{2}). |  |

Taking Î½=â„™n\nu=\mathbb{P}\_{n} and substituting znz\_{n},

|  |  |  |
| --- | --- | --- |
|  | nâ€‹Rnâ€‹(kâˆ—)=nâ€‹Râ€‹(zn)=Z2ğ”¼â„™âˆ—â€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22]+oPâ€‹(1),nR\_{n}(k^{\*})=nR(z\_{n})=\frac{Z^{2}}{\mathbb{E}\_{\mathbb{P}^{\*}}\!\big[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}\big]}+o\_{P}(1), |  |

hence

|  |  |  |
| --- | --- | --- |
|  | nâ€‹Rnâ€‹(kâˆ—)â‡’Î¥:=Z2ğ”¼â„™âˆ—â€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22].nR\_{n}(k^{\*})\Rightarrow\Upsilon:=\frac{Z^{2}}{\mathbb{E}\_{\mathbb{P}^{\*}}\!\big[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}\big]}. |  |

Since Z2Z^{2} is a scaled Ï‡12\chi^{2}\_{1} variable, Î¥\Upsilon is nonnegative.
This completes the proof.
âˆ

Based on the above discussion, we can give the following recipe for computing the optimal DRBC policies with Wasserstein uncertainty set with choosing the optimal Î´\delta based on the data (for a certain time window). This can be viewed as a nonlinear extension of the RWPI method (e.g. see [BlanchetChenZhou2021, Blanchet2021WassersteinDRO]).

* â€¢

  (1) Collect return data {B(i)}i=1,â€¦â€‹n\{B^{(i)}\}\_{i=1,\ldots n}.
* â€¢

  (2) Use the collected data {B(i)}i=1,â€¦â€‹n\{B^{(i)}\}\_{i=1,\ldots n} to solve the equation âˆ«â„dIâ€‹(kâ€‹eâˆ’râ€‹Tğ”¼â„™nâ€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T\int\_{\mathbb{R}^{d}}I\left(\frac{ke^{-rT}}{\mathbb{E}\_{\mathbb{P}\_{n}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT} (this corresponds to estimating ğ’¦â€‹(x0)\mathcal{K}(x\_{0})). Denote the solution as k^\hat{k}.
* â€¢

  (3) Obtain independent samples Y1,â€¦,YNY\_{1},\ldots,Y\_{N} from ğ’©â€‹(0,Tâ€‹Id)\mathcal{N}(0,TI\_{d}). Compute F^â€‹(Yi)=ğ”¼â„™nâ€‹[LTâ€‹(B,Yi)]\hat{F}(Y\_{i})=\mathbb{E}\_{\mathbb{P}\_{n}}[L\_{T}(B,Y\_{i})] for each sample using the collected data {B(i)}i=1,â€¦â€‹n\{B^{(i)}\}\_{i=1,\ldots n}, and then compute ğ”¼â„™nâ€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22]\mathbb{E}\_{\mathbb{P}\_{n}}[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}] as an estimate of the denominator of Î¥,\Upsilon, where âˆ‡Îºâ„™âˆ—â€²â€‹(b)\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(b) is computed by Monte Carlo method with F^â€‹(Yi)\hat{F}(Y\_{i}), LTâ€‹(b,Yi)L\_{T}(b,Y\_{i}), and k^\hat{k} derived in Step (2).
* â€¢

  (4): Estimate ([34](https://arxiv.org/html/2512.01408v1#S4.E34 "In Corollary 2. â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) by the same Monte Carlo method as in Step (3) and denote the estimated variance as Ïƒ^\hat{\sigma}. Define Î¥^=Z^2ğ”¼â„™nâ€‹[â€–âˆ‡Îºâ„™âˆ—â€²â€‹(B)â€–22]\hat{\Upsilon}=\frac{\hat{Z}^{2}}{\mathbb{E}\_{\mathbb{P}\_{n}}[\|\nabla\kappa^{\prime}\_{\mathbb{P}^{\*}}(B)\|\_{2}^{2}]}, where Z^âˆ¼ğ’©â€‹(0,Ïƒ^2)\hat{Z}\sim\mathcal{N}(0,\hat{\sigma}^{2}).
* â€¢

  (5) Obtain independent samples Î¥1,â€¦â€‹Î¥K\Upsilon\_{1},\ldots\Upsilon\_{K} from Î¥^\hat{\Upsilon}. Let Î·^.95\hat{\eta}\_{.95} be the 95%95\% quantile of the sample collections Î¥1,â€¦â€‹Î¥K\Upsilon\_{1},\ldots\Upsilon\_{K}. (KK is a sequence such that Kâ†’âˆK\to\infty as nâ†’âˆn\to\infty, for example, K=logâ¡nK=\log n; see Algorithm 1 in [Blanchet2021WassersteinDRO]).
* â€¢

  (6) Set Î´=Î·^.95n\delta=\frac{\hat{\eta}\_{.95}}{n} and approximate the solution to problem ([21](https://arxiv.org/html/2512.01408v1#S3.E21 "In 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) using Corollary [1](https://arxiv.org/html/2512.01408v1#Thmcorollary1 "Corollary 1 (Asymptotic non-linear optimal perturbation under Wasserstein distance). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and get a worst case probability â„šâˆ—\mathbb{Q}^{\*} for the drift BB.
* â€¢

  (7) Plug in this â„šâˆ—\mathbb{Q}^{\*} into the closed form formula of the optimal fraction with the observed stock prices and interest rates in Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") replacing Î¼\mu by â„šâˆ—\mathbb{Q}^{\*}.

## 5 Synthetic Experiment

### 5.1 Understanding Model Parameters

In this section, we generate synthetic data in a high-dimensional setting and understand how parameters affect the performance of different models. We let the ground-truth drift to be

|  |  |  |  |
| --- | --- | --- | --- |
|  | Biâ€‹t=B02â€‹(1+2â€‹cosâ¡(2â€‹Ï€â€‹Îºiâ€‹t))B\_{it}=\frac{B\_{0}}{2}\left(1+2\cos(2\pi\kappa\_{i}t)\right) |  | (36) |

where ii represents the stock number. Each stockâ€™s Îºi\kappa\_{i} is sampled from the same Gaussian distribution. We set the total number of stocks to be 20. The synthetic stock data is generated using ([2](https://arxiv.org/html/2512.01408v1#S2.E2 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) with drift ([36](https://arxiv.org/html/2512.01408v1#S5.E36 "In 5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), and we set the volatility matrix to be diagonal for simplicity. Throughout the paper, we always assume time 1 to be 1 year, and the unit time is dâ€‹tdt. Given our model is a continuous-time model, dâ€‹tdt should be very granular. The trading rule is simple: for every 22 dâ€‹tdt, calculate data-driven parameters and portfolio weights based on data of the previous 2520 dâ€‹tdt on a rolling basis and trade. The Bayesian Merton and DRBC have different portfolio weights for every dâ€‹tdt, yet others are static. We evaluate the performance using the Sharpe ratio with interest rate r=1%r=1\% on the last 252 dâ€‹tdtâ€™s wealth. We vary B0,dâ€‹tB\_{0},dt and the distribution to sample Îº\kappa to understand the models better, and we would like to use the intuition here to guide our experiments on real data.

All experiment procedures follow algorithm in [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). To be more precise, we estimate â„™0\mathbb{P}\_{0} from the data using Consecutive Drift approach. Then, use the projection method to estimate Î´\delta. After that, we compute Î”â€‹(B)\Delta(B), which is not a projection, but rather a perturbation according to Theorem [3](https://arxiv.org/html/2512.01408v1#Thmtheorem3 "Theorem 3 (Nonlinear optimal perturbations). â€£ 3 Formulation and Main Structural Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). Then we get the modified prior Bâˆ—=B+Î”â€‹(B)B^{\*}=B+\Delta(B), then apply Formulae in [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") with the modified prior distributions to get portfolio weights. Experiment results are shown in Table [1](https://arxiv.org/html/2512.01408v1#S5.T1 "Table 1 â€£ 5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), which is the average of 100 simulations (We use Sharpe Ratio here as performance metric. Table with terminal utility can be found in appendix [3](https://arxiv.org/html/2512.01408v1#Sx3.T3 "Table 3 â€£ Appendix: Additional Experiment Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). Every simulation we use a different seed to sample both Îºi\kappa\_{i} and all the random numbers used in Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). Value for 1/(dâ€‹tÃ—252)1/(dt\times 252) means how many periods we divide a day into. Notice the ground-truth drift is a periodic function with periodicity 1Îº\frac{1}{\kappa}. The drift distribution is estimated as follows: update of drift estimation happens every 30 dâ€‹tdt, each time we use previous 2520 dâ€‹tdt to estimate drift distribution with batched, disjoint time windows. Specifically, we split the 2520 dâ€‹tdt into 10 no-overlapping periods, and estimate annualized return with each stockâ€™s period cumulative return as in Section [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). We call this "Consecutive Drift". We call the market condition smooth when Îºâˆ¼ğ’©â€‹(0,1)\kappa\sim\mathcal{N}(0,1) and is volatile when Îºâˆ¼ğ’©â€‹(12,10)\kappa\sim\mathcal{N}(12,10). During smooth market conditions, models with frequent rebalancing, like Bayesian Merton, DRBC, and DRC, benefit from finer time trading resolution, while DRMV shows worse results. During volatile times, such benefits are not significant. In other words, if one believes the economy will grow steadily with no crisis for a long time, yet they also wants to avoid huge downside risk caused by noise, DRBC could be a reasonable choice.

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Parameters | | | Average Sharpe Ratio | | | | |
| B0B\_{0} | 1/(dâ€‹tÃ—252)1/(dt\times 252) | Îº\kappa | Bayesian Merton | DRBC | DRMV\_no\_rf | DRMV\_rf | DRC |
| 0.2 | 6 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | 0.855 | 0.868 | 1.040 | 1.017 | 0.528 |
|  |  |  | (2.340) | (2.339) | (2.719) | (2.721) | (2.609) |
| 0.2 | 11 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | 0.880 | 0.893 | 0.887 | 0.861 | 0.641 |
|  |  |  | (3.128) | (3.126) | (3.474) | (3.585) | (3.479) |
| 0.4 | 6 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | 2.050 | 2.058 | 2.282 | 2.363 | 1.657 |
|  |  |  | (2.481) | (2.483) | (2.788) | (2.837) | (2.567) |
| 0.4 | 11 | ğ“â€‹(ğŸ,ğŸ)\bm{\mathcal{N}(0,1)} | 2.132 | 2.137 | 1.989 | 2.104 | 1.978 |
|  |  |  | (3.120) | (3.126) | (3.547) | (3.607) | (3.402) |
| 0.2 | 6 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | 0.720 | 0.728 | 0.922 | 0.902 | 0.422 |
|  |  |  | (2.312) | (2.310) | (2.645) | (2.683) | (2.608) |
| 0.2 | 11 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | 0.720 | 0.739 | 0.870 | 0.840 | 0.366 |
|  |  |  | (3.267) | (3.267) | (3.500) | (3.637) | (3.576) |
| 0.4 | 6 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | 1.796 | 1.801 | 2.034 | 2.106 | 1.399 |
|  |  |  | (2.398) | (2.398) | (2.654) | (2.702) | (2.622) |
| 0.4 | 11 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | 1.809 | 1.829 | 1.953 | 2.012 | 1.334 |
|  |  |  | (3.403) | (3.412) | (3.631) | (3.640) | (3.640) |

Table 1: Sharpe Ratio comparison across parameter settings over 100 simulations. Means reported with standard deviations in parentheses.

We also try different ways to estimate the drift distribution and how projection works in DRBC and benchmark methods. Details of DRMV and DRC are discussed in Section [6.1.1](https://arxiv.org/html/2512.01408v1#S6.SS1.SSS1 "6.1.1 DRMV â€£ 6.1 Experiment Design and Data Preparation â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [6.1.2](https://arxiv.org/html/2512.01408v1#S6.SS1.SSS2 "6.1.2 DRC â€£ 6.1 Experiment Design and Data Preparation â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). For drift estimation, we try day-of-week aggregation within larger windows (e.g., averages of â€œMondays,â€ â€œTuesdays,â€ etc.), we call it "Type Drift". In the experiments, all dâ€‹tdt are divided into 10 types to make a more fair comparison with the Consecutive Drift approach. For the perturbation Î”\Delta, we have two choices: change Î”\Delta every dâ€‹tdt by changing the plan time, or keep Î”\Delta static and make plan time the same as drift update frequency. The average Sharpe Ratio results are shown in Table [2](https://arxiv.org/html/2512.01408v1#S5.T2 "Table 2 â€£ 5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") (terminal utility results can be found in appendix [3](https://arxiv.org/html/2512.01408v1#Sx3.T3 "Table 3 â€£ Appendix: Additional Experiment Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). We use B0=0.4,dâ€‹t=1252Ã—11,Îºâˆ¼ğ’©â€‹(0,1)B\_{0}=0.4,dt=\frac{1}{252\times 11},\kappa\sim\mathcal{N}(0,1) suggested by Section [5.1](https://arxiv.org/html/2512.01408v1#S5.SS1 "5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). Consecutive drift and static projection achieves the best performance. A reasonable explanation for the Consecutive approach better than the Type approach is that the implicit number of "types" appears difficult to estimate (e.g. if we think that there is weakly seasonality the number of types should be around 5-7, but likely there are other time-patterns that do not align for all stocks). Only if type number perfectly echoes with Biâ€‹tB\_{it}â€™s period we can get better drift estimation, yet itâ€™s a rare case in practice. The Consecutive approach smooths the drift within the time batch and has better empirical practice overall. Regarding the use of the stating Projection, since here we use very small dâ€‹tdt, time-varying projection is likely influenced by extreme values at the end of drift update period. Simulation results follow our intuition, though the difference is small.

Table 2: Sharpe Ratios on different drift estimation and projection methods over 100 simulations (means on first line; standard deviations in parentheses on the next line)

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Drift | Projection | Bayesian Merton | DRBC | DRMV\_no\_rf | DRMV\_rf | DRC |
| Consecutive | Static | 2.1319 | 2.1374 | 1.9890 | 2.1037 | 1.9778 |
| (3.1203) | (3.1261) | (3.5466) | (3.6072) | (3.4019) |
| Consecutive | Time-varying | 2.1319 | 2.1331 | 1.9890 | 2.1037 | 1.9778 |
| (3.1203) | (3.1268) | (3.5466) | (3.6072) | (3.4019) |
| Type | Static | 1.9815 | 1.9835 | 1.9890 | 2.1037 | 1.9995 |
| (3.4129) | (3.4132) | (3.5466) | (3.6072) | (3.4382) |
| Type | Time-varying | 1.9815 | 1.9814 | 1.9890 | 2.1037 | 1.9995 |
| (3.4129) | (3.4142) | (3.5466) | (3.6072) | (3.4382) |

### 5.2 Role of Radius

In this synthetic experiment, we show how different radii change the performance for DRC and DRBC comparing to optimal strategy, which implicitly proves the importance of data driven radius determination in Section [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). The experiment is a multi-dimensional setting with Wasserstein ball as the uncertainty set and we use the projection approach in Corollary [2](https://arxiv.org/html/2512.01408v1#Thmcorollary2 "Corollary 2. â€£ 4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

The data generation part is similar to Section [5.1](https://arxiv.org/html/2512.01408v1#S5.SS1 "5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). The drift terms are sampled from ([36](https://arxiv.org/html/2512.01408v1#S5.E36 "In 5.1 Understanding Model Parameters â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), and the synthetic stock data is sampled using ([2](https://arxiv.org/html/2512.01408v1#S2.E2 "In 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) with 3024 dâ€‹tdt. We use Mertonâ€™s formula

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï€t=11âˆ’Î±â€‹(Ïƒâ€‹ÏƒT)âˆ’1â€‹(Btâˆ’r)\pi\_{t}=\frac{1}{1-\alpha}(\sigma\sigma^{T})^{-1}(B\_{t}-r) |  | (37) |

to calculate the optimal high dimensional portfolio strategy (policy) and calculate the oracle average terminal utility over one hundred simulated paths. The drift distribution is estimated with batched, disjoint time windows. In this way we have 10 support vectors of the drift distribution, and we assume the drift is uniform on these 10 supports. Here we use Wasserstein uncertainty and algorithm in [4](https://arxiv.org/html/2512.01408v1#S4 "4 Data-Driven Formulation and Choice of Model Parameters â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") to get the portfolio weights. We do not manually set Î´\delta levels, but use a scale factor to scale up the data driven base Î´\delta to explore the best radius since the data driven Î´\delta is rough. Since every point in Figure [1](https://arxiv.org/html/2512.01408v1#S5.F1 "Figure 1 â€£ 5.2 Role of Radius â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") is an average of one hundred simulations, and our data driven Î´\delta calculation gives different base Î´\delta every simulation, we do not show exact Î´\delta in use but show the scaling factor instead, with the average base Î´\delta at the level of 10âˆ’310^{-3}. According to Figure [1](https://arxiv.org/html/2512.01408v1#S5.F1 "Figure 1 â€£ 5.2 Role of Radius â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we observe that for DRBC, radius Î´\delta needs to be carefully calibrated to achieve best terminal utility. For DRC, larger Î´\delta always lead to worse performance.

![Refer to caption](gap_highdim.png)


Figure 1: Expectation of terminal utility gap versus Î´\delta scaling factor for DRC and DRBC in high dimensional case with Wasserstein uncertainty

## 6 Real-data Experiment

For now, we use the same set of data and settings as [BlanchetChenZhou2021], to compare with the overall performance.

### 6.1 Experiment Design and Data Preparation

Inspired by the synthetic data experiment, which shows more granular time period helps continuous time models, we choose to set the trading frequency daily, which is more granular than monthly in [BlanchetChenZhou2021]. We get real data from Wharton Research Database Service (WRDS). The dataset contains all Standard and Poolâ€™s 500 constituents data from 2017-01-01 to 2024-12-31. We choose this time period for two reasons: timeliness and variety of market events. During this period, the market experiences stable uptrend, COVID-19, inflation concerns, market recovery and the boom of Artificial Intelligence, making it very unpredictable and great to test the ability of different strategies in dealing with changes.

The experiment is done with rolling time window of one month. We use 5 years of previous data as the training set for DRBC to get uncertainty radius Î´^\hat{\delta}, empirical distribution B^\hat{B} and values needed for benchmark strategies like DRC and Bayesian Merton. Here for simplicity, we let the Î´\delta scaling factor to be 1. For stocks selection, we randomly sample 20 stocks from S&P 500 constituents in the past 5 years. The real trading period starts from 2022-01-01. DRBC and Bayesian Merton strategies trade daily and follow trading rules in Theorem [1](https://arxiv.org/html/2512.01408v1#Thmtheorem1 "Theorem 1 (Karatzasâ€“Zhao [KZ98]â€™s Solution). â€£ 2 Preliminaries â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), with TT to be two months. Other strategies get static portfolio weights for one month. To avoid future information, specifically in YtY\_{t}, we do not trade on the first day of every month and then start using YtY\_{t} of the previous day. Since the interest rate changes much during our trading period, increases rapidly from about 0 percent to 5 percent and stays at that level, we do a simplification to assume all trades in the trading period with interest rate 5%. For evaluation, we report annualized return, standard deviation and sharpe ratio for the whole time series, and assume the interest rate to be 4%.

#### 6.1.1 DRMV

We include the Wasserstein-robust mean-variance model of [BlanchetChenZhou2021].
Given empirical distribution
Pn=1nâ€‹âˆ‘i=1nÎ´RiP\_{n}=\frac{1}{n}\sum\_{i=1}^{n}\delta\_{R\_{i}},
they consider all return distributions inside the Wasserstein ball

|  |  |  |
| --- | --- | --- |
|  | ğ’°Î´â€‹(Pn)={P:Dcâ€‹(P,Pn)â‰¤Î´},câ€‹(u,v)=â€–uâˆ’vâ€–q2.\mathcal{U}\_{\delta}(P\_{n})=\{P:D\_{c}(P,P\_{n})\leq\delta\},\qquad c(u,v)=\|u-v\|\_{q}^{2}. |  |

The robust Markowitz problem is

|  |  |  |  |
| --- | --- | --- | --- |
|  | minÏ•â¡maxPâˆˆğ’°Î´â€‹(Pn)â¡Ï•âŠ¤â€‹VarPâ¡(R)â€‹Ï•s.t.Â â€‹â€„1âŠ¤â€‹Ï•=1,minPâˆˆğ’°Î´â€‹(Pn)â¡ğ”¼Pâ€‹[R]âŠ¤â€‹Ï•â‰¥Î±Â¯.\min\_{\phi}\;\;\max\_{P\in\mathcal{U}\_{\delta}(P\_{n})}\phi^{\top}\operatorname{Var}\_{P}(R)\phi\quad\text{s.t. }\;\mathbf{1}^{\top}\phi=1,\;\min\_{P\in\mathcal{U}\_{\delta}(P\_{n})}\mathbb{E}\_{P}[R]^{\top}\phi\geq\bar{\alpha}. |  | (38) |

A key result is that ([38](https://arxiv.org/html/2512.01408v1#S6.E38 "In 6.1.1 DRMV â€£ 6.1 Experiment Design and Data Preparation â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is *exactly equivalent* to a regularized empirical problem:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | minÏ•\displaystyle\min\_{\phi} | Ï•âŠ¤â€‹Î£^â€‹Ï•+Î´â€‹â€–Ï•â€–p,\displaystyle\phi^{\top}\hat{\Sigma}\,\phi+\sqrt{\delta}\,\|\phi\|\_{p}, |  | (39) |
|  | s.t. | ğŸâŠ¤â€‹Ï•=1,Î¼^âŠ¤â€‹Ï•â‰¥Î±Â¯+Î´â€‹â€–Ï•â€–p,\displaystyle\mathbf{1}^{\top}\phi=1,\qquad\hat{\mu}^{\top}\phi\geq\bar{\alpha}+\sqrt{\delta}\,\|\phi\|\_{p}, |  |

where Î¼^=ğ”¼Pnâ€‹[R]\hat{\mu}=\mathbb{E}\_{P\_{n}}[R], Î£^=VarPnâ¡(R)\hat{\Sigma}=\operatorname{Var}\_{P\_{n}}(R), and 1/p+1/q=11/p+1/q=1.

Thus, Wasserstein robustness leads to a theoretically justified norm penalty â€–Ï•â€–p\|\phi\|\_{p}, and the ambiguity radius Î´\delta and target Î±Â¯\bar{\alpha} are chosen via data-driven Wasserstein profile inference.

We use two sets of DRMV algorithm, the original one in [BlanchetChenZhou2021] and the one with risk free asset. For the second one, we view the interest rate as the last entry of the return vector, and choose the Î´\delta in the same way as [BlanchetChenZhou2021], and change the annual target return Ï\rho from 10%10\% to 10.5%10.5\%. To avoid trivial results, we manually add a small noise to the interest rate.

#### 6.1.2 DRC

Classical DRC formulations [HansenSargent2001, hansen2008robustness] introduce an adversary who, at every time tt, perturbs the model by selecting a worstâ€“case probability measure within a Ï•\phiâ€“divergence ball.
Given a baseline model PP, at each time step the adversary selects Qâ‰ªPQ\ll P satisfying

|  |  |  |
| --- | --- | --- |
|  | DÏ•â€‹(Qâˆ¥P)â‰¤Î´,D\_{\phi}(Q\|P)\;\leq\;\delta, |  |

where DÏ•D\_{\phi} is the Ï•\phiâ€“divergence generated by a convex function Ï•\phi with Ï•â€‹(1)=0\phi(1)=0.
The controller then solves the dynamic game

|  |  |  |  |
| --- | --- | --- | --- |
|  | supÏ€âˆˆğ’œâ€‹(x0)infQâˆˆğ’°Î´DRCğ”¼Qâ€‹[uâ€‹(XT)],\sup\_{\pi\in\mathcal{A}(x\_{0})}\inf\_{Q\in\mathcal{U}\_{\delta}^{\text{DRC}}}\;\mathbb{E}\_{Q}\!\left[u(X\_{T})\right], |  | (40) |

where ğ’°Î´DRC\mathcal{U}\_{\delta}^{\text{DRC}} denotes the time replenished uncertainty set: the adversary is allowed to choose a new worstâ€“case distribution at every instant.

Here, DRC is a high-dimensional implementation of [Blanchet2025Duality], where an optimization problem induced by the Hamilton-Jacobi-Bellman-Isaacs (HJBI) equation is solved to get the drift estimation, and then the Merton portfolio weight formula ([37](https://arxiv.org/html/2512.01408v1#S5.E37 "In 5.2 Role of Radius â€£ 5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is used to get the portfolio weights. For the same practical concern in shorting stocks as in DRBC, we also assume that the short position of each stock cannot surpass half of the wealth. For the radius in DRC, we directly use the radius from DRBC for simplicity. Note that this is not the optimal radius for DRC.

#### 6.1.3 DRBC

To calculate empirical B^\hat{B} and Î´^\hat{\delta}, we use the previous 5 years of data. We use Ledoit-Wolf [ledoit2004well] algorithm to estimate the covariance matrix, and we calibrate the items in the inverse of the volatility matrix to be within a range for numerical stability. As directly scaling up the daily return to annually might lead to unreasonable values, we also calibrate on the empirical center to keep outliers in a limit. Since BB can be roughly regarded as log return plus volatility, the limit is chosen based on knowledge of financial markets. Besides, given the difficulty to naked short a stock in practice, we assume that the short position of each stock cannot surpass half of wealth.

### 6.2 Comparison and Discussions

We compare the histogram of Sharpe Ratio for aforementioned methods. Figure [2](https://arxiv.org/html/2512.01408v1#S6.F2 "Figure 2 â€£ 6.2 Comparison and Discussions â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") shows the distribution of Sharpe Ratio for Bayes Merton and DRBC. Itâ€™s clear the DRBC distribution shifts rightward and more concentrated on positive Sharpe Ratio. It certifies that true priors in financial markets are high unpredictable and distributionally robust methods are necessary.

Comparison between DRBC and two types of DRMV appear in Figure [4](https://arxiv.org/html/2512.01408v1#S6.F4 "Figure 4 â€£ 6.2 Comparison and Discussions â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [3](https://arxiv.org/html/2512.01408v1#S6.F3 "Figure 3 â€£ 6.2 Comparison and Discussions â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"). Both DRMV methods have more concentrated distributions than DRBC, which is reasonable since DRMV implementations do not allow short selling and borrowing money, thus are more stable than DRBC. Despite not concentrated, DRBC achieves larger average Sharpe Ratio than DRMV during our volatile test period. It is also worth noting that DRBC is a continuous time model while DRMV is not. According to [BlanchetChenZhou2021], continuous time models tend to perform worse than discrete time model, which further ensures the effectiveness of DRBC.

Likewise, as in Figure [5](https://arxiv.org/html/2512.01408v1#S6.F5 "Figure 5 â€£ 6.2 Comparison and Discussions â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), DRBC outperforms DRC with a more right shifted distribution, with both larger maximum and minimum Sharpe Ratio. Figure [5](https://arxiv.org/html/2512.01408v1#S6.F5 "Figure 5 â€£ 6.2 Comparison and Discussions â€£ 6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") also prevails our claim that DRBC can reduce over-pesimissm in DRC.

![Refer to caption](hist_drbc_kara.png)


Figure 2: Histogram of Sharpe Ratios for Bayesian Merton and DRBC

![Refer to caption](hist_drbc_drmvrf.png)


Figure 3: Histogram of Sharpe Ratios for DRMV with riskless asset and DRBC

![Refer to caption](hist_drbc_drmv.png)


Figure 4: Histogram of Sharpe Ratios for DRMV without riskless asset and DRBC

![Refer to caption](hist_drbc_drc.png)


Figure 5: Histogram of Sharpe Ratios for DRC and DRBC

## 7 Conclusions and Future Work

In this paper, we revisited Mertonâ€™s continuous-time portfolio selection problem through a distributionally robust Bayesian control lens. By placing a single ambiguity set on the drift prior, rather than adopting time-rectangular uncertainty on the data-generating process, which tends to be too pessimistic. We preserved the Bayesian learning structure intended to mitigate the over-pessimism often induced by dynamic robust control. A Sion-type minimax swap reduced the DRBC game to a non-linear distributional optimization problem over the drift prior, allowing us to retain the Karatzasâ€“Zhao [KZ98]â€™s closed-form characterization of the value function and optimal policy for each candidate prior. Even if the Sion minimax swap induces a duality gap, weak duality still generates a valid bound which we believe is useful specially in dynamic optimization settings, in which over-pessimism tends to arise more often compared to static adversarial formulations. Therefore, the approach that we propose in this paper, we believe, could be broadly applicable to Bayesian control formulations in which the prior is imposed on certain model parameters.

There are natural directions for future work. One of them is precisely to investigate our proposed approach, as we hinted in the previous paragraph, in distributionally robust Bayesian control settings. This paper provides a blue-print in the setting of Mertonâ€™s model because it is both elegant and of significant interest (both academically and practically). A broader extension would need to be more algorithmic, dealing with efficient methods for solving the Bayesian control problem jointly with the evaluation of the required sensitivities (which we characterize in this paper). However, we believe that such an extension is worth pursuing.

## Supplementary Material

Generalizations of the results to non-compact priors are furnished in the supplementary materials.

## Acknowledgement

J. Blanchet gratefully acknowledges support from DoD through ONR N000142412655, also support from NSF via grants 2312204, 2403007 is gratefully acknowledged. Y. Liu acknowledges financial support from the National Natural Science Foundation of China (Grant No. 12401624), The Chinese University of Hong Kong (Shenzhen) University
Development Fund (Grant No. UDF01003336) and Shenzhen Science and Technology Program (Grant
No. RCBS20231211090814028, JCYJ20250604141203005, 2025TC0010) and is partly supported by the
Guangdong Provincial Key Laboratory of Mathematical Foundations for Artificial Intelligence (Grant No.
2023B1212010001).

## Appendix: Additional Experiment Results

In this section, we show additional experiment results in Section [5](https://arxiv.org/html/2512.01408v1#S5 "5 Synthetic Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and Section [6](https://arxiv.org/html/2512.01408v1#S6 "6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Parameters | | | Average Terminal Utility | | | | |
| B0B\_{0} | 1/(dâ€‹tÃ—252)1/(dt\times 252) | Îº\kappa | Bayesian Merton | DRBC | DRMV\_no\_rf | DRMV\_rf | DRC |
| 0.2 | 6 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | -0.389 | -0.383 | -0.319 | -0.320 | -0.787 |
|  |  |  | (0.386) | (0.373) | (0.033) | (0.030) | (1.396) |
| 0.2 | 11 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | -0.356 | -0.353 | -0.327 | -0.327 | -0.400 |
|  |  |  | (0.225) | (0.218) | (0.024) | (0.022) | (0.298) |
| 0.4 | 6 | ğ’©â€‹(0,1)\mathcal{N}(0,1) | -0.277 | -0.275 | -0.303 | -0.305 | -0.769 |
|  |  |  | (0.345) | (0.338) | (0.033) | (0.030) | (1.975) |
| 0.4 | 11 | ğ“â€‹(ğŸ,ğŸ)\bm{\mathcal{N}(0,1)} | -0.289 | -0.288 | -0.319 | -0.319 | -0.322 |
|  |  |  | (0.216) | (0.209) | (0.023) | (0.022) | (0.308) |
| 0.2 | 6 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | -0.403 | -0.397 | -0.321 | -0.322 | -0.773 |
|  |  |  | (0.390) | (0.376) | (0.033) | (0.030) | (1.267) |
| 0.2 | 11 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | -0.365 | -0.361 | -0.327 | -0.327 | -0.417 |
|  |  |  | (0.229) | (0.221) | (0.024) | (0.022) | (0.306) |
| 0.4 | 6 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | -0.304 | -0.300 | -0.306 | -0.308 | -0.708 |
|  |  |  | (0.358) | (0.347) | (0.031) | (0.029) | (1.660) |
| 0.4 | 11 | ğ’©â€‹(12,10)\mathcal{N}(12,10) | -0.313 | -0.311 | -0.319 | -0.319 | -0.372 |
|  |  |  | (0.236) | (0.230) | (0.024) | (0.022) | (0.338) |

Table 3: Terminal utility comparison across parameter settings over 100 simulations. Means reported with standard deviations in parentheses.




Table 4: Terminal utility on different drift estimation and projection methods over 100 simulations (means on first line; standard deviations in parentheses on the next line)

|  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- |
| Drift | Projection | Bayesian Merton | DRBC | DRMV\_no\_rf | DRMV\_rf | DRC |
| Consecutive | Static | -0.2893 | -0.2883 | -0.3186 | -0.3189 | -0.3224 |
| (0.2156) | (0.2092) | (0.0234) | (0.0216) | (0.3077) |
| Consecutive | Time-varying | -0.2893 | -0.2889 | -0.3186 | -0.3189 | -0.3224 |
| (0.2156) | (0.2113) | (0.0234) | (0.0216) | (0.3077) |
| Type | Static | -0.2986 | -0.2982 | -0.3186 | -0.3189 | -0.3287 |
| (0.2204) | (0.2192) | (0.0234) | (0.0216) | (0.3351) |
| Type | Time-varying | -0.2986 | -0.2984 | -0.3186 | -0.3189 | -0.3287 |
| (0.2204) | (0.2196) | (0.0234) | (0.0216) | (0.3351) |

### 7.1 Discussions for Real Data Experiment

In Section [6](https://arxiv.org/html/2512.01408v1#S6 "6 Real-data Experiment â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we mention the short constraint we add to make sure every single stockâ€™s short position cannot exceed half of the wealth. This is reasonable in practice, yet we want to investigate how many times this constraint is triggered in DRC, DRBC and Bayesian methods, as well as the leverage condition among these methods.

Across all simulations with different data generating parameters, the short constraint happens in more than 90% of trades for DRC method, which is a common disadvantage for Merton-like problems since it always gives extreme values due to the estimation error of average return and variance matrix and the unconstrained optimization. Short constraint appears in about 70% trades in Bayesian setting and about 40% in DRBC setting, illustrating Bayesian methods by [KZ98] can mitigate extreme weights in Merton-like problems and DRBC can further decrease extreme weights.

We also check the overall leverage ratio for three algorithms. DRC on average uses about 13x leverage, with outliers like 31x. Bayesian uses about 7x and DRBC 5x in average. The leverage ratio highly depend on how drift B is estimated, which depends on the training period. If finer constraints on both short and long positions are added, it will give you results with less leverage, yet cannot fully reveal the strength of DRBC method.

## Supplementary Material: Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections

This material is companion to the paper main body of the paper Distributionally Robust Merton Problem Via Nonlinear Wasserstein Projection. In these sections we adapt the results developed in the main body to the case of non-compactly supported prior distributions for power utilities.â€ And then just present the development.

## Appendix A Sub-Gaussian Extensions of the Main Results

In Sections [B](https://arxiv.org/html/2512.01408v1#A2 "Appendix B Generalization of Minimax Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), and [D](https://arxiv.org/html/2512.01408v1#A4 "Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we study a commonly used
utility function in the case where the random drift BB is no longer
compactly supported. This shows that the compactness assumption in the
main text is not essential for the validity of our results; it is
imposed there mainly to avoid lengthy technical arguments involving
exponential moment bounds and Gaussian integrals.

Throughout these sections we fix a CRRA utility

|  |  |  |  |
| --- | --- | --- | --- |
|  | uâ€‹(x)=xÎ±Î±,x>0,Î±<1,Î±â‰ 0,u(x)=\frac{x^{\alpha}}{\alpha},\qquad x>0,\quad\alpha<1,\ \alpha\neq 0, |  | (41) |

and work under a sub-Gaussian assumption on the prior distribution of
BB. More precisely, we assume:

###### Assumption 3 (Sub-Gaussian prior on BB).

There exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™0â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor allÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\exp\bigl(\gamma^{2}\|B\|\_{2}^{2}\bigr)\right]<\infty\qquad\text{for all }\gamma<\gamma\_{0}. |  |

This condition is standard: it requires finite exponential moments of
â€–Bâ€–2\|B\|^{2} and will be used repeatedly to control various Gaussian
integrals arising from the likelihood ratio LTâ€‹(B,y)L\_{T}(B,y) and its
derivatives.

## Appendix B Generalization of Minimax Theorem with Non-compact Support

We first explain how the Minimax Theorem extends to the sub-Gaussian setting when the utility is given by
([41](https://arxiv.org/html/2512.01408v1#A1.E41 "In Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). The goal of this subsection is *only* to
highlight where compactness is used and how Assumption [3](https://arxiv.org/html/2512.01408v1#Thmassumption3 "Assumption 3 (Sub-Gaussian prior on ğµ). â€£ Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")
replaces it; the detailed sub-Gaussian estimates are of the same style
as those developed later in Sections [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [D](https://arxiv.org/html/2512.01408v1#A4 "Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), and we
do not repeat them here.

Recall that in the compact case the proof proceeds in five
steps. Steps 2 and 3 establish continuity and concavity properties of
the map

|  |  |  |
| --- | --- | --- |
|  | (Ï€,â„š)â†¦ğ”¼â„šâ€‹[Uâ€‹(XÏ€â€‹(T))],(\pi,\mathbb{Q})\mapsto\mathbb{E}\_{\mathbb{Q}}[U(X^{\pi}(T))], |  |

while Step 5 uses the closed-form structure of the Karatzasâ€“Zhao
solution to construct an optimal feedback control and to verify that it
lies in the admissible set ğ’œâ€²â€‹(x0)\mathcal{A}^{\prime}(x\_{0}).

Step 2 and Step 3 (moment bounds and continuity).
In the compact-support proof, compactness assumption is used to obtain uniform
bounds on the drift term in the wealth process and on the likelihood
ratio LTâ€‹(b,y)L\_{T}(b,y), uniformly over bâˆˆKb\in K. These bounds, together with
the polynomial growth utility, yield
uniform positive and negative moment bounds for XÏ€â€‹(T)X^{\pi}(T) and hence
integrability of Uâ€‹(XÏ€â€‹(T))U(X^{\pi}(T)); dominated convergence then gives the
required continuity in the model and in the control.

Under Assumption [3](https://arxiv.org/html/2512.01408v1#Thmassumption3 "Assumption 3 (Sub-Gaussian prior on ğµ). â€£ Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), these arguments remain
valid after replacing compactness by exponential moment estimates. The
key observation is that the Gaussian likelihood LTâ€‹(B,y)L\_{T}(B,y) and its
derivatives grow at most exponentially in â€–Bâ€–\|B\| and â€–yâ€–\|y\|. Combined
with Assumption [3](https://arxiv.org/html/2512.01408v1#Thmassumption3 "Assumption 3 (Sub-Gaussian prior on ğµ). â€£ Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), one can bound the relevant
expectations by standard Gaussian integrals and show that

|  |  |  |
| --- | --- | --- |
|  | supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[|XÏ€â€‹(T)|2+Îµ]<âˆ,supâ„šâˆˆğ’°Î´OTâ€‹(â„™0)ğ”¼â„šâ€‹[|XÏ€â€‹(T)|âˆ’m]<âˆ\sup\_{\mathbb{Q}\in\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}\bigl[|X^{\pi}(T)|^{2+\varepsilon}\bigr]<\infty,\qquad\sup\_{\mathbb{Q}\in\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0})}\mathbb{E}\_{\mathbb{Q}}\bigl[|X^{\pi}(T)|^{-m}\bigr]<\infty |  |

for suitable Îµ,m>0\varepsilon,m>0 and all Ï€âˆˆğ’œâ€²â€‹(x0)\pi\in\mathcal{A}^{\prime}(x\_{0}). The
rest of Steps 2 and 3 (continuity in â„š\mathbb{Q} and in Ï€\pi) then
follow exactly as in the compact-support proof; only the bounds used to
justify dominated convergence change, and these are handled by the same
type of sub-Gaussian computations that we carry out in detail for nonlinear perturbation and projection theorems in Sections [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [D](https://arxiv.org/html/2512.01408v1#A4 "Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), respectively.

Step 4 (use of Sionâ€™s Theorem).
In the sub-Gaussian extension in Section [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and
[D](https://arxiv.org/html/2512.01408v1#A4 "Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") (as shown later), the optimal transport cost is no longer the quadratic cost
â€–Î”â€–22\|\Delta\|\_{2}^{2} used in the main text.
Instead, following the Gaussian-integrability estimates derived in this
appendix, the natural cost becomes

|  |  |  |  |
| --- | --- | --- | --- |
|  | cÏ„â€‹(Î”):=eÏ„â€‹â€–Î”â€–22âˆ’â€„1,c\_{\tau}(\Delta)\;:=\;e^{\,\tau\,\|\Delta\|\_{2}^{2}}\;-\;1, |  | (42) |

where the parameter Ï„>0\tau>0 depends explicitly on
Î±\alpha, TT, and â€–Ïƒâˆ’1â€–F2\|\sigma^{-1}\|\_{F}^{2} through the sub-Gaussian
tail bounds of the prior distribution of BB.

We emphasize that this change of transport cost does *not* affect
the minimax argument.
The function Î”â†¦cÏ„â€‹(Î”)\Delta\mapsto c\_{\tau}(\Delta) is convex, and therefore
the divergence ball

|  |  |  |
| --- | --- | --- |
|  | ğ’°Î´cÏ„:={â„š:DcÏ„â€‹(â„šâˆ¥P0)â‰¤Î´}\mathcal{U}\_{\delta}^{c\_{\tau}}:=\bigl\{\mathbb{Q}:D\_{c\_{\tau}}(\mathbb{Q}\,\|\,P\_{0})\leq\delta\bigr\} |  |

is convex.
Moreover, because cÏ„â€‹(Î”)c\_{\tau}(\Delta) grows superlinearly in
â€–Î”â€–2\|\Delta\|\_{2}, the corresponding OT balls are tight and relatively
compact under the topology induced by optimal transport.
Since the payoff functional is linear in â„š\mathbb{Q} and concave in the
control Ï€\pi, all assumptions of Sionâ€™s minimax theorem remain valid.
Hence the change of cost from â€–Î”â€–22\|\Delta\|\_{2}^{2} to cÏ„â€‹(Î”)c\_{\tau}(\Delta) does
not alter the validity of the minâ€“max swap in
Theorem [B](https://arxiv.org/html/2512.01408v1#A2 "Appendix B Generalization of Minimax Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

Step 5 (feedback form and admissibility).
In Step 5 of the main-text proof, the compactness of KK was used to
obtain two-sided exponential bounds on the function Fâ€‹(T,u)F(T,u) and its
gradient, and polynomial growth condition on the utility function was used to control the
ratio

|  |  |  |
| --- | --- | --- |
|  | Îâ€‹(t,y)Î˜â€‹(t,y)\frac{\Xi(t,y)}{\Theta(t,y)} |  |

in terms of expâ¡{câ€‹â€–yâ€–}\exp\{c\|y\|\}. In the present CRRA setting
([41](https://arxiv.org/html/2512.01408v1#A1.E41 "In Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), the inverse marginal utility I=(Uâ€²)âˆ’1I=(U^{\prime})^{-1} and
its derivative admit explicit power-type bounds, so the lower bound on
II required in Step 5 is automatic. Under
Assumption [3](https://arxiv.org/html/2512.01408v1#Thmassumption3 "Assumption 3 (Sub-Gaussian prior on ğµ). â€£ Appendix A Sub-Gaussian Extensions of the Main Results â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the same exponential estimates for
Fâ€‹(T,u)F(T,u) and 1/Fâ€‹(T,u)1/F(T,u) as in the compact case are recovered by
computing Gaussian integrals involving LTâ€‹(B,u)L\_{T}(B,u) and using the
sub-Gaussian tails of BB. Consequently, the ratio
Îâ€‹(t,y)/Î˜â€‹(t,y)\Xi(t,y)/\Theta(t,y) is again controlled by an exponential in
â€–yâ€–\|y\|, and the feedback control Ï€âˆ—,b\pi^{\*,b} satisfies

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„šâ€‹(âˆ«0Tâ€–Ï€âˆ—,bâ€‹(t)â€–2â€‹ğ‘‘t)1/2<âˆ,âˆ€â„šâˆˆğ’°Î´OTâ€‹(â„™0),\mathbb{E}\_{\mathbb{Q}}\Biggl(\int\_{0}^{T}\|\pi^{\*,b}(t)\|^{2}\,dt\Biggr)^{1/2}<\infty,\qquad\forall\,\mathbb{Q}\in\mathcal{U}^{\mathrm{OT}}\_{\delta}(\mathbb{P}\_{0}), |  |

so that Ï€âˆ—,bâˆˆğ’œâ€²â€‹(x0)\pi^{\*,b}\in\mathcal{A}^{\prime}(x\_{0}).

## Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support

In this section, we give a full detailed analysis of how the proofs of the Nonlinear Perturbation Theorem goes without the compact assumption. The proof skills used here are the same as those estimates for Section [B](https://arxiv.org/html/2512.01408v1#A2 "Appendix B Generalization of Minimax Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

After the swapping theorem, with the specific power utility, the distributional optimization problem becomes

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„šâˆ—={argâ¡minâ„šâˆˆğ’°Î´,BDâ€‹(â„™0)â¡ğ’¥â€‹(â„š),ifÂ â€‹Î±âˆˆ(0,1);argâ¡maxâ„šâˆˆğ’°Î´,BDâ€‹(â„™0)â¡ğ’¥â€‹(â„š),ifÂ â€‹Î±<0,\displaystyle\mathbb{Q}^{\*}=\begin{cases}\arg\min\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{D}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q}),&\text{if }\alpha\in(0,1);\\ \arg\max\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{D}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q}),&\text{if }\alpha<0,\end{cases} |  | (43) |

where

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€‹(â„š)=âˆ«â„d(ğ”¼â„šâ€‹[LTâ€‹(B,z)])11âˆ’Î±â€‹Ï†Tâ€‹(z)â€‹ğ‘‘z.\mathcal{J}(\mathbb{Q})=\int\_{\mathbb{R}^{d}}\left(\mathbb{E}\_{\mathbb{Q}}\left[L\_{T}(B,z)\right]\right)^{\frac{1}{1-\alpha}}\varphi\_{T}(z)dz. |  |

We impose a natural sub-Gaussian assumption on BB, and interestingly, the cost function for the optimal transport uncertainty set should be changed to the following: for a displacement Î”âˆˆâ„d\Delta\in\mathbb{R}^{d} and scale Ï„>0\tau>0, the cost function for the optimal transport is defined via

|  |  |  |
| --- | --- | --- |
|  | cÏ„â€‹(Î”):=eÏ„â€‹â€–Î”â€–22âˆ’â€„1.\ c\_{\tau}(\Delta)\;:=\;e^{\,\tau\,\|\Delta\|\_{2}^{2}}\;-\;1. |  |

The main reason of this definition is to ensure the integrability conditions and the use of swapping orders of integration, differentiation, or limit, etc, which are easy to achieve in the compact case.

We remark that the parameter Ï„\tau depends on Î±,T,â€–Ïƒâˆ’1â€–F2\alpha,T,\left\|\sigma^{-1}\right\|\_{F}^{2}. We also assume that

|  |  |  |
| --- | --- | --- |
|  | Ï„>maxâ¡{4â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2,2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹â€–Ïƒâˆ’1â€–F2},\tau>\max\left\{4T\left\|\sigma^{-1}\right\|\_{F}^{2},2T\,(4\beta^{2}-2\beta)\,\|\sigma^{-1}\|\_{F}^{2}\right\}, |  |

where Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}. The precise sub-Gaussian assumption is given below.

###### Assumption 4.

Suppose there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™0â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}\_{0}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{12â€‹(Î²2âˆ’Î²+2+(Î²2âˆ’Î²+2)2+8â€‹(Î²2+Î²)),8,Ï„â‹…2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)Ï„âˆ’2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹â€–Ïƒâˆ’1â€–F2}.\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\;>\;T\max\left\{\frac{1}{2}\Big(\beta^{2}-\beta+2\;+\;\sqrt{\,(\beta^{2}-\beta+2)^{2}+8(\beta^{2}+\beta)\,}\Big)\;,8,\frac{\tau\cdot 2T\,(4\beta^{2}-2\beta)\,}{\tau-2T\,(4\beta^{2}-2\beta)\,\|\sigma^{-1}\|\_{F}^{2}}\right\}. |  |

We begin with the nonlinear perturbation theorem in this setting and stating several technical lemmas.

###### Theorem 5.

Assume that for the fixed Î±\alpha, we have the corresponding cost function and Ï„\tau as in the definition. We define

|  |  |  |  |
| --- | --- | --- | --- |
|  | Hâ€‹(b):=11âˆ’Î±â€‹âˆ«â„dâˆ‡bLTâ€‹(b,y)â€‹ğ”¼â„™0â€‹[LTâ€‹(B,y)]Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yH(b)\;:=\;\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(b,y)\,\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B,y)]^{\frac{\alpha}{1-\alpha}}\;\varphi\_{T}(y)\,dy |  | (44) |

and

|  |  |  |
| --- | --- | --- |
|  | â€–Hâ€–L22â€‹(â„™0):=(ğ”¼â„™0â€‹â€–Hâ€‹(B)â€–22)1/2.\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}:=\Big(\mathbb{E}\_{\mathbb{P}\_{0}}\|H(B)\|\_{2}^{2}\Big)^{1/2}. |  |

Then under Assumption [4](https://arxiv.org/html/2512.01408v1#Thmassumption4 "Assumption 4. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), when Î±âˆˆ(0,1)\alpha\in(0,1), as Î´â†’0\delta\to 0, an asymptotically optimal perturbation is the deterministic pushforward

|  |  |  |
| --- | --- | --- |
|  | Î”Î´âˆ—â€‹(b)=âˆ’Î´Ï„â€‹Hâ€‹(b)â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´)\Delta^{\*}\_{\delta}(b)\;=-\;\sqrt{\frac{\delta}{\tau}}\,\frac{H(b)}{\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}}+o(\sqrt{\delta}) |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
|  | infâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)ğ’¥â€‹(â„š)=ğ’¥â€‹(â„™0)âˆ’Î´Ï„â€‹â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´).\inf\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q})=\mathcal{J}(\mathbb{P}\_{0})-\sqrt{\frac{\delta}{\tau}}\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}). |  | (45) |

When Î±<0\alpha<0, as Î´â†’0\delta\to 0, an asymptotically optimal perturbation is the deterministic pushforward

|  |  |  |
| --- | --- | --- |
|  | Î”Î´âˆ—â€‹(b)=Î´Ï„â€‹Hâ€‹(b)â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´)\Delta^{\*}\_{\delta}(b)\;=\;\sqrt{\frac{\delta}{\tau}}\,\frac{H(b)}{\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}}+o(\sqrt{\delta}) |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
|  | supâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)ğ’¥â€‹(â„š)=ğ’¥â€‹(â„™0)+Î´Ï„â€‹â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´).\sup\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q})=\mathcal{J}(\mathbb{P}\_{0})+\sqrt{\frac{\delta}{\tau}}\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}). |  | (46) |

The proof essentially contains two parts. The first part is Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), giving the required integrability conditions, and the second part is to linearize the problem and then solve the constrained linear problem, similar to the case in the main body.

###### Lemma 2.

Under Assumption [4](https://arxiv.org/html/2512.01408v1#Thmassumption4 "Assumption 4. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), then

* â€¢

  (1) for any Î±<1\alpha<1 and Î±â‰ 0\alpha\neq 0,
  the vector field of Eq. ([44](https://arxiv.org/html/2512.01408v1#A3.E44 "In Theorem 5. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is well-defined â„™0\mathbb{P}\_{0} almost surely and satisfies ğ”¼â„™0â€‹[â€–Hâ€‹(B)â€–22]<âˆ\mathbb{E}\_{\mathbb{P}\_{0}}[\left\|H(B)\right\|\_{2}^{2}]<\infty.
* â€¢

  (2) for any sâˆˆ[0,1]s\in[0,1], set

  |  |  |  |
  | --- | --- | --- |
  |  | Fsâ€‹(B,Î”):=âˆ«â„dâˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€‹(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.F\_{s}(B,\Delta)\;:=\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B+s\Delta,y)\;\Big(\mathbb{E}\big[L\_{T}(B+s\Delta,y)\big]\Big)^{\frac{\alpha}{1-\alpha}}\;\varphi\_{T}(y)\,dy. |  |

  Then there exist constants Câ€‹(B)>0C(B)>0 and finite â„™0\mathbb{P}\_{0} almost surely and C1â‰¤Ï„C\_{1}\leq\tau (Ï„\tau depends on Î±\alpha) such that, â„™0\mathbb{P}\_{0} almost surely,

  |  |  |  |  |
  | --- | --- | --- | --- |
  |  | â€–Fsâ€‹(B,Î”)â€–22â‰¤Câ€‹(B)â€‹expâ¡(C1â€‹â€–Î”â€–22).\|F\_{s}(B,\Delta)\|\_{2}^{2}\;\leq C(B)\exp(C\_{1}\left\|\Delta\right\|\_{2}^{2}). |  | (47) |

###### Proof.

We first prove part (1) and assume Î±<0\alpha<0 and denote Î²:=Î±1âˆ’Î±\beta:=\frac{\alpha}{1-\alpha}. Define Aâ€‹(y):=ğ”¼â„™0â€‹[LTâ€‹(B,y)]A(y):=\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B,y)] where BB is a random vector on â„d\mathbb{R}^{d} with law â„™0\mathbb{P}\_{0}.
Direct computations give

|  |  |  |
| --- | --- | --- |
|  | âˆ‡bLTâ€‹(b,y)=LTâ€‹(b,y)â€‹Ïƒâˆ’Tâ€‹(yâˆ’Tâ€‹aâ€‹(b)).\nabla\_{b}L\_{T}(b,y)\;=\;L\_{T}(b,y)\,\sigma^{-T}\!\big(y-T\,a(b)\big). |  |

and

|  |  |  |
| --- | --- | --- |
|  | LTâ€‹(b,y)2â€‹Ï†Tâ€‹(y)=expâ¡(Tâ€‹â€–aâ€‹(b)â€–22)â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(b)).L\_{T}(b,y)^{2}\,\varphi\_{T}(y)\;=\;\exp\!\big(T\|a(b)\|\_{2}^{2}\big)\;\varphi\_{T}\!\big(y-2T\,a(b)\big). |  |

By the Jensen inequality,

|  |  |  |
| --- | --- | --- |
|  | Aâ€‹(y)=ğ”¼â„™0â€‹[eâŸ¨aâ€‹(B),yâŸ©âˆ’T2â€‹â€–aâ€‹(B)â€–22]â‰¥expâ¡(âŸ¨ğ”¼â„™0â€‹[aâ€‹(B)],yâŸ©âˆ’T2â€‹ğ”¼â„™0â€‹[â€–aâ€‹(B)â€–22]).A(y)\;=\;\mathbb{E}\_{\mathbb{P}\_{0}}\big[e^{\langle a(B),y\rangle-\frac{T}{2}\|a(B)\|\_{2}^{2}}\big]\;\geq\;\exp\!\Big(\langle\mathbb{E}\_{\mathbb{P}\_{0}}[a(B)],y\rangle-\tfrac{T}{2}\,\mathbb{E}\_{\mathbb{P}\_{0}}\left[\|a(B)\|\_{2}^{2}\right]\Big). |  |

Raising to the negative power Î²<0\beta<0 reverses the inequality and gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | Aâ€‹(y)Î²â‰¤Caâ€‹expâ¡(Î²â€‹âŸ¨v,yâŸ©),Ca:=expâ¡(âˆ’Î²â€‹T2â€‹ğ”¼â„™0â€‹[â€–aâ€‹(B)â€–22]),v:=ğ”¼â„™0â€‹[aâ€‹(B)].A(y)^{\beta}\;\leq\;C\_{a}\,\exp\!\big(\beta\,\langle v,y\rangle\big),\qquad C\_{a}:=\exp\!\Big(-\tfrac{\beta T}{2}\,\mathbb{E}\_{\mathbb{P}\_{0}}\left[\|a(B)\|\_{2}^{2}\right]\Big),\ \ v:=\mathbb{E}\_{\mathbb{P}\_{0}}[a(B)]. |  | (48) |

Since

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡bLTâ€‹(B,y)â€–22=LTâ€‹(B,y)2â€‹â€–Ïƒâˆ’Tâ€‹(yâˆ’Tâ€‹aâ€‹(B))â€–22â‰¤â€–Ïƒâˆ’1â€–F2â€‹LTâ€‹(B,y)2â€‹â€–yâˆ’Tâ€‹aâ€‹(B)â€–22,\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}=L\_{T}(B,y)^{2}\,\|\sigma^{-T}(y-Ta(B))\|\_{2}^{2}\leq\,\|\sigma^{-1}\|\_{F}^{2}\,L\_{T}(B,y)^{2}\,\|y-Ta(B)\|\_{2}^{2}, |  |

we use â€–u+vâ€–22â‰¤2â€‹(â€–uâ€–22+â€–vâ€–22)\|u+v\|\_{2}^{2}\leq 2(\|u\|\_{2}^{2}+\|v\|\_{2}^{2}) and have

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡bLTâ€‹(B,y)â€–22â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹LTâ€‹(B,y)2â€‹(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22),\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\;\leq\;C\,\|\sigma^{-1}\|\_{F}^{2}\,L\_{T}(B,y)^{2}\,\big(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2}\big), |  |

where C>0C>0 is a constant (we use CC to absorb constants if there is no confusion). Therefore,

|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ«â„dAâ€‹(y)Î²â€‹ğ”¼â„™0â€‹[â€–âˆ‡bLTâ€‹(B,y)â€–22]â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\mathbb{E}\_{\mathbb{P}\_{0}}\big[\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\big]\;\varphi\_{T}(y)\,dy |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹ğ”¼â„™0â€‹[âˆ«â„dLTâ€‹(B,y)2â€‹(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22)â€‹eÎ²â€‹âŸ¨v,yâŸ©â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y]\displaystyle\ \ \leq\ C\,\|\sigma^{-1}\|\_{F}^{2}\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[\int\_{\mathbb{R}^{d}}L\_{T}(B,y)^{2}\,(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2})\,e^{\beta\langle v,y\rangle}\,\varphi\_{T}(y)\,dy\Big] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Câ€‹â€–Ïƒâˆ’1â€–F2â€‹ğ”¼â„™0â€‹[eTâ€‹â€–aâ€‹(B)â€–22â€‹âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22)â€‹eÎ²â€‹âŸ¨v,yâŸ©â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(B))â€‹ğ‘‘y].\displaystyle\ \ =\ C\,\|\sigma^{-1}\|\_{F}^{2}\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[e^{T\|a(B)\|\_{2}^{2}}\int\_{\mathbb{R}^{d}}(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2})\,e^{\beta\langle v,y\rangle}\,\varphi\_{T}\!\big(y-2Ta(B)\big)\,dy\Big]. |  |

The inner integral is

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22)â€‹eÎ²â€‹âŸ¨v,yâŸ©â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(B))â€‹ğ‘‘y\displaystyle\int\_{\mathbb{R}^{d}}\bigl(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2}\bigr)\,e^{\beta\langle v,y\rangle}\,\varphi\_{T}\bigl(y-2T\,a(B)\bigr)\,dy |  |
|  |  |  |
| --- | --- | --- |
|  | =expâ¡(2â€‹Tâ€‹Î²â€‹âŸ¨v,aâ€‹(B)âŸ©+T2â€‹â€–Î²â€‹vâ€–22)â€‹[â€‰1+Tâ€‹d+â€–2â€‹Tâ€‹aâ€‹(B)+Tâ€‹Î²â€‹vâ€–22+T2â€‹â€–aâ€‹(B)â€–22].\displaystyle=\exp\!\Big(2T\beta\,\langle v,a(B)\rangle+\tfrac{T}{2}\|\beta v\|\_{2}^{2}\Big)\,\Big[\,1+Td+\|2Ta(B)+T\beta v\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2}\,\Big]. |  |

For a fixed Îµ>0\varepsilon>0 (which will be chosen later), by the Young inequality,

|  |  |  |
| --- | --- | --- |
|  | 2â€‹Tâ€‹Î²â€‹âŸ¨v,aâ€‹(B)âŸ©â‰¤2â€‹Tâ€‹Î²â€‹|âŸ¨v,aâ€‹(B)âŸ©|â‰¤Îµâ€‹â€–aâ€‹(B)â€–22+T2â€‹Î²2â€‹â€–vâ€–22Îµ.2T\beta\,\langle v,a(B)\rangle\leq 2T\beta\,\left|\langle v,a(B)\rangle\right|\leq\varepsilon\left\|a(B)\right\|\_{2}^{2}+\frac{T^{2}\beta^{2}\left\|v\right\|\_{2}^{2}}{\varepsilon}. |  |

Hence,

|  |  |  |
| --- | --- | --- |
|  | eâ€‰2â€‹Tâ€‹Î²â€‹âŸ¨v,aâ€‹(B)âŸ©+T2â€‹â€–Î²â€‹vâ€–22â‰¤Ctiltâ€‹(Îµ)â€‹eÎµâ€‹â€–aâ€‹(B)â€–22,e^{\,2T\beta\langle v,a(B)\rangle+\frac{T}{2}\|\beta v\|\_{2}^{2}}\leq C\_{\mathrm{tilt}}(\varepsilon)\,e^{\,\varepsilon\|a(B)\|\_{2}^{2}}, |  |

with

|  |  |  |
| --- | --- | --- |
|  | Ctiltâ€‹(Îµ):=expâ¡(T2â€‹â€–Î²â€‹vâ€–22+T2â€‹Î²2â€‹â€–vâ€–22Îµ).C\_{\mathrm{tilt}}(\varepsilon):=\exp\!\Big(\tfrac{T}{2}\|\beta v\|\_{2}^{2}+\tfrac{T^{2}\beta^{2}\|v\|\_{2}^{2}}{\varepsilon}\Big). |  |

Using the Young inequality in the quadratic bracket, we have

|  |  |  |
| --- | --- | --- |
|  | â€–2â€‹Tâ€‹a+Tâ€‹Î²â€‹vâ€–22â‰¤(1+Îµ)â€‹(2â€‹T)2â€‹â€–aâ€–22+(1+1Îµ)â€‹T2â€‹Î²2â€‹â€–vâ€–22,\|2Ta+T\beta v\|\_{2}^{2}\leq(1+\varepsilon)\,(2T)^{2}\|a\|\_{2}^{2}+\Big(1+\tfrac{1}{\varepsilon}\Big)T^{2}\beta^{2}\|v\|\_{2}^{2}, |  |

and further get

|  |  |  |
| --- | --- | --- |
|  | 1+Tâ€‹d+â€–2â€‹Tâ€‹aâ€‹(B)+Tâ€‹Î²â€‹vâ€–22+T2â€‹â€–aâ€‹(B)â€–22â‰¤C0â€‹(Îµ)+C1â€‹(Îµ)â€‹â€–aâ€‹(B)â€–22,1+Td+\|2Ta(B)+T\beta v\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2}\leq C\_{0}(\varepsilon)+C\_{1}(\varepsilon)\,\|a(B)\|\_{2}^{2}, |  |

where C0â€‹(Îµ):=1+Tâ€‹d+(1+1Îµ)â€‹T2â€‹Î²2â€‹â€–vâ€–22,C\_{0}(\varepsilon):=1+Td+\Big(1+\tfrac{1}{\varepsilon}\Big)T^{2}\beta^{2}\|v\|\_{2}^{2}, and C1â€‹(Îµ):=T2â€‹(5+4â€‹Îµ).C\_{1}(\varepsilon):=T^{2}\big(5+4\varepsilon\big).
Therefore, the inner integral is upper bounded by
Ctiltâ€‹(Îµ)â€‹(C0â€‹(Îµ)+C1â€‹(Îµ)â€‹â€–aâ€‹(B)â€–22)â€‹eÎµâ€‹â€–aâ€‹(B)â€–22.C\_{\mathrm{tilt}}(\varepsilon)\,\bigl(C\_{0}(\varepsilon)+C\_{1}(\varepsilon)\,\|a(B)\|\_{2}^{2}\bigr)\,e^{\,\varepsilon\|a(B)\|\_{2}^{2}}.

Therefore, there exists a constant C>0C>0 such that

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹ğ”¼â„™0â€‹[â€–âˆ‡bLTâ€‹(B,y)â€–22]â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\mathbb{E}\_{\mathbb{P}\_{0}}\big[\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\big]\;\varphi\_{T}(y)\,dy |  |
|  |  |  |
| --- | --- | --- |
|  | â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹Ctiltâ€‹(Îµ)â€‹ğ”¼â„™0â€‹[(C0â€‹(Îµ)+C1â€‹(Îµ)â€‹â€–aâ€‹(B)â€–22)â€‹e(T+Îµ)â€‹â€–aâ€‹(B)â€–22].\displaystyle\leq C\,\|\sigma^{-1}\|\_{F}^{2}\,C\_{\mathrm{tilt}}(\varepsilon)\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[\bigl(C\_{0}(\varepsilon)+C\_{1}(\varepsilon)\|a(B)\|\_{2}^{2}\bigr)\,e^{\,(T+\varepsilon)\|a(B)\|\_{2}^{2}}\Big]. |  |

Let

|  |  |  |
| --- | --- | --- |
|  | Îµâˆ—:=12(Î³022â€‹â€–Ïƒâˆ’1â€–F2âˆ’T)(well-defined andÂ >0Â ifÂ Î³02>2Tâˆ¥Ïƒâˆ’1âˆ¥F2).\varepsilon\_{\*}:=\tfrac{1}{2}\!\left(\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}-T\right)\quad\text{(well-defined and $>0$ if }\penalty 10000\ \gamma\_{0}^{2}>2T\|\sigma^{-1}\|\_{F}^{2}). |  |

Since aâ€‹(B)=Ïƒâˆ’1â€‹Bâˆ’ma(B)=\sigma^{-1}B-m, we have â€–aâ€‹(B)â€–22â‰¤2â€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Bâ€–22+2â€‹â€–mâ€–22\|a(B)\|\_{2}^{2}\leq 2\|\sigma^{-1}\|\_{F}^{2}\|B\|\_{2}^{2}+2\|m\|\_{2}^{2}. Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | (C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹â€–aâ€‹(B)â€–22)â€‹e(T+Îµâˆ—)â€‹â€–aâ€‹(B)â€–22â‰¤Kmâ€‹(1+câ€‹â€–Bâ€–22)â€‹eCâ€²â€‹â€–Bâ€–22,\bigl(C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\|a(B)\|\_{2}^{2}\bigr)\,e^{\,(T+\varepsilon\_{\*})\|a(B)\|\_{2}^{2}}\;\leq\;K\_{m}\,(1+c\|B\|\_{2}^{2})\,e^{\,C^{\prime}\|B\|\_{2}^{2}}, |  | (49) |

for constants Km,c>0K\_{m},c>0 and

|  |  |  |
| --- | --- | --- |
|  | Câ€²:=2â€‹(T+Îµâˆ—)â€‹â€–Ïƒâˆ’1â€–F2=Tâ€‹â€–Ïƒâˆ’1â€–F2+Î³022<Î³02.C^{\prime}:=2\,(T+\varepsilon\_{\*})\,\|\sigma^{-1}\|\_{F}^{2}=T\|\sigma^{-1}\|\_{F}^{2}+\frac{\gamma\_{0}^{2}}{2}\;<\gamma\_{0}^{2}. |  |

To see ([49](https://arxiv.org/html/2512.01408v1#A3.E49 "In Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), recall that aâ€‹(B)=Ïƒâˆ’1â€‹Bâˆ’ma(B)=\sigma^{-1}B-m, and denote

|  |  |  |
| --- | --- | --- |
|  | Îº1:=2â€‹â€–Ïƒâˆ’1â€–F2,Îº0:=2â€‹â€–mâ€–22.\kappa\_{1}:=2\,\|\sigma^{-1}\|\_{F}^{2},\qquad\kappa\_{0}:=2\,\|m\|\_{2}^{2}. |  |

Then

|  |  |  |
| --- | --- | --- |
|  | â€–aâ€‹(B)â€–22=â€–Ïƒâˆ’1â€‹Bâˆ’mâ€–22â‰¤â€„2â€‹â€–Ïƒâˆ’1â€‹Bâ€–22+2â€‹â€–mâ€–22â‰¤Îº1â€‹â€–Bâ€–22+Îº0,\|a(B)\|\_{2}^{2}\;=\;\|\sigma^{-1}B-m\|\_{2}^{2}\;\leq\;2\|\sigma^{-1}B\|\_{2}^{2}+2\|m\|\_{2}^{2}\;\leq\;\kappa\_{1}\|B\|\_{2}^{2}+\kappa\_{0}, |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
|  | (T+Îµâˆ—)â€‹â€–aâ€‹(B)â€–22\displaystyle(T+\varepsilon\_{\*})\|a(B)\|\_{2}^{2} | â‰¤(T+Îµâˆ—)â€‹(Îº1â€‹â€–Bâ€–22+Îº0)=2â€‹(T+Îµâˆ—)â€‹â€–Ïƒâˆ’1â€–F2âŸ=â£:Câ€²â€‹â€–Bâ€–22+â€„2â€‹(T+Îµâˆ—)â€‹â€–mâ€–22,\displaystyle\leq(T+\varepsilon\_{\*})\big(\kappa\_{1}\|B\|\_{2}^{2}+\kappa\_{0}\big)=\underbrace{2(T+\varepsilon\_{\*})\|\sigma^{-1}\|\_{F}^{2}}\_{=:\penalty 10000\ C^{\prime}}\|B\|\_{2}^{2}\;+\;2(T+\varepsilon\_{\*})\|m\|\_{2}^{2}, |  |

where
Câ€²=2â€‹(T+Îµâˆ—)â€‹â€–Ïƒâˆ’1â€–F2=Tâ€‹â€–Ïƒâˆ’1â€–F2+Î³022<Î³02.C^{\prime}=2(T+\varepsilon\_{\*})\|\sigma^{-1}\|\_{F}^{2}=T\|\sigma^{-1}\|\_{F}^{2}+\frac{\gamma\_{0}^{2}}{2}\;<\;\gamma\_{0}^{2}.
Hence,

|  |  |  |
| --- | --- | --- |
|  | e(T+Îµâˆ—)â€‹â€–aâ€‹(B)â€–22â‰¤eâ€‰2â€‹(T+Îµâˆ—)â€‹â€–mâ€–22â€‹eCâ€²â€‹â€–Bâ€–22.e^{(T+\varepsilon\_{\*})\|a(B)\|\_{2}^{2}}\;\leq\;e^{\,2(T+\varepsilon\_{\*})\|m\|\_{2}^{2}}\;e^{\,C^{\prime}\|B\|\_{2}^{2}}. |  |

For the polynomial prefactor,

|  |  |  |  |
| --- | --- | --- | --- |
|  | C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹â€–aâ€‹(B)â€–22\displaystyle C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\|a(B)\|\_{2}^{2} | â‰¤C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹(Îº1â€‹â€–Bâ€–22+Îº0)\displaystyle\leq C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\big(\kappa\_{1}\|B\|\_{2}^{2}+\kappa\_{0}\big) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =(C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹Îº0)âŸ=â£:K1+C1â€‹(Îµâˆ—)â€‹Îº1âŸ=â£:K2â€‹â€–Bâ€–22\displaystyle=\underbrace{\big(C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\kappa\_{0}\big)}\_{=:\penalty 10000\ K\_{1}}\;+\;\underbrace{C\_{1}(\varepsilon\_{\*})\kappa\_{1}}\_{=:\penalty 10000\ K\_{2}}\,\|B\|\_{2}^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =K1â€‹(1+K2K1â€‹â€–Bâ€–22)=K1â€‹(1+câ€‹â€–Bâ€–22),\displaystyle=K\_{1}\Big(1+\frac{K\_{2}}{K\_{1}}\,\|B\|\_{2}^{2}\Big)=K\_{1}\big(1+c\,\|B\|\_{2}^{2}\big), |  |

where

|  |  |  |
| --- | --- | --- |
|  | c:=C1â€‹(Îµâˆ—)â€‹Îº1C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹Îº0>â€„0.c:=\frac{C\_{1}(\varepsilon\_{\*})\kappa\_{1}}{C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\kappa\_{0}}\;>\;0. |  |

Therefore, we get ([49](https://arxiv.org/html/2512.01408v1#A3.E49 "In Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) with

|  |  |  |
| --- | --- | --- |
|  | Km:=K1â€‹eâ€‰2â€‹(T+Îµâˆ—)â€‹â€–mâ€–22=(C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹Îº0)â€‹eâ€‰2â€‹(T+Îµâˆ—)â€‹â€–mâ€–22.K\_{m}\;:=\;K\_{1}\,e^{\,2(T+\varepsilon\_{\*})\|m\|\_{2}^{2}}\;=\;\big(C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\kappa\_{0}\big)\,e^{\,2(T+\varepsilon\_{\*})\|m\|\_{2}^{2}}. |  |

Since Câ€²<Î³02C^{\prime}<\gamma\_{0}^{2}, we pick any Î³\gamma such that Câ€²<Î³2<Î³02C^{\prime}<\gamma^{2}<\gamma\_{0}^{2}.
For tâ‰¥0t\geq 0 and Î´:=Î³2âˆ’Câ€²>0\delta:=\gamma^{2}-C^{\prime}>0, the elementary bound

|  |  |  |
| --- | --- | --- |
|  | 1+câ€‹tâ‰¤(1+ceâ€‹Î´)â€‹eÎ´â€‹t1+ct\;\leq\;\Big(1+\frac{c}{e\,\delta}\Big)\,e^{\delta t} |  |

implies

|  |  |  |
| --- | --- | --- |
|  | (1+câ€‹â€–Bâ€–22)â€‹eCâ€²â€‹â€–Bâ€–22â‰¤Kâ€‹eÎ³2â€‹â€–Bâ€–22,K:=1+ceâ€‹(Î³2âˆ’Câ€²).(1+c\,\|B\|\_{2}^{2})\,e^{\,C^{\prime}\|B\|\_{2}^{2}}\;\leq\;K\,e^{\,\gamma^{2}\|B\|\_{2}^{2}},\qquad K:=1+\frac{c}{e(\gamma^{2}-C^{\prime})}. |  |

Therefore, under the sub-Gaussian assumption
ğ”¼â„™0â€‹[eÎ³2â€‹â€–Bâ€–22]<âˆ\mathbb{E}\_{\mathbb{P}\_{0}}\big[e^{\gamma^{2}\|B\|\_{2}^{2}}\big]<\infty for all Î³<Î³0\gamma<\gamma\_{0},

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™0â€‹[(C0â€‹(Îµâˆ—)+C1â€‹(Îµâˆ—)â€‹â€–aâ€‹(B)â€–22)â€‹e(T+Îµâˆ—)â€‹â€–aâ€‹(B)â€–22]â‰¤Kmâ€‹Kâ€‹ğ”¼â„™0â€‹[eÎ³2â€‹â€–Bâ€–22]<âˆ.\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[\bigl(C\_{0}(\varepsilon\_{\*})+C\_{1}(\varepsilon\_{\*})\|a(B)\|\_{2}^{2}\bigr)\,e^{(T+\varepsilon\_{\*})\|a(B)\|\_{2}^{2}}\Big]\;\leq\;K\_{m}\,K\,\mathbb{E}\_{\mathbb{P}\_{0}}\big[e^{\gamma^{2}\|B\|\_{2}^{2}}\big]\;<\;\infty. |  |

In order to show the well-definedness of HH, we need to show

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y<âˆ\int\_{\mathbb{R}^{d}}A(y)^{\beta}\varphi\_{T}(y)dy<\infty |  | (50) |

since from the Cauchy-Schwarz inequality, for â„™0\mathbb{P}\_{0} almost every bb,

|  |  |  |
| --- | --- | --- |
|  | â€–Hâ€‹(b)â€–2â‰¤11âˆ’Î±â€‹âˆ«â„dAâ€‹(y)Î²â€‹â€–âˆ‡bLTâ€‹(b,y)â€–2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle\left\|H(b)\right\|\_{2}\leq\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}A(y)^{\beta}\left\|\nabla\_{b}L\_{T}(b,y)\right\|\_{2}\,\,\varphi\_{T}(y)\,dy |  |
|  |  |  |
| --- | --- | --- |
|  | â‰¤11âˆ’Î±â€‹(âˆ«â„dâ€–âˆ‡bLTâ€‹(b,y)â€–22â€‹Aâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)12â€‹(âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)12,\displaystyle\leq\frac{1}{1-\alpha}\left(\int\_{\mathbb{R}^{d}}\left\|\nabla\_{b}L\_{T}(b,y)\right\|\_{2}^{2}A(y)^{\beta}\,\varphi\_{T}(y)dy\right)^{\frac{1}{2}}\left(\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)dy\right)^{\frac{1}{2}}, |  |

where the first term is finite â„™0\mathbb{P}\_{0} almost surely. If we take square and then take expectation with respect to â„™0\mathbb{P}\_{0} and use Tonelliâ€™s theorem, then the proof is complete.

When Î±<0\alpha<0, we recall Eq. ([48](https://arxiv.org/html/2512.01408v1#A3.E48 "In Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) and have

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Caâ€‹âˆ«â„deÎ²â€‹âŸ¨v,yâŸ©â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;C\_{a}\int\_{\mathbb{R}^{d}}e^{\beta\langle v,y\rangle}\,\varphi\_{T}(y)\,dy. |  |

Completion of squares gives

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„deÎ²â€‹âŸ¨v,yâŸ©â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=(2â€‹Ï€â€‹T)âˆ’d/2â€‹âˆ«â„dexpâ¡(Î²â€‹âŸ¨v,yâŸ©âˆ’â€–yâ€–222â€‹T)â€‹ğ‘‘y=expâ¡(T2â€‹â€–Î²â€‹vâ€–22).\int\_{\mathbb{R}^{d}}e^{\beta\langle v,y\rangle}\,\varphi\_{T}(y)\,dy=(2\pi T)^{-d/2}\!\!\int\_{\mathbb{R}^{d}}\exp\!\left(\beta\langle v,y\rangle-\frac{\|y\|\_{2}^{2}}{2T}\right)dy=\exp\!\left(\frac{T}{2}\|\beta v\|\_{2}^{2}\right). |  |

Indeed,

|  |  |  |
| --- | --- | --- |
|  | Î²â€‹âŸ¨v,yâŸ©âˆ’â€–yâ€–222â€‹T=âˆ’12â€‹Tâ€‹â€–yâˆ’Tâ€‹Î²â€‹vâ€–22+T2â€‹â€–Î²â€‹vâ€–22.\beta\langle v,y\rangle-\frac{\|y\|\_{2}^{2}}{2T}=-\frac{1}{2T}\Big\|\,y-T\beta v\,\Big\|\_{2}^{2}+\frac{T}{2}\|\beta v\|\_{2}^{2}. |  |

Hence,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Caâ€‹expâ¡(T2â€‹â€–Î²â€‹vâ€–22)<âˆ,âˆ\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;C\_{a}\,\exp\!\left(\frac{T}{2}\|\beta v\|\_{2}^{2}\right)<\infty,\qed |  |

which finishes the proof of the case when Î±<0\alpha<0.
Next we divide the positive Î±\alpha into two cases.

*Case 1: 0<Î²â‰¤10<\beta\leq 1 (equivalently 0<Î±â‰¤120<\alpha\leq\tfrac{1}{2}).*
Let Î¼â€‹(dâ€‹y):=Ï†Tâ€‹(y)â€‹dâ€‹y\mu(dy):=\varphi\_{T}(y)\,dy; then Î¼\mu is a probability measure since
âˆ«â„dÏ†Tâ€‹(y)â€‹ğ‘‘y=1\int\_{\mathbb{R}^{d}}\varphi\_{T}(y)\,dy=1. Set fâ€‹(y):=Aâ€‹(y)=ğ”¼â€‹[LTâ€‹(B,y)]â‰¥0f(y):=A(y)=\mathbb{E}[L\_{T}(B,y)]\geq 0 and

|  |  |  |
| --- | --- | --- |
|  | Ï•â€‹(x):=xÎ²,xâ‰¥0.\phi(x):=x^{\beta},\qquad x\geq 0. |  |

For 0<Î²â‰¤10<\beta\leq 1, the map Ï•\phi is concave and increasing, so the Jensen
inequality for concave functions gives

|  |  |  |
| --- | --- | --- |
|  | Ï•â€‹(âˆ«â„dfâ€‹(y)â€‹Î¼â€‹(dâ€‹y))â‰¥âˆ«â„dÏ•â€‹(fâ€‹(y))â€‹Î¼â€‹(dâ€‹y),\phi\!\left(\int\_{\mathbb{R}^{d}}f(y)\,\mu(dy)\right)\;\geq\;\int\_{\mathbb{R}^{d}}\phi(f(y))\,\mu(dy), |  |

i.e.

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤(âˆ«â„dAâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)Î².\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;\Big(\int\_{\mathbb{R}^{d}}A(y)\,\varphi\_{T}(y)\,dy\Big)^{\beta}. |  | (51) |

It remains to compute âˆ«â„dAâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\int\_{\mathbb{R}^{d}}A(y)\,\varphi\_{T}(y)\,dy. By the Fubini theorem,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=ğ”¼â„™0â€‹[âˆ«â„dLTâ€‹(B,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y]=1\int\_{\mathbb{R}^{d}}A(y)\,\varphi\_{T}(y)\,dy=\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\int\_{\mathbb{R}^{d}}L\_{T}(B,y)\,\varphi\_{T}(y)\,dy\right]=1 |  |

from a completion of squares argument. Thus, plugging into ([51](https://arxiv.org/html/2512.01408v1#A3.E51 "In Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) yields the bound

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤â€„1,0<Î²â‰¤1.\ \int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;1,\qquad 0<\beta\leq 1.\ |  |

*Case 2: Î²>1\beta>1 (equivalently 12<Î±<1\tfrac{1}{2}<\alpha<1).*
Since the map xâ†¦xÎ²x\mapsto x^{\beta} is convex on (0,âˆ)(0,\infty), the Jensen inequality yields

|  |  |  |
| --- | --- | --- |
|  | Aâ€‹(y)Î²=(ğ”¼â„™0â€‹[LTâ€‹(B,y)])Î²â‰¤ğ”¼â„™0â€‹[LTâ€‹(B,y)Î²].A(y)^{\beta}=\big(\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B,y)]\big)^{\beta}\leq\mathbb{E}\_{\mathbb{P}\_{0}}\big[L\_{T}(B,y)^{\beta}\big]. |  |

Integrating and exchanging expectation and integral,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤ğ”¼â„™0â€‹[âˆ«â„dLTâ€‹(B,y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y].\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\int\_{\mathbb{R}^{d}}L\_{T}(B,y)^{\beta}\,\varphi\_{T}(y)\,dy\right]. |  |

For fixed bb, completing the square gives

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dLTâ€‹(b,y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=expâ¡(T2â€‹(Î²2âˆ’Î²)â€‹â€–aâ€‹(b)â€–22).\int\_{\mathbb{R}^{d}}L\_{T}(b,y)^{\beta}\,\varphi\_{T}(y)\,dy=\exp\!\left(\frac{T}{2}(\beta^{2}-\beta)\,\|a(b)\|\_{2}^{2}\right). |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤ğ”¼â„™0â€‹[expâ¡(T2â€‹(Î²2âˆ’Î²)â€‹â€–aâ€‹(B)â€–22)].\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\exp\!\left(\frac{T}{2}(\beta^{2}-\beta)\,\|a(B)\|\_{2}^{2}\right)\right]. |  |

Using â€–aâ€‹(B)â€–22â‰¤2â€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Bâ€–22+2â€‹â€–mâ€–22\|a(B)\|\_{2}^{2}\leq 2\|\sigma^{-1}\|\_{F}^{2}\,\|B\|\_{2}^{2}+2\|m\|\_{2}^{2}, we obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ«â„dAâ€‹(y)Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤expâ¡(Tâ€‹(Î²2âˆ’Î²)â€‹â€–mâ€–22)â€‹ğ”¼â„™0â€‹[expâ¡(Tâ€‹(Î²2âˆ’Î²)â€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Bâ€–22)].\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\varphi\_{T}(y)\,dy\;\leq\;\exp\!\Big(T(\beta^{2}-\beta)\,\|m\|\_{2}^{2}\Big)\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\exp\!\Big(T(\beta^{2}-\beta)\,\|\sigma^{-1}\|\_{F}^{2}\,\|B\|\_{2}^{2}\Big)\right]. |  | (52) |

Hence, under the sub-Gaussian moment assumption

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™0â€‹[eÎ³2â€‹â€–Bâ€–22]<âˆfor allÂ â€‹Î³<Î³0,\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[e^{\gamma^{2}\|B\|\_{2}^{2}}\right]<\infty\quad\text{for all }\gamma<\gamma\_{0}, |  |

the right-hand side of Eq. ([52](https://arxiv.org/html/2512.01408v1#A3.E52 "In Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) is finite whenever

|  |  |  |  |
| --- | --- | --- | --- |
|  | Tâ€‹(Î²2âˆ’Î²)â€‹â€–Ïƒâˆ’1â€–F2<Î³02.\ T(\beta^{2}-\beta)\,\|\sigma^{-1}\|\_{F}^{2}\;<\;\gamma\_{0}^{2}. |  | (53) |

Next, we focus on the bound when Î±âˆˆ(0,1)\alpha\in(0,1).
Define

|  |  |  |
| --- | --- | --- |
|  | â„Î²:=âˆ«â„dAâ€‹(y)Î²â€‹ğ”¼â„™0â€‹[â€–âˆ‡bLTâ€‹(B,y)â€–22]â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\mathcal{I}\_{\beta}\;:=\;\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\big[\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\big]\;\varphi\_{T}(y)\,dy. |  |

We first consider the case when Î²âˆˆ(0,1)\beta\in(0,1).
Write
Gâ€‹(y):=ğ”¼â„™0â€‹[â€–âˆ‡bLTâ€‹(B,y)â€–22].G(y):=\mathbb{E}\_{\mathbb{P}\_{0}}\!\big[\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\big].
Then
â„Î²=âˆ«â„dAâ€‹(y)Î²â€‹Gâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\mathcal{I}\_{\beta}=\int\_{\mathbb{R}^{d}}A(y)^{\beta}\,G(y)\,\varphi\_{T}(y)\,dy.
By the HÃ¶lder inequality with exponents p=1Î²p=\frac{1}{\beta} and q=11âˆ’Î²q=\frac{1}{1-\beta}, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„Î²=âˆ«â„d(Aâ€‹(y)â€‹Gâ€‹(y))Î²â€‹Gâ€‹(y)1âˆ’Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤(âˆ«â„dAâ€‹(y)â€‹Gâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)Î²â€‹(âˆ«â„dGâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1âˆ’Î².\mathcal{I}\_{\beta}=\int\_{\mathbb{R}^{d}}\big(A(y)G(y)\big)^{\beta}\,G(y)^{1-\beta}\,\varphi\_{T}(y)\,dy\;\leq\;\Big(\int\_{\mathbb{R}^{d}}A(y)\,G(y)\,\varphi\_{T}(y)\,dy\Big)^{\!\beta}\Big(\int\_{\mathbb{R}^{d}}G(y)\,\varphi\_{T}(y)\,dy\Big)^{\!1-\beta}. |  | (54) |

Set

|  |  |  |
| --- | --- | --- |
|  | I0:=âˆ«â„dGâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,I1:=âˆ«â„dAâ€‹(y)â€‹Gâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.I\_{0}:=\int\_{\mathbb{R}^{d}}G(y)\,\varphi\_{T}(y)\,dy,\qquad I\_{1}:=\int\_{\mathbb{R}^{d}}A(y)\,G(y)\,\varphi\_{T}(y)\,dy. |  |

It suffices to show I0<âˆI\_{0}<\infty and I1<âˆI\_{1}<\infty under some sub-Gaussian assumptions.

Recall that there exists a constant C>0C>0 such that

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡bLTâ€‹(B,y)â€–22â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹LTâ€‹(B,y)2â€‹(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22).\|\nabla\_{b}L\_{T}(B,y)\|\_{2}^{2}\;\leq\;C\,\|\sigma^{-1}\|\_{F}^{2}\,L\_{T}(B,y)^{2}\,(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2}). |  |

Using the Tonelli theorem,

|  |  |  |  |
| --- | --- | --- | --- |
|  | I0\displaystyle I\_{0} | â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹ğ”¼â„™0â€‹[eTâ€‹â€–aâ€‹(B)â€–22â€‹âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22)â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(B))â€‹ğ‘‘y].\displaystyle\leq C\,\|\sigma^{-1}\|\_{F}^{2}\,\mathbb{E}^{\mathbb{P}\_{0}}\!\Big[e^{T\|a(B)\|\_{2}^{2}}\!\!\int\_{\mathbb{R}^{d}}\!(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2})\,\varphi\_{T}(y-2Ta(B))\,dy\Big]. |  |

For the inner integral,
fix aâˆˆâ„da\in\mathbb{R}^{d} and set the notation

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(a):=âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€–22)â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹a)â€‹ğ‘‘y.J(a):=\int\_{\mathbb{R}^{d}}\bigl(1+\|y\|\_{2}^{2}+T^{2}\|a\|\_{2}^{2}\bigr)\,\varphi\_{T}(y-2Ta)\,dy. |  |

Let Zâˆ¼ğ’©â€‹(0,Tâ€‹Id)Z\sim\mathcal{N}(0,TI\_{d}). Since Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹a)â€‹dâ€‹y\varphi\_{T}(y-2Ta)\,dy is the law of Y:=Z+2â€‹Tâ€‹aY:=Z+2Ta, we have

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(a)=ğ”¼â€‹[1+â€–Yâ€–22+T2â€‹â€–aâ€–22]=1+ğ”¼â€‹[â€–Z+2â€‹Tâ€‹aâ€–22]+T2â€‹â€–aâ€–22=1+dâ€‹T+5â€‹T2â€‹â€–aâ€–22.J(a)=\mathbb{E}\!\left[1+\|Y\|\_{2}^{2}+T^{2}\|a\|\_{2}^{2}\right]=1+\mathbb{E}\left[\|Z+2Ta\|\_{2}^{2}\right]+T^{2}\|a\|\_{2}^{2}=1+dT+5T^{2}\|a\|\_{2}^{2}. |  |

With a=aâ€‹(B)a=a(B), the inner integral in I0I\_{0} equals 1+dâ€‹T+5â€‹T2â€‹â€–aâ€‹(B)â€–221+dT+5T^{2}\|a(B)\|\_{2}^{2}, and therefore

|  |  |  |
| --- | --- | --- |
|  | I0â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹ğ”¼â„™0â€‹[eTâ€‹â€–aâ€‹(B)â€–22â€‹(1+dâ€‹T+5â€‹T2â€‹â€–aâ€‹(B)â€–22)].I\_{0}\leq C\,\|\sigma^{-1}\|\_{F}^{2}\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[e^{T\|a(B)\|\_{2}^{2}}\big(1+dT+5T^{2}\|a(B)\|\_{2}^{2}\big)\Big]. |  |

The estimate for I0I\_{0} requires

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™0â€‹[expâ¡(Tâ€‹â€–aâ€‹(B)â€–22)]<âˆ,\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\exp\!\big(T\|a(B)\|\_{2}^{2}\big)\right]<\infty, |  |

which is actually a sub-Gaussian assumption on BB with condition

|  |  |  |
| --- | --- | --- |
|  | 2â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2<Î³02.2T\,\|\sigma^{-1}\|\_{F}^{2}\;<\;\gamma\_{0}^{2}. |  |

Next, we upper bound I1I\_{1}. By the Young inequality âŸ¨u,vâŸ©â‰¤Îµ2â€‹â€–uâ€–22+12â€‹Îµâ€‹â€–vâ€–22\langle u,v\rangle\leq\tfrac{\varepsilon}{2}\|u\|\_{2}^{2}+\tfrac{1}{2\varepsilon}\|v\|\_{2}^{2} with a fixed Îµ>0\varepsilon>0 (which will be chosen later),

|  |  |  |
| --- | --- | --- |
|  | Aâ€‹(y)â‰¤ğ”¼â„™0â€‹[eâˆ’Tâˆ’Îµ2â€‹â€–aâ€‹(B)â€–22]â€‹expâ¡(â€–yâ€–222â€‹Îµ)=CAâ€‹(Îµ)â€‹ecâ€‹â€–yâ€–22,c:=12â€‹Îµâˆˆ(0,12â€‹T).A(y)\;\leq\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[e^{-\frac{T-\varepsilon}{2}\|a(B)\|\_{2}^{2}}\Big]\;\exp\!\Big(\frac{\|y\|\_{2}^{2}}{2\varepsilon}\Big)\;=\;C\_{A}(\varepsilon)\,e^{c\|y\|\_{2}^{2}},\qquad c:=\frac{1}{2\varepsilon}\in\Big(0,\frac{1}{2T}\Big). |  |

Here CAâ€‹(Îµ)=ğ”¼â„™0â€‹[eÎµâˆ’T2â€‹â€–aâ€‹(B)â€–22]C\_{A}(\varepsilon)=\mathbb{E}\_{\mathbb{P}\_{0}}\!\big[e^{\frac{\varepsilon-T}{2}\|a(B)\|\_{2}^{2}}\big].
Hence, by the Tonelli theorem,

|  |  |  |  |
| --- | --- | --- | --- |
|  | I1\displaystyle I\_{1} | â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹CAâ€‹(Îµ)â€‹ğ”¼â„™0â€‹[eTâ€‹â€–aâ€‹(B)â€–22â€‹âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€‹(B)â€–22)â€‹ecâ€‹â€–yâ€–22â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(B))â€‹ğ‘‘y].\displaystyle\leq C\,\|\sigma^{-1}\|\_{F}^{2}\,C\_{A}(\varepsilon)\,\mathbb{E}^{\mathbb{P}\_{0}}\!\Big[e^{T\|a(B)\|\_{2}^{2}}\!\int\_{\mathbb{R}^{d}}(1+\|y\|\_{2}^{2}+T^{2}\|a(B)\|\_{2}^{2})e^{c\|y\|\_{2}^{2}}\varphi\_{T}(y-2Ta(B))\,dy\Big]. |  |

Fix aâˆˆâ„da\in\mathbb{R}^{d} and câˆˆ(0,12â€‹T)c\in(0,\frac{1}{2T}). Let

|  |  |  |
| --- | --- | --- |
|  | Kcâ€‹(a):=âˆ«â„d(1+â€–yâ€–22+T2â€‹â€–aâ€–22)â€‹ecâ€‹â€–yâ€–22â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹a)â€‹ğ‘‘y.K\_{c}(a):=\int\_{\mathbb{R}^{d}}\bigl(1+\|y\|\_{2}^{2}+T^{2}\|a\|\_{2}^{2}\bigr)\,e^{c\|y\|\_{2}^{2}}\,\varphi\_{T}(y-2Ta)\,dy. |  |

With Yâˆ¼ğ’©â€‹(2â€‹Tâ€‹a,Tâ€‹Id)Y\sim\mathcal{N}(2Ta,TI\_{d}) we have Kcâ€‹(a)=ğ”¼â€‹[(1+â€–Yâ€–22+T2â€‹â€–aâ€–22)â€‹ecâ€‹â€–Yâ€–22]K\_{c}(a)=\mathbb{E}[(1+\|Y\|\_{2}^{2}+T^{2}\|a\|\_{2}^{2})e^{c\|Y\|\_{2}^{2}}].
Define

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(c,a):=âˆ«â„decâ€‹â€–yâ€–22â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹a)â€‹ğ‘‘y=(1âˆ’2â€‹câ€‹T)âˆ’d/2â€‹expâ¡(4â€‹T2â€‹c1âˆ’2â€‹câ€‹Tâ€‹â€–aâ€–22).F(c,a):=\int\_{\mathbb{R}^{d}}e^{c\|y\|\_{2}^{2}}\,\varphi\_{T}(y-2Ta)\,dy=(1-2cT)^{-d/2}\exp\!\Big(\frac{4T^{2}c}{1-2cT}\,\|a\|\_{2}^{2}\Big). |  |

Then

|  |  |  |
| --- | --- | --- |
|  | âˆ‚âˆ‚câ€‹Fâ€‹(c,a)=âˆ«â„dâ€–yâ€–22â€‹ecâ€‹â€–yâ€–22â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹a)â€‹ğ‘‘y=Fâ€‹(c,a)â€‹(dâ€‹T1âˆ’2â€‹câ€‹T+4â€‹T2â€‹â€–aâ€–22(1âˆ’2â€‹câ€‹T)2),\frac{\partial}{\partial c}F(c,a)=\int\_{\mathbb{R}^{d}}\|y\|\_{2}^{2}e^{c\|y\|\_{2}^{2}}\varphi\_{T}(y-2Ta)\,dy=F(c,a)\!\left(\frac{dT}{1-2cT}+\frac{4T^{2}\|a\|\_{2}^{2}}{(1-2cT)^{2}}\right), |  |

so

|  |  |  |  |
| --- | --- | --- | --- |
|  | Kcâ€‹(a)\displaystyle K\_{c}(a) | =(1+T2â€‹â€–aâ€–22)â€‹Fâ€‹(c,a)+âˆ‚âˆ‚câ€‹Fâ€‹(c,a)\displaystyle=(1+T^{2}\|a\|\_{2}^{2})\,F(c,a)+\frac{\partial}{\partial c}F(c,a) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Fâ€‹(c,a)â€‹[1+T2â€‹â€–aâ€–22+dâ€‹T1âˆ’2â€‹câ€‹T+4â€‹T2â€‹â€–aâ€–22(1âˆ’2â€‹câ€‹T)2]â‰¤C1â€‹(c,T,d)â€‹(1+â€–aâ€–22)â€‹Fâ€‹(c,a).\displaystyle=F(c,a)\!\left[1+T^{2}\|a\|\_{2}^{2}+\frac{dT}{1-2cT}+\frac{4T^{2}\|a\|\_{2}^{2}}{(1-2cT)^{2}}\right]\;\leq\;C\_{1}(c,T,d)\,\bigl(1+\|a\|\_{2}^{2}\bigr)\,F(c,a). |  |

Therefore, with c=12â€‹Îµâˆˆ(0,12â€‹T)c=\frac{1}{2\varepsilon}\in(0,\frac{1}{2T}),

|  |  |  |  |
| --- | --- | --- | --- |
|  | I1\displaystyle I\_{1} | â‰¤Câ€‹â€–Ïƒâˆ’1â€–F2â€‹CAâ€‹(Îµ)â€‹ğ”¼â„™0â€‹[eTâ€‹â€–aâ€‹(B)â€–22â€‹Kcâ€‹(aâ€‹(B))]\displaystyle\leq C\,\|\sigma^{-1}\|\_{F}^{2}\,C\_{A}(\varepsilon)\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[e^{T\|a(B)\|\_{2}^{2}}\,K\_{c}\big(a(B)\big)\Big] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Câ€‹(Îµ,T,d,Ïƒ)â€‹ğ”¼â„™0â€‹[(1+â€–aâ€‹(B)â€–22)â€‹expâ¡((T+2â€‹T2Îµâˆ’T)â€‹â€–aâ€‹(B)â€–22)],\displaystyle\leq C(\varepsilon,T,d,\sigma)\,\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[(1+\|a(B)\|\_{2}^{2})\,\exp\!\Big(\Big(T+\frac{2T^{2}}{\varepsilon-T}\Big)\|a(B)\|\_{2}^{2}\Big)\Big], |  |

where

|  |  |  |
| --- | --- | --- |
|  | Câ€‹(Îµ,T,d,Ïƒ)=Câ€‹â€–Ïƒâˆ’1â€–F2â€‹CAâ€‹(Îµ)â€‹(1âˆ’TÎµ)âˆ’d/2â€‹(1+dâ€‹T1âˆ’TÎµ+T2+4â€‹T2(1âˆ’TÎµ)2).C(\varepsilon,T,d,\sigma)=C\;\|\sigma^{-1}\|\_{F}^{2}\;C\_{A}(\varepsilon)\;\Big(1-\tfrac{T}{\varepsilon}\Big)^{-d/2}\left(1+\frac{dT}{1-\tfrac{T}{\varepsilon}}+T^{2}+\frac{4T^{2}}{\big(1-\tfrac{T}{\varepsilon}\big)^{2}}\right). |  |

To make the bound for I1I\_{1} finite, we only need an Îµ>T\varepsilon>T such that

|  |  |  |
| --- | --- | --- |
|  | Îµâˆ’T2<Î³022â€‹â€–Ïƒâˆ’1â€–F2andT+2â€‹T2Îµâˆ’T<Î³022â€‹â€–Ïƒâˆ’1â€–F2.\frac{\varepsilon-T}{2}\;<\;\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}\qquad\text{and}\qquad T+\frac{2T^{2}}{\varepsilon-T}\;<\;\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}. |  |

These two inequalities simultaneously hold whenever

|  |  |  |
| --- | --- | --- |
|  | 4â€‹T2â€‹â€–Ïƒâˆ’1â€–F4+â€„2â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2â€‹Î³02<Î³04,4T^{2}\,\|\sigma^{-1}\|\_{F}^{4}\;+\;2T\,\|\sigma^{-1}\|\_{F}^{2}\,\gamma\_{0}^{2}\;<\;\gamma\_{0}^{4}, |  |

which is equivalent to

|  |  |  |
| --- | --- | --- |
|  | Î³02>(1+5)â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2.\gamma\_{0}^{2}\;>\;(1+\sqrt{5})\,T\,\|\sigma^{-1}\|\_{F}^{2}. |  |

Under this condition, an explicit admissible choice is

|  |  |  |
| --- | --- | --- |
|  | Îµâˆ—:=T+12â€‹(2â€‹T2Î³022â€‹â€–Ïƒâˆ’1â€–F2âˆ’T+Î³02â€–Ïƒâˆ’1â€–F2)>T.\varepsilon^{\*}\;:=\;T+\frac{1}{2}\left(\frac{2T^{2}}{\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}-T}+\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\right)\;>\;T. |  |

For this Îµâˆ—\varepsilon^{\*} we have

|  |  |  |
| --- | --- | --- |
|  | CAâ€‹(Îµâˆ—)=ğ”¼â„™0â€‹[expâ¡(Îµâˆ—âˆ’T2â€‹â€–aâ€‹(B)â€–22)]<âˆ,ğ”¼â„™0â€‹[(1+â€–aâ€‹(B)â€–22)â€‹expâ¡((T+2â€‹T2Îµâˆ—âˆ’T)â€‹â€–aâ€‹(B)â€–22)]<âˆ,C\_{A}(\varepsilon^{\*})=\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[\exp\!\left(\frac{\varepsilon^{\*}-T}{2}\,\|a(B)\|\_{2}^{2}\right)\right]<\infty,\qquad\mathbb{E}\_{\mathbb{P}\_{0}}\!\left[(1+\|a(B)\|\_{2}^{2})\,\exp\!\left(\Big(T+\frac{2T^{2}}{\varepsilon^{\*}-T}\Big)\|a(B)\|\_{2}^{2}\right)\right]<\infty, |  |

by the sub-Gaussian integrability above. Hence, I1<âˆI\_{1}<\infty.

Finally, we upper bound â„Î²\mathcal{I}\_{\beta} when Î²>1\beta>1.
By convexity of the map xâ†¦xÎ²x\mapsto x^{\beta} when Î²>1\beta>1 and the Jensen inequality,

|  |  |  |
| --- | --- | --- |
|  | Aâ€‹(y)Î²=(ğ”¼â„™0â€‹[LTâ€‹(B,y)])Î²â‰¤ğ”¼â„™0â€‹[LTâ€‹(B,y)Î²].A(y)^{\beta}\;=\;\big(\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B,y)]\big)^{\beta}\;\leq\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\big[L\_{T}(B,y)^{\beta}\big]. |  |

Fix Îµ>Î²2â€‹T\varepsilon>\beta^{2}T and use the Young inequality
âŸ¨u,vâŸ©â‰¤Îµ2â€‹â€–uâ€–22+12â€‹Îµâ€‹â€–vâ€–22\langle u,v\rangle\leq\tfrac{\varepsilon}{2}\|u\|\_{2}^{2}+\tfrac{1}{2\varepsilon}\|v\|\_{2}^{2} with u=Î²â€‹aâ€‹(B)u=\beta a(B), v=yv=y:

|  |  |  |
| --- | --- | --- |
|  | LTâ€‹(B,y)Î²=expâ¡(Î²â€‹âŸ¨aâ€‹(B),yâŸ©âˆ’Î²â€‹T2â€‹â€–aâ€‹(B)â€–22)â‰¤expâ¡(Îµâˆ’Î²â€‹T2â€‹â€–aâ€‹(B)â€–22)â€‹ecâ€‹â€–yâ€–22,c:=Î²22â€‹Îµâˆˆ(0,12â€‹T).L\_{T}(B,y)^{\beta}=\exp\!\Big(\beta\langle a(B),y\rangle-\tfrac{\beta T}{2}\|a(B)\|\_{2}^{2}\Big)\leq\exp\!\Big(\tfrac{\varepsilon-\beta T}{2}\|a(B)\|\_{2}^{2}\Big)\,e^{c\|y\|\_{2}^{2}},\quad c:=\frac{\beta^{2}}{2\varepsilon}\in\Big(0,\frac{1}{2T}\Big). |  |

Taking expectation in BB yields

|  |  |  |
| --- | --- | --- |
|  | Aâ€‹(y)Î²â‰¤CÎ²â€‹(Îµ)â€‹ecâ€‹â€–yâ€–22,CÎ²â€‹(Îµ):=ğ”¼â„™0â€‹[expâ¡(Îµâˆ’Î²â€‹T2â€‹â€–aâ€‹(B)â€–22)].A(y)^{\beta}\;\leq\;C\_{\beta}(\varepsilon)\,e^{c\|y\|\_{2}^{2}},\quad C\_{\beta}(\varepsilon):=\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[\exp\!\Big(\tfrac{\varepsilon-\beta T}{2}\|a(B)\|\_{2}^{2}\Big)\Big]. |  |

Thus, exactly as in the I1I\_{1} bound for Î²âˆˆ(0,1)\beta\in(0,1), we obtain

|  |  |  |
| --- | --- | --- |
|  | â„Î²â‰¤Câ€‹(Îµ,T,d,Ïƒ)â€‹ğ”¼â„™0â€‹[(1+â€–aâ€‹(B)â€–22)â€‹expâ¡((T+2â€‹T2â€‹Î²2Îµâˆ’Î²2â€‹T)â€‹â€–aâ€‹(B)â€–22)],\mathcal{I}\_{\beta}\;\leq\;C(\varepsilon,T,d,\sigma)\;\mathbb{E}\_{\mathbb{P}\_{0}}\!\Big[(1+\|a(B)\|\_{2}^{2})\,\exp\!\Big(\Big(T+\frac{2T^{2}\beta^{2}}{\varepsilon-\beta^{2}T}\Big)\|a(B)\|\_{2}^{2}\Big)\Big], |  |

for some finite constant Câ€‹(Îµ,T,d,Ïƒ)C(\varepsilon,T,d,\sigma) whenever câˆˆ(0,1/(2â€‹T))c\in(0,1/(2T)).
Therefore, to have â„Î²<âˆ\mathcal{I}\_{\beta}<\infty it suffices to pick Îµ>Î²2â€‹T\varepsilon>\beta^{2}T such that

|  |  |  |
| --- | --- | --- |
|  | Îµâˆ’Î²â€‹T2<Î³022â€‹â€–Ïƒâˆ’1â€–F2andT+2â€‹T2â€‹Î²2Îµâˆ’Î²2â€‹T<Î³022â€‹â€–Ïƒâˆ’1â€–F2.\frac{\varepsilon-\beta T}{2}\;<\;\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}\qquad\text{and}\qquad T+\frac{2T^{2}\beta^{2}}{\varepsilon-\beta^{2}T}\;<\;\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}. |  |

These two inequalities simultaneously hold precisely when

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>T2â€‹(Î²2âˆ’Î²+2+(Î²2âˆ’Î²+2)2+8â€‹(Î²2+Î²)).\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\;>\;\frac{T}{2}\Big(\beta^{2}-\beta+2\;+\;\sqrt{\,(\beta^{2}-\beta+2)^{2}+8(\beta^{2}+\beta)\,}\Big)\;. |  |

Under the displayed condition, choose any

|  |  |  |
| --- | --- | --- |
|  | Îµâˆˆ(Î²2â€‹T+2â€‹T2â€‹Î²2Î³022â€‹â€–Ïƒâˆ’1â€–F2âˆ’T,Î²â€‹T+Î³02â€–Ïƒâˆ’1â€–F2),\varepsilon\in\Big(\,\beta^{2}T+\frac{2T^{2}\beta^{2}}{\frac{\gamma\_{0}^{2}}{2\|\sigma^{-1}\|\_{F}^{2}}-T}\,,\;\beta T+\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\,\Big), |  |

which is a nonempty interval; then both parts of (â‹†)(\star) hold and the expectation above is finite. Hence â„Î²<âˆ\mathcal{I}\_{\beta}<\infty for all Î²>1\beta>1 under the stated sub-Gaussian slack.

For the proof of part (2), we first notice that there exists

|  |  |  |
| --- | --- | --- |
|  | Î³0â€‰2>Ï„â‹…2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹â€–Ïƒâˆ’1â€–F2Ï„âˆ’2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹â€–Ïƒâˆ’1â€–F2.\gamma\_{0}^{\,2}\;>\;\frac{\tau\cdot 2T\,(4\beta^{2}-2\beta)\,\|\sigma^{-1}\|\_{F}^{2}}{\tau-2T\,(4\beta^{2}-2\beta)\,\|\sigma^{-1}\|\_{F}^{2}}. |  |

such that
ğ”¼â„™0â€‹[eÎ³2â€‹â€–Bâ€–22]<âˆ\mathbb{E}\_{\mathbb{P}\_{0}}[e^{\gamma^{2}\|B\|\_{2}^{2}}]<\infty for all Î³<Î³0\gamma<\gamma\_{0} by Assumption [4](https://arxiv.org/html/2512.01408v1#Thmassumption4 "Assumption 4. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").
By Cauchyâ€“Schwarz inequality in yy and Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha},

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–Fsâ€‹(B,Î”)â€–2\displaystyle\|F\_{s}(B,\Delta)\|\_{2} | =supâ€–uâ€–2=1âŸ¨u,âˆ«â„dâˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€‹(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâŸ©\displaystyle=\sup\_{\|u\|\_{2}=1}\left\langle u,\;\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B+s\Delta,y)\,\big(\mathbb{E}[L\_{T}(B+s\Delta,y)]\big)^{\beta}\,\varphi\_{T}(y)\,dy\right\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =supâ€–uâ€–2=1âˆ«â„dâŸ¨u,âˆ‡bLTâ€‹(B+sâ€‹Î”,y)âŸ©â€‹(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle=\sup\_{\|u\|\_{2}=1}\int\_{\mathbb{R}^{d}}\langle u,\nabla\_{b}L\_{T}(B+s\Delta,y)\rangle\,\big(\mathbb{E}[L\_{T}(B+s\Delta,y)]\big)^{\beta}\,\varphi\_{T}(y)\,dy |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤supâ€–uâ€–2=1(âˆ«â„dâŸ¨u,âˆ‡bLTâ€‹(B+sâ€‹Î”,y)âŸ©2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/2â€‹(âˆ«â„d(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/2\displaystyle\leq\sup\_{\|u\|\_{2}=1}\Bigg(\int\_{\mathbb{R}^{d}}\langle u,\nabla\_{b}L\_{T}(B+s\Delta,y)\rangle^{2}\,\varphi\_{T}(y)\,dy\Bigg)^{\!1/2}\Bigg(\int\_{\mathbb{R}^{d}}\big(\mathbb{E}[L\_{T}(B+s\Delta,y)]\big)^{2\beta}\,\varphi\_{T}(y)\,dy\Bigg)^{\!1/2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤(âˆ«â„dâ€–âˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€–22â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/2â€‹(âˆ«â„d(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/2.\displaystyle\leq\Bigg(\int\_{\mathbb{R}^{d}}\|\nabla\_{b}L\_{T}(B+s\Delta,y)\|\_{2}^{2}\,\varphi\_{T}(y)\,dy\Bigg)^{\!1/2}\Bigg(\int\_{\mathbb{R}^{d}}\big(\mathbb{E}[L\_{T}(B+s\Delta,y)]\big)^{2\beta}\,\varphi\_{T}(y)\,dy\Bigg)^{\!1/2}. |  |

Recall that

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡bLTâ€‹(b,y)â€–22â‰¤â€–Ïƒâˆ’1â€–F2â€‹LTâ€‹(b,y)2â€‹(1+â€–yâ€–22+T2â€‹â€–aâ€‹(b)â€–22).\|\nabla\_{b}L\_{T}(b,y)\|\_{2}^{2}\;\leq\;\|\sigma^{-1}\|\_{F}^{2}\,L\_{T}(b,y)^{2}\big(1+\|y\|\_{2}^{2}+T^{2}\|a(b)\|\_{2}^{2}\big). |  |

With the identity LTâ€‹(b,y)2â€‹Ï†Tâ€‹(y)=eTâ€‹â€–aâ€‹(b)â€–22â€‹Ï†Tâ€‹(yâˆ’2â€‹Tâ€‹aâ€‹(b))L\_{T}(b,y)^{2}\varphi\_{T}(y)=e^{T\|a(b)\|\_{2}^{2}}\,\varphi\_{T}(y-2Ta(b)) and a Gaussian
moment bound,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dâ€–âˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€–22â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Câ€‹(1+â€–aâ€‹(B+sâ€‹Î”)â€–22)â€‹eTâ€‹â€–aâ€‹(B+sâ€‹Î”)â€–22.\int\_{\mathbb{R}^{d}}\|\nabla\_{b}L\_{T}(B+s\Delta,y)\|\_{2}^{2}\,\varphi\_{T}(y)\,dy\;\leq\;C\,\big(1+\|a(B+s\Delta)\|\_{2}^{2}\big)\,e^{T\|a(B+s\Delta)\|\_{2}^{2}}. |  |

Since aâ€‹(B+sâ€‹Î”)=aâ€‹(B)+sâ€‹Ïƒâˆ’1â€‹Î”a(B+s\Delta)=a(B)+s\,\sigma^{-1}\Delta,

|  |  |  |
| --- | --- | --- |
|  | â€–aâ€‹(B+sâ€‹Î”)â€–22â‰¤2â€‹â€–aâ€‹(B)â€–22+2â€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Î”â€–22,\|a(B+s\Delta)\|\_{2}^{2}\leq 2\|a(B)\|\_{2}^{2}+2\|\sigma^{-1}\|\_{F}^{2}\,\|\Delta\|\_{2}^{2}, |  |

we have

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dâ€–âˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€–22â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Câ€‹(B)â€‹expâ¡(C1â€‹â€–Î”â€–22),\int\_{\mathbb{R}^{d}}\|\nabla\_{b}L\_{T}(B+s\Delta,y)\|\_{2}^{2}\,\varphi\_{T}(y)\,dy\;\leq\;C(B)\,\exp\!\big(C\_{1}\,\|\Delta\|\_{2}^{2}\big), |  |

with C1:=2â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2C\_{1}:=2T\,\|\sigma^{-1}\|\_{F}^{2} and
Câ€‹(B):=Câ€‹(1+2â€‹â€–aâ€‹(B)â€–22)â€‹e2â€‹Tâ€‹â€–aâ€‹(B)â€–22C(B):=C\,(1+2\|a(B)\|\_{2}^{2})\,e^{2T\|a(B)\|\_{2}^{2}}.
With a sub-Gaussian assumption
4â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2<Î³024T\|\sigma^{-1}\|\_{F}^{2}<\gamma\_{0}^{2}
and
ğ”¼â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆ\mathbb{E}[\exp(\gamma^{2}\|B\|\_{2}^{2})]<\infty for all Î³<Î³0\gamma<\gamma\_{0}.
Using â€–aâ€‹(B)â€–22â‰¤2â€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Bâ€–22+2â€‹â€–mâ€–22\|a(B)\|\_{2}^{2}\leq 2\|\sigma^{-1}\|\_{F}^{2}\|B\|\_{2}^{2}+2\|m\|\_{2}^{2},
we obtain

|  |  |  |
| --- | --- | --- |
|  | Câ€‹(B)â‰¤Kâ€‹(1+â€–Bâ€–22)â€‹expâ¡(Îºâ€‹â€–Bâ€–22),K:=Câ€‹c0â€‹e4â€‹Tâ€‹â€–mâ€–22,Îº:=4â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2.C(B)\;\leq\;K\,(1+\|B\|\_{2}^{2})\,\exp\!\big(\kappa\|B\|\_{2}^{2}\big),\qquad K:=C\,c\_{0}\,e^{4T\|m\|\_{2}^{2}},\ \ \kappa:=4T\|\sigma^{-1}\|\_{F}^{2}. |  |

Hence Câ€‹(B)C(B) is finite â„™0\mathbb{P}\_{0} almost surely.

Next, we upper bound the second term. We define

|  |  |  |
| --- | --- | --- |
|  | IÎ²â€‹(s):=âˆ«â„d(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.I\_{\beta}(s)\;:=\;\int\_{\mathbb{R}^{d}}\Big(\mathbb{E}\big[L\_{T}(B+s\Delta,y)\big]\Big)^{2\beta}\,\varphi\_{T}(y)\,dy. |  |

When Î²<0\beta<0 (i.e. Î±<0\alpha<0), set

|  |  |  |
| --- | --- | --- |
|  | asâ€‹(B):=Ïƒâˆ’1â€‹(B+sâ€‹Î”)âˆ’m.a\_{s}(B):=\sigma^{-1}(B+s\Delta)-m. |  |

By the Jensen inequality,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)]\displaystyle\mathbb{E}\big[L\_{T}(B+s\Delta,y)\big] | =ğ”¼â€‹[expâ¡(âŸ¨asâ€‹(B),yâŸ©âˆ’T2â€‹â€–asâ€‹(B)â€–22)]\displaystyle=\mathbb{E}\!\left[\exp\!\Big(\langle a\_{s}(B),y\rangle-\frac{T}{2}\|a\_{s}(B)\|\_{2}^{2}\Big)\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¥expâ¡(âŸ¨ğ”¼â€‹[asâ€‹(B)],yâŸ©âˆ’T2â€‹ğ”¼â€‹[â€–asâ€‹(B)â€–22]).\displaystyle\geq\exp\!\Big(\langle\mathbb{E}[a\_{s}(B)],y\rangle-\frac{T}{2}\,\mathbb{E}\left[\|a\_{s}(B)\|\_{2}^{2}\right]\Big). |  |

Since 2â€‹Î²<02\beta<0, raising both sides to the power 2â€‹Î²2\beta reverses the inequality:

|  |  |  |
| --- | --- | --- |
|  | (ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)])2â€‹Î²â‰¤expâ¡(2â€‹Î²â€‹âŸ¨ğ”¼â€‹[asâ€‹(B)],yâŸ©âˆ’Î²â€‹Tâ€‹ğ”¼â€‹[â€–asâ€‹(B)â€–22]).\Big(\mathbb{E}[L\_{T}(B+s\Delta,y)]\Big)^{2\beta}\;\leq\;\exp\!\Big(2\beta\,\langle\mathbb{E}[a\_{s}(B)],y\rangle-\beta T\,\mathbb{E}\left[\|a\_{s}(B)\|\_{2}^{2}\right]\Big). |  |

Integrating against Ï†T\varphi\_{T}, we obtain

|  |  |  |
| --- | --- | --- |
|  | IÎ²â€‹(s)â‰¤expâ¡((2â€‹Î²2âˆ’Î²)â€‹Tâ€‹ğ”¼â€‹[â€–asâ€‹(B)â€–22])<âˆ.I\_{\beta}(s)\;\leq\;\exp\!\Big(\big(2\beta^{2}-\beta\big)\,T\,\mathbb{E}\left[\|a\_{s}(B)\|\_{2}^{2}\right]\Big)<\infty. |  |

When Î²>0\beta>0, we first fix r>1r>1 with râ‰¥2â€‹Î²r\geq 2\beta. By the Lyapunov and Jensen inequalities,

|  |  |  |
| --- | --- | --- |
|  | IÎ²â€‹(s)â‰¤(ğ”¼â€‹[âˆ«â„dLTâ€‹(B+sâ€‹Î”,y)râ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y])2â€‹Î²/r.I\_{\beta}(s)\;\leq\;\Bigg(\mathbb{E}\Big[\int\_{\mathbb{R}^{d}}L\_{T}(B+s\Delta,y)^{\,r}\,\varphi\_{T}(y)\,dy\Big]\Bigg)^{\!2\beta/r}. |  |

Completing the square in yy gives the closed form

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dLTâ€‹(b,y)râ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=expâ¡(T2â€‹(r2âˆ’r)â€‹â€–Ïƒâˆ’1â€‹bâˆ’mâ€–22).\int\_{\mathbb{R}^{d}}L\_{T}(b,y)^{\,r}\,\varphi\_{T}(y)\,dy\;=\;\exp\!\Big(\tfrac{T}{2}\,(r^{2}-r)\,\|\sigma^{-1}b-m\|\_{2}^{2}\Big). |  |

Therefore, with

|  |  |  |
| --- | --- | --- |
|  | cr:=T2â€‹(r2âˆ’r)>0,c\_{r}\;:=\;\frac{T}{2}\,(r^{2}-r)>0, |  |

we obtain

|  |  |  |
| --- | --- | --- |
|  | IÎ²â€‹(s)â‰¤(ğ”¼â€‹[ecrâ€‹â€–asâ€‹(B)â€–22])2â€‹Î²/r.I\_{\beta}(s)\;\leq\;\Big(\mathbb{E}\left[\,e^{\,c\_{r}\,\|a\_{s}(B)\|\_{2}^{2}}\right]\Big)^{2\beta/r}. |  |

Since

|  |  |  |
| --- | --- | --- |
|  | â€–asâ€‹(B)â€–22=â€–Ïƒâˆ’1â€‹(B+sâ€‹Î”)âˆ’mâ€–22â‰¤2â€‹â€–Ïƒâˆ’1â€‹(B+sâ€‹Î”)â€–22+2â€‹â€–mâ€–22â‰¤4â€‹â€–Ïƒâˆ’1â€–F2â€‹(â€–Bâ€–22+â€–Î”â€–22)+2â€‹â€–mâ€–22,\|a\_{s}(B)\|\_{2}^{2}=\|\sigma^{-1}(B+s\Delta)-m\|\_{2}^{2}\leq 2\|\sigma^{-1}(B+s\Delta)\|\_{2}^{2}+2\|m\|\_{2}^{2}\leq 4\|\sigma^{-1}\|\_{F}^{2}\big(\|B\|\_{2}^{2}+\|\Delta\|\_{2}^{2}\big)+2\|m\|\_{2}^{2}, |  |

then

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[ecrâ€‹â€–asâ€‹(B)â€–22]â‰¤eâ€‰2â€‹crâ€‹â€–mâ€–22â€‹ğ”¼â€‹[expâ¡(4â€‹crâ€‹â€–Ïƒâˆ’1â€–F2â€‹(â€–Bâ€–22+â€–Î”â€–22))].\mathbb{E}\left[\,e^{\,c\_{r}\,\|a\_{s}(B)\|\_{2}^{2}}\right]\;\leq\;e^{\,2c\_{r}\|m\|\_{2}^{2}}\,\mathbb{E}\left[\exp\!\left(4c\_{r}\|\sigma^{-1}\|\_{F}^{2}\big(\|B\|\_{2}^{2}+\|\Delta\|\_{2}^{2}\big)\right)\right]. |  |

Let p>1p>1 and q:=ppâˆ’1q:=\frac{p}{p-1}. By the HÃ¶lder inequality,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[expâ¡(4â€‹crâ€‹â€–Ïƒâˆ’1â€–F2â€‹(â€–Bâ€–22+â€–Î”â€–22))]â‰¤(ğ”¼â€‹[eaâ€‹pâ€‹â€–Bâ€–22])1/pâ€‹(ğ”¼â€‹[eaâ€‹qâ€‹â€–Î”â€–22])1/q,\mathbb{E}\left[\exp\!\left(4c\_{r}\|\sigma^{-1}\|\_{F}^{2}\big(\|B\|\_{2}^{2}+\|\Delta\|\_{2}^{2}\big)\right)\right]\;\leq\;\Big(\mathbb{E}\left[e^{\,ap\,\|B\|\_{2}^{2}}\right]\Big)^{\!1/p}\;\Big(\mathbb{E}\left[e^{\,aq\,\|\Delta\|\_{2}^{2}}\right]\Big)^{\!1/q}, |  |

where a:=4â€‹crâ€‹â€–Ïƒâˆ’1â€–F2=2â€‹Tâ€‹(r2âˆ’r)â€‹â€–Ïƒâˆ’1â€–F2.a:=4c\_{r}\|\sigma^{-1}\|\_{F}^{2}=2T(r^{2}-r)\|\sigma^{-1}\|\_{F}^{2}.
Putting the pieces together,

|  |  |  |
| --- | --- | --- |
|  | IÎ²â€‹(s)â‰¤expâ¡(2â€‹Î²â€‹Tâ€‹(râˆ’1)â€‹â€–mâ€–22)â€‹(ğ”¼â€‹[eaâ€‹pâ€‹â€–Bâ€–22])2â€‹Î²/(râ€‹p)âŸ=â£:CÎ²,r,pâ‹…(ğ”¼â€‹[eaâ€‹qâ€‹â€–Î”â€–22])2â€‹Î²/(râ€‹q)âŸ=â£:MÎ”â€‹(Î¸)â€‰2â€‹Î²/(râ€‹q),I\_{\beta}(s)\;\leq\;\underbrace{\exp\!\big(2\beta T(r-1)\|m\|\_{2}^{2}\big)\;\Big(\mathbb{E}\left[e^{\,ap\,\|B\|\_{2}^{2}}\right]\Big)^{\!2\beta/(rp)}}\_{=:\penalty 10000\ C\_{\beta,r,p}}\;\cdot\;\underbrace{\Big(\mathbb{E}\left[e^{\,aq\,\|\Delta\|\_{2}^{2}}\right]\Big)^{\!2\beta/(rq)}}\_{=:\penalty 10000\ M\_{\Delta}(\theta)^{\,2\beta/(rq)}}, |  |

where Î¸:=aâ€‹q=2â€‹Tâ€‹(r2âˆ’r)â€‹â€–Ïƒâˆ’1â€–F2â€‹q.\theta:=aq=2T(r^{2}-r)\|\sigma^{-1}\|\_{F}^{2}\,q.
Recall the sub-Gaussian assumption: there exists Î³0>0\gamma\_{0}>0 such that
ğ”¼â€‹[eÎ³2â€‹â€–Bâ€–22]<âˆ\mathbb{E}[e^{\gamma^{2}\|B\|\_{2}^{2}}]<\infty for all Î³<Î³0\gamma<\gamma\_{0}. Then CÎ²,r,p<âˆC\_{\beta,r,p}<\infty implies

|  |  |  |
| --- | --- | --- |
|  | aâ€‹p=â€„2â€‹Tâ€‹(r2âˆ’r)â€‹â€–Ïƒâˆ’1â€–F2â€‹p<Î³0â€‰2\;ap\;=\;2T(r^{2}-r)\,\|\sigma^{-1}\|\_{F}^{2}\,p\;<\;\gamma\_{0}^{\,2}\; |  |

and MÎ”â€‹(Î¸)â€‰2â€‹Î²/(râ€‹q)<âˆM\_{\Delta}(\theta)^{\,2\beta/(rq)}<\infty implies
Î¸â‰¤Ï„\theta\leq\tau.

Let S:=â€–Ïƒâˆ’1â€–F2S:=\|\sigma^{-1}\|\_{F}^{2}. Taking the minimal admissible r=2â€‹Î²r=2\beta, we have

|  |  |  |
| --- | --- | --- |
|  | aâ€‹(Î²):=â€„2â€‹Tâ€‹(r2âˆ’r)â€‹S=â€„2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹S.a(\beta)\;:=\;2T\,(r^{2}-r)\,S\;=\;2T\,(4\beta^{2}-2\beta)\,S. |  |

For a fixed cost scale Ï„>0\tau>0, the HÃ¶lder coefficients q=Ï„aâ€‹(Î²)q=\dfrac{\tau}{a(\beta)} and p=qqâˆ’1=Ï„Ï„âˆ’aâ€‹(Î²)p=\dfrac{q}{q-1}=\dfrac{\tau}{\tau-a(\beta)} (valid when Ï„>aâ€‹(Î²)\tau>a(\beta)) yield the BB-side requirement

|  |  |  |
| --- | --- | --- |
|  | Ï„>aâ€‹(Î²)andÎ³0â€‰2>Ï„â€‹aâ€‹(Î²)Ï„âˆ’aâ€‹(Î²).\ \tau\;>\;a(\beta)\qquad\text{and}\qquad\gamma\_{0}^{\,2}\;>\;\frac{\tau\,a(\beta)}{\tau-a(\beta)}. |  |

Equivalently, in terms of Î²\beta,

|  |  |  |
| --- | --- | --- |
|  | Ï„>â€„2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹SandÎ³0â€‰2>Ï„â‹…2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹SÏ„âˆ’2â€‹Tâ€‹(4â€‹Î²2âˆ’2â€‹Î²)â€‹S.\ \tau\;>\;2T\,(4\beta^{2}-2\beta)\,S\qquad\text{and}\qquad\gamma\_{0}^{\,2}\;>\;\frac{\tau\cdot 2T\,(4\beta^{2}-2\beta)\,S}{\tau-2T\,(4\beta^{2}-2\beta)\,S}. |  |

###### Proof of Theorem [5](https://arxiv.org/html/2512.01408v1#Thmtheorem5 "Theorem 5. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

Now we are ready to prove Theorem [5](https://arxiv.org/html/2512.01408v1#Thmtheorem5 "Theorem 5. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").
We recall that the cost function is câ€‹(u,v)=eÏ„â€‹â€–uâˆ’vâ€–22âˆ’1c(u,v)=e^{\tau||u-v||\_{2}^{2}}-1 and first do the case when Î±<0\alpha<0 and solve the concave optimization problem

|  |  |  |
| --- | --- | --- |
|  | argâ¡maxâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)â¡ğ’¥â€‹(â„š).\arg\max\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q}). |  |

To begin with, we define, for fixed Î´\delta and qq, the collection of couplings

|  |  |  |
| --- | --- | --- |
|  | CÎ´:={Ï€âˆˆğ’«(â„dÃ—â„d):Ï€(.,â„d)=â„™0,âˆ«(eÏ„â€‹â€–xâˆ’yâ€–22âˆ’1)Ï€(dx,dy)â‰¤Î´}.C\_{\delta}:=\left\{\pi\in\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}):\pi(.,\mathbb{R}^{d})=\mathbb{P}\_{0},\int\left(e^{\tau||x-y||\_{2}^{2}}-1\right)\pi(dx,dy)\leq\delta\right\}. |  |

These couplings play an important role.
In our case, we can write BB and B+Î”B+\Delta as the couplings, and Î”\Delta is the non-deterministic transport (may have randomness that is not from BB, and we write only ğ”¼\mathbb{E} to represent the non-deterministic coupling).

From the Jensen inequality,

|  |  |  |
| --- | --- | --- |
|  | expâ¡(ğ”¼â€‹[Ï„â€‹â€–Î”â€–22])â‰¤ğ”¼â€‹[expâ¡(Ï„â€‹â€–Î”â€–22)]â‰¤Î´+1.\exp\left(\mathbb{E}\left[\tau\left\|\Delta\right\|\_{2}^{2}\right]\right)\leq\mathbb{E}\left[\exp\left(\tau\left\|\Delta\right\|\_{2}^{2}\right)\right]\leq\delta+1. |  |

Therefore, as Î´â†’0\delta\to 0,

|  |  |  |
| --- | --- | --- |
|  | â€–Î”â€–L22=ğ”¼â€‹[â€–Î”â€–22]â‰¤1Ï„â€‹logâ¡(1+Î´)=Î´Ï„+oâ€‹(Î´).\left\|\Delta\right\|\_{L^{2}}^{2}=\mathbb{E}\left[\left\|\Delta\right\|\_{2}^{2}\right]\leq\tfrac{1}{\tau}\log(1+\delta)=\frac{\delta}{\tau}+o(\delta). |  |

With the Taylor expansion and the Fubini theorem (valid by Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")), for Î´>0\delta>0,

|  |  |  |
| --- | --- | --- |
|  | supâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)ğ’¥â€‹(â„š)âˆ’ğ’¥â€‹(â„™0)\displaystyle\sup\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q})-\mathcal{J}(\mathbb{P}\_{0}) |  |
|  |  |  |
| --- | --- | --- |
|  | â‰¤supÎ”:Ï€âˆˆCÎ´âˆ«â„d(ğ”¼â€‹[LTâ€‹(B+Î”,y)]11âˆ’Î±âˆ’ğ”¼â€‹[LTâ€‹(B,y)]11âˆ’Î±)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle\leq\sup\_{\Delta:\pi\in C\_{\delta}}\int\_{\mathbb{R}^{d}}\left(\mathbb{E}\left[L\_{T}(B+\Delta,y)\right]^{\frac{1}{1-\alpha}}-\mathbb{E}\left[L\_{T}(B,y)\right]^{\frac{1}{1-\alpha}}\right)\varphi\_{T}(y)dy |  |
|  |  |  |
| --- | --- | --- |
|  | =supÎ”:Ï€âˆˆCÎ´âˆ«â„d11âˆ’Î±â€‹âˆ«01ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)]Î±1âˆ’Î±â€‹ğ”¼â€‹[âŸ¨âˆ‡bLTâ€‹(B+sâ€‹Î”,y),Î”âŸ©]â€‹ğ‘‘sâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle=\sup\_{\Delta:\pi\in C\_{\delta}}\int\_{\mathbb{R}^{d}}\frac{1}{1-\alpha}\int\_{0}^{1}\mathbb{E}\left[L\_{T}(B+s\Delta,y)\right]^{\frac{\alpha}{1-\alpha}}\mathbb{E}\left[\left\langle\nabla\_{b}L\_{T}(B+s\Delta,y),\Delta\right\rangle\right]ds\varphi\_{T}(y)dy |  |
|  |  |  |
| --- | --- | --- |
|  | â‰¤Î´Ï„+oâ€‹(Î´)â€‹supÎ”:Ï€âˆˆCÎ´âˆ«01(ğ”¼â€‹[â€–11âˆ’Î±â€‹âˆ«â„dâˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€‹ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)]Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–22])12â€‹ğ‘‘s,\displaystyle\leq\sqrt{\frac{\delta}{\tau}+o(\delta)}\sup\_{\Delta:\pi\in C\_{\delta}}\int\_{0}^{1}\left(\mathbb{E}\left[\left\|\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B+s\Delta,y)\mathbb{E}\left[L\_{T}(B+s\Delta,y)\right]^{\frac{\alpha}{1-\alpha}}\varphi\_{T}(y)dy\right\|\_{2}^{2}\right]\right)^{\frac{1}{2}}ds, |  |

where the last step is by the HÃ¶lder inequality.

Any choice of Ï€Î´âˆˆCÎ´\pi^{\delta}\in C\_{\delta} (and the corresponding Î”Î´\Delta\_{\delta}) converges to the pushforward measure of â„™0\mathbb{P}\_{0} under the map xâ†¦(x,x)x\mapsto(x,x) on ğ’«â€‹(â„dÃ—â„d)\mathcal{P}(\mathbb{R}^{d}\times\mathbb{R}^{d}) in the topology induced by the map (x,y)â†¦eÏ„â€‹â€–xâˆ’yâ€–22âˆ’1(x,y)\mapsto e^{\tau||x-y||\_{2}^{2}}-1.

By Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), there exists constants Câ€‹(B)>0C(B)>0 and finite â„™0\mathbb{P}\_{0} almost surely and C1â‰¤Ï„C\_{1}\leq\tau such that

|  |  |  |
| --- | --- | --- |
|  | â€–11âˆ’Î±â€‹âˆ«â„dâˆ‡bLTâ€‹(B+sâ€‹Î”,y)â€‹ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”,y)]Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–22â‰¤Câ€‹(B)â€‹expâ¡(C1â€‹â€–Î”â€–22).\left\|\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B+s\Delta,y)\mathbb{E}\left[L\_{T}(B+s\Delta,y)\right]^{\frac{\alpha}{1-\alpha}}\varphi\_{T}(y)dy\right\|\_{2}^{2}\leq C(B)\exp(C\_{1}\left\|\Delta\right\|\_{2}^{2}). |  |

for all fixed sâˆˆ[0,1]s\in[0,1], small Î´\delta, and almost every BB and yy.

Fix a sequence Î´nâ†“0\delta\_{n}\downarrow 0 and pick any Ï€Î´nâˆˆCÎ´n\pi^{\delta\_{n}}\in C\_{\delta\_{n}} with a
law of (B,B+Î”Î´n)(B,B+\Delta\_{\delta\_{n}}). Define, for sâˆˆ[0,1]s\in[0,1],

|  |  |  |
| --- | --- | --- |
|  | XÎ´nâ€‹(s):=â€–11âˆ’Î±â€‹âˆ«â„dâˆ‡bLTâ€‹(B+sâ€‹Î”Î´n,y)â€‹(ğ”¼â€‹[LTâ€‹(B+sâ€‹Î”Î´n,y)])Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–22.X\_{\delta\_{n}}(s)\ :=\ \Big\|\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B+s\Delta\_{\delta\_{n}},y)\Big(\mathbb{E}[L\_{T}(B+s\Delta\_{\delta\_{n}},y)]\Big)^{\frac{\alpha}{1-\alpha}}\varphi\_{T}(y)\,dy\Big\|\_{2}^{2}. |  |

By Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), there exist Câ€‹(B)>0C(B)>0 and finite â„™0\mathbb{P}\_{0} almost surely and C1â‰¤Ï„C\_{1}\leq\tau such that, for all sâˆˆ[0,1]s\in[0,1] and all admissible Î”\Delta,

|  |  |  |
| --- | --- | --- |
|  | XÎ´nâ€‹(s)â‰¤Câ€‹(B)â€‹expâ¡(C1â€‹â€–Î”Î´nâ€–22)â„™0â€‹-a.s..X\_{\delta\_{n}}(s)\ \leq\ C(B)\,\exp\!\big(C\_{1}\|\Delta\_{\delta\_{n}}\|\_{2}^{2}\big)\qquad\mathbb{P}\_{0}\text{-a.s.}. |  |

Moreover, ğ”¼â€‹[eÏ„â€‹â€–Î”Î´nâ€–22]â‰¤1+Î´n\mathbb{E}[e^{\tau\|\Delta\_{\delta\_{n}}\|\_{2}^{2}}]\leq 1+\delta\_{n} as nâ†’âˆn\to\infty.

Choose any Î·>0\eta>0 with 2â€‹(1+Î·)â€‹C1â‰¤Ï„2(1+\eta)C\_{1}\leq\tau (possible since C1<Ï„2C\_{1}<\frac{\tau}{2}).
Using the HÃ¶lder inequality,

|  |  |  |
| --- | --- | --- |
|  | supnğ”¼â€‹[XÎ´nâ€‹(s)1+Î·]â‰¤(ğ”¼â„™0â€‹[Câ€‹(B)â€‰2â€‹(1+Î·)])12â€‹(supnğ”¼â€‹expâ¡(2â€‹(1+Î·)â€‹C1â€‹â€–Î”Î´nâ€–22))12<âˆ,\sup\_{n}\mathbb{E}\big[X\_{\delta\_{n}}(s)^{1+\eta}\big]\ \leq\ \left(\mathbb{E}\_{\mathbb{P}\_{0}}\big[C(B)^{\,2(1+\eta)}\big]\,\right)^{\frac{1}{2}}\left(\sup\_{n}\mathbb{E}\exp\!\big(2(1+\eta)C\_{1}\|\Delta\_{\delta\_{n}}\|\_{2}^{2}\big)\right)^{\frac{1}{2}}<\ \infty, |  |

where ğ”¼â„™0â€‹[Câ€‹(B)2â€‹(1+Î·)]<âˆ\mathbb{E}\_{\mathbb{P}\_{0}}[C(B)^{2(1+\eta)}]<\infty holds under the sub-Gaussian assumption (recall the proof of Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). Hence, {XÎ´nâ€‹(s)}n\{X\_{\delta\_{n}}(s)\}\_{n} is uniformly integrable.
Since Î”Î´nâ†’0\Delta\_{\delta\_{n}}\to 0 in L2L^{2} (hence in probability) and
bâ†¦âˆ‡bLTâ€‹(b,y)b\mapsto\nabla\_{b}L\_{T}(b,y) is continuous, we have
XÎ´nâ€‹(s)â†’X0â€‹(s)X\_{\delta\_{n}}(s)\to X\_{0}(s) in probability, where

|  |  |  |
| --- | --- | --- |
|  | X0â€‹(s)=â€–11âˆ’Î±â€‹âˆ«â„dâˆ‡bLTâ€‹(B,y)â€‹(ğ”¼â„™0â€‹[LTâ€‹(B,y)])Î±1âˆ’Î±â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–22.X\_{0}(s)\ =\ \Big\|\frac{1}{1-\alpha}\int\_{\mathbb{R}^{d}}\nabla\_{b}L\_{T}(B,y)\Big(\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B,y)]\Big)^{\frac{\alpha}{1-\alpha}}\varphi\_{T}(y)\,dy\Big\|\_{2}^{2}. |  |

Thus, by Vitaliâ€™s theorem,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[XÎ´nâ€‹(s)]âŸ¶ğ”¼â„™0â€‹[X0â€‹(s)]for everyÂ â€‹sâˆˆ[0,1].\mathbb{E}\big[X\_{\delta\_{n}}(s)\big]\ \longrightarrow\ \mathbb{E}\_{\mathbb{P}\_{0}}\big[X\_{0}(s)\big]\qquad\text{for every }s\in[0,1]. |  |

We also have the ssâ€“uniform integrable bound

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[XÎ´nâ€‹(s)]â‰¤(ğ”¼â„™0â€‹[Câ€‹(B)1+Î·])11+Î·â€‹(ğ”¼â€‹eÏ„â€‹â€–Î”Î´nâ€–22)Î·1+Î·â‰¤(ğ”¼â„™0â€‹[Câ€‹(B)1+Î·])11+Î·â€‹(1+Î´n)Î·1+Î·,\mathbb{E}\big[X\_{\delta\_{n}}(s)\big]\ \leq\ \Big(\mathbb{E}\_{\mathbb{P}\_{0}}[C(B)^{1+\eta}]\Big)^{\frac{1}{1+\eta}}\Big(\mathbb{E}e^{\tau\|\Delta\_{\delta\_{n}}\|\_{2}^{2}}\Big)^{\frac{\eta}{1+\eta}}\ \leq\ \Big(\mathbb{E}\_{\mathbb{P}\_{0}}[C(B)^{1+\eta}]\Big)^{\frac{1}{1+\eta}}(1+\delta\_{n})^{\frac{\eta}{1+\eta}}, |  |

independent of ss. Therefore, by dominated convergence theorem in ss,

|  |  |  |
| --- | --- | --- |
|  | âˆ«01ğ”¼â€‹[XÎ´nâ€‹(s)]1/2â€‹ğ‘‘sâŸ¶âˆ«01ğ”¼â„™0â€‹[X0â€‹(s)]1/2â€‹ğ‘‘s,\int\_{0}^{1}\mathbb{E}\big[X\_{\delta\_{n}}(s)\big]^{1/2}\,ds\ \longrightarrow\ \int\_{0}^{1}\mathbb{E}\_{\mathbb{P}\_{0}}\big[X\_{0}(s)\big]^{1/2}\,ds, |  |

which completes the upper bound argument and gives

|  |  |  |
| --- | --- | --- |
|  | supâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)ğ’¥â€‹(â„š)â‰¤ğ’¥â€‹(â„™0)+Î´Ï„â€‹â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´).\sup\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q})\leq\mathcal{J}(\mathbb{P}\_{0})+\sqrt{\frac{\delta}{\tau}}\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}+o(\sqrt{\delta}). |  |

Next we prove the lower bound by a deterministic coupling. From Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), fix a deterministic function hh. Then by the integral form of Taylor expansion, we have

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€‹((Id+h)#â€‹â„™0)âˆ’ğ’¥â€‹(â„™0)\displaystyle\mathcal{J}((\mathrm{Id}+h)\_{\#}\mathbb{P}\_{0})-\mathcal{J}(\mathbb{P}\_{0}) |  |
|  |  |  |
| --- | --- | --- |
|  | =âˆ«â„d(ğ”¼â„™0â€‹[LTâ€‹(B+hâ€‹(B),y)]11âˆ’Î±âˆ’ğ”¼â„™0â€‹[LTâ€‹(B,y)]11âˆ’Î±)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle=\int\_{\mathbb{R}^{d}}\left(\mathbb{E}^{\mathbb{P}\_{0}}\left[L\_{T}(B+h(B),y)\right]^{\frac{1}{1-\alpha}}-\mathbb{E}\_{\mathbb{P}\_{0}}\left[L\_{T}(B,y)\right]^{\frac{1}{1-\alpha}}\right)\varphi\_{T}(y)dy |  |
|  |  |  |
| --- | --- | --- |
|  | =âˆ«â„d11âˆ’Î±â€‹âˆ«01ğ”¼â„™0â€‹[LTâ€‹(B+sâ€‹hâ€‹(B),y)]Î±1âˆ’Î±â€‹ğ”¼â„™0â€‹[âŸ¨âˆ‡bLTâ€‹(B+sâ€‹hâ€‹(B),y),hâ€‹(B)âŸ©]â€‹ğ‘‘sâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\displaystyle=\int\_{\mathbb{R}^{d}}\frac{1}{1-\alpha}\int\_{0}^{1}\mathbb{E}\_{\mathbb{P}\_{0}}\left[L\_{T}(B+sh(B),y)\right]^{\frac{\alpha}{1-\alpha}}\mathbb{E}\_{\mathbb{P}\_{0}}\left[\left\langle\nabla\_{b}L\_{T}(B+sh(B),y),h(B)\right\rangle\right]ds\varphi\_{T}(y)dy. |  |

Define the deterministic map

|  |  |  |
| --- | --- | --- |
|  | hÎ´â€‹(b)=tÎ´â€‹Hâ€‹(b),tÎ´=Î´Ï„â€‹â€–Hâ€–L22â€‹(â„™0)2â€‹(1+oâ€‹(1))(Î´â†“0).h\_{\delta}(b)\;=\;t\_{\delta}\,H(b),\qquad t\_{\delta}\;=\;\sqrt{\frac{\delta}{\tau\,\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}^{2}}}\,(1+o(1))\quad(\delta\downarrow 0). |  |

Then hÎ´h\_{\delta} is feasible for the exponential cost budget
ğ”¼â€‹[eÏ„â€‹â€–hÎ´â€‹(B)â€–22âˆ’1]â‰¤Î´\mathbb{E}\big[e^{\tau\|h\_{\delta}(B)\|\_{2}^{2}}-1\big]\leq\delta for all sufficiently small Î´\delta, and

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€‹((Id+hÎ´)#â€‹â„™0)âˆ’ğ’¥â€‹(â„™0)=Î´Ï„â€‹â€–Hâ€–L22â€‹(â„™0)+oâ€‹(Î´).\mathcal{J}\big((\mathrm{Id}+h\_{\delta})\_{\#}\mathbb{P}\_{0}\big)-\mathcal{J}(\mathbb{P}\_{0})\;=\;\sqrt{\frac{\delta}{\tau}}\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}\,\;+\;o\!\big(\sqrt{\delta}\big). |  |

Consequently, the deterministic class yields the sharp lower bound matching the upper boundâ€™s rate and constant.
To see this, set htâ€‹(b):=tâ€‹Hâ€‹(b)h\_{t}(b):=t\,H(b). For fixed yy, let

|  |  |  |
| --- | --- | --- |
|  | Ïˆyâ€‹(t):=(ğ”¼â„™0â€‹[LTâ€‹(B+htâ€‹(B),y)])11âˆ’Î±.\psi\_{y}(t)\;:=\;\Big(\mathbb{E}\_{\mathbb{P}\_{0}}[L\_{T}(B+h\_{t}(B),y)]\Big)^{\frac{1}{1-\alpha}}. |  |

Then the above Taylor expansion becomes

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€‹((Id+ht)#â€‹â„™0)âˆ’ğ’¥â€‹(â„™0)=tâ€‹â€–Hâ€–L22â€‹(â„™0)2+oâ€‹(t)(tâ†“0).\mathcal{J}\big((\mathrm{Id}+h\_{t})\_{\#}\mathbb{P}\_{0}\big)-\mathcal{J}(\mathbb{P}\_{0})\;=\;t\,\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}^{2}\;+\;o(t)\qquad(t\downarrow 0). |  |

Since â€–htâ€‹(B)â€–22=t2â€‹â€–Hâ€‹(B)â€–22\|h\_{t}(B)\|\_{2}^{2}=t^{2}\|H(B)\|\_{2}^{2} and ğ”¼â„™0â€‹[â€–Hâ€‹(B)â€–22]<âˆ\mathbb{E}^{\mathbb{P}\_{0}}\left[\|H(B)\|\_{2}^{2}\right]<\infty, we have

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[eÏ„â€‹â€–htâ€‹(B)â€–22]=â€„1+Ï„â€‹t2â€‹â€–Hâ€–L22â€‹(â„™0)2+oâ€‹(t2)(tâ†“0).\mathbb{E}\big[e^{\tau\|h\_{t}(B)\|\_{2}^{2}}\big]\;=\;1+\tau t^{2}\,\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}^{2}+o(t^{2})\qquad(t\downarrow 0). |  |

Thus there exists tÎ´=Î´/(Ï„â€‹â€–Hâ€–L22â€‹(â„™0)2)â€‹(1+oâ€‹(1))t\_{\delta}=\sqrt{\delta/(\tau\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}^{2})}\,(1+o(1)) such that
ğ”¼â€‹[eÏ„â€‹â€–htÎ´â€‹(B)â€–22]â‰¤1+Î´\mathbb{E}[e^{\tau\|h\_{t\_{\delta}}(B)\|\_{2}^{2}}]\leq 1+\delta for all sufficiently small Î´\delta.
Plugging t=tÎ´t=t\_{\delta} into the expansion above yields

|  |  |  |
| --- | --- | --- |
|  | ğ’¥â€‹((Id+htÎ´)#â€‹â„™0)âˆ’ğ’¥â€‹(â„™0)=â€–Hâ€–L22â€‹(â„™0)2â€‹tÎ´+oâ€‹(tÎ´)=â€–Hâ€–L22â€‹(â„™0)â€‹Î´Ï„+oâ€‹(Î´),\mathcal{J}\big((\mathrm{Id}+h\_{t\_{\delta}})\_{\#}\mathbb{P}\_{0}\big)-\mathcal{J}(\mathbb{P}\_{0})\;=\;\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}^{2}\,t\_{\delta}+o(t\_{\delta})\;=\;\|H\|\_{L^{2}\_{2}(\mathbb{P}\_{0})}\,\sqrt{\frac{\delta}{\tau}}\;+\;o\!\big(\sqrt{\delta}\big), |  |

as claimed.

Since Lemma [2](https://arxiv.org/html/2512.01408v1#Thmlemma2 "Lemma 2. â€£ Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") provides the estimates needed for the case when Î±âˆˆ(0,1)\alpha\in(0,1), the proof of the case when Î±âˆˆ(0,1)\alpha\in(0,1) and the solution of the convex optimization problem

|  |  |  |
| --- | --- | --- |
|  | argâ¡minâ„šâˆˆğ’°Î´,BOTâ€‹(â„™0)â¡ğ’¥â€‹(â„š)\arg\min\_{\mathbb{Q}\in\mathcal{U}\_{\delta,B}^{\text{OT}}(\mathbb{P}\_{0})}\mathcal{J}(\mathbb{Q}) |  |

is almost verbatim and we only need to notice that the optimal direction is on the opposite of the previous case.
âˆ

## Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support

In this section, we derive a stochastic asymptotic upper bound of the RWPI under the nonlinear projection when BB is not compactly supported. We will use a method that does not depend on Wasserstein geometry. Several technical lemmas are presented at the end of this section. Recall that we consider the case when Î±<1\alpha<1 and Î±â‰ 0\alpha\neq 0 with the cost function cÏ„â€‹(Î”):=eÏ„â€‹â€–Î”â€–22âˆ’â€„1c\_{\tau}(\Delta)\;:=\;e^{\,\tau\,\|\Delta\|\_{2}^{2}}\;-\;1 for a displacement Î”\Delta. B(i)B^{(i)} are i.i.d. (calibrated) samples of BB from a distribution â„™âˆ—\mathbb{P}^{\*}, and they are used to constitute an empirical measure â„™n\mathbb{P}\_{n}, where nn is the sample size. For a fixed k>0k>0,

|  |  |  |
| --- | --- | --- |
|  | gkâ€‹(x)=(erâ€‹Tk)11âˆ’Î±â€‹x11âˆ’Î±,g\_{k}(x)=\left(\frac{e^{rT}}{k}\right)^{\frac{1}{1-\alpha}}x^{\frac{1}{1-\alpha}}, |  |

and kâˆ—k^{\*} represents the optimal Lagrangian multiplier. We still make a sub-Gaussian assumption on BB. Many computational details are similar to those in Section [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") (only the sub-Gaussian parameters are different), thus we omit some proofs for simplicity.

###### Assumption 5.

Suppose there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}^{\*}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{â€‰4â€‹Î²2âˆ’2â€‹Î²,2Î²âˆ’2, 16, 8â€‹Î²+8}\frac{\gamma\_{0}^{2}}{\left\|\sigma^{-1}\right\|\_{F}^{2}}>T\max\Big\{\,4\beta^{2}-2\beta,\ \tfrac{2}{\beta-2},\ 16,\ 8\beta+8\,\Big\} |  |

and Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}.

###### Theorem 6.

We denote Î±â€‹(y)=ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)]\alpha(y)=\mathbb{E}\_{\mathbb{P}^{\*}}\left[L\_{T}(B,y)\right] for each fixed yâˆˆâ„dy\in\mathbb{R}^{d}. Under Assumption [5](https://arxiv.org/html/2512.01408v1#Thmassumption5 "Assumption 5. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), as nâ†’âˆn\to\infty, we have the asymptotic stochastic upper bound:

|  |  |  |
| --- | --- | --- |
|  | nâ€‹Rnâ€‹(kâˆ—)â‰²DL:=Ï„â€‹Z2ğ”¼â„™âˆ—â€‹[â€–âˆ«â„dgkâˆ—â€²â€‹(Î±â€‹(y))â€‹âˆ‡bLTâ€‹(B,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–22],nR\_{n}(k^{\*})\lesssim\_{D}L:=\frac{\tau Z^{2}}{\mathbb{E}\_{\mathbb{P}^{\*}}\left[\left\lVert\int\_{\mathbb{R}^{d}}g\_{k^{\*}}^{\prime}(\alpha(y))\nabla\_{b}L\_{T}(B,y)\varphi\_{T}(y)dy\right\rVert\_{2}^{2}\right]}, |  |

where
Zâˆ¼ğ’©â€‹(0,hâ€‹(â„™âˆ—))Z\sim\mathcal{N}(0,h(\mathbb{P}^{\*}))
and the functional hh is defined by

|  |  |  |
| --- | --- | --- |
|  | hâ€‹(â„™âˆ—)=âˆ«âˆ«gkâˆ—â€²â€‹(Î±â€‹(y1))â€‹gkâˆ—â€²â€‹(Î±â€‹(y2))â€‹Covâ„™âˆ—â€‹(LTâ€‹(B,y1),LTâ€‹(B,y2))â€‹Ï†Tâ€‹(y1)â€‹Ï†Tâ€‹(y2)â€‹ğ‘‘y1â€‹ğ‘‘y2<âˆ.h(\mathbb{P}^{\*})=\int\int g\_{k^{\*}}^{\prime}(\alpha(y\_{1}))g\_{k^{\*}}^{\prime}(\alpha(y\_{2}))\text{Cov}\_{\mathbb{P}^{\*}}\left(L\_{T}(B,y\_{1}),L\_{T}(B,y\_{2})\right)\varphi\_{T}(y\_{1})\varphi\_{T}(y\_{2})dy\_{1}dy\_{2}<\infty. |  |

The proof of Theorem [6](https://arxiv.org/html/2512.01408v1#Thmtheorem6 "Theorem 6. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") consists of six parts. First, we use Taylor expansions to separate terms in Rnâ€‹(kâˆ—)R\_{n}(k^{\*}) and obtain Eq. ([54](https://arxiv.org/html/2512.01408v1#A4.E54 "In D.1 Part I â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). Second, we estimate some remainder terms (R1R\_{1} and R2R\_{2} in Eq. ([54](https://arxiv.org/html/2512.01408v1#A4.E54 "In D.1 Part I â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"))). Third, we compute the optimal deterministic coupling in Eq. ([55](https://arxiv.org/html/2512.01408v1#A4.E55 "In D.3 Part III â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). Fourth, we establish various senses of convergence to be used in the main statement. Fifth, we continue to compute the remainder term. Sixth, we summarize all the required assumptions and conclude the asymptotic result.

### D.1 Part I

To begin with, the uniqueness of kâˆ—k^{\*} is easy to see. In order to prove Theorem [6](https://arxiv.org/html/2512.01408v1#Thmtheorem6 "Theorem 6. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we define a functional JJ on the space of probability measures such that (for notational convenience) gâ€‹(x)=gkâˆ—â€‹(x)g(x)=g\_{k^{\*}}(x) and

|  |  |  |
| --- | --- | --- |
|  | Jâ€‹(â„™)=âˆ«â„dgâ€‹(ğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.J(\mathbb{P})=\int\_{\mathbb{R}^{d}}g\left(\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right]\right)\varphi\_{T}(y)dy. |  |

In particular,

|  |  |  |
| --- | --- | --- |
|  | gâ€²â€‹(x)=11âˆ’Î±â€‹(erâ€‹Tkâˆ—)11âˆ’Î±â€‹xÎ±1âˆ’Î±,g^{\prime}(x)=\frac{1}{1-\alpha}\left(\frac{e^{rT}}{k^{\*}}\right)^{\frac{1}{1-\alpha}}x^{\frac{\alpha}{1-\alpha}}, |  |

and

|  |  |  |
| --- | --- | --- |
|  | gâ€²â€²â€‹(x)=Î±(1âˆ’Î±)2â€‹(erâ€‹Tkâˆ—)11âˆ’Î±â€‹x2â€‹Î±âˆ’11âˆ’Î±,g^{\prime\prime}(x)=\frac{\alpha}{(1-\alpha)^{2}}\left(\frac{e^{rT}}{k^{\*}}\right)^{\frac{1}{1-\alpha}}x^{\frac{2\alpha-1}{1-\alpha}}, |  |

We notice that LTL\_{T} and gg are both twice continuously differentiable functions in each argument. Therefore, the RWP function becomes

|  |  |  |  |
| --- | --- | --- | --- |
|  | Rnâ€‹(kâˆ—)\displaystyle R\_{n}(k^{\*}) | :=infâ„™âˆˆâ„±kâˆ—Dcâ€‹(â„™n,â„™)\displaystyle:=\inf\_{\mathbb{P}\in\mathcal{F}\_{k^{\*}}}D\_{c}(\mathbb{P}\_{n},\mathbb{P}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =inf{Dcâ€‹(â„™,â„™n):âˆ«â„dIâ€‹(kâˆ—â€‹eâˆ’râ€‹Tğ”¼â„™â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=x0â€‹erâ€‹T}\displaystyle=\inf\left\{D\_{c}(\mathbb{P},\mathbb{P}\_{n}):\int\_{\mathbb{R}^{d}}I\left(\frac{k^{\*}e^{-rT}}{\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right]}\right)\varphi\_{T}(y)dy=x\_{0}e^{rT}\right\} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =inf{Dcâ€‹(â„™,â„™n):Jâ€‹(â„™)=Jâ€‹(â„™âˆ—)}.\displaystyle=\inf\left\{D\_{c}(\mathbb{P},\mathbb{P}\_{n}):J(\mathbb{P})=J(\mathbb{P}^{\*})\right\}. |  |

Given the empirical measure â„™n\mathbb{P}\_{n}, we define the perturbed empirical measure â„™nÎ”\mathbb{P}\_{n}^{\Delta} by pushing each atom B(i)B^{(i)} to B(i)+Î”iâ€‹nâˆ’1/2B^{(i)}+\Delta\_{i}n^{-1/2} for Î”iâˆˆâ„d\Delta\_{i}\in\mathbb{R}^{d}. We want to show that for any fixed Îµ>0\varepsilon>0, for all sufficiently large nn, with probability at least 1âˆ’Îµ1-\varepsilon, there exists a correction Î”\Delta with â€–Î”â€–n=Opâ€‹(1)\left\|\Delta\right\|\_{n}=O\_{p}(1) and Jâ€‹(â„™nÎ”)=Jâ€‹(â„™âˆ—)J(\mathbb{P}\_{n}^{\Delta})=J(\mathbb{P}^{\*}), where we use the notation for Î³âˆˆâ„¤\gamma\in\mathbb{Z}, â€–Î”â€–nÎ³:=1nâ€‹âˆ‘i=1nâ€–Î”iâ€–Î³.\left\|\Delta\right\|\_{n}^{\gamma}:=\frac{1}{n}\sum\_{i=1}^{n}\left\|\Delta\_{i}\right\|^{\gamma}.

For each yy and ii, set hi:=Î”i/nh\_{i}:=\Delta\_{i}/\sqrt{n}.
the Taylor theorem in the bbâ€“variable gives

|  |  |  |
| --- | --- | --- |
|  | LTâ€‹(B(i)+hi,y)=LTâ€‹(B(i),y)+âˆ‡bLTâ€‹(B(i),y)â‹…hi+âˆ«01(1âˆ’t)â€‹hiâŠ¤â€‹âˆ‡b2LTâ€‹(B(i)+tâ€‹hi,y)â€‹hiâ€‹ğ‘‘t.L\_{T}(B^{(i)}+h\_{i},y)=L\_{T}(B^{(i)},y)+\nabla\_{b}L\_{T}(B^{(i)},y)\!\cdot\!h\_{i}+\int\_{0}^{1}(1-t)\,h\_{i}^{\top}\nabla\_{b}^{2}L\_{T}(B^{(i)}+th\_{i},y)\,h\_{i}\,dt. |  |

Defining mâ„™â€‹(y)=ğ”¼â„™â€‹[LTâ€‹(B,y)]m\_{\mathbb{P}}(y)=\mathbb{E}\_{\mathbb{P}}\left[L\_{T}(B,y)\right] for a probability measure â„™\mathbb{P} yields

|  |  |  |
| --- | --- | --- |
|  | mâ„™nÎ”â€‹(y)=mâ„™nâ€‹(y)+A1â€‹(y)+A2â€‹(y),m\_{\mathbb{P}\_{n}^{\Delta}}(y)=m\_{\mathbb{P}\_{n}}(y)\;+\;A\_{1}(y)\;+\;A\_{2}(y), |  |

with

|  |  |  |
| --- | --- | --- |
|  | A1â€‹(y)=1nâ‹…1nâ€‹âˆ‘i=1nâˆ‡bLTâ€‹(B(i),y)â‹…Î”iA\_{1}(y)=\frac{1}{\sqrt{n}}\cdot\frac{1}{n}\sum\_{i=1}^{n}\nabla\_{b}L\_{T}(B^{(i)},y)\cdot\Delta\_{i} |  |

and

|  |  |  |
| --- | --- | --- |
|  | A2â€‹(y)=1nâ€‹âˆ‘i=1nâˆ«01(1âˆ’t)â€‹Î”iâŠ¤nâ€‹âˆ‡b2LTâ€‹(B(i)+tâ€‹Î”in,y)â€‹Î”inâ€‹ğ‘‘t.A\_{2}(y)=\frac{1}{n}\sum\_{i=1}^{n}\int\_{0}^{1}(1-t)\,\frac{\Delta\_{i}^{\top}}{\sqrt{n}}\,\nabla\_{b}^{2}L\_{T}\!\Big(B^{(i)}+t\tfrac{\Delta\_{i}}{\sqrt{n}},y\Big)\,\frac{\Delta\_{i}}{\sqrt{n}}\,dt. |  |

Another Taylor expansion gives

|  |  |  |  |
| --- | --- | --- | --- |
|  | gâ€‹(mâ„™nÎ”â€‹(y))\displaystyle g(m\_{\mathbb{P}\_{n}^{\Delta}}(y)) | =gâ€‹(mâ„™nâ€‹(y))+gâ€²â€‹(mâ„™nâ€‹(y))â€‹(A1â€‹(y)+A2â€‹(y))\displaystyle=g(m\_{\mathbb{P}\_{n}}(y))+g^{\prime}(m\_{\mathbb{P}\_{n}}(y))(A\_{1}(y)+A\_{2}(y)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +âˆ«01(1âˆ’t)â€‹gâ€²â€²â€‹(mâ„™nâ€‹(y)+tâ€‹(A1â€‹(y)+A2â€‹(y)))â€‹(A1â€‹(y)+A2â€‹(y))2â€‹ğ‘‘t,\displaystyle+\int\_{0}^{1}(1-t)g^{\prime\prime}(m\_{\mathbb{P}\_{n}}(y)+t(A\_{1}(y)+A\_{2}(y)))(A\_{1}(y)+A\_{2}(y))^{2}dt, |  |

which implies that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Jâ€‹(â„™nÎ”)âˆ’Jâ€‹(â„™âˆ—)=Jâ€‹(â„™n)âˆ’Jâ€‹(â„™âˆ—)+âˆ«gâ€²â€‹(mâ„™nâ€‹(y))â€‹A1â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y+R1+R2,J(\mathbb{P}\_{n}^{\Delta})-J(\mathbb{P}^{\*})=J(\mathbb{P}\_{n})-J(\mathbb{P}^{\*})+\int g^{\prime}(m\_{\mathbb{P}\_{n}}(y))A\_{1}(y)\varphi\_{T}(y)dy+R\_{1}+R\_{2}, |  | (54) |

where

|  |  |  |
| --- | --- | --- |
|  | R1=âˆ«gâ€²â€‹(mâ„™nâ€‹(y))â€‹A2â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,R\_{1}=\int g^{\prime}(m\_{\mathbb{P}\_{n}}(y))A\_{2}(y)\varphi\_{T}(y)dy, |  |

and

|  |  |  |
| --- | --- | --- |
|  | R2=âˆ«01(1âˆ’t)â€‹âˆ«gâ€²â€²â€‹(mâ„™nâ€‹(y)+tâ€‹(A1â€‹(y)+A2â€‹(y)))â€‹(A1â€‹(y)+A2â€‹(y))2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€‹ğ‘‘t.R\_{2}=\int\_{0}^{1}(1-t)\int g^{\prime\prime}(m\_{\mathbb{P}\_{n}}(y)+t(A\_{1}(y)+A\_{2}(y)))(A\_{1}(y)+A\_{2}(y))^{2}\varphi\_{T}(y)dydt. |  |

If we define

|  |  |  |
| --- | --- | --- |
|  | Ciâ€‹(n)=âˆ«gâ€²â€‹(mâ„™nâ€‹(y))â€‹âˆ‡bLTâ€‹(B(i),y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,C\_{i}(n)=\int g^{\prime}(m\_{\mathbb{P}\_{n}}(y))\nabla\_{b}L\_{T}(B^{(i)},y)\varphi\_{T}(y)dy, |  |

then

|  |  |  |
| --- | --- | --- |
|  | âˆ«gâ€²â€‹(mâ„™nâ€‹(y))â€‹A1â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=1n1/2â€‹1nâ€‹âˆ‘i=1nCiâ€‹(n)â‹…Î”i.\int g^{\prime}(m\_{\mathbb{P}\_{n}}(y))A\_{1}(y)\varphi\_{T}(y)dy=\frac{1}{n^{1/2}}\frac{1}{n}\sum\_{i=1}^{n}C\_{i}(n)\cdot\Delta\_{i}. |  |

### D.2 Part II

In this part, we will present Lemmas [3](https://arxiv.org/html/2512.01408v1#Thmlemma3 "Lemma 3. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")-[6](https://arxiv.org/html/2512.01408v1#Thmlemma6 "Lemma 6. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") to estimate R1R\_{1} and R2R\_{2}. Proofs of [3](https://arxiv.org/html/2512.01408v1#Thmlemma3 "Lemma 3. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")-[5](https://arxiv.org/html/2512.01408v1#Thmlemma5 "Lemma 5. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") are similar to the estimates in Section [C](https://arxiv.org/html/2512.01408v1#A3 "Appendix C Generalization of Nonlinear Perturbation Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), where the sub-Gaussian assumptions are used to bound integrability conditions after standard Gaussian integral computations. We only give the proof details of the most complicated term of Lemma [4](https://arxiv.org/html/2512.01408v1#Thmlemma4 "Lemma 4. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections").

#### D.2.1 Part II-i

We propose the following sub-Gaussian assumption.

###### Assumption 6.

Suppose there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}^{\*}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{2â€‹(2â€‹Î²2âˆ’Î²),4}\frac{\gamma\_{0}^{2}}{\left\|\sigma^{-1}\right\|\_{F}^{2}}>T\max\left\{2(2\beta^{2}-\beta),4\right\} |  |

and Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}.

###### Lemma 3.

In the context of the proof of Theorem [6](https://arxiv.org/html/2512.01408v1#Thmtheorem6 "Theorem 6. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), under Assumption [6](https://arxiv.org/html/2512.01408v1#Thmassumption6 "Assumption 6. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), when Î±<1\alpha<1 and Î±â‰ 0\alpha\neq 0, then there exists a constant C>0C>0 such that

|  |  |  |
| --- | --- | --- |
|  | |R1|=Opâ€‹(1nâ€‹(1nâ€‹âˆ‘i=1nâ€–Î”iâ€–4)1/2â€‹[1+â€–Î”â€–nn+1nâ€‹(1nâ€‹âˆ‘i=1nâ€–Î”iâ€–4)1/2]â€‹expâ¡(Câ€²â€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n)).|R\_{1}|=O\_{p}\!\left(\frac{1}{n}\Big(\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{4}\Big)^{\!1/2}\,\Big[1+\frac{\|\Delta\|\_{n}}{\sqrt{n}}+\frac{1}{n}\Big(\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{4}\Big)^{\!1/2}\Big]\,\exp\!\Big(C^{\prime}\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right). |  |

###### Assumption 7.

Suppose there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}^{\*}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{2â€‹sâ€‹(2âˆ’1),6,2â€‹p2âˆ’p},\frac{\gamma\_{0}^{2}}{\left\|\sigma^{-1}\right\|\_{F}^{2}}>T\max\left\{2s(2-1),6,2p^{2}-p\right\}, |  |

where s=1pâˆ’1s=\frac{1}{p-1} and p=Î²âˆ’1p=\beta-1 with Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}.

###### Lemma 4.

In the context of proof of Theorem [6](https://arxiv.org/html/2512.01408v1#Thmtheorem6 "Theorem 6. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), under Assumption [7](https://arxiv.org/html/2512.01408v1#Thmassumption7 "Assumption 7. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), when Î±<1\alpha<1 and Î±â‰ 0\alpha\neq 0, then there exists a constant C>0C>0 such that

|  |  |  |
| --- | --- | --- |
|  | |R2|=Opâ€‹(â€–Î”â€–n2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n))+Opâ€‹(â€–Î”â€–n2nâ‹…max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n)).|R\_{2}|=O\_{p}\left(\frac{\left\|\Delta\right\|\_{n}^{2}}{n}\exp\left(C\max\_{1\ \leq i\leq n}\frac{\left\|\Delta\_{i}\right\|^{2}}{n}\right)\right)+O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\cdot\frac{\max\_{1\leq i\leq n}\|\Delta\_{i}\|^{2}}{n}\;\exp\!\Big(C\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right). |  |

###### Proof.

Bounding R2R\_{2} is equivalent to bound these two terms:

|  |  |  |
| --- | --- | --- |
|  | |R2|â‰¤I1+I2,|R\_{2}|\leq I\_{1}+I\_{2}, |  |

where

|  |  |  |
| --- | --- | --- |
|  | I1=2â€‹âˆ«01(1âˆ’t)â€‹âˆ«|gâ€²â€²â€‹(mâ„™nâ€‹(y)+tâ€‹(A1â€‹(y)+A2â€‹(y)))|â€‹A1â€‹(y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€‹ğ‘‘tI\_{1}=2\int\_{0}^{1}(1-t)\int\left|g^{\prime\prime}(m\_{\mathbb{P}\_{n}}(y)+t(A\_{1}(y)+A\_{2}(y)))\right|A\_{1}(y)^{2}\varphi\_{T}(y)dydt |  |

and

|  |  |  |
| --- | --- | --- |
|  | I2=2â€‹âˆ«01(1âˆ’t)â€‹âˆ«|gâ€²â€²â€‹(mâ„™nâ€‹(y)+tâ€‹(A1â€‹(y)+A2â€‹(y)))|â€‹A2â€‹(y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€‹ğ‘‘t.I\_{2}=2\int\_{0}^{1}(1-t)\int\left|g^{\prime\prime}(m\_{\mathbb{P}\_{n}}(y)+t(A\_{1}(y)+A\_{2}(y)))\right|A\_{2}(y)^{2}\varphi\_{T}(y)dydt. |  |

Recall that Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha} and gâ€²â€²â€‹(x)=CÎ±â€‹xÎ²âˆ’1g^{\prime\prime}(x)=C\_{\alpha}\,x^{\beta-1} for a constant CÎ±C\_{\alpha}. Cauchyâ€“Schwarz inequality yields

|  |  |  |  |
| --- | --- | --- | --- |
|  | |A1â€‹(y)|\displaystyle|A\_{1}(y)| | â‰¤1nâ‹…1nâ€‹(âˆ‘i=1nâ€–âˆ‡bLTâ€‹(B(i),y)â€–22)1/2â€‹(âˆ‘i=1nâ€–Î”iâ€–22)1/2=â€–Î”â€–nâ€‰2nâ€‹(Î2Â¯â€‹(y))1/2,\displaystyle\leq\frac{1}{\sqrt{n}}\cdot\frac{1}{n}\Big(\sum\_{i=1}^{n}\|\nabla\_{b}L\_{T}(B^{(i)},y)\|\_{2}^{2}\Big)^{\!1/2}\!\Big(\sum\_{i=1}^{n}\|\Delta\_{i}\|\_{2}^{2}\Big)^{\!1/2}=\sqrt{\frac{\|\Delta\|\_{n}^{\,2}}{n}}\;\Big(\overline{\Xi^{2}}(y)\Big)^{\!1/2}, |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î2Â¯â€‹(y):=1nâ€‹âˆ‘i=1nâ€–âˆ‡bLTâ€‹(B(i),y)â€–22â‰¤C1â€‹(â€–yâ€–22â€‹L2Â¯â€‹(y)+T2â€‹A2â€‹L2Â¯â€‹(y)),\overline{\Xi^{2}}(y):=\frac{1}{n}\sum\_{i=1}^{n}\|\nabla\_{b}L\_{T}(B^{(i)},y)\|\_{2}^{2}\ \leq\ C\_{1}\Big(\|y\|\_{2}^{2}\,\overline{L^{2}}(y)\;+\;T^{2}\,\overline{A^{2}L^{2}}(y)\Big), |  |

where

|  |  |  |
| --- | --- | --- |
|  | L2Â¯â€‹(y):=1nâ€‹âˆ‘i=1nLTâ€‹(B(i),y)2,A2â€‹L2Â¯â€‹(y):=1nâ€‹âˆ‘i=1nâ€–aâ€‹(B(i))â€–22â€‹LTâ€‹(B(i),y)2,\overline{L^{2}}(y):=\frac{1}{n}\sum\_{i=1}^{n}L\_{T}(B^{(i)},y)^{2},\qquad\overline{A^{2}L^{2}}(y):=\frac{1}{n}\sum\_{i=1}^{n}\|a(B^{(i)})\|\_{2}^{2}\,L\_{T}(B^{(i)},y)^{2}, |  |

and therefore,

|  |  |  |
| --- | --- | --- |
|  | |A1â€‹(y)|2â‰¤â€–Î”â€–nâ€‰2nâ€‹C1â€‹(â€–yâ€–22â€‹L2Â¯â€‹(y)+T2â€‹A2â€‹L2Â¯â€‹(y)).|A\_{1}(y)|^{2}\;\leq\;\frac{\|\Delta\|\_{n}^{\,2}}{n}\;C\_{1}\Big(\|y\|\_{2}^{2}\,\overline{L^{2}}(y)\;+\;T^{2}\,\overline{A^{2}L^{2}}(y)\Big). |  |

Recall that hi:=Î”i/nh\_{i}:=\Delta\_{i}/\sqrt{n}. Define the shifted mixture

|  |  |  |
| --- | --- | --- |
|  | mâ„™n(h)â€‹(y):=1nâ€‹âˆ‘i=1nLTâ€‹(B(i)+hi,y).m\_{\mathbb{P}\_{n}}^{(h)}(y):=\frac{1}{n}\sum\_{i=1}^{n}L\_{T}(B^{(i)}+h\_{i},y). |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | xtâ€‹(y):=(1âˆ’t)â€‹mâ„™nâ€‹(y)+tâ€‹mâ„™n(h)â€‹(y)=mâ„™nâ€‹(y)+tâ€‹(A1â€‹(y)+A2â€‹(y)).x\_{t}(y):=(1-t)\,m\_{\mathbb{P}\_{n}}(y)+t\,m\_{\mathbb{P}\_{n}}^{(h)}(y)=m\_{\mathbb{P}\_{n}}(y)+t\big(A\_{1}(y)+A\_{2}(y)\big). |  |

Let p:=Î²âˆ’1=Î±1âˆ’Î±âˆ’1p:=\beta-1=\frac{\alpha}{1-\alpha}-1.
We write m:=mâ„™nâ€‹(y)>0m:=m\_{\mathbb{P}\_{n}}(y)>0 and m(h):=mâ„™n(h)â€‹(y)>0m^{(h)}:=m\_{\mathbb{P}\_{n}}^{(h)}(y)>0 to lighten notation, so
xt=(1âˆ’t)â€‹m+tâ€‹m(h)x\_{t}=(1-t)m+tm^{(h)}.

When p<0p<0 or pâ‰¥1p\geq 1,
the function fâ€‹(x)=xpf(x)=x^{p} on (0,âˆ)(0,\infty) is convex. Therefore

|  |  |  |
| --- | --- | --- |
|  | xtp=fâ€‹((1âˆ’t)â€‹m+tâ€‹m(h))â‰¤(1âˆ’t)â€‹fâ€‹(m)+tâ€‹fâ€‹(m(h))=(1âˆ’t)â€‹mp+tâ€‹(m(h))pâ‰¤mp+(m(h))p.x\_{t}^{p}=f\big((1-t)m+tm^{(h)}\big)\;\leq\;(1-t)f(m)+tf(m^{(h)})=(1-t)m^{p}+t(m^{(h)})^{p}\;\leq\;m^{p}+(m^{(h)})^{p}. |  |

When pâˆˆ(0,1)p\in(0,1), the map fâ€‹(x)=xpf(x)=x^{p} is increasing and concave. Since xtâ‰¤m+m(h)x\_{t}\leq m+m^{(h)} and ff is increasing, then

|  |  |  |
| --- | --- | --- |
|  | xtpâ‰¤(m+m(h))pâ‰¤mp+(m(h))p,x\_{t}^{p}\ \leq\ (m+m^{(h)})^{p}\ \leq\ m^{p}+(m^{(h)})^{p}, |  |

where the last step uses the subadditivity (a+b)pâ‰¤ap+bp(a+b)^{p}\leq a^{p}+b^{p} for a,bâ‰¥0a,b\geq 0 and 0<pâ‰¤10<p\leq 1.

Therefore,

|  |  |  |
| --- | --- | --- |
|  | |gâ€²â€²â€‹(xt)|=|CÎ±|â€‹xtpâ‰¤|CÎ±|â€‹(mÎ²âˆ’1+(m(h))Î²âˆ’1).|g^{\prime\prime}(x\_{t})|=|C\_{\alpha}|\,x\_{t}^{p}\leq|C\_{\alpha}|\big(m^{\beta-1}+(m^{(h)})^{\beta-1}\big). |  |

Hence

|  |  |  |  |
| --- | --- | --- | --- |
|  | I1\displaystyle I\_{1} | =2â€‹âˆ«01(1âˆ’t)â€‹âˆ«|gâ€²â€²â€‹(xt)|â€‹A12â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Cnâ€‹â€–Î”â€–nâ€‰2â€‹(J1+J2+J1(h)+J2(h)),\displaystyle=2\!\int\_{0}^{1}(1-t)\!\int|g^{\prime\prime}(x\_{t})|\,A\_{1}^{2}(y)\,\varphi\_{T}(y)dy\ \leq\ \frac{C}{n}\,\|\Delta\|\_{n}^{\,2}\,\Big(J\_{1}+J\_{2}+J\_{1}^{(h)}+J\_{2}^{(h)}\Big), |  |

where

|  |  |  |
| --- | --- | --- |
|  | J1:=âˆ«â€–yâ€–2â€‹mâ„™nÎ²âˆ’1â€‹L2Â¯â€‹Ï†T,J2:=âˆ«mâ„™nÎ²âˆ’1â€‹A2â€‹L2Â¯â€‹Ï†T,J\_{1}:=\int\|y\|^{2}m\_{\mathbb{P}\_{n}}^{\beta-1}\,\overline{L^{2}}\,\varphi\_{T},\qquad J\_{2}:=\int m\_{\mathbb{P}\_{n}}^{\beta-1}\,\overline{A^{2}L^{2}}\,\varphi\_{T}, |  |

|  |  |  |
| --- | --- | --- |
|  | J1(h):=âˆ«â€–yâ€–2â€‹(mâ„™n(h))Î²âˆ’1â€‹L2Â¯â€‹Ï†T,J2(h):=âˆ«(mâ„™n(h))Î²âˆ’1â€‹A2â€‹L2Â¯â€‹Ï†T.J\_{1}^{(h)}:=\int\|y\|^{2}(m\_{\mathbb{P}\_{n}}^{(h)})^{\beta-1}\,\overline{L^{2}}\,\varphi\_{T},\qquad J\_{2}^{(h)}:=\int(m\_{\mathbb{P}\_{n}}^{(h)})^{\beta-1}\,\overline{A^{2}L^{2}}\,\varphi\_{T}. |  |

We first focus on the case when p:=Î²âˆ’1<0p:=\beta-1<0, by the Jensen inequality,

|  |  |  |
| --- | --- | --- |
|  | mâ„™nâ€‹(y)=ğ”¼â„™nâ€‹[eâŸ¨aâ€‹(B),yâŸ©âˆ’T2â€‹â€–aâ€‹(B)â€–22]â‰¥expâ¡(âŸ¨ğ”¼â„™nâ€‹[aâ€‹(B)],yâŸ©âˆ’T2â€‹ğ”¼â„™nâ€‹[â€–aâ€‹(B)â€–22]).m\_{\mathbb{P}\_{n}}(y)\;=\;\mathbb{E}\_{\mathbb{P}\_{n}}\big[e^{\langle a(B),y\rangle-\frac{T}{2}\|a(B)\|\_{2}^{2}}\big]\;\geq\;\exp\!\Big(\langle\mathbb{E}\_{\mathbb{P}\_{n}}[a(B)],y\rangle-\tfrac{T}{2}\,\mathbb{E}\_{\mathbb{P}\_{n}}\left[\|a(B)\|\_{2}^{2}\right]\Big). |  |

Raising to the negative power p<0p<0 reverses the inequality, giving

|  |  |  |
| --- | --- | --- |
|  | mâ„™nâ€‹(y)pâ‰¤Caâ€‹expâ¡(pâ€‹âŸ¨v,yâŸ©),Ca:=expâ¡(âˆ’pâ€‹T2â€‹ğ”¼â„™nâ€‹[â€–aâ€‹(B)â€–22]),v:=ğ”¼â„™nâ€‹[aâ€‹(B)].m\_{\mathbb{P}\_{n}}(y)^{p}\;\leq\;C\_{a}\,\exp\!\big(p\,\langle v,y\rangle\big),\qquad C\_{a}:=\exp\!\Big(-\tfrac{pT}{2}\,\mathbb{E}\_{\mathbb{P}\_{n}}\left[\|a(B)\|\_{2}^{2}\right]\Big),\ \ v:=\mathbb{E}\_{\mathbb{P}\_{n}}[a(B)]. |  |

We denote ci:=Ïƒâˆ’1â€‹hic\_{i}:=\sigma^{-1}h\_{i}, then

|  |  |  |
| --- | --- | --- |
|  | mâ„™n(h)â€‹(y)=1nâ€‹âˆ‘i=1nLTâ€‹(B(i)+hi,y)=1nâ€‹âˆ‘i=1nexpâ¡(âŸ¨aâ€‹(B(i))+ci,yâŸ©âˆ’T2â€‹â€–aâ€‹(B(i))+ciâ€–22).m\_{\mathbb{P}\_{n}}^{(h)}(y)=\frac{1}{n}\sum\_{i=1}^{n}L\_{T}(B^{(i)}+h\_{i},y)=\frac{1}{n}\sum\_{i=1}^{n}\exp\!\Big(\,\big\langle a(B^{(i)})+c\_{i},\,y\big\rangle-\tfrac{T}{2}\|a(B^{(i)})+c\_{i}\|\_{2}^{2}\Big). |  |

Introduce the notations

|  |  |  |
| --- | --- | --- |
|  | vh:=1nâ€‹âˆ‘i=1n(aâ€‹(B(i))+ci),s2,h:=1nâ€‹âˆ‘i=1nâ€–aâ€‹(B(i))+ciâ€–22,Hn:=max1â‰¤iâ‰¤nâ¡â€–ciâ€–2.v\_{h}:=\frac{1}{n}\sum\_{i=1}^{n}\big(a(B^{(i)})+c\_{i}\big),\qquad s\_{2,h}:=\frac{1}{n}\sum\_{i=1}^{n}\|a(B^{(i)})+c\_{i}\|\_{2}^{2},\qquad H\_{n}:=\max\_{1\leq i\leq n}\|c\_{i}\|\_{2}. |  |

By Jensenâ€™s inequality,

|  |  |  |
| --- | --- | --- |
|  | mâ„™n(h)â€‹(y)â‰¥expâ¡(âŸ¨vh,yâŸ©âˆ’T2â€‹s2,h).m\_{\mathbb{P}\_{n}}^{(h)}(y)\ \geq\ \exp\!\Big(\,\langle v\_{h},y\rangle-\tfrac{T}{2}\,s\_{2,h}\Big). |  |

Since p<0p<0, raising both sides to the power pp reverses the inequality:

|  |  |  |
| --- | --- | --- |
|  | (mâ„™n(h)â€‹(y))pâ‰¤expâ¡(pâ€‹âŸ¨vh,yâŸ©âˆ’pâ€‹T2â€‹s2,h).\big(m\_{\mathbb{P}\_{n}}^{(h)}(y)\big)^{p}\ \leq\ \exp\!\Big(\,p\,\langle v\_{h},y\rangle-\tfrac{pT}{2}\,s\_{2,h}\Big). |  |

Set

|  |  |  |
| --- | --- | --- |
|  | s2:=ğ”¼â„™nâ€‹[â€–aâ€‹(B)â€–22],Ca:=expâ¡(âˆ’pâ€‹T2â€‹s2).s\_{2}:=\mathbb{E}\_{\mathbb{P}\_{n}}\!\big[\|a(B)\|\_{2}^{2}\big],\qquad C\_{a}:=\exp\!\Big(-\tfrac{pT}{2}\,s\_{2}\Big). |  |

Hence

|  |  |  |
| --- | --- | --- |
|  | J1â‰¤Canâ€‹âˆ‘i=1nâˆ«â€–yâ€–22â€‹epâ€‹âŸ¨v,yâŸ©â€‹LTâ€‹(B(i),y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.J\_{1}\ \leq\ \frac{C\_{a}}{n}\sum\_{i=1}^{n}\int\|y\|\_{2}^{2}\,e^{\,p\langle v,y\rangle}\,L\_{T}(B^{(i)},y)^{2}\,\varphi\_{T}(y)\,dy. |  |

Write ai:=aâ€‹(B(i))a\_{i}:=a(B^{(i)}) and note LTâ€‹(B(i),y)2=expâ¡(2â€‹âŸ¨ai,yâŸ©âˆ’Tâ€‹â€–aiâ€–22)L\_{T}(B^{(i)},y)^{2}=\exp(2\langle a\_{i},y\rangle-T\|a\_{i}\|\_{2}^{2}).
Let Yâˆ¼Nâ€‹(0,Tâ€‹Id)Y\sim N(0,TI\_{d}) so Ï†T\varphi\_{T} is its density. Then, with

|  |  |  |
| --- | --- | --- |
|  | Î»i:=2â€‹ai+pâ€‹vâˆˆâ„d,\lambda\_{i}:=2a\_{i}+p\,v\in\mathbb{R}^{d}, |  |

|  |  |  |
| --- | --- | --- |
|  | âˆ«â€–yâ€–22â€‹epâ€‹âŸ¨v,yâŸ©â€‹LTâ€‹(B(i),y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=eâˆ’Tâ€‹â€–aiâ€–22â€‹(Tâ€‹d+T2â€‹â€–Î»iâ€–22)â€‹eT2â€‹â€–Î»iâ€–22.\int\|y\|\_{2}^{2}\,e^{\,p\langle v,y\rangle}\,L\_{T}(B^{(i)},y)^{2}\,\varphi\_{T}(y)\,dy=e^{-T\|a\_{i}\|\_{2}^{2}}\,(Td+T^{2}\|\lambda\_{i}\|\_{2}^{2})\,e^{\frac{T}{2}\|\lambda\_{i}\|\_{2}^{2}}. |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | J1â‰¤Canâ€‹âˆ‘i=1n(Tâ€‹d+T2â€‹â€–Î»iâ€–22)â€‹expâ¡(T2â€‹â€–Î»iâ€–22âˆ’Tâ€‹â€–aiâ€–22).J\_{1}\ \leq\ \frac{C\_{a}}{n}\sum\_{i=1}^{n}\Big(Td+T^{2}\|\lambda\_{i}\|\_{2}^{2}\Big)\,\exp\!\Big(\tfrac{T}{2}\|\lambda\_{i}\|\_{2}^{2}-T\|a\_{i}\|\_{2}^{2}\Big). |  |

By the inequality (â€–u+zâ€–22â‰¤2â€‹â€–uâ€–22+2â€‹â€–zâ€–22)(\|u+z\|\_{2}^{2}\leq 2\|u\|\_{2}^{2}+2\|z\|\_{2}^{2}) with u=2â€‹aiu=2a\_{i}, z=pâ€‹vz=pv:

|  |  |  |
| --- | --- | --- |
|  | â€–Î»iâ€–22=â€–2â€‹ai+pâ€‹vâ€–22â‰¤ 8â€‹â€–aiâ€–22+2â€‹p2â€‹â€–vâ€–22,\|\lambda\_{i}\|\_{2}^{2}=\|2a\_{i}+pv\|\_{2}^{2}\ \leq\ 8\|a\_{i}\|\_{2}^{2}+2p^{2}\|v\|\_{2}^{2}, |  |

hence

|  |  |  |
| --- | --- | --- |
|  | T2â€‹â€–Î»iâ€–22âˆ’Tâ€‹â€–aiâ€–22â‰¤ 3â€‹Tâ€‹â€–aiâ€–22+Tâ€‹p2â€‹â€–vâ€–22.\frac{T}{2}\|\lambda\_{i}\|\_{2}^{2}-T\|a\_{i}\|\_{2}^{2}\ \leq\ 3T\|a\_{i}\|\_{2}^{2}+Tp^{2}\|v\|\_{2}^{2}. |  |

Also â€–Î»iâ€–22â‰¤8â€‹â€–aiâ€–22+2â€‹p2â€‹â€–vâ€–22\|\lambda\_{i}\|\_{2}^{2}\leq 8\|a\_{i}\|\_{2}^{2}+2p^{2}\|v\|\_{2}^{2} implies
Tâ€‹d+T2â€‹â€–Î»iâ€–22â‰¤Câ€‹(1+â€–aiâ€–22+â€–vâ€–22)Td+T^{2}\|\lambda\_{i}\|\_{2}^{2}\leq C\big(1+\|a\_{i}\|\_{2}^{2}+\|v\|\_{2}^{2}\big)
for a constant C=Câ€‹(T,p,d)C=C(T,p,d).
Therefore

|  |  |  |  |
| --- | --- | --- | --- |
|  | J1\displaystyle J\_{1}\ | â‰¤Câ€‹Caâ€‹eTâ€‹p2â€‹â€–vâ€–22â€‹1nâ€‹âˆ‘i=1n(1+â€–aiâ€–22+â€–vâ€–22)â€‹e3â€‹Tâ€‹â€–aiâ€–22.\displaystyle\leq\ C\,C\_{a}\,e^{Tp^{2}\|v\|\_{2}^{2}}\,\frac{1}{n}\sum\_{i=1}^{n}\big(1+\|a\_{i}\|\_{2}^{2}+\|v\|\_{2}^{2}\big)\,e^{3T\|a\_{i}\|\_{2}^{2}}. |  |

Set

|  |  |  |
| --- | --- | --- |
|  | An:=1nâ€‹âˆ‘i=1ne3â€‹Tâ€‹â€–aiâ€–22,Bn:=1nâ€‹âˆ‘i=1nâ€–aiâ€–22â€‹e3â€‹Tâ€‹â€–aiâ€–22.A\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}e^{3T\|a\_{i}\|\_{2}^{2}},\qquad B\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}\|a\_{i}\|\_{2}^{2}\,e^{3T\|a\_{i}\|\_{2}^{2}}. |  |

Then

|  |  |  |
| --- | --- | --- |
|  | J1â‰¤Câ€‹Caâ€‹eTâ€‹p2â€‹â€–vâ€–22â€‹[(1+â€–vâ€–22)â€‹An+Bn].J\_{1}\ \leq\ C\,C\_{a}\,e^{Tp^{2}\|v\|\_{2}^{2}}\,\Big[(1+\|v\|\_{2}^{2})\,A\_{n}+B\_{n}\Big]. |  |

Since aâ€‹(B)=Ïƒâˆ’1â€‹Bâˆ’ma(B)=\sigma^{-1}B-m, we have
â€–aâ€‹(B)â€–22â‰¤2â€‹â€–Ïƒâˆ’1â€‹Bâ€–22+2â€‹â€–mâ€–22\|a(B)\|\_{2}^{2}\leq 2\|\sigma^{-1}B\|\_{2}^{2}+2\|m\|\_{2}^{2},
and thus

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[e3â€‹Tâ€‹â€–aâ€‹(B)â€–22]â‰¤e6â€‹Tâ€‹â€–mâ€–22â€‹ğ”¼â€‹[e6â€‹Tâ€‹â€–Ïƒâˆ’1â€‹Bâ€–22]â‰¤e6â€‹Tâ€‹â€–mâ€–22â€‹ğ”¼â€‹[e6â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2â€‹â€–Bâ€–22].\mathbb{E}\big[e^{3T\|a(B)\|\_{2}^{2}}\big]\ \leq\ e^{6T\|m\|\_{2}^{2}}\,\mathbb{E}\big[e^{6T\|\sigma^{-1}B\|\_{2}^{2}}\big]\ \leq\ e^{6T\|m\|\_{2}^{2}}\,\mathbb{E}\big[e^{6T\|\sigma^{-1}\|\_{F}^{2}\|B\|\_{2}^{2}}\big]. |  |

Hence ğ”¼â€‹[e3â€‹Tâ€‹â€–aâ€‹(B)â€–22]<âˆ\,\mathbb{E}[e^{3T\|a(B)\|\_{2}^{2}}]<\infty\, if the sub Gaussian parameter satisfies Î³02â€–Ïƒâˆ’1â€–F2>â€„6â€‹T.\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\;>\;6T. The same argument with a polynomial prefactor yields
ğ”¼â€‹[â€–aâ€‹(B)â€–22â€‹e3â€‹Tâ€‹â€–aâ€‹(B)â€–22]<âˆ\mathbb{E}[\|a(B)\|\_{2}^{2}e^{3T\|a(B)\|\_{2}^{2}}]<\infty.
By the law of large numbers, An=Opâ€‹(1)A\_{n}=O\_{p}(1) and Bn=Opâ€‹(1)B\_{n}=O\_{p}(1). Also, by Jensen inequality,
â€–vâ€–22=â€–1nâ€‹âˆ‘aiâ€–22â‰¤1nâ€‹âˆ‘â€–aiâ€–22\|v\|\_{2}^{2}=\big\|\tfrac{1}{n}\sum a\_{i}\big\|\_{2}^{2}\leq\tfrac{1}{n}\sum\|a\_{i}\|\_{2}^{2},
so â€–vâ€–22=Opâ€‹(1)\|v\|\_{2}^{2}=O\_{p}(1) and therefore Caâ€‹eTâ€‹p2â€‹â€–vâ€–22=Opâ€‹(1)C\_{a}e^{Tp^{2}\|v\|\_{2}^{2}}=O\_{p}(1).
Thus J1=Opâ€‹(1)J\_{1}=O\_{p}(1). The bound of J2=Opâ€‹(1)J\_{2}=O\_{p}(1) is almost verbatim since there is no additional term on the exponential.

Similarly, it suffices to upper bound J1(h)J\_{1}^{(h)}.
We introduce new analogous notation

|  |  |  |
| --- | --- | --- |
|  | Ca(h):=expâ¡(âˆ’pâ€‹T2â€‹s2,h).C\_{a}^{(h)}:=\exp\!\Big(-\tfrac{pT}{2}\,s\_{2,h}\Big). |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | J1(h)â‰¤Ca(h)nâ€‹âˆ‘i=1nâˆ«â€–yâ€–22â€‹epâ€‹âŸ¨vh,yâŸ©â€‹LTâ€‹(B(i),y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.J\_{1}^{(h)}\ \leq\ \frac{C\_{a}^{(h)}}{n}\sum\_{i=1}^{n}\int\|y\|\_{2}^{2}\,e^{\,p\langle v\_{h},y\rangle}\,L\_{T}(B^{(i)},y)^{2}\,\varphi\_{T}(y)\,dy. |  |

An analogous computation of the case of J1J\_{1} shows that

|  |  |  |
| --- | --- | --- |
|  | J1(h)â‰¤Câ€‹Ca(h)â€‹eTâ€‹p2â€‹â€–vhâ€–22â€‹1nâ€‹âˆ‘i=1n(1+â€–aiâ€–22+â€–vhâ€–22)â€‹e3â€‹Tâ€‹â€–aiâ€–22.J\_{1}^{(h)}\ \leq\ C\,C\_{a}^{(h)}\,e^{Tp^{2}\|v\_{h}\|\_{2}^{2}}\,\frac{1}{n}\sum\_{i=1}^{n}\big(1+\|a\_{i}\|\_{2}^{2}+\|v\_{h}\|\_{2}^{2}\big)\,e^{3T\|a\_{i}\|\_{2}^{2}}. |  |

Set

|  |  |  |
| --- | --- | --- |
|  | An:=1nâ€‹âˆ‘i=1ne3â€‹Tâ€‹â€–aiâ€–22,Bn:=1nâ€‹âˆ‘i=1nâ€–aiâ€–22â€‹e3â€‹Tâ€‹â€–aiâ€–22.A\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}e^{3T\|a\_{i}\|\_{2}^{2}},\qquad B\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}\|a\_{i}\|\_{2}^{2}\,e^{3T\|a\_{i}\|\_{2}^{2}}. |  |

Then

|  |  |  |
| --- | --- | --- |
|  | J1(h)â‰¤Câ€‹Ca(h)â€‹eTâ€‹p2â€‹â€–vhâ€–22â€‹[(1+â€–vhâ€–22)â€‹An+Bn].J\_{1}^{(h)}\ \leq\ C\,C\_{a}^{(h)}\,e^{Tp^{2}\|v\_{h}\|\_{2}^{2}}\,\Big[(1+\|v\_{h}\|\_{2}^{2})\,A\_{n}+B\_{n}\Big]. |  |

Note
â€–vhâ€–2â‰¤â€–vâ€–2+cÂ¯,cÂ¯:=1nâ€‹âˆ‘iâ€–ciâ€–2â‰¤Hn,\|v\_{h}\|\_{2}\leq\|v\|\_{2}+\bar{c},\ \bar{c}:=\tfrac{1}{n}\sum\_{i}\|c\_{i}\|\_{2}\leq H\_{n},
so â€–vhâ€–22â‰¤2â€‹â€–vâ€–22+2â€‹Hn2\|v\_{h}\|\_{2}^{2}\leq 2\|v\|\_{2}^{2}+2H\_{n}^{2}. Also
s2,hâ‰¤2â€‹s2+2â€‹Hn2,s2:=1nâ€‹âˆ‘iâ€–aiâ€–22,s\_{2,h}\leq 2\,s\_{2}+2\,H\_{n}^{2},\ \ s\_{2}:=\tfrac{1}{n}\sum\_{i}\|a\_{i}\|\_{2}^{2},
hence

|  |  |  |
| --- | --- | --- |
|  | Ca(h)â€‹eTâ€‹p2â€‹â€–vhâ€–22â‰¤eCâ€‹Hn2â€‹expâ¡(âˆ’pâ€‹T2â€‹s2)âŸ=â£:Caâ€‹expâ¡(Tâ€‹p2â€‹â€–vâ€–22).C\_{a}^{(h)}\,e^{Tp^{2}\|v\_{h}\|\_{2}^{2}}\ \leq\ e^{C\,H\_{n}^{2}}\,\underbrace{\exp\!\Big(-\tfrac{pT}{2}\,s\_{2}\Big)}\_{=:C\_{a}}\,\exp\!\big(Tp^{2}\|v\|\_{2}^{2}\big). |  |

Under the same sub-Gaussian condition as for J1J\_{1},

|  |  |  |
| --- | --- | --- |
|  | An=Opâ€‹(1),Bn=Opâ€‹(1),â€–vâ€–2=Opâ€‹(1),A\_{n}=O\_{p}(1),\quad B\_{n}=O\_{p}(1),\quad\|v\|\_{2}=O\_{p}(1), |  |

so for a constant C>0C>0,

|  |  |  |
| --- | --- | --- |
|  | J1(h)=Opâ€‹(eCâ€‹Hn2)=Opâ€‹(expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”â€–2n)).\ J\_{1}^{(h)}\ =\ O\_{p}\!\big(e^{CH\_{n}^{2}}\big)=O\_{p}\left(\exp\left(C\max\_{1\leq i\leq n}\frac{\left\|\Delta\right\|^{2}}{n}\right)\right). |  |

Therefore, when p<0p<0,

|  |  |  |
| --- | --- | --- |
|  | I1=Opâ€‹(â€–Î”â€–n2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”â€–2n)).I\_{1}=O\_{p}\left(\frac{\left\|\Delta\right\|^{2}\_{n}}{n}\exp\left(C\max\_{1\leq i\leq n}\frac{\left\|\Delta\right\|^{2}}{n}\right)\right). |  |

Next we bound I1I\_{1} in the case when pâ‰¥0p\geq 0. It suffices to consider J1J\_{1} and J1(h)J\_{1}^{(h)} here again.
First we assume pâˆˆ(0,1)p\in(0,1), then
by HÃ¶lder ineqaulity with exponents r=1pr=\frac{1}{p}, s=11âˆ’ps=\frac{1}{1-p},

|  |  |  |
| --- | --- | --- |
|  | J1=âˆ«â€–yâ€–2â€‹mâ„™nâ€‹(y)pâ€‹L2Â¯â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤(âˆ«mâ„™nâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)pâ€‹(âˆ«â€–yâ€–2â€‹sâ€‹L2Â¯â€‹(y)sâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/s.J\_{1}=\int\|y\|^{2}\,m\_{\mathbb{P}\_{n}}(y)^{p}\,\overline{L^{2}}(y)\,\varphi\_{T}(y)\,dy\ \leq\ \Big(\int m\_{\mathbb{P}\_{n}}(y)\,\varphi\_{T}(y)\,dy\Big)^{\!p}\Big(\int\|y\|^{2s}\,\overline{L^{2}}(y)^{\,s}\,\varphi\_{T}(y)\,dy\Big)^{\!1/s}. |  |

Since âˆ«LTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=1\int L\_{T}(b,y)\varphi\_{T}(y)dy=1 for all bb, Fubini gives âˆ«mâ„™nâ€‹Ï†T=1\int m\_{\mathbb{P}\_{n}}\varphi\_{T}=1,
so the first factor is 11. For the second term, by convexity of xâ†¦xsx\mapsto x^{s} (s>1s>1),

|  |  |  |  |
| --- | --- | --- | --- |
|  | J1\displaystyle J\_{1}\ | â‰¤(1nâ€‹âˆ‘i=1nâˆ«â€–yâ€–2â€‹sâ€‹LTâ€‹(B(i),y)2â€‹sâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/s\displaystyle\leq\ \Big(\tfrac{1}{n}\sum\_{i=1}^{n}\int\|y\|^{2s}L\_{T}(B^{(i)},y)^{2s}\varphi\_{T}(y)dy\Big)^{\!1/s} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Câ€‹(1nâ€‹âˆ‘i=1n(1+â€–aiâ€–2â€‹s)â€‹eTâ€‹sâ€‹(2â€‹sâˆ’1)â€‹â€–aiâ€–2)1/s.\displaystyle\leq\ C\,\Big(\tfrac{1}{n}\sum\_{i=1}^{n}\big(1+\|a\_{i}\|^{2s}\big)\,e^{\,Ts(2s-1)\,\|a\_{i}\|^{2}}\Big)^{\!1/s}. |  |

Therefore a sufficient sub-Gaussian condition ensuring J1=Opâ€‹(1)J\_{1}=O\_{p}(1) is

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>2â€‹Tâ€‹sâ€‹(2â€‹sâˆ’1).\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}>2\,T\,s(2s-1). |  |

Similarly,

|  |  |  |
| --- | --- | --- |
|  | J1(h)=âˆ«â€–yâ€–2â€‹(mâ„™n(h)â€‹(y))pâ€‹L2Â¯â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤(âˆ«mâ„™n(h)â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)pâ€‹(âˆ«â€–yâ€–2â€‹sâ€‹L2Â¯â€‹(y)sâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/s.J\_{1}^{(h)}=\int\|y\|^{2}\,(m\_{\mathbb{P}\_{n}}^{(h)}(y))^{p}\,\overline{L^{2}}(y)\,\varphi\_{T}(y)\,dy\ \leq\ \Big(\int m\_{\mathbb{P}\_{n}}^{(h)}(y)\,\varphi\_{T}(y)\,dy\Big)^{\!p}\Big(\int\|y\|^{2s}\,\overline{L^{2}}(y)^{\,s}\,\varphi\_{T}(y)\,dy\Big)^{\!1/s}. |  |

Since âˆ«LTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=1\int L\_{T}(b,y)\varphi\_{T}(y)dy=1 for every bb, we have

|  |  |  |
| --- | --- | --- |
|  | âˆ«mâ„™n(h)â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=1nâ€‹âˆ‘j=1nâˆ«LTâ€‹(B(j)+hj,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=1,\int m\_{\mathbb{P}\_{n}}^{(h)}(y)\,\varphi\_{T}(y)\,dy=\frac{1}{n}\sum\_{j=1}^{n}\int L\_{T}(B^{(j)}+h\_{j},y)\varphi\_{T}(y)\,dy=1, |  |

so with the same sub Gaussian assumption J1(h)=Opâ€‹(1)J\_{1}^{(h)}=O\_{p}(1). when pâˆˆ(0,1)p\in(0,1),

|  |  |  |
| --- | --- | --- |
|  | I1=Opâ€‹(â€–Î”â€–n2n).I\_{1}=O\_{p}\left(\frac{\left\|\Delta\right\|^{2}\_{n}}{n}\right). |  |

When pâ‰¥1p\geq 1, then Jensen inequality gives mâ„™nâ€‹(y)pâ‰¤ğ”¼â„™nâ€‹[LTâ€‹(B,y)p]m\_{\mathbb{P}\_{n}}(y)^{p}\leq\mathbb{E}\_{\mathbb{P}\_{n}}[L\_{T}(B,y)^{p}]. Thus

|  |  |  |
| --- | --- | --- |
|  | J1â‰¤1nâ€‹âˆ‘i=1nğ”¼â„™nâ€‹[âˆ«â€–yâ€–2â€‹LTâ€‹(B,y)pâ€‹LTâ€‹(B(i),y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y].J\_{1}\ \leq\ \frac{1}{n}\sum\_{i=1}^{n}\mathbb{E}\_{\mathbb{P}\_{n}}\!\left[\int\|y\|^{2}\,L\_{T}(B,y)^{p}\,L\_{T}(B^{(i)},y)^{2}\,\varphi\_{T}(y)\,dy\right]. |  |

For fixed (B,B(i))(B,B^{(i)}), write Î»:=pâ€‹aâ€‹(B)+2â€‹ai\lambda:=p\,a(B)+2\,a\_{i}.
Completing the square (as in the J1J\_{1} computation) yields

|  |  |  |
| --- | --- | --- |
|  | âˆ«â€–yâ€–2â€‹LTâ€‹(B,y)pâ€‹LTâ€‹(B(i),y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=(Tâ€‹d+T2â€‹â€–Î»â€–2)â€‹expâ¡{T2â€‹â€–Î»â€–2âˆ’T2â€‹pâ€‹â€–aâ€‹(B)â€–2âˆ’Tâ€‹â€–aiâ€–2}.\int\|y\|^{2}\,L\_{T}(B,y)^{p}L\_{T}(B^{(i)},y)^{2}\varphi\_{T}(y)dy=(Td+T^{2}\|\lambda\|^{2})\,\exp\!\Big\{\tfrac{T}{2}\|\lambda\|^{2}-\tfrac{T}{2}p\|a(B)\|^{2}-T\|a\_{i}\|^{2}\Big\}. |  |

Using â€–Î»â€–2â‰¤2â€‹p2â€‹â€–aâ€‹(B)â€–2+8â€‹â€–aiâ€–2\|\lambda\|^{2}\leq 2p^{2}\|a(B)\|^{2}+8\|a\_{i}\|^{2},

|  |  |  |
| --- | --- | --- |
|  | T2â€‹â€–Î»â€–2âˆ’T2â€‹pâ€‹â€–aâ€‹(B)â€–2âˆ’Tâ€‹â€–aiâ€–2â‰¤T2â€‹(2â€‹p2âˆ’p)â€‹â€–aâ€‹(B)â€–2+ 3â€‹Tâ€‹â€–aiâ€–2.\frac{T}{2}\|\lambda\|^{2}-\tfrac{T}{2}p\|a(B)\|^{2}-T\|a\_{i}\|^{2}\ \leq\ \tfrac{T}{2}\,(2p^{2}-p)\,\|a(B)\|^{2}\ +\ 3T\,\|a\_{i}\|^{2}. |  |

Taking expectation in BB,

|  |  |  |
| --- | --- | --- |
|  | J1â‰¤Câ€‹1nâ€‹âˆ‘i=1n(1+â€–aiâ€–2)â€‹e3â€‹Tâ€‹â€–aiâ€–2â€‹ğ”¼â„™nâ€‹[eT2â€‹(2â€‹p2âˆ’p)â€‹â€–aâ€‹(B)â€–2].J\_{1}\ \leq\ C\,\frac{1}{n}\sum\_{i=1}^{n}\big(1+\|a\_{i}\|^{2}\big)\,e^{3T\|a\_{i}\|^{2}}\;\mathbb{E}\_{\mathbb{P}\_{n}}\!\left[e^{\frac{T}{2}(2p^{2}-p)\,\|a(B)\|^{2}}\right]. |  |

Hence a sufficient sub-Gaussian condition (thus J1=Opâ€‹(1)J\_{1}=O\_{p}(1)) is

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{(2â€‹p2âˆ’p),6}.\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}>T\max\left\{\,(2p^{2}-p),6\right\}. |  |

A similar computation gives

|  |  |  |
| --- | --- | --- |
|  | J1(h)â‰¤Câ€‹eCâ€‹pâ€‹Hn2â€‹(1nâ€‹âˆ‘i=1n(1+â€–aiâ€–2)â€‹e3â€‹Tâ€‹â€–aiâ€–2)â€‹(1nâ€‹âˆ‘j=1ne[Tâ€‹(2â€‹p2âˆ’p)+Îµ]â€‹â€–ajâ€–2),\quad J\_{1}^{(h)}\ \leq\ C\,e^{Cp\,H\_{n}^{2}}\,\Big(\frac{1}{n}\sum\_{i=1}^{n}(1+\|a\_{i}\|^{2})\,e^{3T\|a\_{i}\|^{2}}\Big)\,\Big(\frac{1}{n}\sum\_{j=1}^{n}e^{\,[\,T(2p^{2}-p)+\varepsilon\,]\|a\_{j}\|^{2}}\Big),\quad |  |

where the bound is finite under
the same sub Gaussian assumption

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>maxâ¡{6â€‹T,Tâ€‹(2â€‹p2âˆ’p)}.\ \frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\ >\ \max\!\big\{6T,\;T(2p^{2}-p)\big\}. |  |

Therefore, when pâ‰¥1p\geq 1,

|  |  |  |
| --- | --- | --- |
|  | I1=Opâ€‹(â€–Î”â€–n2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”â€–2n)).I\_{1}=O\_{p}\left(\frac{\left\|\Delta\right\|^{2}\_{n}}{n}\exp\left(C\max\_{1\leq i\leq n}\frac{\left\|\Delta\right\|^{2}}{n}\right)\right). |  |

Next, we focus on the bound of I2I\_{2} and begin with a bound for A2â€‹(y)2A\_{2}(y)^{2}.
To begin with, direct computations show that there exists a constant CF=CFâ€‹(d,T,â€–Ïƒâˆ’1â€–F)>0C\_{F}=C\_{F}(d,T,\|\sigma^{-1}\|\_{F})>0 such that

|  |  |  |
| --- | --- | --- |
|  | â€–âˆ‡b2LTâ€‹(b,y)â€–Fâ‰¤CFâ€‹LTâ€‹(b,y)â€‹(1+â€–yâ€–22+T2â€‹â€–aâ€‹(b)â€–22).\big\|\nabla\_{b}^{2}L\_{T}(b,y)\big\|\_{F}\;\leq\;C\_{F}\,L\_{T}(b,y)\,\Big(1+\|y\|\_{2}^{2}+T^{2}\|a(b)\|\_{2}^{2}\Big). |  |

Recall that ci:=Ïƒâˆ’1â€‹hic\_{i}:=\sigma^{-1}h\_{i} and fix any Î·y>0\eta\_{y}>0, Î·a>0\eta\_{a}>0. Then

|  |  |  |
| --- | --- | --- |
|  | LTâ€‹(B(i)+tâ€‹hi,y)=LTâ€‹(B(i),y)â€‹expâ¡{tâ€‹âŸ¨ci,yâŸ©âˆ’Tâ€‹tâ€‹âŸ¨ai,ciâŸ©âˆ’T2â€‹t2â€‹â€–ciâ€–22}.L\_{T}(B^{(i)}+th\_{i},y)=L\_{T}(B^{(i)},y)\,\exp\!\Big\{t\langle c\_{i},y\rangle-Tt\langle a\_{i},c\_{i}\rangle-\tfrac{T}{2}t^{2}\|c\_{i}\|\_{2}^{2}\Big\}. |  |

By the Young inequalities,

|  |  |  |
| --- | --- | --- |
|  | tâ€‹âŸ¨ci,yâŸ©â‰¤â€–yâ€–224â€‹Î·y+Î·yâ€‹t2â€‹â€–ciâ€–22,âˆ’Tâ€‹tâ€‹âŸ¨ai,ciâŸ©â‰¤T2â€‹t24â€‹Î·aâ€‹â€–aiâ€–22+Î·aâ€‹â€–ciâ€–22.t\langle c\_{i},y\rangle\leq\frac{\|y\|\_{2}^{2}}{4\eta\_{y}}+\eta\_{y}t^{2}\|c\_{i}\|\_{2}^{2},\qquad-\,Tt\langle a\_{i},c\_{i}\rangle\leq\frac{T^{2}t^{2}}{4\eta\_{a}}\|a\_{i}\|\_{2}^{2}+\eta\_{a}\|c\_{i}\|\_{2}^{2}. |  |

Since tâˆˆ[0,1]t\in[0,1], the t2t^{2}â€™s are â‰¤1\leq 1, and the negative âˆ’T2â€‹t2â€‹â€–ciâ€–2-\tfrac{T}{2}t^{2}\|c\_{i}\|^{2} can be dropped. Thus,
for a constant C=Câ€‹(T,Î·y,Î·a)C=C(T,\eta\_{y},\eta\_{a}),

|  |  |  |
| --- | --- | --- |
|  | LTâ€‹(B(i)+tâ€‹hi,y)â‰¤expâ¡{â€–yâ€–224â€‹Î·y}â€‹expâ¡{Câ€‹â€–ciâ€–22}â€‹expâ¡{T24â€‹Î·aâ€‹â€–aiâ€–22}â€‹LTâ€‹(B(i),y).L\_{T}(B^{(i)}+th\_{i},y)\ \leq\ \exp\!\Big\{\tfrac{\|y\|\_{2}^{2}}{4\eta\_{y}}\Big\}\,\exp\!\Big\{C\,\|c\_{i}\|\_{2}^{2}\Big\}\,\exp\!\Big\{\tfrac{T^{2}}{4\eta\_{a}}\,\|a\_{i}\|\_{2}^{2}\Big\}\,L\_{T}(B^{(i)},y). |  |

Also â€–aâ€‹(B(i)+tâ€‹hi)â€–2â‰¤â€–aiâ€–2+â€–ciâ€–2\|a(B^{(i)}+th\_{i})\|\_{2}\leq\|a\_{i}\|\_{2}+\|c\_{i}\|\_{2}, hence

|  |  |  |
| --- | --- | --- |
|  | â€–aâ€‹(B(i)+tâ€‹hi)â€–22â‰¤2â€‹â€–aiâ€–22+2â€‹â€–ciâ€–22.\|a(B^{(i)}+th\_{i})\|\_{2}^{2}\leq 2\|a\_{i}\|\_{2}^{2}+2\|c\_{i}\|\_{2}^{2}. |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | |A2â€‹(y)|=1nâ€‹âˆ‘i=1nâˆ«01(1âˆ’t)â€‹|hiâŠ¤â€‹âˆ‡b2LTâ€‹(B(i)+tâ€‹hi,y)â€‹hi|â€‹ğ‘‘tâ‰¤1nâ€‹âˆ‘i=1nâ€–hiâ€–22â€‹âˆ«01â€–âˆ‡b2LTâ€‹(B(i)+tâ€‹hi,y)â€–Fâ€‹ğ‘‘t.|A\_{2}(y)|=\frac{1}{n}\sum\_{i=1}^{n}\int\_{0}^{1}(1-t)\,\big|h\_{i}^{\top}\nabla\_{b}^{2}L\_{T}(B^{(i)}+th\_{i},y)\,h\_{i}\big|\,dt\leq\frac{1}{n}\sum\_{i=1}^{n}\|h\_{i}\|\_{2}^{2}\int\_{0}^{1}\big\|\nabla\_{b}^{2}L\_{T}(B^{(i)}+th\_{i},y)\big\|\_{F}\,dt. |  |

Recall that Hn:=maxiâ¡â€–ciâ€–2H\_{n}:=\max\_{i}\|c\_{i}\|\_{2} and
LÂ¯â€‹(y):=1nâ€‹âˆ‘iLTâ€‹(B(i),y)\overline{L}(y):=\tfrac{1}{n}\sum\_{i}L\_{T}(B^{(i)},y), A2â€‹LÂ¯â€‹(y):=1nâ€‹âˆ‘iâ€–aiâ€–22â€‹LTâ€‹(B(i),y)\overline{A^{2}L}(y):=\tfrac{1}{n}\sum\_{i}\|a\_{i}\|\_{2}^{2}L\_{T}(B^{(i)},y), then

|  |  |  |
| --- | --- | --- |
|  | |A2â€‹(y)|â‰¤Câ€‹(1nâ€‹âˆ‘i=1nâ€–ciâ€–22)âŸâ‰¤Hn2â€‹â€–Ïƒâ€–F2â€‹expâ¡{â€–yâ€–224â€‹Î·y}â€‹eCâ€‹Hn2â€‹[(1+â€–yâ€–22+T2â€‹Hn2)â€‹LÂ¯â€‹(y)+T2â€‹A2â€‹LÂ¯â€‹(y)],|A\_{2}(y)|\ \leq\ C\,\underbrace{\Big(\tfrac{1}{n}\sum\_{i=1}^{n}\|c\_{i}\|\_{2}^{2}\Big)}\_{\leq\,H\_{n}^{2}}\,\|\sigma\|\_{F}^{2}\;\exp\!\Big\{\tfrac{\|y\|\_{2}^{2}}{4\eta\_{y}}\Big\}\,e^{CH\_{n}^{2}}\,\Big[\,(1+\|y\|\_{2}^{2}+T^{2}H\_{n}^{2})\,\overline{L}(y)\ +\ T^{2}\,\overline{A^{2}L}(y)\Big], |  |

where C=Câ€‹(d,T,â€–Ïƒâˆ’1â€–F,Î·y,Î·a)C=C(d,T,\|\sigma^{-1}\|\_{F},\eta\_{y},\eta\_{a}). By Cauchyâ€“Schwarz inequality,

|  |  |  |
| --- | --- | --- |
|  | LÂ¯â€‹(y)â‰¤L2Â¯â€‹(y)1/2,A2â€‹LÂ¯â€‹(y)â‰¤A2â€‹L2Â¯â€‹(y)1/2â€‹A2Â¯1/2.\overline{L}(y)\leq\overline{L^{2}}(y)^{1/2},\qquad\overline{A^{2}L}(y)\leq\overline{A^{2}L^{2}}(y)^{1/2}\overline{A^{2}}^{1/2}. |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | A2â€‹(y)2â‰¤Câ€‹â€–Ïƒâ€–F4â€‹Hn4â€‹expâ¡{â€–yâ€–222â€‹Î·y}â€‹eCâ€‹Hn2â€‹[(1+â€–yâ€–22+T2â€‹Hn2)2â€‹L2Â¯â€‹(y)+T4â€‹A2â€‹L2Â¯â€‹(y)â€‹A2Â¯].A\_{2}(y)^{2}\ \leq\ C\,\|\sigma\|\_{F}^{4}\,H\_{n}^{4}\ \exp\!\Big\{\tfrac{\|y\|\_{2}^{2}}{2\eta\_{y}}\Big\}\,e^{CH\_{n}^{2}}\,\Big[\,(1+\|y\|\_{2}^{2}+T^{2}H\_{n}^{2})^{2}\,\overline{L^{2}}(y)\ +\ T^{4}\,\overline{A^{2}L^{2}}(y)\overline{A^{2}}\,\Big]. |  |

Similarly as in the bound for I1I\_{1}, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | I2\displaystyle I\_{2} | =2â€‹âˆ«01(1âˆ’t)â€‹âˆ«|gâ€²â€²â€‹(xt)|â€‹A2â€‹(y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€‹ğ‘‘t\displaystyle=2\!\int\_{0}^{1}\!(1-t)\int|g^{\prime\prime}(x\_{t})|\,A\_{2}(y)^{2}\,\varphi\_{T}(y)\,dy\,dt |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Câ€‹â€–Ïƒâ€–F4â€‹Hn4â€‹eCâ€‹Hn2â€‹(J~1+J~2+J~1(h)+J~2(h)),\displaystyle\leq C\,\|\sigma\|\_{F}^{4}\,H\_{n}^{4}\,e^{CH\_{n}^{2}}\Big(\widetilde{J}\_{1}+\widetilde{J}\_{2}+\widetilde{J}\_{1}^{(h)}+\widetilde{J}\_{2}^{(h)}\Big), |  |

where

|  |  |  |  |
| --- | --- | --- | --- |
|  | J~1\displaystyle\widetilde{J}\_{1} | :=âˆ«(1+â€–yâ€–22+T2â€‹Hn2)2â€‹eâ€–yâ€–22/(2â€‹Î·y)â€‹mâ„™nâ€‹(y)Î²âˆ’1â€‹L2Â¯â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,\displaystyle:=\int(1+\|y\|\_{2}^{2}+T^{2}H\_{n}^{2})^{2}\,e^{\|y\|\_{2}^{2}/(2\eta\_{y})}\,m\_{\mathbb{P}\_{n}}(y)^{\beta-1}\,\overline{L^{2}}(y)\,\varphi\_{T}(y)\,dy, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | J~2\displaystyle\widetilde{J}\_{2} | :=T4â€‹âˆ«eâ€–yâ€–22/(2â€‹Î·y)â€‹mâ„™nâ€‹(y)Î²âˆ’1â€‹A2â€‹L2Â¯â€‹(y)â€‹A2Â¯â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,\displaystyle:=T^{4}\int e^{\|y\|\_{2}^{2}/(2\eta\_{y})}\,m\_{\mathbb{P}\_{n}}(y)^{\beta-1}\,\overline{A^{2}L^{2}}(y)\,\overline{A^{2}}\,\varphi\_{T}(y)\,dy, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | J~1(h)\displaystyle\widetilde{J}\_{1}^{(h)} | :=âˆ«(1+â€–yâ€–22+T2â€‹Hn2)2â€‹eâ€–yâ€–22/(2â€‹Î·y)â€‹(mâ„™n(h)â€‹(y))Î²âˆ’1â€‹L2Â¯â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,\displaystyle:=\int(1+\|y\|\_{2}^{2}+T^{2}H\_{n}^{2})^{2}\,e^{\|y\|\_{2}^{2}/(2\eta\_{y})}\,\big(m\_{\mathbb{P}\_{n}}^{(h)}(y)\big)^{\beta-1}\,\overline{L^{2}}(y)\,\varphi\_{T}(y)\,dy, |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | J~2(h)\displaystyle\widetilde{J}\_{2}^{(h)} | :=T4â€‹âˆ«eâ€–yâ€–22/(2â€‹Î·y)â€‹(mâ„™n(h)â€‹(y))Î²âˆ’1â€‹A2â€‹L2Â¯â€‹(y)â€‹A2Â¯â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\displaystyle:=T^{4}\int e^{\|y\|\_{2}^{2}/(2\eta\_{y})}\,\big(m\_{\mathbb{P}\_{n}}^{(h)}(y)\big)^{\beta-1}\,\overline{A^{2}L^{2}}(y)\,\overline{A^{2}}\,\varphi\_{T}(y)\,dy. |  |

Each J~\widetilde{J}-term is handled exactly as its I1I\_{1} analogue (J1,J2,J1(h),J2(h)J\_{1},J\_{2},J\_{1}^{(h)},J\_{2}^{(h)}).
When 0<p<10<p<1, use HÃ¶lder inequality with s=11âˆ’p>1s=\frac{1}{1-p}>1; the Gaussian factor eâ€–yâ€–2/(2â€‹Î·y)e^{\|y\|^{2}/(2\eta\_{y})} only changes the yy-moment (choose Î·y>T\eta\_{y}>T so the Gaussian integrals remain finite). One obtains J~1,J~2=Opâ€‹(1)\widetilde{J}\_{1},\widetilde{J}\_{2}=O\_{p}(1) and J~1(h),J~2(h)=Opâ€‹(1)\widetilde{J}\_{1}^{(h)},\widetilde{J}\_{2}^{(h)}=O\_{p}(1) under

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>â€„2â€‹Tâ€‹sâ€‹(2â€‹sâˆ’1),s=11âˆ’p.\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\;>\;2T\,s(2s-1),\qquad s=\frac{1}{1-p}. |  |

The HnH\_{n}-dependence inside (1+â€–yâ€–2+T2â€‹Hn2)2â€‹s(1+\|y\|^{2}+T^{2}H\_{n}^{2})^{2s} contributes only a polynomial prefactor (1+T4â€‹Hn4)\big(1+T^{4}H\_{n}^{4}\big), which is harmless relative to the A2A\_{2} prefactor outside the J~\widetilde{J}â€™s. And this is the case for the rest cases.

When p<0p<0, then by Jensen inequality (the same use),
choosing Î·y>T\eta\_{y}>T, and completing the square in the yyâ€“integrals (with eâ€–yâ€–2/(2â€‹Î·y)e^{\|y\|^{2}/(2\eta\_{y})}) gives that under

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>6â€‹T\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}>6T\, |  |

we have

|  |  |  |
| --- | --- | --- |
|  | J~1,J~2=Opâ€‹(1),J~1(h),J~2(h)=Opâ€‹(eCâ€‹Hn2).\widetilde{J}\_{1},\widetilde{J}\_{2}=O\_{p}(1),\qquad\widetilde{J}\_{1}^{(h)},\widetilde{J}\_{2}^{(h)}=O\_{p}(e^{CH\_{n}^{2}}). |  |

When pâ‰¥1p\geq 1, use Jensen inequality on mâ„™npm\_{\mathbb{P}\_{n}}^{p} (and on (mâ„™n(h))p(m\_{\mathbb{P}\_{n}}^{(h)})^{p}), then complete the square in yy, as in I1I\_{1}, this yields the condition

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>maxâ¡{â€‰6â€‹T,Tâ€‹(2â€‹p2âˆ’p)}.\frac{\gamma\_{0}^{2}}{\|\sigma^{-1}\|\_{F}^{2}}\;>\;\max\{\,6T,\ T(2p^{2}-p)\,\}. |  |

Under these (same) thresholds, all four J~\widetilde{J}-terms are Opâ€‹(1)O\_{p}(1).

Therefore,

|  |  |  |
| --- | --- | --- |
|  | I2=Opâ€‹(â€–Ïƒâ€–F4â€‹Hn4â€‹eCâ€‹Hn2),Hn2=1nâ€‹max1â‰¤iâ‰¤nâ¡â€–Ïƒâˆ’1â€‹Î”iâ€–22.\quad I\_{2}\ =\ O\_{p}\!\big(\|\sigma\|\_{F}^{4}\,H\_{n}^{4}\,e^{CH\_{n}^{2}}\big),\qquad H\_{n}^{2}=\frac{1}{n}\max\_{1\leq i\leq n}\big\|\sigma^{-1}\Delta\_{i}\big\|\_{2}^{2}.\quad |  |

Equivalently, absorbing â€–Ïƒâ€–F,â€–Ïƒâˆ’1â€–F\|\sigma\|\_{F},\|\sigma^{-1}\|\_{F} into CC,

|  |  |  |
| --- | --- | --- |
|  | I2=Opâ€‹(â€–Î”â€–n2nâ‹…max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n)).I\_{2}\ =O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\cdot\frac{\max\_{1\leq i\leq n}\|\Delta\_{i}\|^{2}}{n}\;\exp\!\Big(C\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right). |  |

Therefore,

|  |  |  |
| --- | --- | --- |
|  | |R2|=Opâ€‹(â€–Î”â€–n2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n))+Opâ€‹(â€–Î”â€–n2nâ‹…max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n)).|R\_{2}|=O\_{p}\left(\frac{\left\|\Delta\right\|\_{n}^{2}}{n}\exp\left(C\max\_{1\ \leq i\leq n}\frac{\left\|\Delta\_{i}\right\|^{2}}{n}\right)\right)+O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\cdot\frac{\max\_{1\leq i\leq n}\|\Delta\_{i}\|^{2}}{n}\;\exp\!\Big(C\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right). |  |

âˆ

By Lemmas [3](https://arxiv.org/html/2512.01408v1#Thmlemma3 "Lemma 3. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [4](https://arxiv.org/html/2512.01408v1#Thmlemma4 "Lemma 4. â€£ D.2.1 Part II-i â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we have the bounds for the remainder terms with a constant C,Câˆ—>0C,C^{\*}>0:

|  |  |  |
| --- | --- | --- |
|  | |R1|+|R2|\displaystyle|R\_{1}|+|R\_{2}| |  |
|  |  |  |
| --- | --- | --- |
|  | =Opâ€‹(1nâ€‹(1nâ€‹âˆ‘i=1nâ€–Î”iâ€–4)1/2â€‹[1+â€–Î”â€–nn+1nâ€‹(1nâ€‹âˆ‘i=1nâ€–Î”iâ€–4)1/2]â€‹expâ¡(Câ€²â€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n))\displaystyle=O\_{p}\!\left(\frac{1}{n}\Big(\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{4}\Big)^{\!1/2}\,\Big[1+\frac{\|\Delta\|\_{n}}{\sqrt{n}}+\frac{1}{n}\Big(\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{4}\Big)^{\!1/2}\Big]\,\exp\!\Big(C^{\prime}\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right) |  |
|  |  |  |
| --- | --- | --- |
|  | +Opâ€‹(â€–Î”â€–n2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n))+Opâ€‹(â€–Î”â€–n2nâ‹…max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2nâ€‹expâ¡(Câ€‹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n)).\displaystyle+O\_{p}\left(\frac{\left\|\Delta\right\|\_{n}^{2}}{n}\exp\left(C\max\_{1\ \leq i\leq n}\frac{\left\|\Delta\_{i}\right\|^{2}}{n}\right)\right)+O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\cdot\frac{\max\_{1\leq i\leq n}\|\Delta\_{i}\|^{2}}{n}\;\exp\!\Big(C\,\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}\Big)\right). |  |

#### D.2.2 Part II-ii

We propose the following sub-Gaussian assumption.

###### Assumption 8.

Suppose there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}^{\*}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02>8â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2â€‹maxâ¡{â€‰1+Î²,â€‰2}.\gamma\_{0}^{2}\;>8\,T\,\|\sigma^{-1}\|\_{F}^{2}\,\max\{\,1+\beta,\,2\,\}. |  |

and Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}.

###### Lemma 5.

Let

|  |  |  |
| --- | --- | --- |
|  | Ciâ€‹(n):=ÎºÎ±â€‹âˆ«â„dmâ„™nâ€‹(y)Î²â€‹âˆ‡bLTâ€‹(B(i),y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,Î²=Î±1âˆ’Î±,mâ„™nâ€‹(y)=1nâ€‹âˆ‘j=1nLTâ€‹(B(j),y).C\_{i}(n):=\kappa\_{\alpha}\int\_{\mathbb{R}^{d}}m\_{\mathbb{P}\_{n}}(y)^{\beta}\,\nabla\_{b}L\_{T}(B^{(i)},y)\,\varphi\_{T}(y)\,dy,\qquad\beta=\tfrac{\alpha}{1-\alpha},\quad m\_{\mathbb{P}\_{n}}(y)=\tfrac{1}{n}\sum\_{j=1}^{n}L\_{T}(B^{(j)},y). |  |

Under Assumption [8](https://arxiv.org/html/2512.01408v1#Thmassumption8 "Assumption 8. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), there exists K4<âˆK\_{4}<\infty, independent of nn, such that

|  |  |  |
| --- | --- | --- |
|  | supnâ‰¥1ğ”¼â€‹[â€–C1â€‹(n)â€–4]â‰¤K4.\sup\_{n\geq 1}\ \mathbb{E}\big[\|C\_{1}(n)\|^{4}\big]\ \leq\ K\_{4}. |  |

###### Lemma 6.

Under Assumption [8](https://arxiv.org/html/2512.01408v1#Thmassumption8 "Assumption 8. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), in the context of Proof of Theorem [6](https://arxiv.org/html/2512.01408v1#Thmtheorem6 "Theorem 6. â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), for directions Î”i=Î»â€‹Ciâ€‹(n)\Delta\_{i}=\lambda\,C\_{i}(n) with fixed |Î»|=Oâ€‹(1)|\lambda|=O(1),
we have

|  |  |  |
| --- | --- | --- |
|  | |R1|+|R2|=Opâ€‹(â€–Î”â€–n2n),â€–Î”â€–n2=1nâ€‹âˆ‘i=1nâ€–Î”iâ€–2.|R\_{1}|+|R\_{2}|\;=\;O\_{p}\!\Big(\frac{\|\Delta\|\_{n}^{2}}{n}\Big),\qquad\|\Delta\|\_{n}^{2}=\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{2}. |  |

###### Proof.

With Î”i=Î»â€‹Ciâ€‹(n)\Delta\_{i}=\lambda C\_{i}(n) and fixed |Î»|=Oâ€‹(1)|\lambda|=O(1), Lemma [5](https://arxiv.org/html/2512.01408v1#Thmlemma5 "Lemma 5. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") implies

|  |  |  |
| --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nâ€–Î”iâ€–4=Î»4â€‹1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–4=Opâ€‹(1),â€–Î”â€–n2=1nâ€‹âˆ‘i=1nâ€–Î”iâ€–2=Î˜pâ€‹(1).\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{4}=\lambda^{4}\,\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{4}=O\_{p}(1),\qquad\|\Delta\|\_{n}^{2}=\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|^{2}\;=\;\Theta\_{p}(1). |  |

Moreover, by Markov inequality and a union bound,

|  |  |  |
| --- | --- | --- |
|  | Prâ¡(max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–>t)â‰¤nâ€‹ğ”¼â€‹â€–Î”1â€–4t4âŸ¹max1â‰¤iâ‰¤nâ¡â€–Î”iâ€–2n=Opâ€‹(nâˆ’1/2)=opâ€‹(1),\Pr\!\Big(\max\_{1\leq i\leq n}\|\Delta\_{i}\|>t\Big)\leq\frac{n\,\mathbb{E}\|\Delta\_{1}\|^{4}}{t^{4}}\quad\Longrightarrow\quad\max\_{1\leq i\leq n}\frac{\|\Delta\_{i}\|^{2}}{n}=O\_{p}(n^{-1/2})=o\_{p}(1), |  |

so expâ¡(Câˆ—â€‹maxiâ¡â€–Î”iâ€–2/n)=1+opâ€‹(1)\exp\!\big(C\_{\ast}\max\_{i}\|\Delta\_{i}\|^{2}/n\big)=1+o\_{p}(1) for any fixed Câˆ—>0C\_{\ast}>0.

Insert these in the general bound:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |R1|\displaystyle|R\_{1}| | =Opâ€‹(1nâ€‹(1nâ€‹âˆ‘â€–Î”iâ€–4)1/2â€‹[1+â€–Î”â€–nn+1nâ€‹(1nâ€‹âˆ‘â€–Î”iâ€–4)1/2]â€‹eCâ€²â€‹maxiâ¡â€–Î”iâ€–2/n)\displaystyle=O\_{p}\!\left(\frac{1}{n}\Big(\tfrac{1}{n}\sum\|\Delta\_{i}\|^{4}\Big)^{1/2}\Big[1+\tfrac{\|\Delta\|\_{n}}{\sqrt{n}}+\tfrac{1}{n}\Big(\tfrac{1}{n}\sum\|\Delta\_{i}\|^{4}\Big)^{1/2}\Big]\,e^{\,C^{\prime}\max\_{i}\|\Delta\_{i}\|^{2}/n}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Opâ€‹(1n)=Opâ€‹(â€–Î”â€–n2n),\displaystyle=O\_{p}\!\left(\frac{1}{n}\right)=O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\right), |  |

since the bracket is 1+opâ€‹(1)1+o\_{p}(1) and â€–Î”â€–n2=Î˜pâ€‹(1)\|\Delta\|\_{n}^{2}=\Theta\_{p}(1). For R2R\_{2},

|  |  |  |  |
| --- | --- | --- | --- |
|  | |R2|\displaystyle|R\_{2}| | =Opâ€‹(â€–Î”â€–n2nâ€‹eCâ€‹maxiâ¡â€–Î”iâ€–2/n)+Opâ€‹(â€–Î”â€–n2nâ‹…maxiâ¡â€–Î”iâ€–2nâ€‹eCâ€‹maxiâ¡â€–Î”iâ€–2/n)\displaystyle=O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\,e^{\,C\max\_{i}\|\Delta\_{i}\|^{2}/n}\right)+O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\cdot\frac{\max\_{i}\|\Delta\_{i}\|^{2}}{n}\,e^{\,C\max\_{i}\|\Delta\_{i}\|^{2}/n}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Opâ€‹(â€–Î”â€–n2n)+opâ€‹(â€–Î”â€–n2n),\displaystyle=O\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\right)+o\_{p}\!\left(\frac{\|\Delta\|\_{n}^{2}}{n}\right), |  |

again because maxiâ¡â€–Î”iâ€–2/n=opâ€‹(1)\max\_{i}\|\Delta\_{i}\|^{2}/n=o\_{p}(1). Summing,

|  |  |  |
| --- | --- | --- |
|  | |R1|+|R2|=Opâ€‹(â€–Î”â€–n2n).|R\_{1}|+|R\_{2}|\;=\;O\_{p}\!\Big(\tfrac{\|\Delta\|\_{n}^{2}}{n}\Big). |  |

âˆ

### D.3 Part III

By Lemma [6](https://arxiv.org/html/2512.01408v1#Thmlemma6 "Lemma 6. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), if we consider the minimum-norm direction (defined below), then the remainder bounds |R1|+|R2||R\_{1}|+|R\_{2}| becomes

|  |  |  |
| --- | --- | --- |
|  | |Râ€‹(Î”)|:=|R1|+|R2|=Opâ€‹(â€–Î”â€–n2n).|R(\Delta)|:=|R\_{1}|+|R\_{2}|=O\_{p}\left(\frac{\left\|\Delta\right\|\_{n}^{2}}{n}\right). |  |

Therefore, we have

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(Î”):=Jâ€‹(â„™nÎ”)âˆ’Jâ€‹(â„™âˆ—)=Fâ€‹(0)+Dâ€‹Fâ€‹(0)â€‹[Î”]+Râ€‹(Î”),F(\Delta):=J(\mathbb{P}\_{n}^{\Delta})-J(\mathbb{P}^{\*})=F(0)+DF(0)[\Delta]+R(\Delta), |  |

where Dâ€‹Fâ€‹(0)â€‹[Î”]=1n1/2â€‹1nâ€‹âˆ‘i=1nCiâ€‹(n)â‹…Î”iDF(0)[\Delta]=\frac{1}{n^{1/2}}\frac{1}{n}\sum\_{i=1}^{n}C\_{i}(n)\cdot\Delta\_{i}, Fâ€‹(0)=Jâ€‹(â„™n)âˆ’Jâ€‹(â„™âˆ—)F(0)=J(\mathbb{P}\_{n})-J(\mathbb{P}^{\*}), and |Râ€‹(Î”)|=Opâ€‹(â€–Î”â€–n2n).|R(\Delta)|=O\_{p}\left(\frac{\left\|\Delta\right\|\_{n}^{2}}{n}\right).
To solve Fâ€‹(Î”)=0F(\Delta)=0, consider the minimum-norm direction: Î”i=Î»â€‹Ciâ€‹(n)\Delta\_{i}=\lambda C\_{i}(n)
for a scalar Î»\lambda to be determined. By substituting,
Dâ€‹Fâ€‹(0)â€‹[Î”]=Î»n1/2â‹…1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2.DF(0)[\Delta]=\frac{\lambda}{n^{1/2}}\cdot\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}.
Plug this and Râ€‹(Î”)R(\Delta) into the equation:

|  |  |  |
| --- | --- | --- |
|  | Fâ€‹(0)+Î»n1/2â‹…1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2+Râ€‹(Î”)=0F(0)+\frac{\lambda}{n^{1/2}}\cdot\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}+R(\Delta)=0 |  |

Solving for Î»\lambda (ignoring Râ€‹(Î”)R(\Delta) for a moment, which is justified for small â€–Î”â€–n\|\Delta\|\_{n}), we have

|  |  |  |
| --- | --- | --- |
|  | Î»âˆ—=âˆ’n1/2â€‹Fâ€‹(0)1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2.\lambda^{\*}=-\frac{n^{1/2}F(0)}{\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}}. |  |

Thus, the correction is

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î”iâˆ—=âˆ’n1/2â€‹Fâ€‹(0)1nâ€‹âˆ‘j=1nâ€–Cjâ€‹(n)â€–2â€‹Ciâ€‹(n).\Delta\_{i}^{\*}=-\frac{n^{1/2}F(0)}{\frac{1}{n}\sum\_{j=1}^{n}\|C\_{j}(n)\|^{2}}C\_{i}(n). |  | (55) |

Compute the squared average norm:

|  |  |  |
| --- | --- | --- |
|  | â€–Î”âˆ—â€–n2=1nâ€‹âˆ‘i=1nâ€–Î”iâˆ—â€–2=(Î»âˆ—)2â‹…1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2.\|\Delta^{\*}\|\_{n}^{2}=\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}^{\*}\|^{2}=(\lambda^{\*})^{2}\cdot\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}. |  |

So, using the formula for Î»âˆ—\lambda^{\*}:

|  |  |  |
| --- | --- | --- |
|  | â€–Î”âˆ—â€–n2=(n1/2â€‹Fâ€‹(0)1nâ€‹âˆ‘j=1nâ€–Cjâ€‹(n)â€–2)2â‹…1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2=nâ€‹Fâ€‹(0)2/(1nâ€‹âˆ‘j=1nâ€–Cjâ€‹(n)â€–2).\|\Delta^{\*}\|\_{n}^{2}=\left(\frac{n^{1/2}F(0)}{\frac{1}{n}\sum\_{j=1}^{n}\|C\_{j}(n)\|^{2}}\right)^{2}\cdot\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}=nF(0)^{2}/\left(\frac{1}{n}\sum\_{j=1}^{n}\|C\_{j}(n)\|^{2}\right). |  |

### D.4 Part IV

In this part, we will present Lemmas [7](https://arxiv.org/html/2512.01408v1#Thmlemma7 "Lemma 7. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), [8](https://arxiv.org/html/2512.01408v1#Thmlemma8 "Lemma 8. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [9](https://arxiv.org/html/2512.01408v1#Thmlemma9 "Lemma 9. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") to establish various senses of convergence.

###### Lemma 7.

Define

|  |  |  |
| --- | --- | --- |
|  | Câ‹†â€‹(b):=ÎºÎ±â€‹âˆ«â„dmâ„™âˆ—â€‹(y)Î²â€‹âˆ‡bLTâ€‹(b,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,C^{\star}(b):=\kappa\_{\alpha}\int\_{\mathbb{R}^{d}}m\_{\mathbb{P}^{\*}}(y)^{\beta}\,\nabla\_{b}L\_{T}(b,y)\,\varphi\_{T}(y)\,dy, |  |

where ÎºÎ±=11âˆ’Î±â€‹(erâ€‹Tkâˆ—)11âˆ’Î±\kappa\_{\alpha}=\frac{1}{1-\alpha}\left(\frac{e^{rT}}{k^{\*}}\right)^{\frac{1}{1-\alpha}}, then under Assumption [8](https://arxiv.org/html/2512.01408v1#Thmassumption8 "Assumption 8. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we have the convergence in probability

|  |  |  |
| --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2â†’ğ‘c,c:=ğ”¼â€‹[â€–Câ‹†â€‹(B)â€–2]âˆˆ(0,âˆ).\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}\;\xrightarrow{p}\;c,\qquad c:=\mathbb{E}\big[\|C^{\star}(B)\|^{2}\big]\in(0,\infty). |  |

###### Proof.

Since mâ„™nâ€‹(y)â†’mâ„™âˆ—â€‹(y)m\_{\mathbb{P}\_{n}}(y)\to m\_{\mathbb{P}^{\*}}(y) a.s. for each yy and the sub-Gaussian condition furnishes an
integrable upper bound for the map
yâ†¦mâ„™nâ€‹(y)Î²â€‹âˆ‡bLTâ€‹(B(i),y)â€‹Ï†Tâ€‹(y)y\mapsto m\_{\mathbb{P}\_{n}}(y)^{\beta}\,\nabla\_{b}L\_{T}(B^{(i)},y)\,\varphi\_{T}(y)
(see the derivation in Lemma [5](https://arxiv.org/html/2512.01408v1#Thmlemma5 "Lemma 5. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")),
dominated convergence theorem yields ğ”¼â€‹â€–Câ‹†â€‹(B)â€–2<âˆ\mathbb{E}\|C^{\star}(B)\|^{2}<\infty and

|  |  |  |
| --- | --- | --- |
|  | â€–Ciâ€‹(n)âˆ’Câ‹†â€‹(B(i))â€–â†’nâ†’âˆ 0inÂ â€‹L2.\|C\_{i}(n)-C^{\star}(B^{(i)})\|\ \xrightarrow[n\to\infty]{}\ 0\quad\text{in }L^{2}\ . |  |

Write

|  |  |  |
| --- | --- | --- |
|  | 1nâˆ‘i=1nâˆ¥Ci(n)âˆ¥2=1nâˆ‘i=1nâˆ¥Câ‹†(B(i))âˆ¥2+1nâˆ‘i=1n(âˆ¥Ci(n)âˆ¥2âˆ’âˆ¥Câ‹†(B(i))âˆ¥2)=:An+Rn.\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2}=\frac{1}{n}\sum\_{i=1}^{n}\|C^{\star}(B^{(i)})\|^{2}\;+\;\frac{1}{n}\sum\_{i=1}^{n}\Big(\|C\_{i}(n)\|^{2}-\|C^{\star}(B^{(i)})\|^{2}\Big)=:A\_{n}+R\_{n}. |  |

Then by strong law of large numbers, we have Anâ†’cA\_{n}\to c a.s.

For RnR\_{n}, by Cauchyâ€“Schwarz and the uniform fourth-moment bound from
Lemma [5](https://arxiv.org/html/2512.01408v1#Thmlemma5 "Lemma 5. â€£ D.2.2 Part II-ii â€£ D.2 Part II â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"),

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹|Rn|â‰¤1nâ€‹âˆ‘i=1nğ”¼â€‹[â€–Ciâ€‹(n)âˆ’Câ‹†â€‹(B(i))â€–â€‹(â€–Ciâ€‹(n)â€–+â€–Câ‹†â€‹(B(i))â€–)]â‰¤Kâ€‹(ğ”¼â€‹â€–C1â€‹(n)âˆ’Câ‹†â€‹(B(1))â€–2)1/2,\mathbb{E}|R\_{n}|\;\leq\;\frac{1}{n}\sum\_{i=1}^{n}\mathbb{E}\Big[\|C\_{i}(n)-C^{\star}(B^{(i)})\|\,\big(\|C\_{i}(n)\|+\|C^{\star}(B^{(i)})\|\big)\Big]\;\leq\;K\,\Big(\mathbb{E}\|C\_{1}(n)-C^{\star}(B^{(1)})\|^{2}\Big)^{\!1/2}, |  |

for a constant K<âˆK<\infty independent of nn. Since the right-hand side â†’0\to 0, then
Rnâ†’0R\_{n}\to 0 in L1L^{1} and therefore in probability. Hence the proof is completed.
âˆ

###### Lemma 8.

As nâ†’âˆn\to\infty, Jâ€‹(â„™n)âˆ’Jâ€‹(â„™âˆ—)=Opâ€‹(nâˆ’1/2)J(\mathbb{P}\_{n})-J(\mathbb{P}^{\*})=O\_{p}(n^{-1/2}), and

|  |  |  |
| --- | --- | --- |
|  | nâ€‹(Jâ€‹(â„™n)âˆ’Jâ€‹(â„™âˆ—))â‡’ğ’©â€‹(0,hâ€‹(â„™âˆ—)),\sqrt{n}\left(J(\mathbb{P}\_{n})-J(\mathbb{P}^{\*})\right)\Rightarrow\mathcal{N}(0,h(\mathbb{P}^{\*})), |  |

where

|  |  |  |
| --- | --- | --- |
|  | hâ€‹(â„™âˆ—)=âˆ«âˆ«gâ€²â€‹(Î±â€‹(y1))â€‹gâ€²â€‹(Î±â€‹(y2))â€‹Covâ„™âˆ—â€‹(LTâ€‹(B,y1),LTâ€‹(B,y2))â€‹Ï†Tâ€‹(y1)â€‹Ï†Tâ€‹(y2)â€‹ğ‘‘y1â€‹ğ‘‘y2<âˆ.h(\mathbb{P}^{\*})=\int\int g^{\prime}(\alpha(y\_{1}))g^{\prime}(\alpha(y\_{2}))\text{Cov}\_{\mathbb{P}^{\*}}\left(L\_{T}(B,y\_{1}),L\_{T}(B,y\_{2})\right)\varphi\_{T}(y\_{1})\varphi\_{T}(y\_{2})dy\_{1}dy\_{2}<\infty. |  |

###### Proof.

We define a separable Hilbert space H=L2â€‹(Ï†T)H=L^{2}(\varphi\_{T}) with the norm hâˆˆHh\in H, â€–hâ€–2=âˆ«â„dh2â€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\left\|h\right\|^{2}=\int\_{\mathbb{R}^{d}}h^{2}(y)\varphi\_{T}(y)dy, and Zi(.)=LT(B,.)Z\_{i}(.)=L\_{T}(B,.) as an element of HH. From a similar computation of the Gaussian bounds above, there exist constants 0<K<âˆ0<K<\infty and u2:=2â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2u\_{2}:=2T\,\|\sigma^{-1}\|\_{F}^{2} such that

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dLTâ€‹(b,y)2â€‹Ï†Tâ€‹(y)â€‹dyâ‰¤Kâ€‹expâ¡(u2â€‹â€–bâ€–2)for allÂ â€‹bâˆˆâ„d,\int\_{\mathbb{R}^{d}}L\_{T}(b,y)^{2}\,\varphi\_{T}(y)\,\mathrm{d}y\;\leq\;K\,\exp\!\big(u\_{2}\,\|b\|^{2}\big)\quad\text{for all }b\in\mathbb{R}^{d}, |  |

and therefore

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—[âˆ¥LT(B,.)âˆ¥2]â‰¤Kğ”¼â„™âˆ—exp(u2âˆ¥Bâˆ¥2).\mathbb{E}\_{\mathbb{P}^{\*}}\left[\left\|L\_{T}(B,.)\right\|^{2}\right]\;\leq\;K\,\mathbb{E}\_{\mathbb{P}^{\*}}\exp\!\big(u\_{2}\,\|B\|^{2}\big). |  |

it suffices to assume the sub Gaussian parameter

|  |  |  |
| --- | --- | --- |
|  | Î³02>â€„2â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2.\gamma\_{0}^{2}\;>\;2T\,\|\sigma^{-1}\|\_{F}^{2}. |  |

to make this norm finite.
Hence, the central limit theorem for Hilbert space valued random elements gives the following: as nâ†’âˆn\to\infty,

|  |  |  |
| --- | --- | --- |
|  | n(ğ”¼â„™n[LT(B,.)]âˆ’ğ”¼â„™âˆ—[LT(B,.)])â‡’G,\sqrt{n}\left(\mathbb{E}\_{\mathbb{P}\_{n}}\left[L\_{T}(B,.)\right]-\mathbb{E}\_{\mathbb{P}^{\*}}\left[L\_{T}(B,.)\right]\right)\Rightarrow G, |  |

where GG is distributed as a Gaussian measure in HH with a covariance operator such that for any hâˆˆHh\in H with the Bochner integral

|  |  |  |
| --- | --- | --- |
|  | Ch=Covâ„™âˆ—(âŸ¨LT(B,.),hâŸ©H,LT(B,.)).Ch=\mathrm{Cov}\_{\mathbb{P}^{\*}}\big(\langle L\_{T}(B,.),h\rangle\_{H},L\_{T}(B,.)\big). |  |

This limit is enough for the case when Î²<1\beta<1. When Î²>1\beta>1, we want to show that GâˆˆL1+Î²â€‹(Ï†T)G\in L^{1+\beta}(\varphi\_{T}) a.s. under certain sub Gaussian assumption.
Let p:=1+Î²>2p:=1+\beta>2. Using the similar Gaussian-tilt computation (as above), there exist
constants Kp<âˆK\_{p}<\infty and up>0u\_{p}>0 (depending on T,Ïƒ,mT,\sigma,m and pp) such that for all bb,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„dLTâ€‹(b,y)pâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤Kpâ€‹expâ¡(upâ€‹â€–bâ€–2).\int\_{\mathbb{R}^{d}}L\_{T}(b,y)^{p}\,\varphi\_{T}(y)\,dy\;\leq\;K\_{p}\,\exp\!\big(u\_{p}\,\|b\|^{2}\big). |  |

A safe explicit choice is

|  |  |  |
| --- | --- | --- |
|  | up=Câ€‹pâ€‹(1+p)â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2,e.g.u1+Î²â‰¤â€„2â€‹(1+Î²)â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2,u\_{p}\;=\;C\,p(1+p)\,T\,\|\sigma^{-1}\|\_{F}^{2},\qquad\text{e.g.}\quad u\_{1+\beta}\;\leq\;2(1+\beta)\,T\,\|\sigma^{-1}\|\_{F}^{2}, |  |

where the constant CC absorbs the drift terms (cf. the bounds already used earlier).
Assume the sub-Gaussian radius Î³0\gamma\_{0} of BB satisfies

|  |  |  |
| --- | --- | --- |
|  | Î³02>u1+Î²âŸ¹ğ”¼â„™âˆ—â€‹expâ¡(u1+Î²â€‹â€–Bâ€–2)<âˆ.\gamma\_{0}^{2}\;>\;u\_{1+\beta}\ \quad\Longrightarrow\quad\mathbb{E}\_{\mathbb{P}^{\*}}\exp\!\big(u\_{1+\beta}\,\|B\|^{2}\big)<\infty. |  |

Then, by Tonelli,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹âˆ«LTâ€‹(B,y)1+Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤K1+Î²â€‹ğ”¼â„™âˆ—â€‹expâ¡(u1+Î²â€‹â€–Bâ€–2)<âˆ.\mathbb{E}\_{\mathbb{P}^{\*}}\!\int L\_{T}(B,y)^{1+\beta}\,\varphi\_{T}(y)\,dy\;\leq\;K\_{1+\beta}\,\mathbb{E}\_{\mathbb{P}^{\*}}\exp\!\big(u\_{1+\beta}\,\|B\|^{2}\big)\;<\;\infty. |  |

For Xâ€‹(y):=LTâ€‹(B,y)âˆ’Î¼â€‹(y)X(y):=L\_{T}(B,y)-\mu(y) with Î¼â€‹(y)=ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)]\mu(y)=\mathbb{E}\_{\mathbb{P}^{\*}}[L\_{T}(B,y)], we have

|  |  |  |
| --- | --- | --- |
|  | â€–Xâ€–L1+Î²â€‹(Ï†T)â€‰2=(âˆ«|Xâ€‹(y)|1+Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)21+Î².\|X\|\_{L^{1+\beta}(\varphi\_{T})}^{\,2}=\Big(\int|X(y)|^{1+\beta}\,\varphi\_{T}(y)\,dy\Big)^{\frac{2}{1+\beta}}. |  |

Since 21+Î²âˆˆ(0,1)\frac{2}{1+\beta}\in(0,1), the map xâ†¦x21+Î²x\mapsto x^{\frac{2}{1+\beta}} is concave on â„+\mathbb{R}\_{+},
hence Jensen yields

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[â€–Xâ€–L1+Î²2]â‰¤(ğ”¼â€‹âˆ«|Xâ€‹(y)|1+Î²â€‹Ï†Tâ€‹(dâ€‹y))21+Î²â‰¤(21+Î²â€‹ğ”¼â€‹âˆ«LTâ€‹(B,y)1+Î²â€‹Ï†Tâ€‹(dâ€‹y))21+Î²<âˆ,\mathbb{E}\big[\|X\|\_{L^{1+\beta}}^{2}\big]\;\leq\;\Big(\mathbb{E}\int|X(y)|^{1+\beta}\,\varphi\_{T}(dy)\Big)^{\!\frac{2}{1+\beta}}\;\leq\;\Big(2^{1+\beta}\,\mathbb{E}\int L\_{T}(B,y)^{1+\beta}\,\varphi\_{T}(dy)\Big)^{\!\frac{2}{1+\beta}}\;<\;\infty, |  |

thus
ğ”¼â€‹â€–Xâ€–L1+Î²2<âˆ\mathbb{E}\|X\|\_{L^{1+\beta}}^{2}<\infty.
The space L1+Î²â€‹(Ï†T)L^{1+\beta}(\varphi\_{T}) with 1+Î²>21+\beta>2 is a type-2 Banach space.
Therefore, by the CLT for i.i.d. Banach-valued random variables,
the averages mâ„™n=1nâ€‹âˆ‘i=1nLTâ€‹(B(i),â‹…)m\_{\mathbb{P}\_{n}}=\frac{1}{n}\sum\_{i=1}^{n}L\_{T}(B^{(i)},\cdot) satisfy

|  |  |  |
| --- | --- | --- |
|  | nâ€‹(mâ„™nâˆ’mâ„™âˆ—)â‡’GinÂ â€‹L1+Î²â€‹(Ï†T),\sqrt{n}\,\big(m\_{\mathbb{P}\_{n}}-m\_{\mathbb{P}^{\*}}\big)\ \Rightarrow\ G\quad\text{in }L^{1+\beta}(\varphi\_{T}), |  |

where GG is a centered Gaussian measure on L1+Î²â€‹(Ï†T)L^{1+\beta}(\varphi\_{T}).
In particular, GâˆˆL1+Î²â€‹(Ï†T)G\in L^{1+\beta}(\varphi\_{T}) a.s.
Since Ï†T\varphi\_{T} is a probability measure, the continuous embedding
L1+Î²â€‹(Ï†T)â†ªL2â€‹(Ï†T)L^{1+\beta}(\varphi\_{T})\hookrightarrow L^{2}(\varphi\_{T}) implies the same CLT in L2L^{2}.

Next, we show hâ€‹(â„™âˆ—)<âˆh(\mathbb{P}^{\*})<\infty.
By Cauchy Schwartz inequality, we have |Covâ€‹(X,Y)|â‰¤Varâ€‹(X)â€‹Varâ€‹(Y)â‰¤ğ”¼â€‹[X2]â€‹ğ”¼â€‹[Y2]|\text{Cov}(X,Y)|\leq\sqrt{\text{Var}(X)\text{Var}(Y)}\leq\sqrt{\mathbb{E}[X^{2}]\mathbb{E}[Y^{2}]}, thus

|  |  |  |
| --- | --- | --- |
|  | |hâ€‹(â„™âˆ—)|â‰¤(âˆ«|gâ€²â€‹(Î±â€‹(y))|â€‹ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)2]â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)2.|h(\mathbb{P}^{\*})|\;\leq\;\Bigg(\int|g^{\prime}\!\big(\alpha(y)\big)|\,\sqrt{\mathbb{E}\_{\mathbb{P}^{\*}}\!\big[L\_{T}(B,y)^{2}\big]}\;\varphi\_{T}(y)\,dy\Bigg)^{\!2}. |  |

Another application of Cauchyâ€“Schwarz inequality gives

|  |  |  |
| --- | --- | --- |
|  | |hâ€‹(â„™âˆ—)|â‰¤(âˆ«gâ€²â€‹(Î±â€‹(y))2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)â€‹(âˆ«ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)2]â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y).|h(\mathbb{P}^{\*})|\;\leq\;\Bigg(\int g^{\prime}\!\big(\alpha(y)\big)^{2}\,\varphi\_{T}(y)\,dy\Bigg)\Bigg(\int\mathbb{E}\_{\mathbb{P}^{\*}}\!\big[L\_{T}(B,y)^{2}\big]\;\varphi\_{T}(y)\,dy\Bigg). |  |

Hence it suffices to show that the first integral is finite.

Recall that gâ€²â€‹(Î±)=ÎºÎ±â€‹Î±Î²g^{\prime}(\alpha)=\kappa\_{\alpha}\,\alpha^{\beta} with Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}, then

|  |  |  |
| --- | --- | --- |
|  | âˆ«gâ€²â€‹(Î±â€‹(y))2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y=ÎºÎ±2â€‹âˆ«Î±â€‹(y)2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\int g^{\prime}(\alpha(y))^{2}\,\varphi\_{T}(y)\,dy=\kappa\_{\alpha}^{2}\int\alpha(y)^{2\beta}\,\varphi\_{T}(y)\,dy. |  |

For Î²â‰¥12\beta\geq\tfrac{1}{2}, the Jensen inequality yields Î±â€‹(y)2â€‹Î²â‰¤ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)2â€‹Î²]\alpha(y)^{2\beta}\leq\mathbb{E}\_{\mathbb{P}^{\*}}[L\_{T}(B,y)^{2\beta}].
For 0<Î²<120<\beta<\tfrac{1}{2}, use x2â€‹Î²â‰¤CÎ²â€‹(1+x2â€‹Î²+x2)x^{2\beta}\leq C\_{\beta}\,(1+x^{2\beta}+x^{2}) for xâ‰¥0x\geq 0.
In both cases,

|  |  |  |
| --- | --- | --- |
|  | âˆ«Î±â€‹(y)2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤CÎ²â€‹(1+ğ”¼â„™âˆ—â€‹âˆ«LTâ€‹(B,y)2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y+ğ”¼â„™âˆ—â€‹âˆ«LTâ€‹(B,y)2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y).\int\alpha(y)^{2\beta}\,\varphi\_{T}(y)\,dy\;\leq\;C\_{\beta}\Bigg(1+\mathbb{E}\_{\mathbb{P}^{\*}}\!\int L\_{T}(B,y)^{2\beta}\varphi\_{T}(y)\,dy\;+\;\mathbb{E}\_{\mathbb{P}^{\*}}\!\int L\_{T}(B,y)^{2}\varphi\_{T}(y)\,dy\Bigg). |  |

Again by the Gaussian-tilt bound, for all bb,

|  |  |  |
| --- | --- | --- |
|  | âˆ«LTâ€‹(b,y)2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤K2â€‹Î²â€‹expâ¡(u2â€‹Î²â€‹â€–bâ€–2),\int L\_{T}(b,y)^{2\beta}\varphi\_{T}(y)\,dy\;\leq\;K\_{2\beta}\,\exp\!\big(u\_{2\beta}\|b\|^{2}\big), |  |

with K2â€‹Î²<âˆK\_{2\beta}<\infty and u2â€‹Î²>0u\_{2\beta}>0 depending on T,Ïƒ,m,Î²T,\sigma,m,\beta
(a safe choice is u2â€‹Î²=2â€‹(1+Î²)â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2u\_{2\beta}=2(1+\beta)T\|\sigma^{-1}\|\_{F}^{2}).
Therefore

|  |  |  |
| --- | --- | --- |
|  | âˆ«gâ€²â€‹(Î±â€‹(y))2â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ‰¤ÎºÎ±2â€‹CÎ²â€‹(1+K2â€‹Î²â€‹ğ”¼â„™âˆ—â€‹eu2â€‹Î²â€‹â€–Bâ€–2+K2â€‹ğ”¼â„™âˆ—â€‹eu2â€‹â€–Bâ€–2),\int g^{\prime}(\alpha(y))^{2}\,\varphi\_{T}(y)\,dy\;\leq\;\kappa\_{\alpha}^{2}\,C\_{\beta}\Big(1+K\_{2\beta}\,\mathbb{E}\_{\mathbb{P}^{\*}}e^{u\_{2\beta}\|B\|^{2}}+K\_{2}\,\mathbb{E}\_{\mathbb{P}^{\*}}e^{u\_{2}\|B\|^{2}}\Big), |  |

which is finite provided u2â€‹Î²<Î³02u\_{2\beta}<\gamma\_{0}^{2} and u2<Î³02u\_{2}<\gamma\_{0}^{2}.
Combining above cases yields hâ€‹(â„™âˆ—)<âˆh(\mathbb{P}^{\*})<\infty.
A convenient single sufficient condition is

|  |  |  |
| --- | --- | --- |
|  | Î³02>â€„8â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2â€‹maxâ¡{â€‰1+Î²,â€‰2},\gamma\_{0}^{2}\;>\;8\,T\,\|\sigma^{-1}\|\_{F}^{2}\,\max\{\,1+\beta,\,2\,\}, |  |

which ensures u2â€‹Î²<Î³02u\_{2\beta}<\gamma\_{0}^{2} and u2<Î³02u\_{2}<\gamma\_{0}^{2}.

Denote Î¼=ğ”¼â„™âˆ—[LT(B,.)]âˆˆH\mu=\mathbb{E}\_{\mathbb{P}^{\*}}\left[L\_{T}(B,.)\right]\in H. By Lemma [9](https://arxiv.org/html/2512.01408v1#Thmlemma9 "Lemma 9. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the map ğ’¯:Hâ†’â„\mathcal{T}:H\to\mathbb{R} such that ğ’¯â€‹(h)=âˆ«gâ€‹(hâ€‹(y))â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\mathcal{T}(h)=\int g(h(y))\varphi\_{T}(y)dy is Hadamard differentiable at Î¼\mu if Î²â‰¤1\beta\leq 1 and is Hadamard differentiable at Î¼\mu tangential to L1+Î²L^{1+\beta} if Î²>1\beta>1. Thus, from the functional Delta theorem and its weaker version with tangential Hadamard differentiability, we have

|  |  |  |
| --- | --- | --- |
|  | n(ğ’¯(ğ”¼â„™n[LT(B,.)])âˆ’ğ’¯(Î¼))\displaystyle\sqrt{n}\left(\mathcal{T}\left(\mathbb{E}\_{\mathbb{P}\_{n}}\left[L\_{T}(B,.)\right]\right)-\mathcal{T}(\mu)\right) |  |
|  |  |  |
| --- | --- | --- |
|  | =nâ€‹(âˆ«gâ€‹(ğ”¼â„™nâ€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâˆ’âˆ«gâ€‹(ğ”¼â„™âˆ—â€‹[LTâ€‹(B,y)])â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)\displaystyle=\sqrt{n}\left(\int g(\mathbb{E}\_{\mathbb{P}\_{n}}\left[L\_{T}(B,y)\right])\varphi\_{T}(y)dy-\int g(\mathbb{E}\_{\mathbb{P}^{\*}}\left[L\_{T}(B,y)\right])\varphi\_{T}(y)dy\right) |  |
|  |  |  |
| --- | --- | --- |
|  | =Jâ€‹(â„™n)âˆ’Jâ€‹(â„™âˆ—)â‡’ğ’¯Î¼â€²â€‹(G),\displaystyle=J(\mathbb{P}\_{n})-J(\mathbb{P}^{\*})\Rightarrow\mathcal{T}^{\prime}\_{\mu}(G), |  |

where ğ’¯Î¼â€²\mathcal{T}^{\prime}\_{\mu} is the Hadamard derivative at Î¼\mu. By Lemma [9](https://arxiv.org/html/2512.01408v1#Thmlemma9 "Lemma 9. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the limiting distribution becomes

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’¯Î¼â€²â€‹(G)\displaystyle\mathcal{T}^{\prime}\_{\mu}(G) | =âˆ«gâ€²â€‹(Î±â€‹(y))â€‹Gâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâˆ¼ğ’©â€‹(0,hâ€‹(â„™âˆ—)).\displaystyle=\int g^{\prime}(\alpha(y))G(y)\varphi\_{T}(y)dy\sim\mathcal{N}(0,h(\mathbb{P}^{\*})). |  |

âˆ

###### Lemma 9.

In the context of Lemma [8](https://arxiv.org/html/2512.01408v1#Thmlemma8 "Lemma 8. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), the map ğ’¯\mathcal{T} is Hadamard differentiable at Î¼\mu if Î²â‰¤1\beta\leq 1 and is Hadamard differentiable at Î¼\mu tangential to L1+Î²L^{1+\beta} if Î²>1\beta>1. In particular, for a fixed direction vâˆˆHv\in H (or vâˆˆL1+Î²v\in L^{1+\beta} in the tangential case),

|  |  |  |
| --- | --- | --- |
|  | ğ’¯Î¼â€²â€‹(v)=âˆ«gâ€²â€‹(Î±â€‹(y))â€‹vâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.\mathcal{T}^{\prime}\_{\mu}(v)=\int g^{\prime}(\alpha(y))v(y)\varphi\_{T}(y)dy. |  |

###### Proof.

We first focus on the case when Î²>0\beta>0 and fix vâˆˆHv\in H and any perturbations vtâˆˆHv\_{t}\in H with vtâ†’vv\_{t}\to v in HH as tâ†“0t\downarrow 0.
We must show

|  |  |  |
| --- | --- | --- |
|  | ğ’¯â€‹(Î±+tâ€‹vt)âˆ’ğ’¯â€‹(Î±)tâŸ¶âˆ«gâ€²â€‹(Î±)â€‹vâ€‹Ï†TasÂ â€‹tâ†“0.\frac{\mathcal{T}(\alpha+tv\_{t})-\mathcal{T}(\alpha)}{t}\;\longrightarrow\;\int g^{\prime}(\alpha)\,v\,\varphi\_{T}\quad\text{as }t\downarrow 0. |  |

By the fundamental theorem of calculus,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ’¯â€‹(Î¼+tâ€‹vt)âˆ’ğ’¯â€‹(Î¼)t\displaystyle\frac{\mathcal{T}(\mu+tv\_{t})-\mathcal{T}(\mu)}{t} | =âˆ«â„dgâ€‹(Î¼â€‹(y)+tâ€‹vtâ€‹(y))âˆ’gâ€‹(Î¼â€‹(y))tâ€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\displaystyle=\int\_{\mathbb{R}^{d}}\frac{g(\mu(y)+tv\_{t}(y))-g(\mu(y))}{t}\,\varphi\_{T}(y)\,dy |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ«01âˆ«â„dgâ€²â€‹(Î¼â€‹(y)+sâ€‹tâ€‹vtâ€‹(y))â€‹vtâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€‹ğ‘‘s.\displaystyle=\int\_{0}^{1}\!\int\_{\mathbb{R}^{d}}g^{\prime}\big(\mu(y)+stv\_{t}(y)\big)\,v\_{t}(y)\,\varphi\_{T}(y)\,dy\,ds. |  |

Add and subtract âˆ«â„dgâ€²â€‹(Î¼â€‹(y))â€‹vâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y\int\_{\mathbb{R}^{d}}g^{\prime}(\mu(y))\,v(y)\,\varphi\_{T}(y)\,dy:

|  |  |  |
| --- | --- | --- |
|  | ğ’¯â€‹(Î¼+tâ€‹vt)âˆ’ğ’¯â€‹(Î¼)tâˆ’âˆ«â„dgâ€²â€‹(Î¼)â€‹vâ€‹Ï†T=âˆ«â„dgâ€²â€‹(Î¼)â€‹(vtâˆ’v)â€‹Ï†TâŸ=â£:At+âˆ«01âˆ«â„d[gâ€²â€‹(Î¼+sâ€‹tâ€‹vt)âˆ’gâ€²â€‹(Î¼)]â€‹vtâ€‹Ï†Tâ€‹ğ‘‘yâ€‹ğ‘‘sâŸ=â£:Bt.\frac{\mathcal{T}(\mu+tv\_{t})-\mathcal{T}(\mu)}{t}-\int\_{\mathbb{R}^{d}}g^{\prime}(\mu)\,v\,\varphi\_{T}=\underbrace{\int\_{\mathbb{R}^{d}}g^{\prime}(\mu)\,(v\_{t}-v)\,\varphi\_{T}}\_{=:A\_{t}}+\underbrace{\int\_{0}^{1}\!\int\_{\mathbb{R}^{d}}\!\big[g^{\prime}(\mu+stv\_{t})-g^{\prime}(\mu)\big]\,v\_{t}\,\varphi\_{T}\,dy\,ds}\_{=:B\_{t}}. |  |

By Cauchyâ€“Schwarz inequality,

|  |  |  |
| --- | --- | --- |
|  | |At|â‰¤â€–gâ€²â€‹(Î¼)â€–L2â€‹(Ï†T)â€‹â€–vtâˆ’vâ€–L2â€‹(Ï†T)âŸ¶â€„0,|A\_{t}|\;\leq\;\|g^{\prime}(\mu)\|\_{L^{2}(\varphi\_{T})}\,\|v\_{t}-v\|\_{L^{2}(\varphi\_{T})}\;\longrightarrow\;0, |  |

since gâ€²â€‹(Î¼)âˆˆL2â€‹(Ï†T)g^{\prime}(\mu)\in L^{2}(\varphi\_{T}) (see the estimate in proof of Lemma [8](https://arxiv.org/html/2512.01408v1#Thmlemma8 "Lemma 8. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) and vtâ†’vv\_{t}\to v in L2â€‹(Ï†T)L^{2}(\varphi\_{T}). Hence Atâ†’0A\_{t}\to 0.

Fix Î´âˆˆ(0,minâ¡{Î²,1})\delta\in(0,\min\{\beta,1\}). Using the elementary inequality

|  |  |  |
| --- | --- | --- |
|  | |xÎ²âˆ’yÎ²|â‰¤Î²Î´â€‹|xâˆ’y|Î´â€‹(xÎ²âˆ’Î´+yÎ²âˆ’Î´)(x,yâ‰¥0),|x^{\beta}-y^{\beta}|\;\leq\;\frac{\beta}{\delta}\,|x-y|^{\delta}\,\big(x^{\beta-\delta}+y^{\beta-\delta}\big)\qquad(x,y\geq 0), |  |

applied with x=Î¼â€‹(y)+sâ€‹tâ€‹|vtâ€‹(y)|x=\mu(y)+st|v\_{t}(y)|, y=Î¼â€‹(y)y=\mu(y) and gâ€²â€‹(m)=ÎºÎ±â€‹mÎ²g^{\prime}(m)=\kappa\_{\alpha}m^{\beta}, we obtain

|  |  |  |
| --- | --- | --- |
|  | |Bt|â‰¤Câ€‹|t|Î´â€‹âˆ«â„d(Î¼â€‹(y)Î²âˆ’Î´+(Î¼â€‹(y)+sâ€‹tâ€‹|vtâ€‹(y)|)Î²âˆ’Î´)â€‹|vtâ€‹(y)|1+Î´â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y.|B\_{t}|\;\leq\;C\,|t|^{\delta}\!\int\_{\mathbb{R}^{d}}\!\Big(\mu(y)^{\beta-\delta}+(\mu(y)+st|v\_{t}(y)|)^{\beta-\delta}\Big)\,|v\_{t}(y)|^{1+\delta}\,\varphi\_{T}(y)\,dy. |  |

Using (a+b)Î²âˆ’Î´â‰¤Câ€‹(aÎ²âˆ’Î´+bÎ²âˆ’Î´)(a+b)^{\beta-\delta}\leq C\,(a^{\beta-\delta}+b^{\beta-\delta}) and |t|Î²âˆ’Î´â‰¤1|t|^{\beta-\delta}\leq 1 for small tt,

|  |  |  |
| --- | --- | --- |
|  | |Bt|â‰¤Câ€‹|t|Î´â€‹{âˆ«â„dÎ¼â€‹(y)Î²âˆ’Î´â€‹|vtâ€‹(y)|1+Î´â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâŸIt,1+|t|Î²âˆ’Î´â€‹âˆ«â„d|vtâ€‹(y)|1+Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâŸIt,2}.|B\_{t}|\;\leq\;C\,|t|^{\delta}\!\left\{\underbrace{\int\_{\mathbb{R}^{d}}\mu(y)^{\beta-\delta}\,|v\_{t}(y)|^{1+\delta}\,\varphi\_{T}(y)\,dy}\_{I\_{t,1}}\;+\;\underbrace{|t|^{\beta-\delta}\int\_{\mathbb{R}^{d}}|v\_{t}(y)|^{1+\beta}\,\varphi\_{T}(y)\,dy}\_{I\_{t,2}}\right\}. |  |

For the first term, apply the HÃ¶lder inequality with p=21+Î´p=\tfrac{2}{1+\delta} and q=21âˆ’Î´q=\tfrac{2}{1-\delta}:

|  |  |  |
| --- | --- | --- |
|  | It,1â‰¤â€–Î¼Î²âˆ’Î´â€–Lqâ€‹(Ï†T)â€‹â€–vtâ€–L2â€‹(Ï†T).I\_{t,1}\;\leq\;\|\mu^{\beta-\delta}\|\_{L^{q}(\varphi\_{T})}\,\|v\_{t}\|\_{L^{2}(\varphi\_{T})}. |  |

Under the sub-Gaussian parameter

|  |  |  |
| --- | --- | --- |
|  | Î³02>â€„2â€‹(1+Î²)â€‹Tâ€‹â€–Ïƒâˆ’1â€–F2,\gamma\_{0}^{2}\;>\;2(1+\beta)\,T\,\|\sigma^{-1}\|\_{F}^{2}, |  |

we have
â€–Î¼Î²âˆ’Î´â€–Lqâ€‹(Ï†T)<âˆ\|\mu^{\beta-\delta}\|\_{L^{q}(\varphi\_{T})}<\infty for any small Î´âˆˆ(0,1)\delta\in(0,1), and since vtâ†’vv\_{t}\to v in L2â€‹(Ï†T)L^{2}(\varphi\_{T}),
â€–vtâ€–L2â€‹(Ï†T)\|v\_{t}\|\_{L^{2}(\varphi\_{T})} is uniformly bounded. Hence It,1â‰¤CI\_{t,1}\leq C uniformly in tt.

For the second term, we consider two cases.
When 0<Î²â‰¤10<\beta\leq 1, because 1+Î²â‰¤21+\beta\leq 2,

|  |  |  |
| --- | --- | --- |
|  | âˆ«â„d|vt|1+Î²â€‹Ï†Tâ‰¤â€„1+âˆ«â„d|vt|2â€‹Ï†Tâ‰¤C,\int\_{\mathbb{R}^{d}}|v\_{t}|^{1+\beta}\,\varphi\_{T}\;\leq\;1+\int\_{\mathbb{R}^{d}}|v\_{t}|^{2}\,\varphi\_{T}\;\leq\;C, |  |

uniformly in tt. Choose Î´=Î²\delta=\beta (so Î´â‰¤1\delta\leq 1). Then

|  |  |  |
| --- | --- | --- |
|  | |Bt|â‰¤Câ€‹(|t|Î´+|t|Î´)=Câ€‹|t|Î²âŸ¶ 0.|B\_{t}|\;\leq\;C\,\big(|t|^{\delta}+|t|^{\delta}\big)\;=\;C\,|t|^{\beta}\ \longrightarrow\ 0. |  |

When Î²>1\beta>1, suppose that vâˆˆL1+Î²â€‹(Ï†T)â€‹andÂ â€‹vtâ†’vâ€‹Â inÂ â€‹L1+Î²v\in L^{1+\beta}(\varphi\_{T})\ \text{and }v\_{t}\to v\text{ in }L^{1+\beta}, then

|  |  |  |
| --- | --- | --- |
|  | sup0<tâ‰¤1â€–vtâ€–L1+Î²â€‹(Ï†T)<âˆ.\sup\_{0<t\leq 1}\ \|v\_{t}\|\_{L^{1+\beta}(\varphi\_{T})}\ <\ \infty. |  |

Therefore It,2â‰¤Câ€‹|t|Î²âˆ’Î´=Câ€‹|t|Î²âˆ’1+Îµâ†’0I\_{t,2}\leq C\,|t|^{\beta-\delta}=C\,|t|^{\beta-1+\varepsilon}\to 0 as tâ†“0t\downarrow 0. Hence

|  |  |  |
| --- | --- | --- |
|  | |Bt|â‰¤Câ€‹|t|Î´â€‹It,1+Câ€‹|t|Î´â€‹It,2â‰¤Câ€‹|t|Î´+Câ€‹|t|Î²âˆ’1+Îµâ†’tâ†“0 0,|B\_{t}|\ \leq\ C\,|t|^{\delta}\,I\_{t,1}\;+\;C\,|t|^{\delta}\,I\_{t,2}\ \leq\ C\,|t|^{\delta}\;+\;C\,|t|^{\beta-1+\varepsilon}\ \xrightarrow[t\downarrow 0]{}\ 0, |  |

since Î´=1âˆ’Îµâˆˆ(0,1)\delta=1-\varepsilon\in(0,1) and Î²âˆ’1+Îµ>0\beta-1+\varepsilon>0.

When Î²<0\beta<0, let t:=Ïƒâˆ’Tâ€‹Bt:=\sigma^{-T}B and pick any R>0R>0; then

|  |  |  |
| --- | --- | --- |
|  | Î¼(y)=ğ”¼[exp(âŸ¨t,yâŸ©âˆ’T2âˆ¥tâˆ¥2)]â‰¥â„™(âˆ¥tâˆ¥â‰¤R)exp(âˆ’Râˆ¥yâˆ¥âˆ’T2R2)=:c0eâˆ’Râ€‹â€–yâ€–.\mu(y)=\mathbb{E}\!\left[\exp\!\left(\langle t,y\rangle-\tfrac{T}{2}\|t\|^{2}\right)\right]\;\geq\;\mathbb{P}(\|t\|\leq R)\,\exp\!\left(-R\|y\|-\tfrac{T}{2}R^{2}\right)=:c\_{0}\,e^{-R\|y\|}. |  |

Hence, for Îµâˆˆ(0,c0)\varepsilon\in(0,c\_{0}),

|  |  |  |
| --- | --- | --- |
|  | {Î¼<Îµ}âŠ‚{â€–yâ€–>1Râ€‹logâ¡c0Îµ}.\{\mu<\varepsilon\}\ \subset\ \Big\{\|y\|>\tfrac{1}{R}\log\!\tfrac{c\_{0}}{\varepsilon}\Big\}. |  |

Since Ï†T\varphi\_{T} is a nondegenerate Gaussian measure, there are C1,C2>0C\_{1},C\_{2}>0 such that

|  |  |  |
| --- | --- | --- |
|  | Ï†Tâ€‹{Î¼<Îµ}â‰¤Ï†Tâ€‹(â€–yâ€–>1Râ€‹logâ¡c0Îµ)â‰¤C1â€‹expâ¡(âˆ’C2â€‹(logâ¡(1/Îµ))2).\varphi\_{T}\{\mu<\varepsilon\}\ \leq\ \varphi\_{T}\!\Big(\|y\|>\tfrac{1}{R}\log\!\tfrac{c\_{0}}{\varepsilon}\Big)\ \leq\ C\_{1}\,\exp\!\Big(-C\_{2}\,(\log(1/\varepsilon))^{2}\Big). |  |

We will also use that for any a>0a>0,

|  |  |  |
| --- | --- | --- |
|  | âˆ«{â€–yâ€–>L}eaâ€‹â€–yâ€–â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ†’Lâ†’âˆ 0,sinceÂ â€‹eaâ€‹â€–yâ€–â‰ªecâ€‹â€–yâ€–2â€‹for Gaussian tails.\int\_{\{\|y\|>L\}}e^{a\|y\|}\,\varphi\_{T}(y)\,dy\ \xrightarrow[L\to\infty]{}\ 0,\quad\text{since }\ e^{a\|y\|}\ll e^{c\|y\|^{2}}\ \text{for Gaussian tails}. |  |

For Îµ>0\varepsilon>0 define

|  |  |  |
| --- | --- | --- |
|  | gÎµâ€²â€‹(m):=ÎºÎ±â€‹(mâˆ¨Îµ)Î²,gÎµâ€‹(0):=gâ€‹(0),gÎµâ€‹(m):=gâ€‹(0)+âˆ«0mgÎµâ€²â€‹(u)â€‹ğ‘‘u,g^{\prime}\_{\varepsilon}(m):=\kappa\_{\alpha}\,(m\vee\varepsilon)^{\beta},\qquad g\_{\varepsilon}(0):=g(0),\quad g\_{\varepsilon}(m):=g(0)+\int\_{0}^{m}g^{\prime}\_{\varepsilon}(u)\,du, |  |

and set ğ’¯Îµâ€‹(h):=âˆ«gÎµâ€‹(h)â€‹Ï†T\mathcal{T}\_{\varepsilon}(h):=\int g\_{\varepsilon}(h)\,\varphi\_{T}.
For fixed Îµ>0\varepsilon>0, gÎµâ€²g^{\prime}\_{\varepsilon} is bounded and Lipschitz on [0,âˆ)[0,\infty), so the standard L2L^{2} chain rule gives

|  |  |  |
| --- | --- | --- |
|  | ğ’¯Îµâ€‹(Î¼+tâ€‹vt)âˆ’ğ’¯Îµâ€‹(Î¼)tâŸ¶âˆ«â„dgÎµâ€²(Î¼(y))v(y)Ï†T(y)dy=:ğ’¯Îµâ€²(Î¼)[v]asÂ tâ†“0,vtâ†’vÂ inÂ H.\frac{\mathcal{T}\_{\varepsilon}(\mu+tv\_{t})-\mathcal{T}\_{\varepsilon}(\mu)}{t}\ \longrightarrow\ \int\_{\mathbb{R}^{d}}g^{\prime}\_{\varepsilon}(\mu(y))\,v(y)\,\varphi\_{T}(y)\,dy=:\mathcal{T}^{\prime}\_{\varepsilon}(\mu)[v]\quad\text{as }t\downarrow 0,\ \ v\_{t}\to v\text{ in }H. |  |

For any vtâ†’vv\_{t}\to v in HH as tâ†“0t\downarrow 0,

|  |  |  |
| --- | --- | --- |
|  | ğ’¯â€‹(Î¼+tâ€‹vt)âˆ’ğ’¯â€‹(Î¼)tâˆ’âˆ«gâ€²â€‹(Î¼)â€‹vâ€‹Ï†T=E1,Îµ,t+E2,Îµ,t+E3,Îµ,\frac{\mathcal{T}(\mu+tv\_{t})-\mathcal{T}(\mu)}{t}-\int g^{\prime}(\mu)\,v\,\varphi\_{T}=E\_{1,\varepsilon,t}+E\_{2,\varepsilon,t}+E\_{3,\varepsilon}, |  |

where

|  |  |  |
| --- | --- | --- |
|  | E1,Îµ,t:=ğ’¯â€‹(Î¼+tâ€‹vt)âˆ’ğ’¯Îµâ€‹(Î¼+tâ€‹vt)t,E2,Îµ,t:=ğ’¯Îµâ€‹(Î¼+tâ€‹vt)âˆ’ğ’¯Îµâ€‹(Î¼)tâˆ’ğ’¯Îµâ€²â€‹(Î¼)â€‹[v],E3,Îµ:=ğ’¯Îµâ€²â€‹(Î¼)â€‹[v]âˆ’ğ’¯â€²â€‹(Î¼)â€‹[v].E\_{1,\varepsilon,t}:=\frac{\mathcal{T}(\mu+tv\_{t})-\mathcal{T}\_{\varepsilon}(\mu+tv\_{t})}{t},\ \ E\_{2,\varepsilon,t}:=\frac{\mathcal{T}\_{\varepsilon}(\mu+tv\_{t})-\mathcal{T}\_{\varepsilon}(\mu)}{t}-\mathcal{T}^{\prime}\_{\varepsilon}(\mu)[v],\ \ E\_{3,\varepsilon}:=\mathcal{T}^{\prime}\_{\varepsilon}(\mu)[v]-\mathcal{T}^{\prime}(\mu)[v]. |  |

For fixed Îµ>0\varepsilon>0, E2,Îµ,tâ†’0E\_{2,\varepsilon,t}\to 0 as tâ†“0t\downarrow 0.

On {Î¼+tâ€‹vtâ‰¥Îµ}\{\mu+tv\_{t}\geq\varepsilon\}, gÎµ=gg\_{\varepsilon}=g; on {Î¼+tâ€‹vt<Îµ}\{\mu+tv\_{t}<\varepsilon\} and for mâ‰¤Îµm\leq\varepsilon,
a direct computation shows |gâ€‹(m)âˆ’gÎµâ€‹(m)|â‰¤Câ€‹ÎµÎ²+1|g(m)-g\_{\varepsilon}(m)|\leq C\,\varepsilon^{\beta+1}.
Hence

|  |  |  |
| --- | --- | --- |
|  | |E1,Îµ,t|â‰¤Câ€‹ÎµÎ²+1|t|â€‹Ï†Tâ€‹(Î¼+tâ€‹|vt|<Îµ).|E\_{1,\varepsilon,t}|\ \leq\ \frac{C\,\varepsilon^{\beta+1}}{|t|}\,\varphi\_{T}(\mu+t|v\_{t}|<\varepsilon). |  |

Using {Î¼+tâ€‹|vt|<Îµ}âŠ‚{Î¼<2â€‹Îµ}âˆª{|t|â€‹|vt|>Îµ}\{\mu+t|v\_{t}|<\varepsilon\}\subset\{\mu<2\varepsilon\}\cup\{|t|\,|v\_{t}|>\varepsilon\} and Chebyshev,

|  |  |  |
| --- | --- | --- |
|  | Ï†Tâ€‹(Î¼+tâ€‹|vt|<Îµ)â‰¤Ï†Tâ€‹(Î¼<2â€‹Îµ)+|t|2Îµ2â€‹â€–vtâ€–22.\varphi\_{T}(\mu+t|v\_{t}|<\varepsilon)\ \leq\ \varphi\_{T}(\mu<2\varepsilon)+\frac{|t|^{2}}{\varepsilon^{2}}\,\|v\_{t}\|\_{2}^{2}. |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | |E1,Îµ,t|â‰¤Câ€‹{ÎµÎ²+1|t|â€‹eâˆ’C2â€‹(logâ¡(1/Îµ))2+|t|Îµ1âˆ’Î²}+oâ€‹(1)(tâ†“0).|E\_{1,\varepsilon,t}|\ \leq\ C\left\{\frac{\varepsilon^{\beta+1}}{|t|}\,e^{-C\_{2}(\log(1/\varepsilon))^{2}}+\frac{|t|}{\varepsilon^{1-\beta}}\right\}+o(1)\qquad(t\downarrow 0). |  |

Choose Îµ=Îµâ€‹(t):=|t|k\varepsilon=\varepsilon(t):=|t|^{k} with any kâˆˆ(0,11âˆ’Î²)k\in\big(0,\,\tfrac{1}{1-\beta}\big) (possible since Î²<0\beta<0).
Then |t|Îµ1âˆ’Î²=|t|â€‰1âˆ’kâ€‹(1âˆ’Î²)â†’0\frac{|t|}{\varepsilon^{1-\beta}}=|t|^{\,1-k(1-\beta)}\to 0, and the term with eâˆ’C2â€‹(logâ¡(1/Îµ))2e^{-C\_{2}(\log(1/\varepsilon))^{2}} also vanishes.

Next,

|  |  |  |
| --- | --- | --- |
|  | |E3,Îµ|=|âˆ«((Î¼âˆ¨Îµ)Î²âˆ’Î¼Î²)â€‹vâ€‹Ï†T|â‰¤â€–vâ€–2â€‹â€–((Î¼âˆ¨Îµ)Î²âˆ’Î¼Î²)â€‹ğŸ{Î¼<Îµ}â€–2.|E\_{3,\varepsilon}|=\left|\int\big((\mu\vee\varepsilon)^{\beta}-\mu^{\beta}\big)\,v\,\varphi\_{T}\right|\ \leq\ \|v\|\_{2}\,\Big\|\big((\mu\vee\varepsilon)^{\beta}-\mu^{\beta}\big)\mathbf{1}\_{\{\mu<\varepsilon\}}\Big\|\_{2}. |  |

On {Î¼<Îµ}\{\mu<\varepsilon\} we have (Î¼âˆ¨Îµ)Î²=ÎµÎ²â‰¤Î¼Î²(\mu\vee\varepsilon)^{\beta}=\varepsilon^{\beta}\leq\mu^{\beta} (since Î²<0\beta<0), so

|  |  |  |
| --- | --- | --- |
|  | â€–((Î¼âˆ¨Îµ)Î²âˆ’Î¼Î²)â€‹ğŸ{Î¼<Îµ}â€–2â‰¤â€–Î¼Î²â€‹â€‰1{Î¼<Îµ}â€–2=(âˆ«{Î¼<Îµ}Î¼â€‹(y)2â€‹Î²â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y)1/2.\Big\|\big((\mu\vee\varepsilon)^{\beta}-\mu^{\beta}\big)\mathbf{1}\_{\{\mu<\varepsilon\}}\Big\|\_{2}\ \leq\ \|\mu^{\beta}\,\mathbf{1}\_{\{\mu<\varepsilon\}}\|\_{2}=\left(\int\_{\{\mu<\varepsilon\}}\mu(y)^{2\beta}\,\varphi\_{T}(y)\,dy\right)^{\!1/2}. |  |

Using Î¼â€‹(y)â‰¥c0â€‹eâˆ’Râ€‹â€–yâ€–\mu(y)\geq c\_{0}e^{-R\|y\|}, we get Î¼â€‹(y)2â€‹Î²â‰¤c02â€‹Î²â€‹e|2â€‹Î²|â€‹Râ€‹â€–yâ€–\mu(y)^{2\beta}\leq c\_{0}^{2\beta}\,e^{\,|2\beta|R\|y\|}.
Together with {Î¼<Îµ}âŠ‚{â€–yâ€–>(1/R)â€‹logâ¡(c0/Îµ)}\{\mu<\varepsilon\}\subset\{\|y\|>(1/R)\log(c\_{0}/\varepsilon)\},

|  |  |  |
| --- | --- | --- |
|  | âˆ«{Î¼<Îµ}Î¼2â€‹Î²â€‹Ï†TâŸ¶ 0(Îµâ†“0),\int\_{\{\mu<\varepsilon\}}\mu^{2\beta}\,\varphi\_{T}\ \longrightarrow\ 0\qquad(\varepsilon\downarrow 0), |  |

hence E3,Îµâ†’0E\_{3,\varepsilon}\to 0.

Therefore with all cases,

|  |  |  |
| --- | --- | --- |
|  | ğ’¯â€‹(Î¼+tâ€‹vt)âˆ’ğ’¯â€‹(Î¼)tâŸ¶âˆ«â„dgâ€²â€‹(Î¼â€‹(y))â€‹vâ€‹(y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,\frac{\mathcal{T}(\mu+tv\_{t})-\mathcal{T}(\mu)}{t}\ \longrightarrow\ \int\_{\mathbb{R}^{d}}g^{\prime}(\mu(y))\,v(y)\,\varphi\_{T}(y)\,dy, |  |

which proves Hadamard differentiability of ğ’¯\mathcal{T} at Î¼\mu with derivative ğ’¯Î¼â€²â€‹(v)\mathcal{T}^{\prime}\_{\mu}(v) as claimed.
âˆ

By Lemmas [7](https://arxiv.org/html/2512.01408v1#Thmlemma7 "Lemma 7. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") and [8](https://arxiv.org/html/2512.01408v1#Thmlemma8 "Lemma 8. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), we have Fâ€‹(0)=Opâ€‹(nâˆ’1/2)F(0)=O\_{p}(n^{-1/2}) and the denominator converges to c>0c>0 in probability, and hence

|  |  |  |
| --- | --- | --- |
|  | â€–Î”âˆ—â€–n=Opâ€‹(1).\|\Delta^{\*}\|\_{n}=O\_{p}(1). |  |

### D.5 Part V

Now we solve the equation for a Î»\lambda with the remainder term Râ€‹(Î”)R(\Delta). We first redefine some notations for convenience.
Let

|  |  |  |
| --- | --- | --- |
|  | cÂ¯n:=1nâ€‹âˆ‘i=1nâ€–Ciâ€‹(n)â€–2,Î”â€‹(Î»)i:=Î»â€‹Ciâ€‹(n),Gnâ€‹(Î»):=Fâ€‹(0)+cÂ¯nnâ€‹Î»+Rnâ€‹(Î»),\bar{c}\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}\|C\_{i}(n)\|^{2},\qquad\Delta(\lambda)\_{i}:=\lambda\,C\_{i}(n),\qquad G\_{n}(\lambda):=F(0)+\frac{\bar{c}\_{n}}{\sqrt{n}}\,\lambda+R\_{n}(\lambda), |  |

where Rnâ€‹(Î»)R\_{n}(\lambda) is the Taylor remainder term. Therefore, cÂ¯nâ†’ğ‘c>0\bar{c}\_{n}\xrightarrow{p}c>0, nâ€‹Fâ€‹(0)=Opâ€‹(1)\sqrt{n}\,F(0)=O\_{p}(1), and for any fixed Mâ‰¥1M\geq 1 there exist random constants
K1,n,K2,n,K1,nâ€²=Opâ€‹(1)K\_{1,n},K\_{2,n},K^{\prime}\_{1,n}=O\_{p}(1) such that for all |Î»|â‰¤M|\lambda|\leq M,

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |Rnâ€‹(Î»)|\displaystyle|R\_{n}(\lambda)| | â‰¤K1,nâ€‹â€–Î”â€‹(Î»)â€–n2n+K2,nâ€‹(â€–Î”â€‹(Î»)â€–n2n)2,\displaystyle\leq K\_{1,n}\,\frac{\|\Delta(\lambda)\|\_{n}^{2}}{n}+K\_{2,n}\,\Big(\frac{\|\Delta(\lambda)\|\_{n}^{2}}{n}\Big)^{2}, |  | (56) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |Rnâ€‹(Î»1)âˆ’Rnâ€‹(Î»2)|\displaystyle|R\_{n}(\lambda\_{1})-R\_{n}(\lambda\_{2})| | â‰¤K1,nâ€²â€‹cÂ¯nnâ€‹(|Î»1|+|Î»2|)â€‹|Î»1âˆ’Î»2|for allÂ â€‹|Î»1|,|Î»2|â‰¤M,\displaystyle\leq K^{\prime}\_{1,n}\,\frac{\bar{c}\_{n}}{n}\,(\,|\lambda\_{1}|+|\lambda\_{2}|\,)\,|\lambda\_{1}-\lambda\_{2}|\qquad\text{for all }|\lambda\_{1}|,|\lambda\_{2}|\leq M, |  | (57) |

where â€–Î”â€‹(Î»)â€–n2=Î»2â€‹cÂ¯n\|\Delta(\lambda)\|\_{n}^{2}=\lambda^{2}\,\bar{c}\_{n}.
Define Tnâ€‹(Î»):=âˆ’nâ€‹Fâ€‹(0)+nâ€‹Rnâ€‹(Î»)cÂ¯nT\_{n}(\lambda):=-\dfrac{\sqrt{n}\,F(0)+\sqrt{n}\,R\_{n}(\lambda)}{\bar{c}\_{n}}. Since cÂ¯nâ†’ğ‘c>0\bar{c}\_{n}\xrightarrow{p}c>0 and nâ€‹Fâ€‹(0)=Opâ€‹(1)\sqrt{n}\,F(0)=O\_{p}(1), choose c0âˆˆ(0,c)c\_{0}\in(0,c) and K0>0K\_{0}>0 so that, for large nn, with probability â‰¥1âˆ’Îµ\geq 1-\varepsilon,
cÂ¯nâ‰¥c0\bar{c}\_{n}\geq c\_{0} and nâ€‹|Fâ€‹(0)|â‰¤K0\sqrt{n}\,|F(0)|\leq K\_{0}. For |Î»1|,|Î»2|â‰¤M|\lambda\_{1}|,|\lambda\_{2}|\leq M, by ([57](https://arxiv.org/html/2512.01408v1#A4.E57 "In D.5 Part V â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")),

|  |  |  |
| --- | --- | --- |
|  | |Tn(Î»1)âˆ’Tn(Î»2)|=ncÂ¯n|Rn(Î»1)âˆ’Rn(Î»2)|â‰¤2â€‹K1,nâ€²â€‹Mn|Î»1âˆ’Î»2|=:qn(M)|Î»1âˆ’Î»2|.|T\_{n}(\lambda\_{1})-T\_{n}(\lambda\_{2})|=\frac{\sqrt{n}}{\bar{c}\_{n}}|R\_{n}(\lambda\_{1})-R\_{n}(\lambda\_{2})|\leq\frac{2K^{\prime}\_{1,n}M}{\sqrt{n}}\,|\lambda\_{1}-\lambda\_{2}|=:q\_{n}(M)\,|\lambda\_{1}-\lambda\_{2}|. |  |

Since K1,nâ€²=Opâ€‹(1)K^{\prime}\_{1,n}=O\_{p}(1), qnâ€‹(M)â†’0q\_{n}(M)\to 0 in probability; hence for nn large enough, qnâ€‹(M)â‰¤12q\_{n}(M)\leq\tfrac{1}{2}, so TnT\_{n} is a contraction on [âˆ’M,M][-M,M].

Next, we show that TnT\_{n} maps [âˆ’M,M][-M,M] into itself with high probability. For |Î»|â‰¤M|\lambda|\leq M, using ([56](https://arxiv.org/html/2512.01408v1#A4.E56 "In D.5 Part V â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) and â€–Î”â€‹(Î»)â€–n2=Î»2â€‹cÂ¯n\|\Delta(\lambda)\|\_{n}^{2}=\lambda^{2}\bar{c}\_{n},

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Tnâ€‹(Î»)|\displaystyle|T\_{n}(\lambda)| | â‰¤nâ€‹|Fâ€‹(0)|cÂ¯n+ncÂ¯nâ€‹|Rnâ€‹(Î»)|\displaystyle\leq\frac{\sqrt{n}\,|F(0)|}{\bar{c}\_{n}}+\frac{\sqrt{n}}{\bar{c}\_{n}}|R\_{n}(\lambda)| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤K0c0+K1,nâ€‹M2n+K2,nâ€‹M4â€‹cÂ¯nn3/2=K0c0+opâ€‹(1).\displaystyle\leq\frac{K\_{0}}{c\_{0}}+\frac{K\_{1,n}M^{2}}{\sqrt{n}}+\frac{K\_{2,n}M^{4}\,\bar{c}\_{n}}{n^{3/2}}=\frac{K\_{0}}{c\_{0}}+o\_{p}(1). |  |

Choose Mâ‰¥2â€‹K0/c0M\geq 2K\_{0}/c\_{0}. Then Tnâ€‹([âˆ’M,M])âŠ†[âˆ’M,M]T\_{n}([-M,M])\subseteq[-M,M]. By Banach fixed point theorem, a unique fixed point Î»nâˆ—âˆˆ[âˆ’M,M]\lambda\_{n}^{\*}\in[-M,M] exists with Tnâ€‹(Î»nâˆ—)=Î»nâˆ—T\_{n}(\lambda\_{n}^{\*})=\lambda\_{n}^{\*}.
Hence â€–Î”âˆ—â€–n=|Î»nâˆ—|â€‹cÂ¯n1/2=Opâ€‹(1)\|\Delta^{\*}\|\_{n}=|\lambda\_{n}^{\*}|\,\bar{c}\_{n}^{1/2}=O\_{p}(1). Let

|  |  |  |
| --- | --- | --- |
|  | Î»nlin:=âˆ’nâ€‹Fâ€‹(0)/cÂ¯n,\lambda\_{n}^{\mathrm{lin}}:=-\sqrt{n}\,F(0)/\bar{c}\_{n}, |  |

then

|  |  |  |
| --- | --- | --- |
|  | Î»nâˆ—âˆ’Î»nlin=âˆ’nâ€‹Rnâ€‹(Î»nâˆ—)cÂ¯n=Opâ€‹(ncÂ¯nâ‹…(Î»nâˆ—)2â€‹cÂ¯nn)=Opâ€‹(nâˆ’1/2).\lambda\_{n}^{\*}-\lambda\_{n}^{\mathrm{lin}}=-\frac{\sqrt{n}\,R\_{n}(\lambda\_{n}^{\*})}{\bar{c}\_{n}}=O\_{p}\!\Big(\frac{\sqrt{n}}{\bar{c}\_{n}}\cdot\frac{(\lambda\_{n}^{\*})^{2}\bar{c}\_{n}}{n}\Big)=O\_{p}(n^{-1/2}). |  |

Hence, we have shown that for any fixed Îµ>0\varepsilon>0, there exists NÎµN\_{\varepsilon} such that for all nâ‰¥NÎµn\geq N\_{\varepsilon}, with probability at least 1âˆ’Îµ1-\varepsilon, there is a correction Î”=Î”n\Delta=\Delta\_{n} satisfying

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–Î”â€–n=Opâ€‹(1)andJâ€‹(â„™nÎ”)=Jâ€‹(â„™âˆ—).\|\Delta\|\_{n}=O\_{p}(1)\qquad\text{and}\qquad J(\mathbb{P}\_{n}^{\Delta})=J(\mathbb{P}^{\*}). |  | (58) |

Let EnE\_{n} be the event in ([58](https://arxiv.org/html/2512.01408v1#A4.E58 "In D.5 Part V â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")). We define a measurable choice to work on EnE\_{n} by

|  |  |  |
| --- | --- | --- |
|  | Î”^n:={Î”nonÂ â€‹En,0onÂ â€‹Enc.\widehat{\Delta}\_{n}\;:=\;\begin{cases}\Delta\_{n}&\text{on }E\_{n},\\ 0&\text{on }E\_{n}^{c}.\end{cases} |  |

By construction, â€–Î”^nâ€–n=Opâ€‹(1)\|\widehat{\Delta}\_{n}\|\_{n}=O\_{p}(1) and Jâ€‹(â„™nÎ”^n)=Jâ€‹(â„™âˆ—)J(\mathbb{P}\_{n}^{\widehat{\Delta}\_{n}})=J(\mathbb{P}^{\*}) on EnE\_{n}.
With the cost function cÏ„â€‹(Î”):=eÏ„â€‹â€–xâˆ’yâ€–22âˆ’â€„1c\_{\tau}(\Delta)\;:=\;e^{\,\tau\,\|x-y\|\_{2}^{2}}\;-\;1, couple BiB\_{i} with Bi+Î”^n,i/nB\_{i}+\widehat{\Delta}\_{n,i}/\sqrt{n}. Then with the notation mn=max1â‰¤iâ‰¤nâ¡â€–Î”^n,iâ€–22nm\_{n}=\max\_{1\leq i\leq n}\frac{\|\widehat{\Delta}\_{n,i}\|\_{2}^{2}}{n}, we have

|  |  |  |
| --- | --- | --- |
|  | Dcâ€‹(â„™n,â„™nÎ”^n)â‰¤Ï„nâ€‹âˆ‘i=1nâ€–Î”^n,inâ€–22â€‹eÏ„â€‹mn=Ï„â€‹â€–Î”^nâ€–n2nâ€‹eÏ„â€‹mn=opâ€‹(1),D\_{c}(\mathbb{P}\_{n},\mathbb{P}\_{n}^{\widehat{\Delta}\_{n}})\;\leq\;\frac{\tau}{n}\sum\_{i=1}^{n}\Big\|\frac{\widehat{\Delta}\_{n,i}}{\sqrt{n}}\Big\|\_{2}^{2}e^{\tau m\_{n}}=\frac{\tau\|\widehat{\Delta}\_{n}\|\_{n}^{2}}{n}e^{\tau m\_{n}}=o\_{p}(1), |  |

since â€–Î”^nâ€–n=Opâ€‹(1)\|\widehat{\Delta}\_{n}\|\_{n}=O\_{p}(1) and max1â‰¤iâ‰¤nâ¡â€–Î”^nâ€–2=Opâ€‹(n1/4)\max\_{1\leq i\leq n}\|\widehat{\Delta}\_{n}\|\_{2}=O\_{p}(n^{1/4}).

Then

|  |  |  |
| --- | --- | --- |
|  | Rnâ€‹(kâˆ—)â‰¤Dcâ€‹(â„™n,â„™nÎ”^n)and hencenâ€‹Rnâ€‹(kâˆ—)â‰¤Ï„â€‹â€–Î”^nâ€–n2â€‹(1+opâ€‹(1))=Opâ€‹(1).R\_{n}(k^{\*})\ \leq\ D\_{c}(\mathbb{P}\_{n},\mathbb{P}\_{n}^{\widehat{\Delta}\_{n}})\qquad\text{and hence}\qquad n\,R\_{n}(k^{\*})\ \leq\ \tau\|\widehat{\Delta}\_{n}\|\_{n}^{2}(1+o\_{p}(1))\;=\;O\_{p}(1). |  |

Write

|  |  |  |
| --- | --- | --- |
|  | Gi:=âˆ«gâ€²â€‹(Î±â€‹(y))â€‹âˆ‡bLTâ€‹(Bi,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘y,gn:=1nâ€‹âˆ‘i=1nâ€–Giâ€–22.G\_{i}\ :=\ \int g^{\prime}(\alpha(y))\,\nabla\_{b}L\_{T}(B\_{i},y)\,\varphi\_{T}(y)\,dy,\qquad g\_{n}:=\frac{1}{n}\sum\_{i=1}^{n}\|G\_{i}\|\_{2}^{2}. |  |

Since

|  |  |  |
| --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nGiâ‹…Î”i=1nâ€‹âˆ‘i=1nCiâ€‹(n)â‹…Î”i+1nâ€‹âˆ‘i=1n(Giâˆ’Ciâ€‹(n))â‹…Î”i,\frac{1}{n}\sum\_{i=1}^{n}G\_{i}\cdot\Delta\_{i}=\frac{1}{n}\sum\_{i=1}^{n}C\_{i}(n)\cdot\Delta\_{i}\;+\;\frac{1}{n}\sum\_{i=1}^{n}\bigl(G\_{i}-C\_{i}(n)\bigr)\cdot\Delta\_{i}, |  |

we have

|  |  |  |
| --- | --- | --- |
|  | |1nâ€‹âˆ‘i=1n(Giâˆ’Ciâ€‹(n))â‹…Î”i|â‰¤1nâ€‹âˆ‘i=1nâ€–Î”iâ€–2â€‹â€–âˆ«(gâ€²â€‹(mPnâ€‹(y))âˆ’gâ€²â€‹(Î±â€‹(y)))â€‹âˆ‡bLTâ€‹(Bi,y)â€‹Ï†Tâ€‹(y)â€‹ğ‘‘yâ€–2=opâ€‹(1).\Bigl|\frac{1}{n}\sum\_{i=1}^{n}\bigl(G\_{i}-C\_{i}(n)\bigr)\cdot\Delta\_{i}\Bigr|\leq\frac{1}{n}\sum\_{i=1}^{n}\|\Delta\_{i}\|\_{2}\,\Bigl\|\int\!\bigl(g^{\prime}(m\_{P\_{n}}(y))-g^{\prime}(\alpha(y))\bigr)\,\nabla\_{b}L\_{T}(B\_{i},y)\,\varphi\_{T}(y)\,dy\Bigr\|\_{2}=o\_{p}(1). |  |

Hence,

|  |  |  |
| --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nGiâ‹…Î”i=âˆ’nâ€‹Fâ€‹(0)+opâ€‹(1).\frac{1}{n}\sum\_{i=1}^{n}G\_{i}\cdot\Delta\_{i}=-\,\sqrt{n}\,F(0)\;+\;o\_{p}(1). |  |

By the HÃ¶lder inequality, the feasibility constraint is

|  |  |  |  |
| --- | --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nGiâ‹…Î”i=âˆ’nâ€‹Fâ€‹(0)+opâ€‹(1),\frac{1}{n}\sum\_{i=1}^{n}G\_{i}\cdot\Delta\_{i}\;=\;-\sqrt{n}\,F(0)\ +\ o\_{p}(1), |  | (59) |

and minimizing the quadratic surrogate cost 1nâ€‹âˆ‘â€–Î”i/nâ€–22\frac{1}{n}\sum\|\Delta\_{i}/\sqrt{n}\|\_{2}^{2} subject to ([59](https://arxiv.org/html/2512.01408v1#A4.E59 "In D.5 Part V â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections")) yields the candidate

|  |  |  |
| --- | --- | --- |
|  | Î”ilin:=âˆ’nâ€‹Fâ€‹(0)gnâ€‹Gi,i=1,â€¦,n.\;\;\Delta\_{i}^{\mathrm{lin}}\;:=\;-\,\frac{\sqrt{n}\,F(0)}{\,g\_{n}\,}\;G\_{i}\;,\;\;i=1,\dots,n. |  |

Then the feasibility constraint holds exactly:

|  |  |  |
| --- | --- | --- |
|  | 1nâ€‹âˆ‘i=1nGiâ‹…Î”ilin=âˆ’nâ€‹Fâ€‹(0)gnâ€‹1nâ€‹âˆ‘i=1nGiâ‹…Gi=âˆ’nâ€‹Fâ€‹(0)gnâ€‹1nâ€‹âˆ‘i=1nâ€–Giâ€–22=âˆ’nâ€‹Fâ€‹(0).\frac{1}{n}\sum\_{i=1}^{n}G\_{i}\cdot\Delta\_{i}^{\mathrm{lin}}=-\,\frac{\sqrt{n}\,F(0)}{g\_{n}}\,\frac{1}{n}\sum\_{i=1}^{n}G\_{i}\cdot G\_{i}=-\,\frac{\sqrt{n}\,F(0)}{g\_{n}}\,\frac{1}{n}\sum\_{i=1}^{n}\|G\_{i}\|\_{2}^{2}=-\,\sqrt{n}\,F(0). |  |

Moreover,

|  |  |  |
| --- | --- | --- |
|  | â€–Î”linâ€–n2:=1nâ€‹âˆ‘i=1nâ€–Î”ilinâ€–22=nâ€‹Fâ€‹(0)2gn2â‹…1nâ€‹âˆ‘i=1nâ€–Giâ€–22=nâ€‹Fâ€‹(0)2gn.\bigl\|\Delta^{\mathrm{lin}}\bigr\|\_{n}^{2}:=\frac{1}{n}\sum\_{i=1}^{n}\bigl\|\Delta\_{i}^{\mathrm{lin}}\bigr\|\_{2}^{2}=\frac{nF(0)^{2}}{g\_{n}^{2}}\cdot\frac{1}{n}\sum\_{i=1}^{n}\|G\_{i}\|\_{2}^{2}=\frac{nF(0)^{2}}{g\_{n}}. |  |

Using the remainder bounds from the Taylor expansion and the contraction mapping argument proved earlier,
the exact correction Î”^n\widehat{\Delta}\_{n} differs from Î”lin\Delta^{\mathrm{lin}} by opâ€‹(1)o\_{p}(1) in âˆ¥â‹…âˆ¥n\|\cdot\|\_{n},
and hence

|  |  |  |
| --- | --- | --- |
|  | nâ€‹Rnâ€‹(kâˆ—)â‰¤nâ€‹Dcâ€‹(â„™n,â„™nÎ”^n)=Ï„â€‹nâ€‹Fâ€‹(0)2gn+opâ€‹(1).n\,R\_{n}(k^{\*})\ \leq\ n\,D\_{c}(\mathbb{P}\_{n},\mathbb{P}\_{n}^{\widehat{\Delta}\_{n}})\ =\tau\frac{n\,F(0)^{2}}{g\_{n}}\ +\ o\_{p}(1). |  |

Then an application of Lemma [8](https://arxiv.org/html/2512.01408v1#Thmlemma8 "Lemma 8. â€£ D.4 Part IV â€£ Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections"), weak law of large numbers, and the continuous mapping theorem shows the asymptotic result on EnE\_{n}.

### D.6 Part VI

###### Lemma 10.

We define Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}, then the sub-Gaussian assumption to make all the lemmas in Section [D](https://arxiv.org/html/2512.01408v1#A4 "Appendix D Generalization of Nonlinear Projection Theorem with Non-compact Support â€£ Bayesian Distributionally Robust Merton Problem with Nonlinear Wasserstein Projections") all hold is there exists Î³0>0\gamma\_{0}>0 such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â„™âˆ—â€‹[expâ¡(Î³2â€‹â€–Bâ€–22)]<âˆfor everyÂ â€‹Î³<Î³0.\mathbb{E}\_{\mathbb{P}^{\*}}\big[\exp(\gamma^{2}\|B\|\_{2}^{2})\big]<\infty\quad\text{for every }\gamma<\gamma\_{0}. |  |

with

|  |  |  |
| --- | --- | --- |
|  | Î³02â€–Ïƒâˆ’1â€–F2>Tâ€‹maxâ¡{â€‰4â€‹Î²2âˆ’2â€‹Î²,2Î²âˆ’2, 16, 8â€‹Î²+8}.\frac{\gamma\_{0}^{2}}{\left\|\sigma^{-1}\right\|\_{F}^{2}}>T\max\Big\{\,4\beta^{2}-2\beta,\ \tfrac{2}{\beta-2},\ 16,\ 8\beta+8\,\Big\}. |  |

###### Proof.

It suffices to reduce the maximum

|  |  |  |
| --- | --- | --- |
|  | maxâ¡{2â€‹(2â€‹Î²2âˆ’Î²),2â€‹sâ€‹(2âˆ’1),2â€‹p2âˆ’p,16,8â€‹(1+Î²)}\max\left\{2(2\beta^{2}-\beta),2s(2-1),2p^{2}-p,16,8(1+\beta)\right\} |  |

with s=1pâˆ’1s=\frac{1}{p-1} and p=Î²âˆ’1p=\beta-1, where Î²=Î±1âˆ’Î±\beta=\frac{\alpha}{1-\alpha}.

Rewrite each term in Î²\beta:

|  |  |  |
| --- | --- | --- |
|  | 2â€‹(2â€‹Î²2âˆ’Î²)=4â€‹Î²2âˆ’2â€‹Î²,2â€‹sâ€‹(2âˆ’1)=2Î²âˆ’2,2â€‹p2âˆ’p=2â€‹(Î²âˆ’1)2âˆ’(Î²âˆ’1)=2â€‹Î²2âˆ’5â€‹Î²+3,2(2\beta^{2}-\beta)=4\beta^{2}-2\beta,\qquad 2s(2-1)=\frac{2}{\beta-2},\qquad 2p^{2}-p=2(\beta-1)^{2}-(\beta-1)=2\beta^{2}-5\beta+3, |  |

|  |  |  |
| --- | --- | --- |
|  | 8â€‹(1+Î²)=8â€‹Î²+8.\qquad 8(1+\beta)=8\beta+8. |  |

Hence

|  |  |  |
| --- | --- | --- |
|  | Mâ€‹(Î²)=maxâ¡{â€‰4â€‹Î²2âˆ’2â€‹Î²,2Î²âˆ’2, 2â€‹Î²2âˆ’5â€‹Î²+3, 16, 8â€‹Î²+8}.M(\beta)=\max\Big\{\,4\beta^{2}-2\beta,\ \tfrac{2}{\beta-2},\ 2\beta^{2}-5\beta+3,\ 16,\ 8\beta+8\,\Big\}. |  |

Note that

|  |  |  |
| --- | --- | --- |
|  | (4â€‹Î²2âˆ’2â€‹Î²)âˆ’(2â€‹Î²2âˆ’5â€‹Î²+3)=2â€‹Î²2+3â€‹Î²âˆ’3.(4\beta^{2}-2\beta)-(2\beta^{2}-5\beta+3)=2\beta^{2}+3\beta-3. |  |

The RHS is â‰¥0\geq 0 for Î²â‰¥Î²0:=âˆ’3+334â‰ˆ0.686\beta\geq\beta\_{0}:=\frac{-3+\sqrt{33}}{4}\approx 0.686. For 0<Î²â‰¤Î²00<\beta\leq\beta\_{0},
2â€‹Î²2âˆ’5â€‹Î²+3â‰¤3<162\beta^{2}-5\beta+3\leq 3<16
(since 2â€‹Î²2âˆ’5â€‹Î²+32\beta^{2}-5\beta+3 is strictly decreasing on (0,Î²0](0,\beta\_{0}]).
Therefore 2â€‹Î²2âˆ’5â€‹Î²+32\beta^{2}-5\beta+3 never attains the maximum on Î²>0\beta>0, and we may simplify to

|  |  |  |
| --- | --- | --- |
|  | Mâ€‹(Î²)=maxâ¡{â€‰4â€‹Î²2âˆ’2â€‹Î²,2Î²âˆ’2, 16, 8â€‹Î²+8}.M(\beta)=\max\Big\{\,4\beta^{2}-2\beta,\ \tfrac{2}{\beta-2},\ 16,\ 8\beta+8\,\Big\}. |  |

âˆ

Finally, suppose XnX\_{n} and YnY\_{n} are sequences of random variables such that
0â‰¤Xnâ‰¤Yn0\leq X\_{n}\leq Y\_{n} on the events EnE\_{n} which is true with probability 1 as nâ†’âˆn\to\infty. Hence, for any fixed Îµ>0\varepsilon>0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(Xnâ‰¥Îµ)\displaystyle\mathbb{P}\left(X\_{n}\geq\varepsilon\right) | =â„™â€‹(Xnâ‰¥Îµ,En)+â„™â€‹(Xnâ‰¥Îµ,Enc)\displaystyle=\mathbb{P}\left(X\_{n}\geq\varepsilon,E\_{n}\right)+\mathbb{P}\left(X\_{n}\geq\varepsilon,E\_{n}^{c}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤â„™â€‹(Ynâ‰¥Îµ,En)+â„™â€‹(Enc).\displaystyle\leq\mathbb{P}\left(Y\_{n}\geq\varepsilon,E\_{n}\right)+\mathbb{P}\left(E\_{n}^{c}\right). |  |

Hence, Yn=opâ€‹(1)Y\_{n}=o\_{p}(1) implies Xn=opâ€‹(1)X\_{n}=o\_{p}(1) and the same is for Opâ€‹(1)O\_{p}(1). If we let Xn=nâ€‹Rnâ€‹(kâˆ—)X\_{n}=n\,R\_{n}(k^{\*}) and Yn=Ï„â€‹nâ€‹Fâ€‹(0)2gn+opâ€‹(1)Y\_{n}=\tau\ \frac{n\,F(0)^{2}}{g\_{n}}\ +\ o\_{p}(1), then for any tâ‰¥0t\geq 0,

|  |  |  |
| --- | --- | --- |
|  | lim supnâ†’âˆâ„™â€‹(Xn>t)â‰¤â„™â€‹(Yn>t).\limsup\_{n\to\infty}\mathbb{P}\left(X\_{n}>t\right)\leq\mathbb{P}\left(Y\_{n}>t\right). |  |

Hence, the proof of the asymptotic stochastic upper bound is completed.