---
authors:
- Hanqing Jin
- Renyuan Xu
- Yanzhao Yang
doc_id: arxiv:2512.14991v1
family_id: arxiv:2512.14991
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes
url_abs: http://arxiv.org/abs/2512.14991v1
url_html: https://arxiv.org/html/2512.14991v1
venue: arXiv q-fin
version: 1
year: 2025
---


Hanqing Jin
Mathematical Institute, University of Oxford. Email: hanqing.jin@spc.ox.ac.uk and yanzhao.yang@merton.ox.ac.uk .
â€ƒâ€ƒ
Renyuan Xu
Department of Management Science and Engineering, Stanford University. R.X. is supported in part by the NSF CAREER Award DMS-2524465 and a gift fund from Point72. Email: renyuanxu@stanford.edu
â€ƒâ€ƒ
Yanzhao Yang 11footnotemark: 1

(December 17, 2025)

###### Abstract

We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewardsâ€”settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint stateâ€“action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

## 1 Introduction

Data-driven decision-making has emerged as a foundational paradigm in modern scientific and engineering disciplines, enabling systems to adapt and optimize behavior in complex, uncertain environments by learning from empirical evidence. In particular, reinforcement learning (RL) formalizes sequential decision-making under uncertainty as a mathematical framework involving agents interacting with unknown environments to maximize long-term cumulative reward. Applications range from robotics (Kober etÂ al., [2013](https://arxiv.org/html/2512.14991v1#bib.bib42); Zhao etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib66)) and autonomous systems (Kiran etÂ al., [2021](https://arxiv.org/html/2512.14991v1#bib.bib39); Shalev-Shwartz etÂ al., [2016](https://arxiv.org/html/2512.14991v1#bib.bib52)) to finance (Hambly etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib27)) and healthcare (Yu etÂ al., [2021](https://arxiv.org/html/2512.14991v1#bib.bib64)), especially in settings where traditional model-based methods may fail due to restrictive structural assumptions or limited flexibility.

The literature on RL theory has progressed through a structured hierarchy of assumptions on stateâ€“action spaces, beginning with finite (tabular) settings and extending toward infinite states/actions or continuous domains. Earlier seminal works focused on tabular MDPs with finite state-action spaces, where convergence and sample efficiency of model-free algorithms, such as Q-learning, are studied under exact representations (Auer etÂ al., [2008](https://arxiv.org/html/2512.14991v1#bib.bib2); Dayan and Watkins, [1992](https://arxiv.org/html/2512.14991v1#bib.bib16); Jaakkola etÂ al., [1993](https://arxiv.org/html/2512.14991v1#bib.bib32); Kakade, [2003](https://arxiv.org/html/2512.14991v1#bib.bib36)). These settings allow for strong performance guarantees using regret and PAC frameworks (Azar etÂ al., [2017](https://arxiv.org/html/2512.14991v1#bib.bib3); Dann etÂ al., [2017](https://arxiv.org/html/2512.14991v1#bib.bib15)). As attention shifted to large or continuous state spaces, linear function approximation has been introduced, preserving tractability while enabling generalization (Tsitsiklis and VanÂ Roy, [1996](https://arxiv.org/html/2512.14991v1#bib.bib57); Bertsekas and Tsitsiklis, [1996](https://arxiv.org/html/2512.14991v1#bib.bib6); Lazaric etÂ al., [2012](https://arxiv.org/html/2512.14991v1#bib.bib43)). These frameworks often retain finite action spaces and require bounded features or realizability assumptions. More recent work explores continuous or unbounded state spaces using either nonparametric techniques (e.g., nearest-neighbor methods (Jin etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib35))) or neural network approximations (Fan etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib21); Fu etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib23); Wang etÂ al., [2019](https://arxiv.org/html/2512.14991v1#bib.bib61)), though theoretical guarantees remain limited in the latter (in terms of the choice of network architectures). Finite action spaces remain the standard setting in theoretical RL studies, largely due to the combinatorial challenges posed by continuous action spaces, namely the interrelated difficulties in optimization, exploration, and representation. Only a few exceptions exist, such as studies focusing on problems with special structure (e.g., linear-quadratic regulators (Fazel etÂ al., [2018](https://arxiv.org/html/2512.14991v1#bib.bib22); Hambly etÂ al., [2021](https://arxiv.org/html/2512.14991v1#bib.bib26); Guo etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib25))) or those exploring discretization-based nonparametric methods, which include both uniform partitioning (Bayraktar and Kara, [2023](https://arxiv.org/html/2512.14991v1#bib.bib4); Kara and Yuksel, [2023](https://arxiv.org/html/2512.14991v1#bib.bib38)) and adaptive partitioning approaches (Dong etÂ al., [2019](https://arxiv.org/html/2512.14991v1#bib.bib18); Pazis and Parr, [2013](https://arxiv.org/html/2512.14991v1#bib.bib49); Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)). This progression of the theoretical RL literature reflects a trade-off between tractability and expressive power: tabular and linearly parameterized settings are more tractable for analysis, whereas generic continuous stateâ€“action spaces, though more general and practically important, remain less understood and less theoretically developed due to their complexity.

Many critical decision-making problems in finance, economics, and operations research involve unbounded, continuous state spaces, as well as continuous (often high-dimensional) action spaces, and unbounded reward functions. A central class of such problems arises in portfolio optimization, where agents take continuous actions by dynamically adjusting their wealth allocations across risky assets in response to evolving market conditions. These problems typically involve an unbounded and continuous state space, representing asset prices and wealth levels, and often feature unbounded reward (utility functions) subject to suitable growth conditions (Black and Litterman, [1992](https://arxiv.org/html/2512.14991v1#bib.bib9); Zhou and Li, [2000](https://arxiv.org/html/2512.14991v1#bib.bib67); He etÂ al., [2015](https://arxiv.org/html/2512.14991v1#bib.bib29)). Optimal execution and intraday trading problems are often formulated within a continuous state-action framework, as traders must balance market impact, adverse selection risk, and order flow dynamics in a tractable manner (Almgren and Chriss, [2001](https://arxiv.org/html/2512.14991v1#bib.bib1); Cartea etÂ al., [2015](https://arxiv.org/html/2512.14991v1#bib.bib13)). In dynamic hedging, particularly in incomplete markets or under stochastic volatility, agents must continuously adjust their positions to manage risk exposure (Carr etÂ al., [2001](https://arxiv.org/html/2512.14991v1#bib.bib12); Duffie etÂ al., [1997](https://arxiv.org/html/2512.14991v1#bib.bib20)). Credit risk and asset-liability management problems faced by banks, insurers, and pension funds also fall within this framework, as they involve dynamic decision-making under uncertainty, often with evolving and potentially unbounded risk profiles (Tektas etÂ al., [2005](https://arxiv.org/html/2512.14991v1#bib.bib56)). At a broader scale, macro-financial decisions (such as sovereign debt issuance and monetary policy under uncertainty) rely on models with unbounded, continuous spaces to capture long-term dynamics and structural risks (Blommestein and Turner, [2012](https://arxiv.org/html/2512.14991v1#bib.bib10); Du etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib19)).
Despite their importance, such settings remain less understood in the RL literature, particularly regarding algorithmic development and theoretical guarantees.

Motivated by these challenges, this work seeks to address the following open question:

* Can we design an adaptive partition scheme tailored to (unknown) high-dimensional diffusion processes and simultaneously learn the optimal policy efficiently within the RL framework?

### 1.1 Our work and contributions

We investigate the above-mentioned open question in a setting governed by diffusion-type dynamics over a finite time horizon, with an unbounded state space and a continuous action space. To facilitate learning, we consider a discrete-time Markov decision process (MDP) with Gaussian increments, serving as an approximation of continuous-time diffusion processes. Crucially, we allow the expected reward to exhibit polynomial growth, going beyond the standard bounded reward assumptions, which enables our framework to capture a broader class of real-world applications.

To address the challenges of unbounded state space, we localize the state space by restricting the learning to a bounded ball, whose radius is carefully chosen to control the ultimate regret. The learning algorithm operates in an episodic setting. Throughout the learning process, we maintain representative estimators of both the drift and volatility within each partition of the joint state-action space. These partitions are refined adaptively: when the estimated bias exceeds the statistical confidence of the representative estimators, the partition is subdivided. Using the estimated drift and volatility, we construct a Q-function and select actions based on the upper confidence bound of this function. Mathematically, we show that the proposed algorithm achieves a regret of order ğ’ª~â€‹(Hâ€‹K1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4))\tilde{\mathcal{O}}({H}K^{1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}}), with HH the horizon of the problem, KK the number of episodes, pp the highest bounded moments for the initial state distribution, m+1m+1 the order of reward polynomial growth, dğ’®d\_{\mathcal{S}} the dimension of state space and zmax,cz\_{\max,c} the worst-case zooming dimension over the entire horizon. Here, the zooming dimension quantifies problem benignness, with zmax,cz\_{\max,c} often much smaller than the joint state-action space dimension dğ’œ+dğ’®d\_{\mathcal{A}}+d\_{\mathcal{S}} for benign instances (Kleinberg etÂ al., [2019](https://arxiv.org/html/2512.14991v1#bib.bib41)).
The idea of adaptive partitioning is largely inspired by (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), which considers a markedly different settingâ€”namely, an MDP with a bounded state space and bounded rewards. Nevertheless, as pp tends to infinity, our regret order asymptotically approaches ğ’ª~â€‹(Hâ€‹Kzmax,c+1zmax,c+2)\tilde{\mathcal{O}}({H}K^{\frac{z\_{\max,c}+1}{z\_{\max,c}+2}}), which is consistent with the order established in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) in terms of the episodes number KK, despite the substantial differences in both the problem setting and the underlying technical analysis.

From a technical perspective, a key challenge lies in defining an appropriate notion of zooming dimension which affects the algorithm design and hyperparameter set-up. Unlike the classical zooming dimension defined for bounded state-action spaces, our setting requires a new formulation suited to unbounded state spaces, one that can be meaningfully linked to the regret analysis (see DefinitionÂ [5.15](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem15 "Definition 5.15 (Zooming dimension and maximum zooming dimension). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and the proof of LemmaÂ [5.17](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem17 "Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). Furthermore, as we aim to analyze regret in diffusion-type settings, our approach differs from that of (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), which characterizes the concentration of Markov transition kernels. Instead, we fully leverage the structure of the dynamics and derive concentration inequalities for the drift and volatility terms (see the proof of TheoremÂ [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In particular, deriving concentration inequalities for covariance matrices under only Lipschitz regularity of the volatility is challenging. To address this, we introduce and carefully analyze two intermediate terms (see ([4.2](https://arxiv.org/html/2512.14991v1#S4.E2 "In 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))). Moreover, to accommodate practical applications, we allow general reward functions with polynomial growth. This introduces additional challenges in estimator construction when the domain is unbounded (see ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))â€“([5.14](https://arxiv.org/html/2512.14991v1#S5.E14 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the proof of TheoremÂ [5.3](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem3 "Theorem 5.3. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). Finally, our regret analysis must also accommodate martingale difference terms that are unbounded, requiring concentration tools more sophisticated than the standard Azumaâ€“Hoeffding inequality (see the proof of TheoremÂ [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

### 1.2 Closely related literature

##### Uniform partition and adaptive partition.

Uniform partitioning or discretization is a straightforward nonparametric approach for continuous-state problems (Bayraktar and Kara, [2023](https://arxiv.org/html/2512.14991v1#bib.bib4); Kara and Yuksel, [2023](https://arxiv.org/html/2512.14991v1#bib.bib38)). However, these methods may suffer from the curse of dimensionality: fine grids are computationally intensive, whereas coarse grids produce inaccurate results and numerical instability (Zhang and Suen, [2025](https://arxiv.org/html/2512.14991v1#bib.bib65)), limiting their effectiveness in higher dimensions. For example, value iteration has a per-iteration complexity of ğ’ªâ€‹(|ğ’®|2â€‹|ğ’œ|)\mathcal{O}(|\mathcal{S}|^{2}|\mathcal{A}|), and policy iteration requires ğ’ªâ€‹(|ğ’®|3+|ğ’®|2â€‹|ğ’œ|)\mathcal{O}(|\mathcal{S}|^{3}+|\mathcal{S}|^{2}|\mathcal{A}|) per iteration (Puterman, [2014](https://arxiv.org/html/2512.14991v1#bib.bib50)), with |ğ’®||\mathcal{S}| and |ğ’œ||\mathcal{A}| denoting the size of discretized state and action spaces respectively. Moreover, uniform schemes are often suboptimal due to heterogeneous state visit frequenciesâ€”leading to wasted resolution on rarely visited states and insufficient resolution where it matters most. The challenge intensifies in unbounded state spaces, such as those arising in diffusion processes with applications in finance, physics, and engineering. In these settings, discretization typically requires domain truncation, which introduces bias, while extending grids to the full space is computationally prohibitive. Scalable and principled methods for such domains remain largely unresolved.

Adaptive partition in RL addresses the inefficiency of uniform grids by refining the state-action spaces only where needed. Early methods, such as U-Tree (McCallum, [1996](https://arxiv.org/html/2512.14991v1#bib.bib44)) and variable-resolution discretization (Munos and Moore, [2002](https://arxiv.org/html/2512.14991v1#bib.bib45)), focused on adaptively partitioning the state space based on visitation frequency or value approximation error. Subsequent works incorporated function approximation and confidence bounds to guide refinement more systematically (Strehl and Littman, [2006](https://arxiv.org/html/2512.14991v1#bib.bib55); Munos and SzepesvÃ¡ri, [2008](https://arxiv.org/html/2512.14991v1#bib.bib46); Ortner etÂ al., [2014](https://arxiv.org/html/2512.14991v1#bib.bib48)). While some algorithms extend adaptivity to continuous action spaces under smoothness assumptions (Pazis and Parr, [2013](https://arxiv.org/html/2512.14991v1#bib.bib49); Dong etÂ al., [2019](https://arxiv.org/html/2512.14991v1#bib.bib18)), jointly handling continuous, high-dimensional state-action spaces, especially under complex dynamics, remains a major challenge. A notable recent exception is (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), which proposes an adaptive partitioning method for MDPs with bounded, continuous state-action spaces.

##### Zooming algorithms.

The use of zooming algorithms for adaptive partitioning was initially developed in the contextual multi-armed bandits (MAB) literature, particularly for problems with Lipschitz structure. (Kleinberg etÂ al., [2008](https://arxiv.org/html/2512.14991v1#bib.bib40)) introduced a zooming algorithm for adaptive exploration and defined the zooming dimension to quantify the complexity of such problems. Building on this, (Slivkins, [2011](https://arxiv.org/html/2512.14991v1#bib.bib54)) extended the approach to contextual bandits, proposing a zooming algorithm for adaptive partitioning of the context-action space and analyzing its regret.

These ideas were later generalized to RL by (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), who studied adaptive partition in finite-horizon RL with bounded state-action spaces, assuming a bounded reward function. They proposed both model-free and model-based algorithms and provided unified regret bounds. The model-free variant achieves a regret of order ğ’ª~â€‹(H52â€‹Kzmax,câ€²+1zmax,câ€²+2)\tilde{\mathcal{O}}\Big(H^{\frac{5}{2}}K^{\frac{{z^{\prime}\_{\max,c}}+1}{{z^{\prime}\_{\max,c}}+2}}\Big), while the model-based variant achieves ğ’ª~â€‹(H52â€‹Kzmax,câ€²+dğ’®âˆ’1zmax,câ€²+dğ’®)\tilde{\mathcal{O}}\Big(H^{\frac{5}{2}}K^{\frac{{z^{\prime}\_{\max,c}}+d\_{\mathcal{S}}-1}{{z^{\prime}\_{\max,c}}+d\_{\mathcal{S}}}}\Big) when dğ’®>2d\_{\mathcal{S}}>2 and ğ’ª~â€‹(H52â€‹Kzmax,câ€²+1zmax,câ€²+2)\tilde{\mathcal{O}}\Big(H^{\frac{5}{2}}K^{\frac{{z^{\prime}\_{\max,c}}+1}{{z^{\prime}\_{\max,c}}+2}}\Big) when dğ’®â‰¤2d\_{\mathcal{S}}\leq 2, where zmax,câ€²z^{\prime}\_{\max,c} denotes the worst-case zooming dimension under bounded state assumptions. These algorithms inspire the design of our framework, though our setting departs from theirs in several important ways.
More recently, (Kar and Singh, [2024](https://arxiv.org/html/2512.14991v1#bib.bib37)) proposed adaptive partitioning algorithms for non-episodic RL with infinite time horizons, under an ergodicity assumption. Their model-based algorithm attains a regret bound of order ğ’ª~â€‹(T1âˆ’12â€‹dğ’®+z+3)\tilde{\mathcal{O}}\left(T^{1-\frac{1}{2d\_{\mathcal{S}}+z+3}}\right), where TT denotes the total number of decision steps, dğ’®d\_{\mathcal{S}} is the dimension of the state space, and zz is the zooming dimension tailored to their setting.

##### Continuous-time RL under diffusion processes.

As our study concerns diffusion-type dynamics in discrete time, it naturally relates to the literature on RL with system dynamics governed by continuous-time diffusion processes. Recent contributions in this area, such as (Wang etÂ al., [2020](https://arxiv.org/html/2512.14991v1#bib.bib60); Jia and Zhou, [2023](https://arxiv.org/html/2512.14991v1#bib.bib34); Dai etÂ al., [2025](https://arxiv.org/html/2512.14991v1#bib.bib14); Jia and Zhou, [2022](https://arxiv.org/html/2512.14991v1#bib.bib33); Huang etÂ al., [2025](https://arxiv.org/html/2512.14991v1#bib.bib31); Han etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib28)), provide elegant mathematical frameworks and demonstrate substantial algorithmic progress. At the same time, aspects such as sample complexity or regret guarantees at the implementation levelâ€”particularly in terms of the number of observations collected from the environmentâ€”are typically not the primary focus of these works. In addition, theoretical treatments of unbounded stateâ€“action spaces and of implementable sampling schemes for general (non-Gaussian) policies over such spaces remain relatively limited. Addressing these issues constitutes one of the main focuses of our work.

This paper is organized as follows. Section [2](https://arxiv.org/html/2512.14991v1#S2 "2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") introduces the mathematical formulation of the problem, and Section [3](https://arxiv.org/html/2512.14991v1#S3 "3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") presents the design of our algorithm. We then turn to the technical developments: Section [4](https://arxiv.org/html/2512.14991v1#S4 "4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") establishes concentration inequalities for the estimators used in the algorithm, while Section [5](https://arxiv.org/html/2512.14991v1#S5 "5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") provides the regret analysis. Finally, Section [6](https://arxiv.org/html/2512.14991v1#S6 "6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") evaluates the algorithmâ€™s performance through some numerical experiments.

## 2 Mathematical set-up

To facilitate learning and implementation, we consider a discrete-time Markov decision process (MDP) with Gaussian increments fully characterized by (â„dğ’®,ğ’œ,H,Î¼,Ïƒ)(\mathbb{R}^{d\_{\mathcal{S}}},\mathcal{A},H,\mu,\sigma), serving as an approximation of continuous-time diffusion processes. Here HH is the number of timestamps indexed in each episode, with [H]={1,2,â‹¯,H}[H]=\{1,2,\cdots,H\}. In addition, â„dğ’®\mathbb{R}^{d\_{\mathcal{S}}} denotes the state space with dimension dğ’®âˆˆâ„•+d\_{\mathcal{S}}\in\mathbb{N}\_{+}, equipped with metric ğ’Ÿğ’®\mathcal{D}\_{\mathcal{S}}. ğ’œ\mathcal{A} is the action/control space equipped with metric ğ’Ÿğ’œ\mathcal{D}\_{\mathcal{A}}. For analytical convenience, we assume that ğ’œ\mathcal{A} is a closed hypercube in â„dğ’œ\mathbb{R}^{d\_{\mathcal{A}}} whose center is 0 and diamâ€‹(ğ’œ)=2â€‹aÂ¯>0{\rm diam}(\mathcal{A})=2\bar{a}>0. For the joint state-action space â„dğ’®Ã—ğ’œ\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}, we define the metric
ğ’Ÿâ€‹((x,a),(xâ€²,aâ€²))=(ğ’Ÿğ’®â€‹(x,xâ€²))2+(ğ’Ÿğ’œâ€‹(a,aâ€²))2\mathcal{D}((x,a),(x^{\prime},a^{\prime}))=\sqrt{(\mathcal{D}\_{\mathcal{S}}(x,x^{\prime}))^{2}+(\mathcal{D}\_{\mathcal{A}}(a,a^{\prime}))^{2}} for (x,a),(xâ€²,aâ€²)âˆˆâ„dğ’®Ã—ğ’œ(x,a),(x^{\prime},a^{\prime})\in\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}. To ease the notation, we denote by âˆ¥.âˆ¥\|.\| the â„“2\ell\_{2} norm, unless specified otherwise.

The state transition are governed by a collection of drift and volatility terms Î¼:={Î¼hâ€‹(x,a)}hâˆˆ[Hâˆ’1]{\mu}:=\{\mu\_{h}(x,a)\}\_{h\in[H-1]} and Ïƒ:={Ïƒhâ€‹(x,a)}hâˆˆ[Hâˆ’1]\sigma:=\{\sigma\_{h}(x,a)\}\_{h\in[H-1]}, with Î¼h:â„dğ’®Ã—ğ’œâ†¦â„dğ’®\mu\_{h}:\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}\mapsto\mathbb{R}^{d\_{\mathcal{S}}} and Ïƒh:â„dğ’®Ã—ğ’œâ†¦â„dğ’®Ã—dğ’®\sigma\_{h}:\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}\mapsto\mathbb{R}^{d\_{\mathcal{S}}\times d\_{\mathcal{S}}}. Mathematically, for hâˆˆ[Hâˆ’1]h\in[H-1], the state process follows:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Xh+1âˆ’Xh\displaystyle X\_{h+1}-X\_{h} | =\displaystyle= | Î¼hâ€‹(Xh,Ah)â€‹Î”+Ïƒhâ€‹(Xh,Ah)â€‹Bhâ€‹Î”,\displaystyle\mu\_{h}(X\_{h},A\_{h})\Delta+\sigma\_{h}(X\_{h},A\_{h})B\_{h}\sqrt{\Delta}, |  | (2.1) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | X1\displaystyle X\_{1} | =\displaystyle= | Î¾,\displaystyle\xi, |  |

where Î”>0\Delta>0 is the time-increment between two consecutive time stamps, BhB\_{h} are i.i.d. samples from the multi-variate Gaussian distribution ğ’©â€‹(0,Idğ’®)\mathcal{N}(0,I\_{d\_{\mathcal{S}}}) and Î¾\xi is independently sampled from an initial distribution Î\Xi. Note that ([2.1](https://arxiv.org/html/2512.14991v1#S2.E1 "In 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) can be viewed as a controlled diffusion process discretized in time.
We further denote the transition kernel of the dynamics as Th(â‹…|x,a)âˆˆğ’«(â„dğ’®)T\_{h}(\cdot|x,a)\in\mathcal{P}(\mathbb{R}^{d\_{\mathcal{S}}}) conditioned on Xh=x,Ah=aX\_{h}=x,A\_{h}=a. Clearly, for non-degenerate Ïƒhâ€‹(x,a)\sigma\_{h}(x,a), we have Th(â‹…|x,a)=ğ’©(Î¼h(x,a)Î”,Î£h(x,a)Î”)T\_{h}(\cdot|x,a)=\mathcal{N}\Big(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta\Big), where Î£hâ€‹(x,a)=Ïƒhâ€‹(x,a)â€‹ÏƒhâŠ¤â€‹(x,a)\Sigma\_{h}(x,a)=\sigma\_{h}(x,a)\sigma\_{h}^{\top}(x,a).

At timestamp hh, given state Xh=xX\_{h}=x and after taking an action Ah=aA\_{h}=a, the agent receives an instantaneous stochastic reward rhâ€‹(x,a)r\_{h}(x,a), which is drawn from a distribution Rh:â„dğ’®Ã—ğ’œâ†¦ğ’«â€‹(â„)R\_{h}:\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}\mapsto{\mathcal{P}(\mathbb{R})}. We let R={Rh}hâˆˆ[H]R=\{R\_{h}\}\_{h\in[H]} denote the collection of reward distributions and let RÂ¯hâ€‹(x,a)=ğ”¼rhâˆ¼Rhâ€‹(x,a)â€‹[rh]\bar{R}\_{h}(x,a)=\mathbb{E}\_{r\_{h}\sim R\_{h}(x,a)}[r\_{h}] be the mean-reward at timestamp hh under the state-action pair (x,a)(x,a).

The agent interacts with the environment (â„dğ’®,ğ’œ,H,Î¼,Ïƒ,R)(\mathbb{R}^{d\_{\mathcal{S}}},\mathcal{A},H,\mu,\sigma,R) by taking actions according to a (randomized) control policy Ï€\pi. Such a policy is specified by a collection of distributions Ï€={Ï€h}hâˆˆ[H]\pi=\{\pi\_{h}\}\_{h\in[H]}, where each timestamp-hh component Ï€h:â„dğ’®â†¦ğ’«â€‹(ğ’œ)\pi\_{h}:\mathbb{R}^{d\_{\mathcal{S}}}\mapsto\mathcal{P}(\mathcal{A}) maps a given state xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}}
to a distribution over the action space ğ’œ\mathcal{A}. In the control literature, this is also referred to as a mixed control strategy (Yong and Zhou, [1999](https://arxiv.org/html/2512.14991v1#bib.bib63)).

### 2.1 Value function, Bellman equations and evaluation criterion

##### Bellman equation for generic policy.

For any policy Ï€\pi, we define the policy value function under a given policy Ï€\pi as

|  |  |  |
| --- | --- | --- |
|  | VhÏ€â€‹(x):=ğ”¼â€‹[âˆ‘hâ€²=hHrhâ€²|Xh=x]â€‹Â subject toÂ â€‹rhâ€²âˆ¼Rhâ€²â€‹(Xhâ€²,Ahâ€²Ï€)â€‹Â andÂ â€‹Ahâ€²Ï€âˆ¼Ï€hâ€²â€‹(Xhâ€²).\displaystyle V\_{h}^{\pi}(x):=\mathbb{E}\Bigg[\sum\_{h^{\prime}=h}^{H}r\_{h^{\prime}}\Bigg|X\_{h}=x\Bigg]\mbox{ subject to }r\_{h^{\prime}}\sim R\_{h^{\prime}}(X\_{h^{\prime}},A\_{h^{\prime}}^{\pi})\mbox{ and }A^{\pi}\_{h^{\prime}}\sim\pi\_{h^{\prime}}(X\_{h^{\prime}}). |  |

Similarly, we define the state-action value function (or Q-function) QhÏ€:â„dğ’®Ã—ğ’œâ†¦â„Q\_{h}^{\pi}:\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}\mapsto\mathbb{R} as

|  |  |  |
| --- | --- | --- |
|  | QhÏ€(x,a):=RÂ¯h(x,a)+ğ”¼[âˆ‘hâ€²=h+1Hrhâ€²|Xh+1âˆ¼Th(â‹…|x,a)],\displaystyle Q\_{h}^{\pi}(x,a):=\bar{R}\_{h}(x,a)+\mathbb{E}\left[\sum\_{h^{\prime}=h+1}^{H}r\_{h^{\prime}}\,\Bigg|\,X\_{h+1}\sim T\_{h}(\cdot|x,a)\right], |  |

subject to rhâ€²âˆ¼Rhâ€²â€‹(Xhâ€²,Ahâ€²Ï€)r\_{h^{\prime}}\sim R\_{h^{\prime}}(X\_{h^{\prime}},A\_{h^{\prime}}^{\pi}) and Ahâ€²Ï€âˆ¼Ï€hâ€²â€‹(Xhâ€²)A^{\pi}\_{h^{\prime}}\sim\pi\_{h^{\prime}}(X\_{h^{\prime}}). Intuitively, QhÏ€â€‹(x,a)Q\_{h}^{\pi}(x,a) is the value of taking action aa in state xx at timestamp hh and playing according to policy Ï€\pi thereafter.

For a generic randomized policy Ï€={Ï€h}hâˆˆ[H]\pi=\{\pi\_{h}\}\_{h\in[H]}, the associated action-value function QÏ€Q^{\pi} and value function VÏ€V^{\pi} satisfy the Bellman equations (Puterman, [2014](https://arxiv.org/html/2512.14991v1#bib.bib50)). Specifically, for any xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}} and ğ’œ\mathcal{A},

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VhÏ€â€‹(x)\displaystyle V\_{h}^{\pi}(x) | =\displaystyle= | ğ”¼aâˆ¼Ï€hâ€‹(x)â€‹[QhÏ€â€‹(x,a)],\displaystyle\mathbb{E}\_{a\sim\pi\_{h}(x)}\Big[Q\_{h}^{\pi}(x,a)\Big], |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QhÏ€â€‹(x,a)\displaystyle Q\_{h}^{\pi}(x,a) | =\displaystyle= | RÂ¯hâ€‹(x,a)+ğ”¼Xh+1âˆ¼Th(â‹…|x,a),aâ€²âˆ¼Ï€h+1(Xh+1)â€‹[Qh+1Ï€â€‹(Xh+1,aâ€²)],\displaystyle\bar{R}\_{h}(x,a)+\mathbb{E}\_{X\_{h+1}\sim T\_{h}(\cdot|x,a),a^{\prime}\sim\pi\_{h+1}(X\_{h+1})}\Big[Q\_{h+1}^{\pi}(X\_{h+1},a^{\prime})\Big], |  |

with terminal condition VH+1Ï€â€‹(x)=0V\_{H+1}^{\pi}(x)=0 and QH+1Ï€â€‹(x,a)=0Q\_{H+1}^{\pi}(x,a)=0. As a consequence, we have for hâˆˆ[H]h\in[H] and xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}},

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VhÏ€â€‹(x)\displaystyle V\_{h}^{\pi}(x) | =ğ”¼aâˆ¼Ï€hâ€‹(x)â€‹[RÂ¯hâ€‹(x,a)]+ğ”¼Xh+1âˆ¼Th(â‹…|x,a),aâˆ¼Ï€h(x)â€‹[Vh+1Ï€â€‹(Xh+1)].\displaystyle=\mathbb{E}\_{a\sim\pi\_{h}(x)}\Big[\bar{R}\_{h}(x,a)\Big]+\mathbb{E}\_{X\_{h+1}\sim T\_{h}(\cdot|x,a),a\sim\pi\_{h}(x)}\Big[V\_{h+1}^{\pi}(X\_{h+1})\Big]. |  |  |

##### Bellman equation for optimal policy.

The optimal value function is defined as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Vhâˆ—â€‹(x)=supÏ€VhÏ€â€‹(x).\displaystyle V\_{h}^{\*}(x)=\sup\_{\pi}V\_{h}^{\pi}(x). |  | (2.2) |

The corresponding Bellman equation for the optimal value function is defined as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Vhâˆ—â€‹(x)=supaâˆˆğ’œ{RÂ¯hâ€‹(x,a)+ğ”¼Xâ€²âˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(Xâ€²)]},\displaystyle V\_{h}^{\*}(x)=\sup\_{a\in\mathcal{A}}\Big\{\bar{R}\_{h}(x,a)+\mathbb{E}\_{X^{\prime}\sim T\_{h}(\cdot|x,a)}\Big[V\_{h+1}^{\*}(X^{\prime})\Big]\Big\}, |  | (2.3) |

with terminal condition VH+1âˆ—â€‹(x)=0V^{\*}\_{H+1}(x)=0. We write the value function as

|  |  |  |
| --- | --- | --- |
|  | Vhâˆ—â€‹(x)=supaâˆˆğ’œQhâˆ—â€‹(x,a)\displaystyle V\_{h}^{\*}(x)=\sup\_{a\in\mathcal{A}}Q\_{h}^{\*}(x,a) |  |

where the Qhâˆ—Q^{\*}\_{h} function is defined to be

|  |  |  |  |
| --- | --- | --- | --- |
|  | Qhâˆ—â€‹(x,a)=RÂ¯hâ€‹(x,a)+ğ”¼Xâ€²âˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(Xâ€²)].\displaystyle Q^{\*}\_{h}(x,a)=\bar{R}\_{h}(x,a)+\mathbb{E}\_{X^{\prime}\sim T\_{h}(\cdot|x,a)}\Big[V\_{h+1}^{\*}(X^{\prime})\Big]. |  | (2.4) |

There is also a Bellman equation for the Qâˆ—Q^{\*}-function given by

|  |  |  |
| --- | --- | --- |
|  | Qhâˆ—â€‹(x,a)=RÂ¯hâ€‹(x,a)+ğ”¼Xâ€²âˆ¼Th(â‹…|x,a)â€‹[supaâ€²âˆˆğ’œQh+1âˆ—â€‹(Xâ€²,aâ€²)].\displaystyle Q^{\*}\_{h}(x,a)=\bar{R}\_{h}(x,a)+\mathbb{E}\_{X^{\prime}\sim T\_{h}(\cdot|x,a)}\Big[\sup\_{a^{\prime}\in\mathcal{A}}Q\_{h+1}^{\*}(X^{\prime},a^{\prime})\Big]. |  |

##### Objective and evaluation criterion.

It is well known in the literature that for the MDP problem ([2.2](https://arxiv.org/html/2512.14991v1#S2.E2 "In Bellman equation for optimal policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) with a closed and bounded action space, there always exists an optimal policy that is deterministic (Puterman, [2014](https://arxiv.org/html/2512.14991v1#bib.bib50)). Specifically, Ï€âˆ—={Ï€hâˆ—}hâˆˆ[H]\pi^{\*}=\{\pi\_{h}^{\*}\}\_{h\in[H]}, where each Ï€hâˆ—â€‹(x)=Î´ahâˆ—â€‹(x)â€‹(â‹…)\pi\_{h}^{\*}(x)=\delta\_{a^{\*}\_{h}(x)}(\cdot) is a Dirac measure concentrated on some action ahâˆ—â€‹(x)âˆˆğ’œa\_{h}^{\*}(x)\in\mathcal{A}. In this case, when no ambiguity arises, we simply write Ï€hâˆ—â€‹(x)=ahâˆ—â€‹(x)\pi\_{h}^{\*}(x)=a^{\*}\_{h}(x) and refer to {ahâˆ—â€‹(x)}hâˆˆ[H]\{a^{\*}\_{h}(x)\}\_{h\in[H]} as the optimal deterministic policy (which may not be unique). Throughout the remainder of the paper, the term optimal policy will always refer to the optimal deterministic policy.

The goal is to design an algorithm that generates a sequence of randomized policies through interaction with the environment. The objective is that, as the episodes progress, the output policies improve in the sense that their corresponding value functions approach the optimal value function. To quantify the performance of such an algorithm, we introduce the notion of regret, defined as follows.

###### Definition 2.1.

For an algorithm deploying a sequence of policies {Ï€k}kâˆˆ[K]\{\pi\_{k}\}\_{k\in[K]} with a given sequences of initial states {X1k}kâˆˆ[K]\{X\_{1}^{k}\}\_{k\in[K]}, define the regret as

|  |  |  |
| --- | --- | --- |
|  | Regretâ€‹(K):=âˆ‘k=1K(V1âˆ—â€‹(X1k)âˆ’V1Ï€kâ€‹(X1k)).\displaystyle{\rm Regret}(K):=\sum\_{k=1}^{K}\Big(V\_{1}^{\*}(X\_{1}^{k})-V\_{1}^{\pi\_{k}}(X\_{1}^{k})\Big). |  |

### 2.2 Outstanding assumptions

In this subsection, we list the outstanding assumptions used throughout the paper. Specifially, we assume that Î¼h\mu\_{h}, Ïƒh\sigma\_{h}, and RÂ¯h\bar{R}\_{h} satisfy (local) Lipschitz continuity, and that the distribution Rhâ€‹(x,a)R\_{h}(x,a) exhibits sub-Gaussian tail decay, which are standard assumptions in the control and RL literature (see (Yong and Zhou, [1999](https://arxiv.org/html/2512.14991v1#bib.bib63)) and (Bubeck etÂ al., [2011](https://arxiv.org/html/2512.14991v1#bib.bib11)) for example).

###### Assumption 2.1 (Regularity of the dynamics).

Assume there exists constants â„“Î¼,â„“Ïƒ>0\ell\_{\mu},\ell\_{\sigma}>0, mâˆˆâ„•m\in\mathbb{N} and L0>0L\_{0}>0 such that for all hâˆˆ[Hâˆ’1]h\in[H-1], x1,x2âˆˆâ„dğ’®x\_{1},x\_{2}\in\mathbb{R}^{d\_{\mathcal{S}}}, and a1,a2âˆˆğ’œa\_{1},a\_{2}\in\mathcal{A}, it holds that:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â€–Î¼hâ€‹(x1,a1)âˆ’Î¼hâ€‹(x2,a2)â€–\displaystyle\|\mu\_{h}(x\_{1},a\_{1})-\mu\_{h}(x\_{2},a\_{2})\| | â‰¤\displaystyle\leq | â„“Î¼â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle\ell\_{\mu}\Big(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|\Big), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â€–Ïƒhâ€‹(x1,a1)âˆ’Ïƒhâ€‹(x1,a2)â€–\displaystyle\|\sigma\_{h}(x\_{1},a\_{1})-\sigma\_{h}(x\_{1},a\_{2})\| | â‰¤\displaystyle\leq | â„“Ïƒâ€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle\ell\_{\sigma}\Big(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|\Big), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | maxhâˆˆ[Hâˆ’1]â¡{â€–Î¼hâ€‹(0,0)â€–,â€–Ïƒhâ€‹(0,0)â€–}\displaystyle\max\_{h\in[H-1]}\{\|\mu\_{h}(0,0)\|,\|\sigma\_{h}(0,0)\|\} | â‰¤\displaystyle\leq | L0.\displaystyle L\_{0}. |  |

In addition, assume the following elliptic condition, i.e., there exists a constant Î»>0\lambda>0 such that âˆ€xâˆˆâ„dğ’®,aâˆˆğ’œ,\forall x\in\mathbb{R}^{d\_{\mathcal{S}}},a\in\mathcal{A}, and hâˆˆ[Hâˆ’1]h\in[H-1]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ïƒhâ€‹(x,a)â€‹Ïƒhâ€‹(x,a)âŠ¤â‰»Î»â€‹Idğ’®.\displaystyle\sigma\_{h}(x,a)\sigma\_{h}(x,a)^{\top}\succ\lambda I\_{d\_{\mathcal{S}}}. |  | (2.5) |

###### Assumption 2.2 (Regularity of the reward).

Assume the expected reward is local Lipschitz, namely, there exists constants â„“r>0\ell\_{r}>0, mâˆˆâ„•m\in\mathbb{N} and L0>0L\_{0}>0 such that for all hâˆˆ[H]h\in[H], x1,x2âˆˆâ„dğ’®x\_{1},x\_{2}\in\mathbb{R}^{d\_{\mathcal{S}}}, and a1,a2âˆˆğ’œa\_{1},a\_{2}\in\mathcal{A}, it holds that:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |RÂ¯hâ€‹(x1,a1)âˆ’RÂ¯hâ€‹(x2,a2)|\displaystyle|\bar{R}\_{h}(x\_{1},a\_{1})-\bar{R}\_{h}(x\_{2},a\_{2})| | â‰¤\displaystyle\leq | â„“râ€‹(â€–x1â€–m+â€–x2â€–m+1)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle{\ell\_{r}\Big(\|x\_{1}\|^{m}+\|x\_{2}\|^{m}{+1}\Big)\,\Big(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|\Big)}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | maxhâˆˆ[H]â¡|RÂ¯hâ€‹(0,0)|\displaystyle\max\_{h\in[H]}|\bar{R}\_{h}(0,0)| | â‰¤\displaystyle\leq | L0.\displaystyle L\_{0}. |  |

In addition, assume that the reward distribution has sub-Gaussian tail decay, i.e., there exists a known constant Î¸>0\theta>0 such that âˆ€xâˆˆâ„dğ’®,aâˆˆğ’œ,Î»1âˆˆâ„\forall x\in\mathbb{R}^{d\_{\mathcal{S}}},a\in\mathcal{A},\lambda\_{1}\in\mathbb{R}, and hâˆˆ[H]h\in[H]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼rhâˆ¼Rhâ€‹(x,a)â€‹[expâ¡(Î»1â€‹(rhâˆ’RÂ¯hâ€‹(x,a)))]â‰¤eÎ¸â€‹Î»122.\displaystyle\mathbb{E}\_{{}\_{r\_{h}\sim R\_{h}(x,a)}}\Big[\exp\Big(\lambda\_{1}(r\_{h}-\bar{R}\_{h}(x,a))\Big)\Big]\leq e^{\frac{\theta\lambda\_{1}^{2}}{2}}. |  | (2.6) |

###### Assumption 2.3 (Regularity of the initial distribution).

Assume that there exists pâˆˆâ„•p\in\mathbb{N} with p2>(m+1)2â€‹(dğ’®+dğ’œ+2)+(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)p^{2}>(m+1)^{2}(d\_{\mathcal{S}}+d\_{\mathcal{A}}+2)+(m+1)(2d\_{\mathcal{S}}+2m+4), such that the initial state X1=Î¾X\_{1}=\xi of the diffusion process in ([2.1](https://arxiv.org/html/2512.14991v1#S2.E1 "In 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) satisfies:

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]<+âˆ,\displaystyle\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]<+\infty, |  |

The assumption that p2>(m+1)2â€‹(dğ’®+dğ’œ+2)+(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)p^{2}>(m+1)^{2}(d\_{\mathcal{S}}+d\_{\mathcal{A}}+2)+(m+1)(2d\_{\mathcal{S}}+2m+4) ensures that the initial distribution is well behaved. This requirement is not restrictive; for example, Gaussian and, more generally, sub-Gaussian distributions satisfy it. This condition is useful for the regret analysis.

### 2.3 Properties of the dynamics and value functions

Under the assumptions outlined in Section [2.2](https://arxiv.org/html/2512.14991v1#S2.SS2 "2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we establish several useful properties of the dynamics and the associated value functions, which will play a central role in the subsequent analysis.

###### Proposition 2.2.

Given Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), there exists a constant MM such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[suphâˆˆ[H]â€–Xhâ€–p]â‰¤Mâ€‹(1+ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]),\displaystyle\mathbb{E}\left[\sup\_{h\in[H]}\|X\_{h}\|^{p}\right]\leq M\Big(1+\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]\Big), |  |

where MM depends only on H,â„“Î¼,â„“Ïƒ,p,aÂ¯,L0H,\ell\_{\mu},\ell\_{\sigma},p,\bar{a},L\_{0} and Î”\Delta.

The proof of Proposition [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem2 "Proposition 2.2. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [A.1](https://arxiv.org/html/2512.14991v1#A1.SS1 "A.1 Proof of Proposition 2.2 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). Proposition [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem2 "Proposition 2.2. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") immediately implies the following result.

###### Corollary 2.3.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"),[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. For any given Ï>0\rho>0, there exists a constant MpM\_{p} independent of Ï\rho such that

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(suphâˆˆ[H]â€–Xhâ€–â‰¥Ï)â‰¤MpÏp.\displaystyle\mathbb{P}\left(\sup\_{h\in[H]}\|X\_{h}\|\geq\rho\right)\leq\frac{M\_{p}}{\rho^{p}}. |  |

Corollary [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem3 "Corollary 2.3. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") suggests that, with probability at least 1âˆ’MpÏp1-\frac{M\_{p}}{\rho^{p}}, the entire state trajectory collected in one episode is within the radius Ï\rho.

Next, we establish the local Lipschitz continuity of the optimal value function and a growth condition for the value function under any generic policy Ï€\pi. Both results are essential for algorithm design and regret analysis.

###### Proposition 2.4 (Local Lipschitz property of the value function).

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. Then for each hâˆˆ[H]h\in[H], it holds that

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Vhâˆ—â€‹(x1)âˆ’Vhâˆ—â€‹(x2)|â‰¤CÂ¯hâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle|V\_{h}^{\*}(x\_{1})-V\_{h}^{\*}(x\_{2})|\leq\overline{C}\_{h}\Big(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m}\Big)\|x\_{1}-x\_{2}\|, |  | (2.7) |

with CÂ¯h:=CÂ¯hâ€‹(CÂ¯h+1,L0,â„“Î¼,â„“Ïƒ,â„“r,Î”,m)\overline{C}\_{h}:=\overline{C}\_{h}(\overline{C}\_{h+1},L\_{0},\ell\_{\mu},\ell\_{\sigma},\ell\_{r},\Delta,m).

The proof of Proposition [2.4](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem4 "Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [A.2](https://arxiv.org/html/2512.14991v1#A1.SS2 "A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

When the expected reward function is locally Lipschtiz with order mm (see Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the value function of any admissible policy Ï€\pi has a polynomial growth of order m+1m+1.

###### Proposition 2.5.

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. Then for all hâˆˆ[H]h\in[H] and any policy Ï€\pi, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | |VhÏ€â€‹(x)|â‰¤C~hâ€‹(â€–xâ€–m+1+1),\displaystyle|V\_{h}^{\pi}(x)|\leq\widetilde{C}\_{h}(\|x\|^{m+1}+1), |  | (2.8) |

with constant C~h:=C~hâ€‹(C~h+1,L0,â„“Î¼,â„“Ïƒ,â„“r,aÂ¯,H,h,Î”,m)\widetilde{C}\_{h}:=\widetilde{C}\_{h}(\widetilde{C}\_{h+1},L\_{0},\ell\_{\mu},\ell\_{\sigma},\ell\_{r},\bar{a},H,h,\Delta,m).

The proof of Proposition [2.5](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem5 "Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [A.3](https://arxiv.org/html/2512.14991v1#A1.SS3 "A.3 Proof of Proposition 2.5 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

## 3 Algorithm design

This section provides an overview of the algorithm design and its key ingredients, with the technical details and theoretical guarantees deferred to Sections [4](https://arxiv.org/html/2512.14991v1#S4 "4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [5](https://arxiv.org/html/2512.14991v1#S5 "5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). We develop a value-based algorithm that maintains estimators for both the Q-function and the value function over each partition of the joint stateâ€“action space. Based on these estimators, the algorithm implements a greedy policy by selecting the action that maximizes the estimated Q-function. The adaptive partitioning of the stateâ€“action space is guided by a biasâ€“variance trade-off, following the approach introduced by Sinclair et al. (2023), which was originally developed for bounded stateâ€“action spaces.

##### Initial state partition.

Since the state space is unbounded, we restrict our learning and optimization to a subset of the full space, defined as

|  |  |  |
| --- | --- | --- |
|  | ğ’®1:={xâˆˆâ„dğ’®|â€–xâ€–â‰¤Ï},\mathcal{S}\_{1}:=\Big\{x\in\mathbb{R}^{d\_{\mathcal{S}}}\,\,\Big|\,\,\|x\|\leq\rho\Big\}, |  |

where Ï>0\rho>0 is a radius to be specified in the regret analysis (see SectionÂ [5](https://arxiv.org/html/2512.14991v1#S5 "5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) such that the state process remains within ğ’®1\mathcal{S}\_{1} with high probability. For states outside this subset, we will apply some coarse estimations that do not affect the leading-order term in the regret bound.

Due to the unbounded nature of the state space, our initial partition of the state-action space differs from that in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)). We first partition the entire state-action space â„dğ’®Ã—ğ’œ\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A} into (closed) hypercubes of fixed diameter D>0D>0. 111The constant DD can be chosen arbitrarily, provided that 2â€‹aÂ¯â€‹dğ’®+dğ’œDâ€‹dğ’œ\frac{2\bar{a}\sqrt{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}{D\sqrt{d\_{\mathcal{A}}}} is a positive integer. This ensures that the state-action space can be partitioned into those hypercubes. Denote by ğ’µD\mathcal{Z}\_{D} the collection of these hypercubes, and we construct the initial partition of our subset of state-action space by

|  |  |  |
| --- | --- | --- |
|  | â„¬D:={B|Bâˆˆğ’µD,Bâˆ©(ğ’®1Ã—ğ’œ)â‰ âˆ…},\displaystyle\mathcal{B}\_{D}:=\left\{B\,\Big|\,B\in\mathcal{Z}\_{D},B\cap(\mathcal{S}\_{1}\times\mathcal{A})\neq\emptyset\right\}, |  |

with |â„¬D|<âˆ|\mathcal{B}\_{D}|<\infty. The adaptive partition procedure will be carried out only for Bâˆˆâ„¬DB\in\mathcal{B}\_{D} (not ğ’µD\mathcal{Z}\_{D}). For further use, define the partition space as

|  |  |  |  |
| --- | --- | --- | --- |
|  | ZÂ¯:=âˆªBâˆˆâ„¬DB.\displaystyle\bar{Z}:=\cup\_{B\in\mathcal{B}\_{D}}B. |  | (3.1) |

As a consequence, ğ’®1Ã—ğ’œâŠ†ZÂ¯\mathcal{S}\_{1}\times\mathcal{A}\subseteq\bar{Z}.

The main algorithm, especially the key mechanism behind adaptive partition, is inspired by (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)).
In a nutshell, the proposed Adaptive Partition and Learning for Diffusions (APL-Diffusion) Algorithm (see Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) consists of the following key steps:

* â€¢

  Construct the estimators QÂ¯hk(.),VÂ¯hk(.)\overline{Q}\_{h}^{k}(.),\overline{V}\_{h}^{k}(.) for the QQ-function and the value function;
* â€¢

  Select block BhkB\_{h}^{k} according to the estimated QQ-function;
* â€¢

  Construct the confidence level CONFhkâ€‹(Bhk){\rm CONF}\_{h}^{k}(B\_{h}^{k}) for each visited block BhkB\_{h}^{k};
* â€¢

  If CONFhkâ€‹(Bhk)â‰¤diamâ€‹(Bhk){\rm CONF}\_{h}^{k}(B\_{h}^{k})\leq{\rm diam}(B\_{h}^{k}), split the block BhkB\_{h}^{k}

  + â€“

    Each side of the block is divided evenly into two parts along every dimension,
  + â€“

    As a result, BkhB\_{k}^{h} is split into smaller (closed) hypercubes with half the diameter of the original block.

Note that our estimation of the Q-functions and value functions, as well as the construction of the confidence measure, differs from (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) due to the different problem setting.

Algorithm 1  Adaptive Partition and Learning for Diffusions (APL-Diffusion)

1:Initialize:
Initialize the partition ğ’«h0=â„¬D\mathcal{P}\_{h}^{0}=\mathcal{B}\_{D} for hâˆˆ[H]h\in[H] and the counting with
nh0â€‹(B)=0n\_{h}^{0}(B)=0 for Bâˆˆğ’«h0B\in\mathcal{P}\_{h}^{0}.
Also, initialize the function estimators
QÂ¯h0,VÂ¯h0\overline{Q}\_{h}^{0},\overline{V}\_{h}^{0} according to ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and QÂ¯hkâ€‹(ZÂ¯âˆ)\overline{Q}\_{h}^{k}(\bar{Z}^{\complement}) according to ([5.5](https://arxiv.org/html/2512.14991v1#S5.E5 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) for kâˆˆ[K]âˆª{0}k\in[K]\cup\{0\}

2:for each episode k=1,2,â‹¯,Kk=1,2,\cdots,K do

3:â€ƒâ€‚for each step h=1,2,â‹¯,Hh=1,2,\cdots,H do

4:â€ƒâ€ƒâ€ƒObserve XhkX\_{h}^{k}

5:â€ƒâ€ƒâ€ƒ Select BhkB\_{h}^{k} by BLOCK SELECTION(Xhk)(X\_{h}^{k})

6:â€ƒâ€ƒâ€ƒ Take action: AhkA\_{h}^{k} uniformly sampled from the action set Î“ğ’œâ€‹(Bhk)\Gamma\_{\mathcal{A}}(B\_{h}^{k})

7:â€ƒâ€ƒâ€ƒReceive rhkr\_{h}^{k} and transition to Xh+1kX\_{h+1}^{k}

8:â€ƒâ€‚end for

9:â€ƒâ€‚for each step h=H,Hâˆ’1,â‹¯,1h=H,H-1,\cdots,1 do

10:â€ƒâ€ƒâ€ƒUPDATE COUNTS (Bhk)(B\_{h}^{k})

11:â€ƒâ€ƒâ€ƒSPLITTING (Bhk)(B\_{h}^{k})

12:â€ƒâ€ƒâ€ƒUPDATE ESTIMATE (Xhk,Ahk,Xh+1k,rhk,Bhk)(X\_{h}^{k},A\_{h}^{k},X\_{h+1}^{k},r\_{h}^{k},B\_{h}^{k})

13:â€ƒâ€‚end for

14:end for

Projection operators (line [6](https://arxiv.org/html/2512.14991v1#alg1.l6 "In Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and line [1](https://arxiv.org/html/2512.14991v1#alg2.l1 "In Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
For a block BâŠ‚â„dğ’®Ã—ğ’œB\subset\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}, we denote Î“ğ’®â€‹(B)\Gamma\_{\mathcal{S}}(B) and Î“ğ’œâ€‹(B)\Gamma\_{\mathcal{A}}(B) as the projections of BB into â„dğ’®\mathbb{R}^{d\_{\mathcal{S}}} and ğ’œ\mathcal{A}, respectively.

The three primary components (sub-algorithms) of Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), BLOCK SELECTION(Xhk)(X\_{h}^{k}), UPDATE ESTIMATE (Xhk,Ahk,Xh+1k,rhk,Bhk)(X\_{h}^{k},A\_{h}^{k},X\_{h+1}^{k},r\_{h}^{k},B\_{h}^{k}) and SPLITTING(Bhk)(B\_{h}^{k}), are presented below.

Algorithm 2  BLOCK SELECTION(Xhk)(X\_{h}^{k})

1:
Determine RELEVANThkâ€‹(Xhk)={Bâˆˆğ’«hkâˆ’1âˆª{ZÂ¯âˆ}|XhkâˆˆÎ“ğ’®â€‹(B)}{\rm RELEVANT}\_{h}^{k}(X\_{h}^{k})=\{B\in\mathcal{P}\_{h}^{k-1}\cup\{\bar{Z}^{\complement}\}|X\_{h}^{k}\in\Gamma\_{\mathcal{S}}(B)\}

2:
Greedy selection rule: select Bhkâˆˆargâ¡maxBâˆˆRELEVANThkâ€‹(Xhk)â¡QÂ¯hkâˆ’1â€‹(B)B\_{h}^{k}\in\arg\max\_{B\in{\rm RELEVANT}\_{h}^{k}(X\_{h}^{k})}\overline{Q}\_{h}^{k-1}(B)

For a given state XhkX\_{h}^{k}, Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") determines all Bâˆˆğ’«hkâˆ’1âˆª{ZÂ¯âˆ}B\in\mathcal{P}\_{h}^{k-1}\cup\{\bar{Z}^{\complement}\} that XhkX\_{h}^{k} lies in and chooses the one that maximizes the current estimate of the Q function QÂ¯hkâˆ’1\overline{Q}\_{h}^{k-1}.

Algorithm 3  UPDATE COUNTS(Bhk)(B\_{h}^{k})

1:for Bâˆˆğ’«hkâˆ’1B\in\mathcal{P}\_{h}^{k-1} do

2:â€ƒâ€‚
Update nhkâ€‹(B)n\_{h}^{k}(B) via ([3.2](https://arxiv.org/html/2512.14991v1#S3.E2 "In Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))

3:end for

Counts updates (line [2](https://arxiv.org/html/2512.14991v1#alg3.l2 "In Algorithm 3 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [3](https://arxiv.org/html/2512.14991v1#alg3 "Algorithm 3 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
Note that nhkâ€‹(B)n\_{h}^{k}(B) is the number of times the block BB or its ancestors have been visited up to (and including) episode kk. It is updated for the visited block BhkB\_{h}^{k} if Bhkâˆˆğ’«hkâˆ’1B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1} and remained the same for other blocks Bâˆˆğ’«hkâˆ’1âˆ–{Bhk}B\in\mathcal{P}\_{h}^{k-1}\setminus\{B\_{h}^{k}\}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | nhkâ€‹(Bhk)=nhkâˆ’1â€‹(Bhk)+1,nhkâ€‹(B)=nhkâˆ’1â€‹(B).\displaystyle n\_{h}^{k}(B\_{h}^{k})=n\_{h}^{k-1}(B\_{h}^{k})+1,\quad n\_{h}^{k}(B)=n\_{h}^{k-1}(B). |  | (3.2) |

Algorithm 4  SPLITTING(Bhk)(B\_{h}^{k})

1: If Bhkâˆˆğ’«hkâˆ’1B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1}, CONFhkâ€‹(Bhk)â‰¤diamâ€‹(Bhk){\rm CONF}\_{h}^{k}(B\_{h}^{k})\leq{\rm{\rm diam}}(B\_{h}^{k})
then:

2:â€ƒâ€ƒ Construct ğ’«â€‹(Bhk)={B1,â‹¯,B2dğ’®+dğ’œ}\mathcal{P}(B\_{h}^{k})=\{B\_{1},\cdots,B\_{2^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}\} as the partition of BhkB\_{h}^{k} such that each BiB\_{i} is a (closed) hypercube with diamâ€‹(Bi)=diamâ€‹(B)2{\rm diam}(B\_{i})=\frac{{\rm diam}(B)}{2} such that âˆªi=12dğ’®+dğ’œBi=Bhk\cup\_{i=1}^{2^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}B\_{i}=B\_{h}^{k}

3:â€ƒâ€ƒ Update ğ’«hk=ğ’«hkâˆ’1âˆªğ’«â€‹(Bhk)âˆ–Bhk\mathcal{P}\_{h}^{k}=\mathcal{P}\_{h}^{k-1}\cup\mathcal{P}(B\_{h}^{k})\setminus B\_{h}^{k}

4:for B1,â‹¯,B2dğ’®+dğ’œB\_{1},\cdots,B\_{2^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}} do

5:â€ƒâ€‚Initialize nhkâ€‹(Bi)=nhkâ€‹(Bhk)n\_{h}^{k}(B\_{i})=n\_{h}^{k}(B\_{h}^{k})

6:end for

7:Else Bhkâˆˆğ’«hkâˆ’1B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1} with CONFhkâ€‹(Bhk)>diamâ€‹(Bhk){\rm CONF}\_{h}^{k}(B\_{h}^{k})>{\rm{\rm diam}}(B\_{h}^{k}) or Bhk=ZÂ¯âˆB\_{h}^{k}=\bar{Z}^{\complement}
then:

8:â€ƒâ€ƒ Update ğ’«hk=ğ’«hkâˆ’1\mathcal{P}\_{h}^{k}=\mathcal{P}\_{h}^{k-1}

Splitting rule (line [1](https://arxiv.org/html/2512.14991v1#alg4.l1 "In Algorithm 4 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [4](https://arxiv.org/html/2512.14991v1#alg4 "Algorithm 4 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
To refine the partition over episodes, in episode kk and step hh, we split the visited block BhkB\_{h}^{k} if

|  |  |  |  |
| --- | --- | --- | --- |
|  | CONFhkâ€‹(Bhk)â‰¤diamâ€‹(Bhk),\displaystyle{\rm CONF}\_{h}^{k}(B\_{h}^{k})\leq{\rm diam}(B\_{h}^{k}), |  | (3.3) |

where CONFhk{\rm CONF}\_{h}^{k} is formally defined in ([4.20](https://arxiv.org/html/2512.14991v1#S4.E20 "In 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), which represents the confidence of a block in its estimators. In a nutshell, ([3.3](https://arxiv.org/html/2512.14991v1#S3.E3 "In Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) compares the confidence of the estimators for the visited block, quantified by CONFhkâ€‹(Bhk){\rm CONF}\_{h}^{k}(B\_{h}^{k}), and the bias of the block, which is proportional to the diameter of the block. If the bias associated with a block, in representing all the points it contains, exceeds the confidence level of its estimators, the block should be further partitioned.

Algorithm 5  UPDATE ESTIMATE (Xhk,Ahk,Xh+1k,rhk,Bhk)(X\_{h}^{k},A\_{h}^{k},X\_{h+1}^{k},r\_{h}^{k},B\_{h}^{k})

1:for Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} do

2:â€ƒâ€‚
Update the following quantities:

* â€¢

  Î¼^hkâ€‹(B)\widehat{\mu}\_{h}^{k}(B), Î£^hkâ€‹(B)\widehat{\Sigma}\_{h}^{k}(B) and TÂ¯hk(â‹…|B)\bar{T}\_{h}^{k}(\cdot|B) via ([4.1](https://arxiv.org/html/2512.14991v1#S4.E1 "In 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))
* â€¢

  R^hkâ€‹(B)\hat{R}\_{h}^{k}(B) via ([4.3](https://arxiv.org/html/2512.14991v1#S4.Ex21 "4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))

3:â€ƒâ€‚Update QÂ¯hk\overline{Q}\_{h}^{k} and VÂ¯hk\overline{V}\_{h}^{k} via ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))-([5.14](https://arxiv.org/html/2512.14991v1#S5.E14 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))

4:end for

Estimators (line [2](https://arxiv.org/html/2512.14991v1#alg5.l2 "In Algorithm 5 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [5](https://arxiv.org/html/2512.14991v1#alg5 "Algorithm 5 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
For Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k}, R^hkâ€‹(B)\hat{R}\_{h}^{k}(B), Î¼^hkâ€‹(B)\widehat{\mu}\_{h}^{k}(B), Î£^hkâ€‹(B)\widehat{\Sigma}\_{h}^{k}(B) and TÂ¯hk(â‹…|B)\bar{T}\_{h}^{k}(\cdot|\,B) are the estimators of RÂ¯hâ€‹(x,a)\bar{R}\_{h}(x,a), Î¼hâ€‹(x,a)\mu\_{h}(x,a), Î£hâ€‹(x,a)\Sigma\_{h}(x,a) and Th(â‹…|x,a)T\_{h}(\cdot|\,x,a), for the state-action pairs (x,a)âˆˆB(x,a)\in B. In addition, QÂ¯hkâ€‹(B)\overline{Q}\_{h}^{k}(B) is the estimate of Qhâˆ—â€‹(x,a)Q\_{h}^{\*}(x,a) for (x,a)âˆˆB(x,a)\in B and VÂ¯hkâ€‹(x)\overline{V}\_{h}^{k}(x) is the estimate of Vhâˆ—â€‹(x)V\_{h}^{\*}(x) for xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}}.

For further use, we define the APL-Diffusion policy as the sequences of policies described in line [5](https://arxiv.org/html/2512.14991v1#alg1.l5 "In Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [6](https://arxiv.org/html/2512.14991v1#alg1.l6 "In Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and denote it by

|  |  |  |  |
| --- | --- | --- | --- |
|  | {Ï€~k}kâˆˆ[K].\displaystyle\{\tilde{\pi}^{k}\}\_{k\in[K]}. |  | (3.4) |

Demonstration of the algorithm. Given the complexity of the algorithm and sophistication of the design,
below we provide a demonstration example with visualization, which is inspired by Figure 1 from Sinclair etÂ al. ([2023](https://arxiv.org/html/2512.14991v1#bib.bib53)).

![Refer to caption](Adaptive_Partition_Heat.png)


(a) Illustration of the adaptive partition. The right panel zooms
  
into the current partition ğ’«hkâˆ’1\mathcal{P}\_{h}^{k-1}.

![Refer to caption](Adaptive_Partition_Tree.png)


(b) History partitions {ğ’«hj}j=0kâˆ’1\{\mathcal{P}\_{h}^{j}\}\_{j=0}^{k-1} .

Figure 1: Partitioning scheme for â„Ã—ğ’œ=(âˆ’âˆ,+âˆ)Ã—[âˆ’3,3]\mathbb{R}\times\mathcal{A}=(-\infty,+\infty)\times[-3,3].

In Figure [1](https://arxiv.org/html/2512.14991v1#S3.F1 "Figure 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") (a)-left, the color indicates the true value of Qhâˆ—Q\_{h}^{\*}, with the darker corresponding to larger values. Note that the partition is more refined in areas which have higher Qhâˆ—Q\_{h}^{\*}.
In Figure [1](https://arxiv.org/html/2512.14991v1#S3.F1 "Figure 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") (a)-right, we zoom in the current partition ğ’«hkâˆ’1\mathcal{P}\_{h}^{k-1}. In Figure [1](https://arxiv.org/html/2512.14991v1#S3.F1 "Figure 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") (b), the history partitions {ğ’«hj}j=0kâˆ’1\{\mathcal{P}\_{h}^{j}\}\_{j=0}^{k-1} are depicted by a tree diagram.

## 4 Concentration inequalities of the estimators

This section is devoted to the development of concentration inequalities of the estimators associated with the transition kernel. Different from (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), we fully utilize the property of diffusion process and construct estimators for the drift and volatility. Note that establishing concentration inequalities for covariance matrices under merely Lipschitz conditions on the volatility is challenging. To address this, we introduce and carefully analyze two intermediate terms (see ([4.2](https://arxiv.org/html/2512.14991v1#S4.E2 "In 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))).

Here, we denote k1â‰¤,â‹¯,â‰¤knhkâ€‹(B)k\_{1}\leq,\cdots,\leq k\_{n\_{h}^{k}(B)} the episode indices such that BB or its ancestors have been visited by the algorithm up to episode kk. It is clear that knhkâ€‹(B)â‰¤kk\_{n\_{h}^{k}(B)}\leq k.

For each block Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with (h,k)âˆˆ[Hâˆ’1]Ã—[K](h,k)\in[H-1]\times[K], when nhkâ€‹(B)>0n^{k}\_{h}(B)>0 we construct the estimators Î¼^hkâ€‹(B)\widehat{\mu}\_{h}^{k}(B) and Î£^hkâ€‹(B)\widehat{\Sigma}\_{h}^{k}(B) by

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î¼^hkâ€‹(B)\displaystyle\widehat{\mu}\_{h}^{k}(B) | =\displaystyle= | âˆ‘i(Xh+1kiâˆ’Xhki)nhkâ€‹(B)â€‹Î”,\displaystyle\frac{\sum\_{i}(X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})}{n\_{h}^{k}(B)\Delta}, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Î£^hkâ€‹(B)\displaystyle\widehat{\Sigma}\_{h}^{k}(B) | =\displaystyle= | âˆ‘i((Xh+1kiâˆ’Xhki)âˆ’Î¼^hkâ€‹(B)â€‹Î”)â€‹((Xh+1kiâˆ’Xhki)âˆ’Î¼^hkâ€‹(B)â€‹Î”)âŠ¤nhkâ€‹(B)â€‹Î”.\displaystyle\frac{\sum\_{i}\Big((X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\widehat{\mu}\_{h}^{k}(B)\Delta\Big)\Big((X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\widehat{\mu}\_{h}^{k}(B)\Delta\Big)^{\top}}{n\_{h}^{k}(B)\Delta}. |  | (4.1) |

When nhkâ€‹(B)=0n^{k}\_{h}(B)=0, we simply take
Î¼^hkâ€‹(B)=0â€‹Â andÂ â€‹Î£^hkâ€‹(B)=0.\widehat{\mu}\_{h}^{k}(B)=0\mbox{ and }\widehat{\Sigma}\_{h}^{k}(B)=0.

As a result, the transition kernel can be estimated by

|  |  |  |
| --- | --- | --- |
|  | TÂ¯hk(â‹…|B):=ğ’©(Î¼^hk(B)Î”,Î£^hk(B)Î”).\displaystyle\bar{T}\_{h}^{k}(\cdot|B):=\mathcal{N}\Big(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta\Big). |  |

Since the analysis heavily relies on conditioning arguments, we also introduce the following notations:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ”¼Â¯â€‹[â‹…]\displaystyle\overline{\mathbb{E}}\Big[\cdot\Big] | :=\displaystyle:= | ğ”¼[â‹…|Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B)],\displaystyle\mathbb{E}\Big[\,\,\cdot\,\,\Big|X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}}\Big], |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ•Â¯â€‹[â‹…]\displaystyle\overline{\mathbb{V}}\Big[\cdot\Big] | :=\displaystyle:= | ğ•[â‹…|Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B)],\displaystyle\mathbb{\mathbb{V}}\Big[\,\,\cdot\,\,\Big|X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}}\Big], |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ’²Â¯2â€‹(â‹…)\displaystyle\overline{\mathcal{W}}\_{2}\Big(\cdot\Big) | :=\displaystyle:= | ğ’²2(â‹…|Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B)).\displaystyle\mathcal{W}\_{2}\Big(\,\,\cdot\,\,\Big|X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}}\Big). |  |

Note that Xh+1k1âˆ’Xhk1,â€¦,Xh+1knhkâ€‹(B)âˆ’Xhknhkâ€‹(B)X\_{h+1}^{k\_{1}}-X\_{h}^{k\_{1}},...,X\_{h+1}^{k\_{n\_{h}^{k}(B)}}-X\_{h}^{k\_{n\_{h}^{k}(B)}} are conditionally independent given Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B)X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}}, and Ahknhkâ€‹(B)A\_{h}^{k\_{n\_{h}^{k}(B)}}. Hence it is straightforward to derive concentration inequality for Î¼^hkâ€‹(B)\widehat{\mu}\_{h}^{k}(B). However, the expectation and variance of the estimator Î£^hkâ€‹(B)\widehat{\Sigma}\_{h}^{k}(B) are challenging to analyze as Xh+1k1âˆ’Xhk1âˆ’Î¼^hkâ€‹(B)â€‹Î”X\_{h+1}^{k\_{1}}-X\_{h}^{k\_{1}}-\widehat{\mu}\_{h}^{k}(B)\Delta ,â‹¯\cdots,Xh+1knhkâ€‹(B)âˆ’Xhknhkâ€‹(B)âˆ’Î¼^hkâ€‹(B)â€‹Î”X\_{h+1}^{k\_{n\_{h}^{k}(B)}}-X\_{h}^{k\_{n\_{h}^{k}(B)}}-\widehat{\mu}\_{h}^{k}(B)\Delta are dependent.
Hence, we consider the following intermediate quantity and decomposition to proceed:

|  |  |  |
| --- | --- | --- |
|  | Î£~hkâ€‹(B):=âˆ‘i((Xh+1kiâˆ’Xhki)âˆ’Î”â€‹ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])â€‹((Xh+1kiâˆ’Xhki)âˆ’Î”â€‹ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])âŠ¤nhkâ€‹(B)â€‹Î”,\displaystyle\widetilde{\Sigma}\_{h}^{k}(B):=\frac{\sum\_{i}\Big((X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\Delta\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big)\Big((X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\Delta\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big)^{\top}}{n\_{h}^{k}(B)\Delta}, |  |

and

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–Î£^hkâ€‹(B)âˆ’Î£hâ€‹(x,a)â€–F\displaystyle\|\widehat{\Sigma}\_{h}^{k}(B)-\Sigma\_{h}(x,a)\|\_{F} |  | (4.2) |
|  |  | â‰¤\displaystyle\leq | â€–Î£^hkâ€‹(B)âˆ’Î£~hkâ€‹(B)â€–FâŸ(I)+â€–Î£~hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]â€–FâŸ(Iâ€‹I)+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–FâŸ(Iâ€‹Iâ€‹I).\displaystyle\underbrace{\Big\|\widehat{\Sigma}\_{h}^{k}(B)-\widetilde{\Sigma}\_{h}^{k}(B)\Big\|\_{F}}\_{(I)}+\underbrace{\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\_{F}}\_{(II)}+\underbrace{\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\_{F}}\_{(III)}. |  |

We analyze (I)-(III) in the next subsection. As a heads-up,

* â€¢

  Term (II) on the RHS is straightforward to bound as Xh+1k1âˆ’Xhk1âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€‹Î”,â‹¯,Xh+1knhkâ€‹(B)âˆ’Xhknhkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€‹Î”X\_{h+1}^{k\_{1}}-X\_{h}^{k\_{1}}-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Delta,\cdots,X\_{h+1}^{k\_{n\_{h}^{k}(B)}}-X\_{h}^{k\_{n\_{h}^{k}(B)}}-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Delta are conditionally independent. We handle this term by Lemma [B.2](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem2 "Lemma B.2. â€£ B.2 Lemma B.2 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Proposition [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
* â€¢

  To bound term (I), let Pi:=(Xh+1kiâˆ’Xhki)âˆ’Î¼^hkâ€‹(B)â€‹Î”P\_{i}:=(X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\widehat{\mu}\_{h}^{k}(B)\Delta and Qi:=(Xh+1kiâˆ’Xhki)âˆ’Î”â€‹ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]Q\_{i}:=(X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}})-\Delta\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]. Then we have

  |  |  |  |  |  |  |
  | --- | --- | --- | --- | --- | --- |
  |  | â€–Î£^hkâ€‹(B)âˆ’Î£~hkâ€‹(B)â€–\displaystyle\|\widehat{\Sigma}\_{h}^{k}(B)-\widetilde{\Sigma}\_{h}^{k}(B)\| | =\displaystyle= | â€–âˆ‘iPiâ€‹PiâŠ¤nhkâ€‹(B)â€‹Î”âˆ’âˆ‘iQiâ€‹QiâŠ¤nhkâ€‹(B)â€‹Î”â€–\displaystyle\Bigg\|\frac{\sum\_{i}P\_{i}P\_{i}^{\top}}{n\_{h}^{k}(B)\Delta}-\frac{\sum\_{i}Q\_{i}Q\_{i}^{\top}}{n\_{h}^{k}(B)\Delta}\Bigg\| |  | (4.3) |
  |  |  | =\displaystyle= | â€–âˆ‘iPiâ€‹(PiâŠ¤âˆ’QiâŠ¤)nhkâ€‹(B)â€‹Î”+âˆ‘i(Piâˆ’Qi)â€‹QiâŠ¤nhkâ€‹(B)â€‹Î”â€–\displaystyle\Bigg\|\frac{\sum\_{i}P\_{i}(P\_{i}^{\top}-Q\_{i}^{\top})}{n\_{h}^{k}(B)\Delta}+\frac{\sum\_{i}(P\_{i}-Q\_{i})Q\_{i}^{\top}}{n\_{h}^{k}(B)\Delta}\Bigg\| |  |
  |  |  | =\displaystyle= | â€–(Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])â€‹(Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])âŠ¤â€‹Î”â€–,\displaystyle\Bigg\|\Big(\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big)\Big(\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big)^{\top}\Delta\Bigg\|, |  |

  which will be handled by Lemma [B.1](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem1 "Lemma B.1. â€£ B.1 Lemma B.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Proposition [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
* â€¢

  As for term (III), we provide an upper bound in Theorem [4.7](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem7 "Theorem 4.7. â€£ 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 4.1 Concentration of the estimators for drift and volatility

In this section, we provide concentration inequalities for the drift and volatility estimators.

For convinience, denote

|  |  |  |  |
| --- | --- | --- | --- |
|  | L:=maxâ¡{â„“Î¼,â„“Ïƒ},\displaystyle L:=\max\{\ell\_{\mu},\ell\_{\sigma}\}, |  | (4.4) |

where â„“Î¼,â„“Ïƒ\ell\_{\mu},\ell\_{\sigma} are the Lipschitz constants defined in Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
For any hâˆˆ[H],kâˆˆ[K]âˆª{0}h\in[H],k\in[K]\cup\{0\}, Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k}, denote

|  |  |  |  |
| --- | --- | --- | --- |
|  | x~â€‹(B),a~â€‹(B)\tilde{x}(B),\tilde{a}(B) as centers of Î“ğ’®â€‹(B),Î“ğ’œâ€‹(B)\Gamma\_{\mathcal{S}}(B),\Gamma\_{\mathcal{A}}(B) respectively. |  | (4.5) |

In addition, denote Bo{}^{o}B as the block in the original partition that contains a given block BB, i.e., Bo{}^{o}B is the unique set satisfying

|  |  |  |  |
| --- | --- | --- | --- |
|  | BâŠ‚oBâ€‹Â such thatÂ oâ€‹Bâˆˆâ„¬D.\displaystyle B\subset\,^{o}B\mbox{ such that }^{o}B\in\mathcal{B}\_{D}. |  | (4.6) |

With these notations, we have, for any (x,a)âˆˆB(x,a)\in B and f=Î¼h,Ïƒhf=\mu\_{h},\sigma\_{h},

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | â€–fâ€‹(x,a)â€–\displaystyle\|f(x,a)\| | â‰¤\displaystyle\leq | âˆ¥f(x~(oB),a~(oB))âˆ¥+âˆ¥f(x,a)âˆ’f(x~(oB),a~(oB))âˆ¥\displaystyle\Big\|f(\tilde{x}(^{o}B),\tilde{a}(^{o}B))\Big\|+\Big\|f(x,a)-f(\tilde{x}(^{o}B),\tilde{a}(^{o}B))\Big\| |  | (4.7) |
|  |  | â‰¤\displaystyle\leq | L0+L(âˆ¥x~(oB)âˆ¥+aÂ¯)+2LD:=Î·(âˆ¥x~(oB)âˆ¥),\displaystyle L\_{0}+L(\|\tilde{x}(^{o}B)\|+\bar{a})+2LD:=\eta(\|\tilde{x}(^{o}B)\|), |  |

in which we defined Î·:â„+âˆª{0}â†¦â„+\eta:\mathbb{R}\_{+}\cup\{0\}\mapsto\mathbb{R}\_{+}.

Next, we establish concentration inequalities for the estimators of the drift and volatility terms, as presented in Propositions [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proposition 4.1.

Suppose Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") holds, then we have the following result:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(âˆ¥Î¼^hk(B)âˆ’ğ”¼Â¯[Î¼^hk(B)]âˆ¥â‰¤ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)),âˆ€hâˆˆ[Hâˆ’1],kâˆˆ[K],Bâˆˆğ’«hkâ€‹Â withâ€‹nhkâ€‹(B)>0)â‰¥1âˆ’Î´,\displaystyle\mathbb{P}\begin{pmatrix}&\left\|\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\right\|\leq\kappa\_{\mu}\big(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)\big),\\ &\forall h\in[H-1],k\in[K],B\in\mathcal{P}\_{h}^{k}\,\,\mbox{ with}\,\,n\_{h}^{k}(B)>0\end{pmatrix}\geq 1-\delta, |  | (4.8) |

where ÎºÎ¼:(0,1]Ã—(â„+âˆª{0})Ã—â„•+â†¦â„+\kappa\_{\mu}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\times\mathbb{N}\_{+}\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |
| --- | --- | --- |
|  | ÎºÎ¼â€‹(Î´,y,n):=Î·â€‹(y)Î”â€‹(dğ’®n+2â€‹logâ¡(Hâ€‹K2Î´)n).\displaystyle\kappa\_{\mu}(\delta,y,n):=\frac{\eta(y)}{\sqrt{\Delta}}\Big(\sqrt{\frac{d\_{\mathcal{S}}}{n}}+\sqrt{\frac{2\log(\frac{HK^{2}}{\delta})}{n}}\Big). |  |

The proof of Proposition [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is largely inspired by the proof of Lemma 5 in (Nguyen etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib47)), which is deferred to Appendix [B.3](https://arxiv.org/html/2512.14991v1#A2.SS3 "B.3 Proof of Proposition 4.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proposition 4.2.

Suppose Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") holds. Then there exist universal constants D1>0,D2>1,D3>0D\_{1}>0,D\_{2}>1,D\_{3}>0 (independent of Ï\rho) such that:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(âˆ¥Î£~hk(B)âˆ’ğ”¼Â¯[Î£~hk(B)]âˆ¥â‰¤ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)),âˆ€hâˆˆ[Hâˆ’1],kâˆˆ[K],Bâˆˆğ’«hkâ€‹Â withâ€‹nhkâ€‹(B)>0)â‰¥1âˆ’Î´,\displaystyle\mathbb{P}\begin{pmatrix}\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\leq\kappa\_{\Sigma}\big(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)\big),\\ \forall h\in[H-1],k\in[K],B\in\mathcal{P}\_{h}^{k}\,\,\mbox{ with}\,\,n\_{h}^{k}(B)>0\end{pmatrix}\geq 1-\delta, |  | (4.9) |

where ÎºÎ£:(0,1]Ã—(â„+âˆª{0})Ã—â„•+â†¦â„+\kappa\_{\Sigma}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\times\mathbb{N}\_{+}\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |
| --- | --- | --- |
|  | ÎºÎ£â€‹(Î´,y,n):=Î·â€‹(y)2â€‹(D1â€‹(dğ’®n+dğ’®n)+(logâ¡(D2dğ’®)D3â€‹n+logâ¡(D2â€‹Hâ€‹K2Î´)D3â€‹n)).\displaystyle\kappa\_{\Sigma}(\delta,y,n):=\eta(y)^{2}\Bigg(D\_{1}\Big(\sqrt{\frac{d\_{\mathcal{S}}}{n}}+\frac{d\_{\mathcal{S}}}{\sqrt{n}}\Big)+\Bigg(\sqrt{\frac{\log(\frac{D\_{2}}{d\_{\mathcal{S}}})}{D\_{3}n}}+\frac{\log(\frac{D\_{2}HK^{2}}{\delta})}{D\_{3}\sqrt{n}}\Bigg)\Bigg). |  |

The proof of Proposition [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is essentially based on Theorem 6.5 in (Wainwright, [2019](https://arxiv.org/html/2512.14991v1#bib.bib59)) and Lemma 6 in (Nguyen etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib47)), which is deferred to Appendix [B.4](https://arxiv.org/html/2512.14991v1#A2.SS4 "B.4 Proof of Proposition 4.2 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 4.2 Concentration inequalities for transition kernel estimators

Building upon Propositions [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we have the following result bounding the Wasserstein distance between the true transition kernel and the estimated transition kernel. The detailed proof is deferred to Appendix [B.5](https://arxiv.org/html/2512.14991v1#A2.SS5 "B.5 Proof of Theorem 4.3 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Theorem 4.3.

Given Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), it holds with probability at least 1âˆ’2â€‹Î´1-2\delta that, for any (h,k)âˆˆ[Hâˆ’1]Ã—[K](h,k)\in[H-1]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ’²Â¯2â€‹(ğ’©â€‹(Î¼^hkâ€‹(B)â€‹Î”,Î£^hkâ€‹(B)â€‹Î”),ğ’©â€‹(Î¼hâ€‹(x,a)â€‹Î”,Î£hâ€‹(x,a)â€‹Î”))\displaystyle\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big) |  | (4.10) |
|  |  | â‰¤\displaystyle\leq | Î”ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))+Î”32Î»ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))2+dğ’®â€‹Î”12Î»ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))\displaystyle\Delta\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))+\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{2}+\frac{\sqrt{d\_{\mathcal{S}}}\Delta^{\frac{1}{2}}}{\sqrt{\lambda}}\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)) |  |
|  |  |  | +â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î».\displaystyle+\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}}. |  |

With the above inequality, we quantify the following difference:

|  |  |  |
| --- | --- | --- |
|  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Vh+1âˆ—â€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(Y)]|.\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[V\_{h+1}^{\*}(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(Y)]\right|. |  |

To do so, we characterize the concentration inequality of the transition kernels, for which we define the following function T-UCBhkâ€‹(B)\mbox{\rm T-UCB}\_{h}^{k}(B) to represent the uncertainty in the transition kernel. Specifically, for all (h,k)âˆˆ[H]Ã—[K],Bâˆˆğ’«hk(h,k)\in[H]\times[K],B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, define

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | T-UCBhkâ€‹(B)\displaystyle\mbox{\rm T-UCB}\_{h}^{k}(B) | :=\displaystyle:= | LV(Î´,âˆ¥x~(oB)âˆ¥)Ã—(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))Î”+Î”32Î»ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))2\displaystyle L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\times\Bigg(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Delta+\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{2} |  |
|  |  |  | +dğ’®â€‹Î”12Î»ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))),h<H,\displaystyle+\frac{\sqrt{d\_{\mathcal{S}}}\Delta^{\frac{1}{2}}}{\sqrt{\lambda}}\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Bigg),\quad h<H, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | T-UCBHkâ€‹(B)\displaystyle\mbox{\rm T-UCB}\_{H}^{k}(B) | :=\displaystyle:= | 0,\displaystyle 0, |  | (4.11) |

where the function LV:(0,1]Ã—(â„+âˆª{0})â†¦â„+L\_{V}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | LVâ€‹(Î´,y)\displaystyle L\_{V}(\delta,y) | :=\displaystyle:= | 3CÂ¯max(1+C~(m,dğ’®)(2m((nÎºÎ¼(Î´,y,n))m+Î·(y)m)Î”m\displaystyle\sqrt{3}\,\overline{C}\_{\max}\Bigg(1+{\widetilde{C}(m,d\_{\mathcal{S}})}\Bigg(2^{m}\Big((\sqrt{n}\,\,\kappa\_{\mu}(\delta,y,n))^{m}+\eta(y)^{m}\Big)\Delta^{m} |  | (4.12) |
|  |  |  | +3m2â€‹((nâ€‹ÎºÎ¼â€‹(Î´,y,n))mâ€‹Î”m2+(nâ€‹ÎºÎ£â€‹(Î´,y,n))m2+(Î·â€‹(y)2+L2â€‹D2â€‹Î”)m2)â€‹Î”m2\displaystyle\quad+3^{\frac{m}{2}}\Big((\sqrt{n}\,\,\kappa\_{\mu}(\delta,y,n))^{m}\Delta^{\frac{m}{2}}+(\sqrt{n}\,\,\kappa\_{\Sigma}(\delta,y,n))^{\frac{m}{2}}+\Big(\eta(y)^{2}+L^{2}D^{2}\Delta\Big)^{\frac{m}{2}}\Big)\Delta^{\frac{m}{2}} |  |
|  |  |  | +Î·(y)mÎ”m+Î·(y)mÎ”m2))\displaystyle\quad+\eta(y)^{m}\Delta^{m}+\eta(y)^{m}\Delta^{\frac{m}{2}}\Bigg)\Bigg) |  |

with the constant CÂ¯mâ€‹aâ€‹x\overline{C}\_{max} and C~â€‹(m,dğ’®)\widetilde{C}(m,d\_{\mathcal{S}}) defined by

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | CÂ¯max\displaystyle\overline{C}\_{\max} | :=\displaystyle:= | maxhâˆˆ[H]â¡CÂ¯h,\displaystyle\max\_{h\in[H]}\overline{C}\_{h}, |  | (4.13) |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | C~â€‹(m,dğ’®)\displaystyle\widetilde{C}(m,d\_{\mathcal{S}}) | :=\displaystyle:= | dğ’®34â€‹m+1â€‹23â€‹mâˆ’12â€‹Î“â€‹(m+12)12Ï€14.\displaystyle d\_{\mathcal{S}}^{\frac{3}{4}m+1}2^{\frac{3m-1}{2}}\frac{\Gamma(m+\frac{1}{2})^{\frac{1}{2}}}{\pi^{\frac{1}{4}}}. |  | (4.14) |

Hence, we can bound the difference of expected value functions using the T-UCB function.

###### Theorem 4.4.

Assume Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")
holds. With probability at least 1âˆ’2â€‹Î´1-2\delta, we have that, for any (h,k)âˆˆ[Hâˆ’1]Ã—[K](h,k)\in[H-1]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and (x,a)âˆˆB(x,a)\in B:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Vh+1âˆ—â€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[V\_{h+1}^{\*}(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(Y)]\right| |  |
|  |  | â‰¤\displaystyle\leq | T-UCBhk(B)+LV(Î´,âˆ¥x~(oB)âˆ¥)(âˆ¥ğ”¼Â¯[Î¼^hk(B)]âˆ’Î¼h(x,a)âˆ¥Î”+âˆ¥ğ”¼Â¯[Î£~hk(B)]âˆ’Î£h(x,a)âˆ¥Î”Î»).\displaystyle\mbox{\rm T-UCB}\_{h}^{k}(B)+L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\,\,\Big(\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}}\Big). |  |

The proof of Theorem [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [B.6](https://arxiv.org/html/2512.14991v1#A2.SS6 "B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 4.3 Concentration on reward estimators and properties of adaptive partition

We construct the estimator of the reward for any (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K] and Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k}:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | R^hkâ€‹(B)\displaystyle\widehat{R}\_{h}^{k}(B) | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)rhkinhkâ€‹(B),ifâ€‹nhkâ€‹(B)>0,\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B)},\quad\mbox{if}\,\,n\_{h}^{k}(B)>0, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | R^hkâ€‹(B)\displaystyle\widehat{R}\_{h}^{k}(B) | =\displaystyle= | 0,ifâ€‹nhkâ€‹(B)=0,\displaystyle 0,\quad\mbox{if}\,\,n\_{h}^{k}(B)=0, |  | (4.16) |

where rhkir\_{h}^{k\_{i}} are the corresponding instantaneous rewards received in episode kik\_{i} at step hh.

We then characterize the concentration inequality for reward estimation, introducing R-UCBhkâ€‹(B)\mbox{\rm R-UCB}\_{h}^{k}(B) to quantify the associated uncertainty. Specifically, for all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K] and all Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k}, we define R-UCBhkâ€‹(B)\mbox{\rm R-UCB}\_{h}^{k}(B) as follows when nhkâ€‹(B)>0n\_{h}^{k}(B)>0:

|  |  |  |  |
| --- | --- | --- | --- |
|  | R-UCBhkâ€‹(B):=logâ¡(2â€‹Hâ€‹K2Î´)â€‹Î¸nhkâ€‹(B),\displaystyle\mbox{\rm R-UCB}\_{h}^{k}(B):=\sqrt{\frac{\log(\frac{2HK^{2}}{\delta})\,\theta}{n\_{h}^{k}(B)}}, |  | (4.17) |

with Î¸\theta defined in ([2.6](https://arxiv.org/html/2512.14991v1#S2.E6 "In Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Theorem 4.5.

Under Assumption [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), It holds with probability at least 1âˆ’Î´1-\delta that, for any (h,k)âˆˆ[H]Ã—[K],Bâˆˆğ’«hk(h,k)\in[H]\times[K],B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B,

|  |  |  |  |
| --- | --- | --- | --- |
|  | |R^hkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|â‰¤R-UCBhkâ€‹(B)+|âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|.\displaystyle|\widehat{R}\_{h}^{k}(B)-\bar{R}\_{h}(x,a)|\leq\mbox{\rm R-UCB}\_{h}^{k}(B)+\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right|. |  | (4.18) |

###### Proof.

For fixed h,kh,k and Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} such that nhkâ€‹(B)>0n\_{h}^{k}(B)>0, by sub-Gaussian assumption of expected reward in ([2.6](https://arxiv.org/html/2512.14991v1#S2.E6 "In Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |
| --- | --- | --- |
|  | â„™Â¯â€‹(|âˆ‘i=1nhkâ€‹(B)rhkinhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)|â‰¥R-UCBhkâ€‹(B))â‰¤Î´Hâ€‹K2.\displaystyle\overline{\mathbb{P}}\Bigg(\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\right|\geq\mbox{\rm R-UCB}\_{h}^{k}(B)\Bigg)\leq\frac{\delta}{HK^{2}}. |  |

Taking expectations we get:

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(|âˆ‘i=1nhkâ€‹(B)rhkinhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)|â‰¥R-UCBhkâ€‹(B))â‰¤Î´Hâ€‹K2.\displaystyle\mathbb{P}\Bigg(\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\right|\geq\mbox{\rm R-UCB}\_{h}^{k}(B)\Bigg)\leq\frac{\delta}{HK^{2}}. |  |

Then we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â„™(âˆ©h=1Hâˆ©k=1Kâˆ©Bâˆˆğ’«hk,nhkâ€‹(B)>0{|âˆ‘i=1nhkâ€‹(B)rhkinhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)|â‰¤R-UCBhk(B)})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H}\cap\_{k=1}^{K}\cap\_{B\in\mathcal{P}\_{h}^{k},n\_{h}^{k}(B)>0}\Bigg\{\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\right|\leq\mbox{\rm R-UCB}\_{h}^{k}(B)\Bigg\}\Bigg) |  | (4.19) |
|  |  | =\displaystyle= | â„™(âˆ©h=1Hâˆ©k=1Kâˆ©nhkâ€‹(Bhk)=1K{|âˆ‘i=1nhkâ€‹(Bhk)rhkinhkâ€‹(Bhk)âˆ’âˆ‘i=1nhkâ€‹(Bhk)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(Bhk)|â‰¤logâ¡(2â€‹Hâ€‹K2Î´)â€‹Î¸nhkâ€‹(Bhk)})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H}\cap\_{k=1}^{K}\cap\_{n\_{h}^{k}(B\_{h}^{k})=1}^{K}\Bigg\{\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B\_{h}^{k})}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B\_{h}^{k})}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B\_{h}^{k})}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B\_{h}^{k})}\right|\leq\sqrt{\frac{\log(\frac{2HK^{2}}{\delta})\,\theta}{n\_{h}^{k}(B\_{h}^{k})}}\Bigg\}\Bigg) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’âˆ‘h=1Hâˆ‘k=1Kâˆ‘nhkâ€‹(Bhk)=1Kâ„™â€‹(|âˆ‘i=1nhkâ€‹(Bhk)rhkinhkâ€‹(Bhk)âˆ’âˆ‘i=1nhkâ€‹(Bhk)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(Bhk)|â‰¥logâ¡(2â€‹Hâ€‹K2Î´)â€‹Î¸nhkâ€‹(Bhk))\displaystyle 1-\sum\_{h=1}^{H}\sum\_{k=1}^{K}\sum\_{n\_{h}^{k}(B\_{h}^{k})=1}^{K}\mathbb{P}\Bigg(\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B\_{h}^{k})}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B\_{h}^{k})}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B\_{h}^{k})}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B\_{h}^{k})}\right|\geq\sqrt{\frac{\log(\frac{2HK^{2}}{\delta})\,\theta}{n\_{h}^{k}(B\_{h}^{k})}}\Bigg) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’Î´,\displaystyle 1-\delta, |  |

where BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). The first equality holds since only the estimate of selected block BhkB\_{h}^{k} is updated for each (h,k)(h,k) pair. The first inequality holds since for a countable sets of events {Ei}\{E\_{i}\} we have â„™â€‹(âˆ©iEi)â‰¥1âˆ’âˆ‘iâ„™â€‹(Eiâˆ)\mathbb{P}(\cap\_{i}E\_{i})\geq 1-\sum\_{i}\mathbb{P}(E\_{i}^{\complement}).

Furthermore, we have

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |R^hkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|\displaystyle|\widehat{R}\_{h}^{k}(B)-\bar{R}\_{h}(x,a)| |  |
|  |  | â‰¤\displaystyle\leq | |âˆ‘i=1nhkâ€‹(B)rhkinhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)|+|âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|.\displaystyle\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}r\_{h}^{k\_{i}}}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\right|+\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right|. |  |

Combine ([4.19](https://arxiv.org/html/2512.14991v1#S4.E19 "In 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([4.3](https://arxiv.org/html/2512.14991v1#S4.Ex28 "4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we verify that the desirable result in ([4.18](https://arxiv.org/html/2512.14991v1#S4.E18 "In Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds.
âˆ

To upper bound R-UCBhkâ€‹(B)+T-UCBhkâ€‹(B)\mbox{\rm R-UCB}\_{h}^{k}(B)+\mbox{\rm T-UCB}\_{h}^{k}(B), we construct the confidence of a block by

|  |  |  |  |
| --- | --- | --- | --- |
|  | CONFhkâ€‹(B)=g1(Î´,âˆ¥x~(oB)âˆ¥)nhkâ€‹(B),\displaystyle{\rm CONF}\_{h}^{k}(B)=\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{\sqrt{n\_{h}^{k}(B)}}, |  | (4.20) |

for all (h,k)âˆˆ[H]Ã—[K],Bâˆˆğ’«hk(h,k)\in[H]\times[K],B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0. Here
g1:(0,1]Ã—(â„+âˆª{0})â†¦â„+g\_{1}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | g1(Î´,y):=n(LV(Î´,y)(ÎºÎ¼(Î´,y,n)Î”+nÎ”32Î»ÎºÎ¼(Î´,y,n)2+dğ’®â€‹Î”12Î»ÎºÎ£(Î´,y,n))+logâ¡(2â€‹Hâ€‹K2Î´)â€‹Î¸n).g\_{1}(\delta,y):=\sqrt{n}\Big(L\_{V}(\delta,y)\,\,\Big(\kappa\_{\mu}(\delta,y,n)\Delta+\sqrt{n}\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\kappa\_{\mu}(\delta,y,n)^{2}+\frac{\sqrt{d\_{\mathcal{S}}}\Delta^{\frac{1}{2}}}{\sqrt{\lambda}}\kappa\_{\Sigma}(\delta,y,n)\Big)+\sqrt{\frac{\log(\frac{2HK^{2}}{\delta})\,\theta}{n}}\Big). |  | (4.21) |

Next, we provide upper bounds for âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)} and âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)2nhkâ€‹(B)\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})^{2}}{n\_{h}^{k}(B)} with respect to diamâ€‹(B){\rm diam}(B). Note that the proof of Lemma [4.6](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem6 "Lemma 4.6. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") relies on the CONFhkâ€‹(B){\rm CONF}\_{h}^{k}(B) specified in ([4.20](https://arxiv.org/html/2512.14991v1#S4.E20 "In 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). We defer the full proof to Appendix [B.7](https://arxiv.org/html/2512.14991v1#A2.SS7 "B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Lemma 4.6.

For all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K] and Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)â‰¤4â€‹diamâ€‹(B)â€‹Â andÂ â€‹âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)2nhkâ€‹(B)â‰¤4â€‹Dâ€‹diamâ€‹(B),\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\leq 4\,{\rm diam}(B)\,\,\mbox{ and }\,\,\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})^{2}}{n\_{h}^{k}(B)}\leq 4D\,{\rm diam}(B), |  | (4.22) |

where k1â‰¤,â‹¯,â‰¤knhkâ€‹(B)k\_{1}\leq,\cdots,\leq k\_{n\_{h}^{k}(B)} are the corresponding episode indices such that BB or its ancestors have been visited by Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 4.4 Bias of the estimators

Next, we provide upper bounds for â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î»\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}}, for which we introduce T-BIASâ€‹(B)\mbox{\rm T-BIAS}(B) to represent the block-wise bias in estimating the transition kernel

|  |  |  |
| --- | --- | --- |
|  | T-BIAS(B)=(8LÎ”+16LÎ·(âˆ¥x~(oB)âˆ¥)Î”Î»+32L2DÎ”32Î»+128L2DÎ”32Î»)diam(B).\displaystyle\mbox{\rm T-BIAS}(B)=\Bigg(8L\Delta+16L\,\,\eta(\|\tilde{x}(^{o}B)\|)\frac{\sqrt{\Delta}}{\sqrt{\lambda}}+32L^{2}D\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}+128L^{2}D\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\Bigg){\rm diam}(B). |  |

###### Theorem 4.7.

With the same assumptions as in Theorem [4.3](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), the following inequality holds for all hâˆˆ[Hâˆ’1],kâˆˆ[K]h\in[H-1],k\in[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î»â‰¤T-BIASâ€‹(B).\displaystyle\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}}\leq\mbox{\rm T-BIAS}(B). |  | (4.23) |

###### Proof.

Recall from Lemma [B.1](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem1 "Lemma B.1. â€£ B.1 Lemma B.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Lemma [B.2](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem2 "Lemma B.2. â€£ B.2 Lemma B.2 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") that,

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]\displaystyle\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)] | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B),\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]\displaystyle\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)] | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)(Î£hâ€‹(Xhki,Ahki)+(Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])â€‹(Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])âŠ¤â€‹Î”)nhkâ€‹(B).\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big(\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})+\big(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)\big(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)^{\top}\Delta\Big)}{n\_{h}^{k}(B)}. |  |

Then we have,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î»\displaystyle\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}} |  | (4.24) |
|  |  | â‰¤\displaystyle\leq | â€–âˆ‘i=1nhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–âˆ‘i=1nhkâ€‹(B)Î£hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î»\displaystyle\,\,\Big\|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}} |  |
|  |  |  | +âˆ‘i=1nhkâ€‹(B)â€–(Î¼hâ€‹(Xhki,Ahki)âˆ’Î¼hâ€‹(x,a)+Î¼hâ€‹(x,a)âˆ’âˆ‘inhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B))â€–2nhkâ€‹(B)â€‹Î”32Î»\displaystyle\qquad+\sum\_{i=1}^{n\_{h}^{k}(B)}\frac{\Big\|(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\mu\_{h}(x,a)+\mu\_{h}(x,a)-\frac{\sum\_{i}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)})\Big\|^{2}}{n\_{h}^{k}(B)}\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}} |  |
|  |  | â‰¤\displaystyle\leq | F0â€‹Î”+(F1+2â€‹F2+2â€‹F3)â€‹Î”Î»,\displaystyle F\_{0}\Delta+(F\_{1}+2F\_{2}+2F\_{3})\frac{\sqrt{\Delta}}{\sqrt{\lambda}}, |  |

in which

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | F0\displaystyle F\_{0} | =\displaystyle= | â€–âˆ‘i=1nhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’Î¼hâ€‹(x,a)â€–,F1=â€–âˆ‘i=1nhkâ€‹(B)Î£hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’Î£hâ€‹(x,a)â€–,\displaystyle\Big\|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\mu\_{h}(x,a)\Big\|,\quad F\_{1}=\Big\|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\Sigma\_{h}(x,a)\Big\|, |  | (4.25) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | F2\displaystyle F\_{2} | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)â€–(Î¼hâ€‹(Xhki,Ahki)âˆ’Î¼hâ€‹(x,a))â€–2nhkâ€‹(B)â€‹Î”,F3=âˆ‘i=1nhkâ€‹(B)â€–(Î¼hâ€‹(x,a)âˆ’âˆ‘inhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B))â€–2nhkâ€‹(B)â€‹Î”.\displaystyle\sum\_{i=1}^{n\_{h}^{k}(B)}\frac{\Big\|(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\mu\_{h}(x,a))\Big\|^{2}}{n\_{h}^{k}(B)}\Delta,\quad F\_{3}=\sum\_{i=1}^{n\_{h}^{k}(B)}\frac{\Big\|(\mu\_{h}(x,a)-\frac{\sum\_{i}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)})\Big\|^{2}}{n\_{h}^{k}(B)}\Delta. |  |

For F0F\_{0} in ([4.25](https://arxiv.org/html/2512.14991v1#S4.E25 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")),
since (x,a)(x,a) and (Xhki,Ahki)(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}}) lie in BhkiB\_{h}^{k\_{i}}, we have â€–Î¼hâ€‹(Xhki,Ahki)âˆ’Î¼hâ€‹(x,a)â€–â‰¤Lâ€‹diamâ€‹(Bhki)\Big\|\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\mu\_{h}(x,a)\Big\|\leq L\,{\rm diam}(B\_{h}^{k\_{i}}). Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | F0â‰¤âˆ‘i=1nhkâ€‹(B)â€–Î¼hâ€‹(Xhki,Ahki)âˆ’Î¼hâ€‹(x,a)â€–nhkâ€‹(B)â‰¤2â€‹Lâ€‹âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B).\displaystyle F\_{0}\leq\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big\|\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\mu\_{h}(x,a)\Big\|}{n\_{h}^{k}(B)}\leq\frac{2L\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}. |  | (4.26) |

For F1F\_{1},
we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | F1\displaystyle F\_{1} | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)â€–Î£hâ€‹(Xhki,Ahki)âˆ’Î£hâ€‹(x,a)â€–nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big\|\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\Sigma\_{h}(x,a)\Big\|}{n\_{h}^{k}(B)} |  | (4.27) |
|  |  | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)(â€–Ïƒhâ€‹(Xhki,Ahki)â€–+â€–Ïƒhâ€‹(x,a)â€–)â€‹â€–Ïƒhâ€‹(Xhki,Ahki)âˆ’Ïƒhâ€‹(x,a)â€–nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big(\Big\|\sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\Big\|+\Big\|\sigma\_{h}(x,a)\Big\|\Big)\Big\|\sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\sigma\_{h}(x,a)\Big\|}{n\_{h}^{k}(B)} |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)2Î·(âˆ¥x~(oB)âˆ¥)âˆ¥Ïƒh(Xhki,Ahki)âˆ’Ïƒh(x,a)âˆ¥nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}2\eta(\|\tilde{x}(^{o}B)\|)\Big\|\sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\sigma\_{h}(x,a)\Big\|}{n\_{h}^{k}(B)} |  |
|  |  | â‰¤\displaystyle\leq | 4LÎ·(âˆ¥x~(oB)âˆ¥)âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B),\displaystyle 4L\,\,\eta(\|\tilde{x}(^{o}B)\|)\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}, |  |

where we used ([4.7](https://arxiv.org/html/2512.14991v1#S4.E7 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) in getting the third inequality of ([4.27](https://arxiv.org/html/2512.14991v1#S4.E27 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For F2F\_{2} and F3F\_{3}
we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | F2â‰¤4â€‹L2â€‹âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)2nhkâ€‹(B),F3â‰¤(2â€‹Lâ€‹âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B))2,\displaystyle F\_{2}\leq\frac{4L^{2}\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})^{2}}{n\_{h}^{k}(B)},\quad F\_{3}\leq\left(2L\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\right)^{2}, |  | (4.28) |

Combining ([4.24](https://arxiv.org/html/2512.14991v1#S4.E24 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([4.26](https://arxiv.org/html/2512.14991v1#S4.E26 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([4.27](https://arxiv.org/html/2512.14991v1#S4.E27 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([4.28](https://arxiv.org/html/2512.14991v1#S4.E28 "In 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([4.22](https://arxiv.org/html/2512.14991v1#S4.E22 "In Lemma 4.6. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")),
we get ([4.23](https://arxiv.org/html/2512.14991v1#S4.E23 "In Theorem 4.7. â€£ 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
âˆ

Then we derive upper bounds for |âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right|, for which we define R-BIASâ€‹(B)\mbox{\rm R-BIAS}(B) to represent the block-wise bias in reward estimator

|  |  |  |
| --- | --- | --- |
|  | R-BIAS(B)=4Lm(âˆ¥x~(oB)âˆ¥)diam(B),\displaystyle\mbox{\rm R-BIAS}(B)=4L\_{m}(\|\tilde{x}(^{o}B)\|){\rm diam}(B), |  |

with Lm:â„+âˆª{0}â†¦â„+L\_{m}:\mathbb{R}\_{+}\cup\{0\}\mapsto\mathbb{R}\_{+} defined by

|  |  |  |
| --- | --- | --- |
|  | Lmâ€‹(y):=4â€‹Lâ€‹(1+2â€‹(y+D)m).\displaystyle L\_{m}(y):=4L\Big(1+2(y+D)^{m}\Big). |  |

In Proposition [C.1](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem1 "Proposition C.1. â€£ C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") of Appendix [C.3](https://arxiv.org/html/2512.14991v1#A3.SS3 "C.3 Proof of Theorem 5.5 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we show that |âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|â‰¤R-BIASâ€‹(B)\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right|\leq\mbox{\rm R-BIAS}(B) holds almost surely.

## 5 Regret analysis

In this section, we provide the regret analysis of the proposed adaptive partition framework.

### 5.1 Construction of value estimators

In this subsection, we construct estimators of the value functions.

To proceed, we first introduce a few notations. Define the block-wise bias consisting both the bias of transition estimator and the bias of reward estimator:

|  |  |  |  |
| --- | --- | --- | --- |
|  | BIAS(B):=R-BIAS(B)+LV(Î´,âˆ¥x~(oB)âˆ¥)T-BIAS(B):=g2(Î´,âˆ¥x~(oB)âˆ¥)diam(B),\displaystyle{\rm BIAS}(B):=\mbox{\rm R-BIAS}(B)+L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\mbox{\rm T-BIAS}(B):=g\_{2}(\delta,\|\tilde{x}(^{o}B)\|){\rm diam}(B), |  | (5.1) |

with g2:(0,1]Ã—(â„+âˆª{0})â†¦â„g\_{2}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R} defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | g2â€‹(Î´,y):=(4â€‹Lmâ€‹(y)+LVâ€‹(Î´,y)â€‹(8â€‹Lâ€‹Î”+16â€‹Lâ€‹Î·â€‹(y)â€‹Î”Î»+32â€‹L2â€‹Dâ€‹Î”32Î»+128â€‹L2â€‹Dâ€‹Î”32Î»)).\displaystyle g\_{2}(\delta,y):=\Bigg(4L\_{m}(y)+L\_{V}(\delta,y)\Big(8L\Delta+16L\,\eta(y)\frac{\sqrt{\Delta}}{\sqrt{\lambda}}+32L^{2}D\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}+128L^{2}D\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\Big)\Bigg). |  | (5.2) |

Here Î·\eta is defined in ([4.7](https://arxiv.org/html/2512.14991v1#S4.E7 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), x~\tilde{x} is defined in ([4.5](https://arxiv.org/html/2512.14991v1#S4.E5 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Bo{}^{o}B is defined in ([4.6](https://arxiv.org/html/2512.14991v1#S4.E6 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and LVL\_{V} is defined in ([4.12](https://arxiv.org/html/2512.14991v1#S4.E12 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

In addition, âˆ€(h,k)âˆˆ[H]Ã—[K]\forall(h,k)\in[H]\times[K], let

|  |  |  |
| --- | --- | --- |
|  | Î“ğ’®â€‹(ğ’«hk):=âˆª{Bâˆˆğ’«hkâ€‹s.t.âˆ„â€‹Bâ€²âˆˆğ’«hk,Î“ğ’®â€‹(Bâ€²)âŠŠÎ“ğ’®â€‹(B)}{Î“ğ’®â€‹(B)}\displaystyle\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}):=\cup\_{\{B\in\mathcal{P}\_{h}^{k}\,\,{\rm s.t.}\,\,\nexists B^{\prime}\in\mathcal{P}\_{h}^{k},\Gamma\_{\mathcal{S}}(B^{\prime})\subsetneq\Gamma\_{\mathcal{S}}(B)\}}\{\Gamma\_{\mathcal{S}}(B)\} |  |

be the state partition induced by the current state-action partition ğ’«hk\mathcal{P}\_{h}^{k}.
For SâˆˆÎ“ğ’®â€‹(ğ’«hk)S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}), we overload the notation defined in ([4.5](https://arxiv.org/html/2512.14991v1#S4.E5 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), i.e., denote x~â€‹(S)\tilde{x}(S) as the center of SS.

Finally, we set the local Lipschitz constant as follows, which will be used below in the construction of value function estimators

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ch:=maxâ¡{CÂ¯h,2m+1â€‹C~h},âˆ€hâˆˆ[H],\displaystyle C\_{h}:=\max\Big\{\overline{C}\_{h},2^{m+1}\widetilde{C}\_{h}\Big\},\quad\forall h\in[H], |  | (5.3) |

where CÂ¯h\overline{C}\_{h} is defined in ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and C~h\widetilde{C}\_{h} is defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). It is worth emphasizing that such choice of local Lipschitz constant is necessary to guarantee the local Lipschitz property of VÂ¯hk\overline{V}\_{h}^{k} which is formally stated in Theorem [5.3](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem3 "Theorem 5.3. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

##### Design of value estimators.

For k=0,hâˆˆ[H],Bâˆˆğ’«h0,S=Î“ğ’®â€‹(B)k=0,h\in[H],B\in\mathcal{P}\_{h}^{0},S=\Gamma\_{\mathcal{S}}(B), and xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}}, the function estimators are initialized with

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QÂ¯h0â€‹(B)\displaystyle\overline{Q}\_{h}^{0}(B) | :=\displaystyle:= | C~h(1+(âˆ¥x~(oB)âˆ¥+D)m+1),\displaystyle\widetilde{C}\_{h}(1+(\|\tilde{x}(^{o}B)\|+D)^{m+1}), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | V~h0â€‹(S)\displaystyle\widetilde{V}\_{h}^{0}(S) | :=\displaystyle:= | C~hâ€‹(1+(â€–x~â€‹(S)â€–+D)m+1),\displaystyle\widetilde{C}\_{h}(1+(\|\tilde{x}(S)\|+D)^{m+1}), |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | VÂ¯h0â€‹(x)\displaystyle\overline{V}\_{h}^{0}(x) | :=\displaystyle:= | C~hâ€‹(1+â€–xâ€–m+1).\displaystyle\widetilde{C}\_{h}(1+\|x\|^{m+1}). |  | (5.4) |

In addition, for (h,k)âˆˆ[H]Ã—([K]âˆª{0})(h,k)\in[H]\times([K]\cup\{0\}), we set QÂ¯hkâ€‹(ZÂ¯âˆ)\overline{Q}\_{h}^{k}(\bar{Z}^{\complement}) as:

|  |  |  |  |
| --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(ZÂ¯âˆ):=âˆ’C~hâ€‹(1+Ïm+1).\displaystyle\overline{Q}\_{h}^{k}(\bar{Z}^{\complement}):=-\widetilde{C}\_{h}(1+\rho^{m+1}). |  | (5.5) |

Now we specify the following recursive definition with respect to kâ‰¥1k\geq 1. Specifically, at the terminal timestamp HH, for Bâˆˆğ’«HkB\in\mathcal{P}\_{H}^{k}, SâˆˆÎ“ğ’®â€‹(ğ’«Hk)S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{H}^{k}), xâˆˆğ’®1x\in\mathcal{S}\_{1}, we define

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | QÂ¯Hkâ€‹(B)\displaystyle\overline{Q}\_{H}^{k}(B) | :=\displaystyle:= | {R^Hkâ€‹(B)+R-UCBHkâ€‹(B)+R-BIASâ€‹(B)Â ifÂ â€‹nHkâ€‹(B)>0QÂ¯H0â€‹(B)Â ifÂ â€‹nHkâ€‹(B)=0,\displaystyle\left\{\begin{array}[]{lll}\widehat{R}\_{H}^{k}(B)+\mbox{\rm R-UCB}\_{H}^{k}(B)+\mbox{\rm R-BIAS}(B)&&\mbox{ if }n\_{H}^{k}(B)>0\\ \overline{Q}\_{H}^{0}(B)&&\mbox{ if }n\_{H}^{k}(B)=0,\end{array}\right. |  | (5.8) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | V~Hkâ€‹(S)\displaystyle\widetilde{V}\_{H}^{k}(S) | :=\displaystyle:= | minâ¡{V~Hkâˆ’1â€‹(S),maxBâˆˆğ’«Hk,SâŠ‚Î“ğ’®â€‹(B)â¡QÂ¯Hkâ€‹(B)},\displaystyle\min\Big\{\widetilde{V}\_{H}^{k-1}(S),\max\_{B\in\mathcal{P}\_{H}^{k},S\subset\Gamma\_{\mathcal{S}}(B)}\overline{Q}\_{H}^{k}(B)\Big\}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VH,klocalâ€‹(x,S)\displaystyle V\_{H,k}^{\rm local}(x,S) | :=\displaystyle:= | V~Hkâ€‹(S)+CHâ€‹(1+â€–xâ€–m+â€–x~â€‹(S)â€–m)â€‹â€–xâˆ’x~â€‹(S)â€–,\displaystyle\widetilde{V}\_{H}^{k}(S)+C\_{H}\Big(1+\|x\|^{m}+\|\tilde{x}(S)\|^{m}\Big)\|x-\tilde{x}(S)\|, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | VÂ¯Hkâ€‹(x)\displaystyle\overline{V}\_{H}^{k}(x) | :=\displaystyle:= | minSâˆˆÎ“ğ’®â€‹(ğ’«Hk)â¡VH,klocalâ€‹(x,S).\displaystyle\min\_{S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{H}^{k})}V\_{H,k}^{\rm local}(x,S). |  | (5.9) |

For xâˆˆâ„dğ’®âˆ–ğ’®1x\in\mathbb{R}^{d\_{\mathcal{S}}}\setminus\mathcal{S}\_{1}, we define

|  |  |  |  |
| --- | --- | --- | --- |
|  | VÂ¯Hkâ€‹(x):=VÂ¯Hkâ€‹(Ïâ€–xâ€–â€‹x)+CHâ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–.\displaystyle\overline{V}\_{H}^{k}(x):=\overline{V}\_{H}^{k}\left(\frac{\rho}{\|x\|}x\right)+C\_{H}(1+\|x\|^{m}+\rho^{m})\left\|\left(1-\frac{\rho}{\|x\|}\right)x\right\|. |  | (5.10) |

Note that this extrapolation ensures the continuity of VÂ¯Hk\overline{V}\_{H}^{k} on the entire state space.

Similarly, we define the values for h<Hh<H. For Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k},SâˆˆÎ“ğ’®â€‹(ğ’«hk)S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}), xâˆˆğ’®1x\in\mathcal{S}\_{1} we define

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(B)\displaystyle\overline{Q}\_{h}^{k}(B) | :=\displaystyle:= | {R^hkâ€‹(B)+R-UCBhkâ€‹(B)+ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]+T-UCBhkâ€‹(B)+BIASâ€‹(B)ifÂ â€‹nhkâ€‹(B)>0QÂ¯h0â€‹(B)ifÂ â€‹nhkâ€‹(B)=0,\displaystyle\left\{\begin{array}[]{lll}\widehat{R}\_{h}^{k}(B)+\mbox{\rm R-UCB}\_{h}^{k}(B)+\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]\\ +\mbox{\rm T-UCB}\_{h}^{k}(B)+{\rm BIAS}(B)&&\mbox{if }n\_{h}^{k}(B)>0\\ \overline{Q}\_{h}^{0}(B)&&\mbox{if }n\_{h}^{k}(B)=0,\end{array}\right. |  | (5.12) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | V~hkâ€‹(S)\displaystyle\widetilde{V}\_{h}^{k}(S) | :=\displaystyle:= | minâ¡{V~hkâˆ’1â€‹(S),maxBâˆˆğ’«hk,SâŠ‚Î“ğ’®â€‹(B)â¡QÂ¯hkâ€‹(B)},\displaystyle\min\Big\{\widetilde{V}\_{h}^{k-1}(S),\max\_{B\in\mathcal{P}\_{h}^{k},S\subset\Gamma\_{\mathcal{S}}(B)}\overline{Q}\_{h}^{k}(B)\Big\}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Vh,klocalâ€‹(x,S)\displaystyle V\_{h,k}^{\rm local}(x,S) | :=\displaystyle:= | V~hkâ€‹(S)+Châ€‹(1+â€–xâ€–m+â€–x~â€‹(S)â€–m)â€‹â€–xâˆ’x~â€‹(S)â€–,\displaystyle\widetilde{V}\_{h}^{k}(S)+C\_{h}\Big(1+\|x\|^{m}+\|\tilde{x}(S)\|^{m}\Big)\|x-\tilde{x}(S)\|, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(x)\displaystyle\overline{V}\_{h}^{k}(x) | :=\displaystyle:= | minSâˆˆÎ“ğ’®â€‹(ğ’«hk)â¡Vh,klocalâ€‹(x,S).\displaystyle\min\_{S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k})}V\_{h,k}^{\rm local}(x,S). |  | (5.13) |

Finally, for xâˆˆâ„dğ’®âˆ–ğ’®1x\in\mathbb{R}^{d\_{\mathcal{S}}}\setminus\mathcal{S}\_{1}, we define

|  |  |  |  |
| --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(x):=VÂ¯hkâ€‹(Ïâ€–xâ€–â€‹x)+Châ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–.\displaystyle\overline{V}\_{h}^{k}(x):=\overline{V}\_{h}^{k}\left(\frac{\rho}{\|x\|}x\right)+C\_{h}(1+\|x\|^{m}+\rho^{m})\left\|\left(1-\frac{\rho}{\|x\|}\right)x\right\|. |  | (5.14) |

###### Remark 5.1 (Role of Vh,klocalV^{\rm local}\_{h,k}).

We design
Vh,klocal(.,S)V^{\rm local}\_{h,k}(.,S) as a locally Lipschitz extension of the estimate for SS across the entire state space. The local Lipschitz property plays a key role in establishing concentration bounds associated with VÂ¯hk\overline{V}\_{h}^{k}. This is formalized in Corollary [5.4](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem4 "Corollary 5.4. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

The update formulas ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))-([5.14](https://arxiv.org/html/2512.14991v1#S5.E14 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) correspond to a value iteration step, where the true rewards and transition kernels in the Bellman equation ([2.1](https://arxiv.org/html/2512.14991v1#S2.Ex5 "Bellman equation for generic policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) are replaced by their respective estimators. The terms R-UCBhkâ€‹(B)\mbox{\rm R-UCB}\_{h}^{k}(B), T-UCBhkâ€‹(B)\mbox{\rm T-UCB}\_{h}^{k}(B), and BIASâ€‹(B){\rm BIAS}(B) serve as bonus terms that account for uncertainty in reward estimation, uncertainty in transition kernel estimation, and partition biases, respectively.

Below we show that the value estimators QÂ¯hk\overline{Q}\_{h}^{k}, V~hk\widetilde{V}\_{h}^{k}, and VÂ¯hk\overline{V}\_{h}^{k} defined in ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))-([5.14](https://arxiv.org/html/2512.14991v1#S5.E14 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) serve as upper bounds of the true value functions.

###### Theorem 5.2.

Under Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), with probability at least 1âˆ’3â€‹Î´1-3\delta, it holds that for all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K],

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(B)\displaystyle\overline{Q}\_{h}^{k}(B) | â‰¥\displaystyle\geq | Qhâˆ—â€‹(x,a),for allÂ Bâˆˆğ’«hkÂ andÂ (x,a)âˆˆB,\displaystyle Q\_{h}^{\*}(x,a),\,\,\mbox{for all $B\in\mathcal{P}\_{h}^{k}$ and $(x,a)\in B$}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | V~hkâ€‹(S)\displaystyle\widetilde{V}\_{h}^{k}(S) | â‰¥\displaystyle\geq | Vhâˆ—â€‹(x),for allÂ SâˆˆÎ“ğ’®â€‹(ğ’«hk)Â andÂ xâˆˆS,\displaystyle V\_{h}^{\*}(x),\,\,\mbox{for all $S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k})$ and $x\in S$}, |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(x)\displaystyle\overline{V}\_{h}^{k}(x) | â‰¥\displaystyle\geq | Vhâˆ—â€‹(x),for allÂ xâˆˆâ„dğ’®.\displaystyle V\_{h}^{\*}(x),\,\,\mbox{for all $x\in\mathbb{R}^{d\_{\mathcal{S}}}$}. |  | (5.15) |

The proof of Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.1](https://arxiv.org/html/2512.14991v1#A3.SS1 "C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Next, we show that the estimated value functions satisfy a local Lipschitz property.

###### Theorem 5.3.

Under Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), with probability at least 1âˆ’3â€‹Î´1-3\delta, for all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], x1,x2âˆˆâ„dğ’®x\_{1},x\_{2}\in\mathbb{R}^{d\_{\mathcal{S}}},

|  |  |  |
| --- | --- | --- |
|  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|â‰¤C^hâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle\Big|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})\Big|\leq\widehat{C}\_{h}\Big(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m}\Big)\|x\_{1}-x\_{2}\|, |  |

where

|  |  |  |  |
| --- | --- | --- | --- |
|  | C^h:=C^hâ€‹(m,Ch,C~h,D),\displaystyle\widehat{C}\_{h}:=\widehat{C}\_{h}(m,C\_{h},\widetilde{C}\_{h},D), |  | (5.16) |

with ChC\_{h} defined in ([5.3](https://arxiv.org/html/2512.14991v1#S5.E3 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and C~h\widetilde{C}\_{h} defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Note that the initialization in ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), together with the subsequently constructed value estimates in ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))â€“([5.14](https://arxiv.org/html/2512.14991v1#S5.E14 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), plays a pivotal role in establishing the local Lipschitz property. The proof underscores the challenges and complexities introduced by the polynomial structure inherent to our setting, which is different from (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)). The detailed proof of Theorem [5.3](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem3 "Theorem 5.3. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is provided in Appendix [C.2](https://arxiv.org/html/2512.14991v1#A3.SS2 "C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Applying Lemma [B.4](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem4 "Lemma B.4. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") in the same fashion as in the proof of Theorem [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") yields the following corollary.

###### Corollary 5.4.

Assume the same assumptions as in Theorem [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). With probability at least 1âˆ’2â€‹Î´1-2\delta, for any (h,k)âˆˆ[Hâˆ’1]Ã—[K],Bâˆˆğ’«hk(h,k)\in[H-1]\times[K],B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B, we have the following:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[\overline{V}\_{h+1}^{k}(Y)]\right| |  | (5.17) |
|  |  | â‰¤\displaystyle\leq | C^maxCÂ¯max(T-UCBhk(B)+LV(Î´,âˆ¥x~(oB)âˆ¥)T-BIAS(B)),\displaystyle\,\,\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm T-UCB}\_{h}^{k}(B)+L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\,\,\mbox{\rm T-BIAS}(B)\Big), |  |

where C^max:=maxhâˆˆ[H]â¡C^h\widehat{C}\_{\max}:=\max\_{h\in[H]}\widehat{C}\_{h} with C^h\widehat{C}\_{h} defined in ([5.16](https://arxiv.org/html/2512.14991v1#S5.E16 "In Theorem 5.3. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), CÂ¯max\overline{C}\_{\max} in ([4.13](https://arxiv.org/html/2512.14991v1#S4.E13 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), x~\tilde{x} in ([4.5](https://arxiv.org/html/2512.14991v1#S4.E5 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Bo{}^{o}B in ([4.6](https://arxiv.org/html/2512.14991v1#S4.E6 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and LVL\_{V} in ([4.12](https://arxiv.org/html/2512.14991v1#S4.E12 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

We then bound the difference between the Q-estimators and the true Q-functions in the following Theorem [5.5](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem5 "Theorem 5.5. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Proposition [5.6](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem6 "Proposition 5.6. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Theorem 5.5.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. The following inequality holds with probability at least 1âˆ’3â€‹Î´1-3\delta, for any (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0 , and (x,a)âˆˆB(x,a)\in B,

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QÂ¯Hkâ€‹(B)âˆ’QHâˆ—â€‹(x,a)\displaystyle\overline{Q}\_{H}^{k}(B)-Q\_{H}^{\*}(x,a) | â‰¤\displaystyle\leq | 2â€‹C^maxCÂ¯maxâ€‹(R-UCBHkâ€‹(B)+R-BIASâ€‹(B));\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{H}^{k}(B)+\mbox{\rm R-BIAS}(B)\Big); |  |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(B)âˆ’Qhâˆ—â€‹(x,a)\displaystyle\overline{Q}\_{h}^{k}(B)-Q\_{h}^{\*}(x,a) | â‰¤\displaystyle\leq | 2â€‹C^maxCÂ¯maxâ€‹(R-UCBhkâ€‹(B)+T-UCBhkâ€‹(B)+BIASâ€‹(B))\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k}(B)+\mbox{\rm T-UCB}\_{h}^{k}(B)+{\rm BIAS}(B)\Big) |  | (5.18) |
|  |  |  | +ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)],h<H.\displaystyle+\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(X)],h<H. |  |

The proof of Theorem [5.5](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem5 "Theorem 5.5. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.3](https://arxiv.org/html/2512.14991v1#A3.SS3 "C.3 Proof of Theorem 5.5 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proposition 5.6.

Assume that Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. For any (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)=0n\_{h}^{k}(B)=0, (x,a)âˆˆB(x,a)\in B,
the following inequality holds:

|  |  |  |  |
| --- | --- | --- | --- |
|  | QÂ¯hk(B)âˆ’Qhâˆ—(x,a)â‰¤2C~hD(1+(âˆ¥x~(oB)âˆ¥+D)m+1)diam(B),\displaystyle\overline{Q}\_{h}^{k}(B)-Q\_{h}^{\*}(x,a)\leq 2\frac{\widetilde{C}\_{h}}{D}(1+(\|\tilde{x}(^{o}B)\|+D)^{m+1}){\rm diam}(B), |  | (5.19) |

where C~h\widetilde{C}\_{h} is defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

The proof of Proposition [5.6](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem6 "Proposition 5.6. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.4](https://arxiv.org/html/2512.14991v1#A3.SS4 "C.4 Proof of Proposition 5.6 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

We also have the following bounds on value function estimators evaluated at XhkX\_{h}^{k}.

###### Proposition 5.7.

For any (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], conditioned on Xhkâˆˆğ’®1X\_{h}^{k}\in\mathcal{S}\_{1}, we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | VÂ¯hkâˆ’1(Xhk)â‰¤QÂ¯hkâˆ’1(Bhk)+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk),\displaystyle\overline{V}\_{h}^{k-1}(X\_{h}^{k})\leq\overline{Q}\_{h}^{k-1}(B\_{h}^{k})+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}), |  | (5.20) |

where BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Bhko{}^{o}B\_{h}^{k} is defined in ([4.6](https://arxiv.org/html/2512.14991v1#S4.E6 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

The proof of Proposition [5.7](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem7 "Proposition 5.7. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.5](https://arxiv.org/html/2512.14991v1#A3.SS5 "C.5 Proof of Proposition 5.7 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 5.2 Upper bound via clipping

In this subsection, we use the Clipping method (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53), Section E) to obtain an upper bound for

|  |  |  |  |
| --- | --- | --- | --- |
|  | Î”h(k):=VÂ¯hkâˆ’1â€‹(Xhk)âˆ’VhÏ€~kâ€‹(Xhk),\displaystyle\Delta\_{h}^{(k)}:=\overline{V}\_{h}^{k-1}(X\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k}), |  | (5.21) |

with terminal condition Î”H+1(k)=0\Delta\_{H+1}^{(k)}=0. Here {Ï€~k}kâˆˆ[K]\{\tilde{\pi}^{k}\}\_{k\in[K]} is defined in ([3.4](https://arxiv.org/html/2512.14991v1#S3.E4 "In Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). he upper bound of Î”h(k)\Delta\_{h}^{(k)} will play an important role in controlling the final regret bound.

The clip function is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | CLIPâ€‹(Î½1|Î½2):=Î½1â€‹ğ•€Î½1â‰¥Î½2,âˆ€Î½1,Î½2âˆˆâ„.\displaystyle{\rm CLIP}(\nu\_{1}|\nu\_{2}):=\nu\_{1}\mathbb{I}\_{\nu\_{1}\geq\nu\_{2}},\forall\nu\_{1},\nu\_{2}\in\mathbb{R}. |  | (5.22) |

Intuitively, Î½2\nu\_{2} is used to clip Î½1\nu\_{1}, as it takes the value of Î½1\nu\_{1} if and only if Î½1â‰¥Î½2\nu\_{1}\geq\nu\_{2} and its value is zero otherwise.

Before proceeding, we introduce a few useful notations:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | G~â€‹aphâ€‹(x,a)\displaystyle{\rm\widetilde{G}ap}\_{h}(x,a) | :=\displaystyle:= | Vhâˆ—â€‹(x)âˆ’Qhâˆ—â€‹(x,a);\displaystyle V\_{h}^{\*}(x)-Q\_{h}^{\*}(x,a); |  | (5.23) |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Gaphâ€‹(B)\displaystyle{\rm Gap}\_{h}(B) | :=\displaystyle:= | min(x,a)âˆˆBâ¡G~â€‹aphâ€‹(x,a);\displaystyle\min\_{(x,a)\in B}{\rm\widetilde{G}ap}\_{h}(x,a); |  | (5.24) |
|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | fh+1kâˆ’1â€‹(Xhk,Ahk)\displaystyle f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k}) | :=\displaystyle:= | ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[VÂ¯h+1kâˆ’1â€‹(Y)]âˆ’ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1âˆ—â€‹(Y)],h<H,\displaystyle\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\overline{V}\_{h+1}^{k-1}(Y)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\*}(Y)],h<H, |  | (5.25) |

with terminal fH+1kâˆ’1â€‹(XHk,AHk)=0f\_{H+1}^{k-1}(X\_{H}^{k},A\_{H}^{k})=0.

Also, to further ease the notation, for (h,k)âˆˆ[H]Ã—[K],Bhkâˆˆğ’«hkâˆ’1(h,k)\in[H]\times[K],B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1} we denote:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Ghkâ€‹(Bhk)\displaystyle G\_{h}^{k}(B\_{h}^{k}) | :=\displaystyle:= | {2C~hD(1+(âˆ¥x~(oBhk)âˆ¥+D)m+1)diam(Bhk),ifhâˆˆ[H],nhkâˆ’1(Bhk)=0,kâ‰¥1;2â€‹C^maxCÂ¯maxâ€‹(R-UCBhkâˆ’1â€‹(Bhk)+T-UCBhkâˆ’1â€‹(Bhk)+BIASâ€‹(Bhk))+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk),ifh<H,nhkâˆ’1(Bhk)>0,k>1;2â€‹C^maxCÂ¯maxâ€‹(R-UCBhkâˆ’1â€‹(Bhk)+R-BIASâ€‹(Bhk))+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk),ifh=H,nhkâˆ’1(Bhk)>0,k>1,\displaystyle\left\{\begin{array}[]{lll}2\frac{\widetilde{C}\_{h}}{D}(1+(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m+1}){\rm diam}(B\_{h}^{k}),\,\,\,\,\mbox{if}\,\,h\in[H],n\_{h}^{k-1}(B\_{h}^{k})=0,k\geq 1;\\ 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k-1}(B\_{h}^{k})+\mbox{\rm T-UCB}\_{h}^{k-1}(B\_{h}^{k})+{\rm BIAS}(B\_{h}^{k})\Big)\\ +C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}),\,\,\,\,\mbox{if}\,\,h<H,n\_{h}^{k-1}(B\_{h}^{k})>0,k>1;\\ 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k-1}(B\_{h}^{k})+\mbox{\rm R-BIAS}(B\_{h}^{k})\Big)\\ +C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}),\,\,\,\,\mbox{if}\,\,h=H,n\_{h}^{k-1}(B\_{h}^{k})>0,k>1,\end{array}\right. |  | (5.31) |

where x~\tilde{x} is defined in ([4.5](https://arxiv.org/html/2512.14991v1#S4.E5 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), C~h\widetilde{C}\_{h} in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ChC\_{h} in ([5.3](https://arxiv.org/html/2512.14991v1#S5.E3 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), CÂ¯max\overline{C}\_{\max} in ([4.13](https://arxiv.org/html/2512.14991v1#S4.E13 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), C^max\widehat{C}\_{\max} in ([5.17](https://arxiv.org/html/2512.14991v1#S5.E17 "In Corollary 5.4. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In addition, BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Bhko{}^{o}B\_{h}^{k} is defined in ([4.6](https://arxiv.org/html/2512.14991v1#S4.E6 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Remark 5.8 (Role of Ghkâ€‹(Bhk)G\_{h}^{k}(B\_{h}^{k})).

We remark that Ghkâ€‹(Bhk)G\_{h}^{k}(B\_{h}^{k}) represents the overall bonus terms and bias of the estimate w.r.t the selected block BhkB\_{h}^{k}. By "clipping" it with the gap term, it provides a useful upper bound for us to control the final regret; see more analysis in Lemma [5.17](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem17 "Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Theorem 5.9.

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. With probability at least 1âˆ’3â€‹Î´1-3\delta, for all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], Bhkâˆˆğ’«hkâˆ’1B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1}, we have that:

|  |  |  |
| --- | --- | --- |
|  | Î”h(k)â‰¤CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+(1+1H)â€‹fh+1kâˆ’1â€‹(Xhk,Ahk)+Qhâˆ—â€‹(Xhk,Ahk)âˆ’VhÏ€~kâ€‹(Xhk).\displaystyle\Delta\_{h}^{(k)}\leq{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\,\,\Bigg|\,\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+\Big(1+\frac{1}{H}\Big)f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k})+Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k}). |  |

The proof of Theorem [5.9](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem9 "Theorem 5.9. â€£ 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.6](https://arxiv.org/html/2512.14991v1#A3.SS6 "C.6 Proof of Theorem 5.9 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 5.3 Concentrations on the size of JÏKJ\_{\rho}^{K} and initial value function

In this subsection, we provide some useful concentrations before establishing the final regret bound.

We categorize the sample trajectories into two types: those remains within ğ’®1\mathcal{S}\_{1} for the entire episode, denoted by

|  |  |  |  |
| --- | --- | --- | --- |
|  | JÏK:={kâˆˆ[K]:maxhâˆˆ[H]â¡â€–Xhkâ€–â‰¤Ï},\displaystyle J\_{\rho}^{K}:=\left\{k\in[K]:\max\_{h\in[H]}\|X\_{h}^{k}\|\leq\rho\right\}, |  | (5.32) |

and those
exceeds ğ’®1\mathcal{S}\_{1}.
We also denote

|  |  |  |
| --- | --- | --- |
|  | Ik:=ğ•€{kâˆˆJÏK},pÏk=â„™â€‹(kâˆˆJÏK)=ğ”¼â€‹[Ik],andK0=âˆ‘k=1KIk=|JÏK|.\displaystyle I\_{k}:=\mathbb{I}\_{\{k\in J^{K}\_{\rho}\}},\quad p\_{\rho}^{k}=\mathbb{P}\left(k\in J^{K}\_{\rho}\right)=\mathbb{E}[I\_{k}],\quad\mbox{and}\quad K\_{0}=\sum\_{k=1}^{K}I\_{k}=|J\_{\rho}^{K}|. |  |

According to Corollary [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem3 "Corollary 2.3. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we know that

|  |  |  |  |
| --- | --- | --- | --- |
|  | pÏkâ‰¥1âˆ’MpÏp,Â and henceÂ â€‹ğ”¼â€‹[K0]â‰¥Kâ€‹(1âˆ’MpÏp).\displaystyle p\_{\rho}^{k}\geq 1-\frac{M\_{p}}{\rho^{p}},\mbox{ and hence }\mathbb{E}[K\_{0}]\geq K\left(1-\frac{M\_{p}}{\rho^{p}}\right). |  | (5.33) |

We also have the following concentration bound for K0K\_{0}.

###### Proposition 5.10.

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. The following holds with probability at least 1âˆ’Î´1-\delta,

|  |  |  |
| --- | --- | --- |
|  | Kâˆ’K0â‰¤Kâ€‹MpÏp+2â€‹Kâ€‹logâ¡(1Î´).\displaystyle K-K\_{0}\leq\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log\left(\frac{1}{\delta}\right)}. |  |

The proof of Proposition [5.10](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem10 "Proposition 5.10. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.7](https://arxiv.org/html/2512.14991v1#A3.SS7 "C.7 Proof of Proposition 5.10 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Next, we present a concentration result for value functions associated with state processes that exit the ball of radius Ï\rho.

###### Theorem 5.11.

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. For any policy Ï€\pi, we have the following holds with probability at least 1âˆ’Î´1-\delta,

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘kâˆˆ[K]\JÏK|V1Ï€â€‹(X1k)|â‰¤Kâ€‹Îºm+1â€‹(Î´,Ï)+C~1â€‹(1+Ïm+1)â€‹(Kâˆ’K0),\displaystyle\sum\_{k\in[K]\backslash J\_{\rho}^{K}}|V\_{1}^{\pi}(X\_{1}^{k})|\leq K\kappa\_{m+1}(\delta,\rho)+\widetilde{C}\_{1}\Big(1+\rho^{m+1}\Big)(K-K\_{0}), |  | (5.34) |

where Îºm+1:(0,1]Ã—(â„+âˆª{0})â†¦â„+\kappa\_{m+1}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Îºm+1â€‹(Î´,y):=1Î´â€‹C~1â€‹(ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]yp+ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]ypâˆ’(m+1)),\displaystyle\kappa\_{m+1}(\delta,y):=\frac{1}{\delta}\widetilde{C}\_{1}\Big(\frac{\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]}{y^{p}}+\frac{\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]}{y^{p-(m+1)}}\Big), |  | (5.35) |

and C~1\widetilde{C}\_{1} is defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

The proof of Theorem [5.11](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem11 "Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.8](https://arxiv.org/html/2512.14991v1#A3.SS8 "C.8 Proof of Theorem 5.11 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

### 5.4 Regret composition

In this subsection, we provide the regret analysis of Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). In Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we bound the regret by separating two types of episodes.

###### Theorem 5.12.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. With probability at least 1âˆ’6â€‹Î´1-6\delta, we have:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJ1CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´)\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{1}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)} |  |
|  |  |  | +2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)+4â€‹C~1â€‹(L~3+Ïm+1+e2â€‹L~2â€‹Hâ€‹(Mpâ€‹KÎ´)m+1p)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´)),\displaystyle+2K\kappa\_{m+1}(\delta,\rho)+4\widetilde{C}\_{1}\Big(\widetilde{L}\_{3}+\rho^{m+1}+e^{2}\widetilde{L}\_{2}H\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right), |  |

where L~1,L~2\widetilde{L}\_{1},\widetilde{L}\_{2} depends only on m,D,dğ’®,C~max,Cmaxm,D,d\_{\mathcal{S}},\widetilde{C}\_{\max},C\_{\max} and L~3:=1+e2â€‹L~2â€‹H\widetilde{L}\_{3}:=1+e^{2}\widetilde{L}\_{2}H
with

|  |  |  |  |
| --- | --- | --- | --- |
|  | C~max:=maxhâˆˆ[H]â¡C~h,Cmax:=maxhâˆˆ[H]â¡Ch.\displaystyle\widetilde{C}\_{\max}:=\max\_{h\in[H]}\widetilde{C}\_{h},\quad C\_{\max}:=\max\_{h\in[H]}C\_{h}. |  | (5.36) |

Here C~h\widetilde{C}\_{h} is defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ChC\_{h} in ([5.3](https://arxiv.org/html/2512.14991v1#S5.E3 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), C~\widetilde{C} in ([4.14](https://arxiv.org/html/2512.14991v1#S4.E14 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Î·\eta in ([4.7](https://arxiv.org/html/2512.14991v1#S4.E7 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Gaph{\rm Gap}\_{h} in ([5.24](https://arxiv.org/html/2512.14991v1#S5.E24 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), GhkG\_{h}^{k} in ([5.31](https://arxiv.org/html/2512.14991v1#S5.E31 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and Îºm+1\kappa\_{m+1} in ([5.35](https://arxiv.org/html/2512.14991v1#S5.E35 "In Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In addition, BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

The proof of Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") is deferred to Appendix [C.10](https://arxiv.org/html/2512.14991v1#A3.SS10 "C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Before deriving the ultimate regret bound, we introduce the key concepts of near-optimal sets and zooming dimensions, which are commonly used in the contextual bandits literature to bound an algorithmâ€™s regret (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)). However, in our setting, where the state space is unbounded and the reward function is polynomial, these concepts require modification.

###### Definition 5.13 (Near optimal set).

The near optimal set of ZÂ¯\bar{Z} for a given value rr is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | Zhr,Ï={(x,a)âˆˆZÂ¯|G~â€‹aphâ€‹(x,a)â‰¤gÂ¯â€‹(Î´,x)â€‹(H+1)â€‹r},\displaystyle Z\_{h}^{r,\rho}=\Big\{(x,a)\in\bar{Z}\,\Big|\,{\rm\widetilde{G}ap}\_{h}(x,a)\leq\bar{g}(\delta,x)(H+1)r\Big\}, |  | (5.37) |

where the partition space ZÂ¯\overline{Z} is defined in ([3.1](https://arxiv.org/html/2512.14991v1#S3.E1 "In Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and gÂ¯:(0,1]Ã—â„dğ’®â†¦â„+\bar{g}:(0,1]\times\mathbb{R}^{d\_{\mathcal{S}}}\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | gÂ¯â€‹(Î´,x):=2â€‹g3â€‹(Î´,â€–xâ€–+D)+3â€‹CÂ¯maxâ€‹(1+2â€‹(â€–xâ€–+2â€‹D)m)+2â€‹C~maxDâ€‹(1+(â€–xâ€–+D)m+1).\displaystyle\bar{g}(\delta,x):=2g\_{3}(\delta,\|x\|+D)+3\overline{C}\_{\max}\Big(1+2(\|x\|+2D)^{m}\Big)+2\frac{\widetilde{C}\_{\max}}{D}\Big(1+(\|x\|+D)^{m+1}\Big). |  | (5.38) |

Also, g3:(0,1]Ã—(â„+âˆª{0})â†¦â„+g\_{3}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | g3â€‹(Î´,y):=2â€‹C^maxCÂ¯max+2â€‹C^maxCÂ¯maxâ€‹g2â€‹(Î´,y)+Cmaxâ€‹(1+2â€‹(y+D)m),\displaystyle g\_{3}(\delta,y):=2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}+2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}g\_{2}(\delta,y)+C\_{\max}\Big(1+2(y+D)^{m}\Big), |  | (5.39) |

where g2g\_{2} is defined in ([5.2](https://arxiv.org/html/2512.14991v1#S5.E2 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), CÂ¯max\overline{C}\_{\max} is defined in ([4.13](https://arxiv.org/html/2512.14991v1#S4.E13 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), C~max\widetilde{C}\_{\max} and CmaxC\_{\max} are defined in ([5.36](https://arxiv.org/html/2512.14991v1#S5.E36 "In Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and C^max\widehat{C}\_{\max} is defined in ([5.17](https://arxiv.org/html/2512.14991v1#S5.E17 "In Corollary 5.4. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

While the quantity G~â€‹aphâ€‹(x,a){\rm\widetilde{G}ap}\_{h}(x,a) is commonly used to measure the sub-optimality of a given action, we introduce gÂ¯â€‹(Î´,x)\bar{g}(\delta,x) to capture the polynomial structure of the entire system. This quantity provides an alternative perspective, serving as a measure of the learning difficulty within our algorithm.

In the following regret analysis, we demonstrate that the algorithmâ€™s regret can be bounded in terms of the size of near-optimal sets. Note that the near-optimal set typically resides on a manifold of much lower dimension than dğ’®+dğ’œd\_{\mathcal{S}}+d\_{\mathcal{A}}. For instance, this occurs in several cases discussed in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)).

To quantify the size of near-optimal sets, we introduce the concepts of packing, packing numbers, and zooming dimension.

###### Definition 5.14 (rr-packing and rr-packing number, Definition 4.2.4 in (Vershynin, [2018](https://arxiv.org/html/2512.14991v1#bib.bib58))).

* â€¢

  For a given r>0r>0 and a compact set ğ’°\mathcal{U}, an r-packing Pğ’°râŠ‚ğ’°{\rm P}\_{\mathcal{U}}^{r}\subset\mathcal{U} is a set such that â€–xâˆ’xâ€²â€–>r\|x-x^{\prime}\|>r for any two distinct x,xâ€²âˆˆPğ’°rx,x^{\prime}\in{\rm P}\_{\mathcal{U}}^{r}.
* â€¢

  We define the rr-packing number of ğ’°\mathcal{U}, denoted Nrâ€‹(ğ’°)N\_{r}(\mathcal{U}), as the maximum cardinality among all rr-packings of ğ’°\mathcal{U}.

###### Definition 5.15 (Zooming dimension and maximum zooming dimension).

The step-hh zooming dimension zh,cz\_{h,c} with a given positive constant cc is defined as

|  |  |  |
| --- | --- | --- |
|  | zh,c=inf{d>0:Nrâ€‹(Zhr,Ï)Ïdğ’®â‰¤câ€‹râˆ’d,âˆ€0<râ‰¤D,âˆ€Ï>D}.\displaystyle z\_{h,c}=\inf\left\{d>0\,:\,\frac{N\_{r}(Z\_{h}^{r,\rho})}{\rho^{d\_{\mathcal{S}}}}\leq c\,r^{-d},\forall 0<r\leq D,\forall\rho>D\right\}. |  |

The maximum zooming dimension zmâ€‹aâ€‹x,cz\_{max,c} is defined as

|  |  |  |
| --- | --- | --- |
|  | zmax,c=maxhâˆˆ[H]â¡zh,c.\displaystyle z\_{\max,c}=\max\_{h\in[H]}z\_{h,c}. |  |

In the above, we modify the concept of zooming dimension in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) to adapt to the current unbounded state setting, such that the zooming dimension defined here is independent of Ï\rho. This is crucial to obtain potentially improved regret bounds by utilizing the zooming dimension instead of the ambient dimension dğ’®+dğ’œd\_{\mathcal{S}}+d\_{\mathcal{A}} in the context of an unbounded state setting.

###### Remark 5.16 (Choice of cc in Definition [5.15](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem15 "Definition 5.15 (Zooming dimension and maximum zooming dimension). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

In Definition [5.15](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem15 "Definition 5.15 (Zooming dimension and maximum zooming dimension). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), if we take câ‰¥Cğ’®,ğ’œ:=2dğ’®â€‹Î“â€‹(dğ’®+dğ’œ2+1)â€‹aÂ¯dğ’œÎ“â€‹(dğ’®2+1)â€‹Î“â€‹(dğ’œ2+1)c\geq C\_{\mathcal{S},\mathcal{A}}:=\frac{2^{d\_{\mathcal{S}}}\Gamma(\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}+1)\bar{a}^{d\_{\mathcal{A}}}}{\Gamma(\frac{d\_{\mathcal{S}}}{2}+1)\Gamma(\frac{d\_{\mathcal{A}}}{2}+1)}, then it holds that zh,câ‰¤dğ’®+dğ’œz\_{h,c}\leq d\_{\mathcal{S}}+d\_{\mathcal{A}}.

To see this, first note that

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Nrâ€‹(Zhr,Ï)\displaystyle N\_{r}(Z\_{h}^{r,\rho}) | â‰¤\displaystyle\leq | Nrâ€‹(ZÂ¯)â‰¤Î“â€‹(dğ’®+dğ’œ2+1)Î“â€‹(dğ’®2+1)â€‹Î“â€‹(dğ’œ2+1)â€‹(Ï+Dr)dğ’®â€‹(aÂ¯r)dğ’œ\displaystyle N\_{r}(\bar{Z})\leq\frac{\Gamma(\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}+1)}{\Gamma(\frac{d\_{\mathcal{S}}}{2}+1)\Gamma(\frac{d\_{\mathcal{A}}}{2}+1)}\left(\frac{\rho+D}{r}\right)^{d\_{\mathcal{S}}}\left(\frac{\bar{a}}{r}\right)^{d\_{\mathcal{A}}} |  | (5.40) |
|  |  | â‰¤\displaystyle\leq | Cğ’®,ğ’œâ€‹Ïdğ’®rdğ’®+dğ’œâ‰¤câ€‹Ïdğ’®rdğ’®+dğ’œ.\displaystyle C\_{\mathcal{S},\mathcal{A}}\frac{\rho^{d\_{\mathcal{S}}}}{r^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}\leq c\frac{\rho^{d\_{\mathcal{S}}}}{r^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}. |  |

Rearrange ([5.40](https://arxiv.org/html/2512.14991v1#S5.E40 "In Remark 5.16 (Choice of ğ‘ in Definition 5.15). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and we get:

|  |  |  |
| --- | --- | --- |
|  | Nrâ€‹(Zhr,Ï)Ïdğ’®â‰¤câ€‹râˆ’(dğ’®+dğ’œ).\displaystyle\frac{N\_{r}(Z\_{h}^{r,\rho})}{\rho^{d\_{\mathcal{S}}}}\leq cr^{-(d\_{\mathcal{S}}+d\_{\mathcal{A}})}. |  |

Hence, by Definition [5.15](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem15 "Definition 5.15 (Zooming dimension and maximum zooming dimension). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we have zh,câ‰¤dğ’®+dğ’œz\_{h,c}\leq d\_{\mathcal{S}}+d\_{\mathcal{A}}.

In light of Remark [5.15](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem15 "Definition 5.15 (Zooming dimension and maximum zooming dimension). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we take câ‰¥Cğ’®,ğ’œc\geq C\_{\mathcal{S},\mathcal{A}} throughout the rest of the paper. This ensures that the zooming dimension does not exceed the ambient dimension dğ’®+dğ’œd\_{\mathcal{S}}+d\_{\mathcal{A}}.

We now restate Theorem F.3 of (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) in a form suited to our setting with an unbounded state space and polynomial rewards. The proof is deferred to Appendix [C.11.1](https://arxiv.org/html/2512.14991v1#A3.SS11.SSS1 "C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Lemma 5.17 (Theorem F.3 in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53))).

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold.Then for any given constant r0>0r\_{0}>0 we have the following:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | âˆ‘hâˆ‘kâˆˆJÏKCLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\,\Bigg|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg) |  | (5.41) |
|  |  | â‰¤\displaystyle\leq | âˆ‘h=1H(2â€‹g3â€‹(Î´,Ï+D)â€‹Kâ€‹r0+g4â€‹(Î´,Ï+D)â€‹âˆ‘râ‰¥r0,râˆˆâ„›Nrâ€‹(Zhr,Ï)â€‹1r),\displaystyle\sum\_{h=1}^{H}\,\,\left(2g\_{3}(\delta,\rho+D)Kr\_{0}+g\_{4}(\delta,\rho+D)\sum\_{r\geq r\_{0},r\in\mathcal{R}}N\_{r}(Z\_{h}^{r,\rho})\frac{1}{r}\right), |  |

where â„›:={r|âˆƒhâˆˆ[H],kâˆˆJÏK,diamâ€‹(Bhk)=r}\mathcal{R}:=\{r\,\,|\,\,\exists h\in[H],k\in J\_{\rho}^{K},{\rm diam}(B\_{h}^{k})=r\}. Here JÏKJ\_{\rho}^{K} is defined in ([5.32](https://arxiv.org/html/2512.14991v1#S5.E32 "In 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), CÂ¯max\overline{C}\_{\max} in ([4.13](https://arxiv.org/html/2512.14991v1#S4.E13 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Gaph{\rm Gap}\_{h} in ([5.24](https://arxiv.org/html/2512.14991v1#S5.E24 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), GhkG\_{h}^{k} in ([5.31](https://arxiv.org/html/2512.14991v1#S5.E31 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), g1g\_{1} in ([4.21](https://arxiv.org/html/2512.14991v1#S4.E21 "In 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), g3g\_{3} in ([5.39](https://arxiv.org/html/2512.14991v1#S5.E39 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and gÂ¯\bar{g} in ([5.38](https://arxiv.org/html/2512.14991v1#S5.E38 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In addition, g4:(0,1]Ã—(â„+âˆª{0})â†¦â„+g\_{4}:(0,1]\times(\mathbb{R}\_{+}\cup\{0\})\mapsto\mathbb{R}\_{+} is defined as

|  |  |  |  |
| --- | --- | --- | --- |
|  | g4â€‹(Î´,y):=g3â€‹(Î´,y)â€‹g1â€‹(Î´,y)2+(2â€‹aÂ¯)dğ’œDdğ’®+dğ’œâˆ’2â€‹(dğ’®+dğ’œ)dğ’®+dğ’œ2â€‹ydğ’®â€‹gÂ¯â€‹(Î´,y).\displaystyle g\_{4}(\delta,y):=g\_{3}(\delta,y)g\_{1}(\delta,y)^{2}+\frac{(2\bar{a})^{d\_{\mathcal{A}}}}{D^{d\_{\mathcal{S}}+d\_{\mathcal{A}}-2}}(d\_{\mathcal{S}}+d\_{\mathcal{A}})^{\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}}y^{d\_{\mathcal{S}}}\bar{g}(\delta,y). |  | (5.42) |

Note that the upper bound in ([5.41](https://arxiv.org/html/2512.14991v1#S5.E41 "In Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for any generic r0>0r\_{0}>0. The choice of r0r\_{0} is to be specified in the final regret analysis (see Theorem [5.19](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem19 "Theorem 5.19. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Finally, we are ready to provide the regret bound.

###### Theorem 5.18.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. With probability at least 1âˆ’6â€‹Î´1-6\delta, we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1H(2â€‹g3â€‹(Î´,Ï+D)â€‹Kâ€‹r0+g4â€‹(Î´,Ï+D)â€‹âˆ‘râ‰¥r0,râˆˆâ„›Nrâ€‹(Zhr,Ï)â€‹1r)\displaystyle e^{2}\sum\_{h=1}^{H}\,\,\left(2g\_{3}(\delta,\rho+D)Kr\_{0}+g\_{4}(\delta,\rho+D)\sum\_{r\geq r\_{0},r\in\mathcal{R}}N\_{r}(Z\_{h}^{r,\rho})\frac{1}{r}\right) |  | (5.43) |
|  |  |  | +2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´)+2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)\displaystyle+2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)}+2K\kappa\_{m+1}(\delta,\rho) |  |
|  |  |  | +4â€‹C~1â€‹(L~3+Ïm+1+e2â€‹L~2â€‹Hâ€‹(Mpâ€‹KÎ´)m+1p)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´)),\displaystyle+4\widetilde{C}\_{1}\Big(\widetilde{L}\_{3}+\rho^{m+1}+e^{2}\widetilde{L}\_{2}H\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right), |  |

where g3g\_{3} is defined in ([5.39](https://arxiv.org/html/2512.14991v1#S5.E39 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), g4g\_{4} is defined in ([5.42](https://arxiv.org/html/2512.14991v1#S5.E42 "In Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), C~1\widetilde{C}\_{1} is defined in ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and Îºm+1\kappa\_{m+1} is defined in ([5.35](https://arxiv.org/html/2512.14991v1#S5.E35 "In Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Furthermore, if we set Ï=Mp1pâ€‹KÎ²\rho=M\_{p}^{\frac{1}{p}}K^{\beta}, r0=KÎ³r\_{0}=K^{\gamma}, then:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) | â‰²\displaystyle\lesssim | Cmaxâ€‹Mpm+1pâ€‹Hâ€‹K1+Î³+(m+1)â€‹Î²â€‹(logâ¡(2â€‹Hâ€‹K2Î´))m2\displaystyle C\_{\max}M\_{p}^{\frac{m+1}{p}}HK^{1+\gamma+(m+1)\beta}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{m}{2}}}} |  | (5.44) |
|  |  |  | +(Cmaxâ€‹CÂ¯max2+Cmax)â€‹âˆ‘h=1HMp2â€‹dğ’®+3â€‹m+5pâ€‹Hâ€‹K(2â€‹dğ’®+3â€‹m+5)â€‹Î²âˆ’Î³â€‹(zh,c+1)â€‹(logâ¡(2â€‹Hâ€‹K2Î´))3â€‹m2+2\displaystyle+(C\_{\max}\overline{C}\_{\max}^{2}+C\_{\max})\sum\_{h=1}^{H}M\_{p}^{\frac{2d\_{\mathcal{S}}+3m+5}{p}}HK^{(2d\_{\mathcal{S}}+3m+5)\beta-\gamma(z\_{h,c}+1)}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{3m}{2}+2}}} |  |
|  |  |  | +L~1â€‹Hâ€‹Mpm+1pâ€‹K12+m+1p+C~1â€‹(Mp+Mpm+1p)â€‹K1âˆ’(pâˆ’(m+1))â€‹Î²\displaystyle+\sqrt{\widetilde{L}\_{1}H}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}+\widetilde{C}\_{1}(M\_{p}+M\_{p}^{\frac{m+1}{p}})K^{1-(p-(m+1))\beta} |  |
|  |  |  | +C~1â€‹Mpm+1pâ€‹K12+(m+1)â€‹Î²+Mp1+m+1pâ€‹K1+m+1pâˆ’pâ€‹Î²+Hâ€‹Mpm+1pâ€‹K12+m+1p,\displaystyle+\widetilde{C}\_{1}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+(m+1)\beta}+M\_{p}^{1+\frac{m+1}{p}}K^{1+\frac{m+1}{p}-p\beta}+HM\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}, |  |

where â‰²\lesssim omits constants that are independent of H,KH,K.

###### Proof.

Take Ï=Mp1pâ€‹KÎ²\rho=M\_{p}^{\frac{1}{p}}K^{\beta} and r0=KÎ³r\_{0}=K^{\gamma} in Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we have with probability at least 1âˆ’6â€‹Î´1-6\delta:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) |  | (5.45) |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJ1CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´)\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{1}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)} |  |
|  |  |  | +2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)+4â€‹C~1â€‹(L~3+Ïm+1+e2â€‹L~2â€‹Hâ€‹(Mpâ€‹KÎ´)m+1p)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´))\displaystyle+2K\kappa\_{m+1}(\delta,\rho)+4\widetilde{C}\_{1}\Big(\widetilde{L}\_{3}+\rho^{m+1}+e^{2}\widetilde{L}\_{2}H\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right) |  |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1H(2â€‹g3â€‹(Î´,Ï+D)â€‹Kâ€‹r0+g4â€‹(Î´,Ï+D)â€‹âˆ‘râ‰¥r0,râˆˆâ„›Nrâ€‹(Zhr,Ï)â€‹1r)\displaystyle e^{2}\sum\_{h=1}^{H}\,\,\left(2g\_{3}(\delta,\rho+D)Kr\_{0}+g\_{4}(\delta,\rho+D)\sum\_{r\geq r\_{0},r\in\mathcal{R}}N\_{r}(Z\_{h}^{r,\rho})\frac{1}{r}\right) |  |
|  |  |  | +2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´)+2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)\displaystyle+2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)}+2K\kappa\_{m+1}(\delta,\rho) |  |
|  |  |  | +4â€‹C~1â€‹(L~3+Ïm+1+e2â€‹L~2â€‹Hâ€‹(Mpâ€‹KÎ´)m+1p)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´))\displaystyle+4\widetilde{C}\_{1}\Big(\widetilde{L}\_{3}+\rho^{m+1}+e^{2}\widetilde{L}\_{2}H\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right) |  |
|  |  | â‰²\displaystyle\lesssim | Cmaxâ€‹Mpm+1pâ€‹Hâ€‹K1+Î³+(m+1)â€‹Î²â€‹(logâ¡(2â€‹Hâ€‹K2Î´))m2\displaystyle C\_{\max}M\_{p}^{\frac{m+1}{p}}HK^{1+\gamma+(m+1)\beta}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{m}{2}}}} |  |
|  |  |  | +(Cmaxâ€‹CÂ¯max2+Cmax)â€‹âˆ‘h=1HMp2â€‹dğ’®+3â€‹m+5pâ€‹Hâ€‹K(2â€‹dğ’®+3â€‹m+5)â€‹Î²âˆ’Î³â€‹(zh,c+1)â€‹(logâ¡(2â€‹Hâ€‹K2Î´))3â€‹m2+2\displaystyle+(C\_{\max}\overline{C}\_{\max}^{2}+C\_{\max})\sum\_{h=1}^{H}M\_{p}^{\frac{2d\_{\mathcal{S}}+3m+5}{p}}HK^{(2d\_{\mathcal{S}}+3m+5)\beta-\gamma(z\_{h,c}+1)}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{3m}{2}+2}}} |  |
|  |  |  | +L~1â€‹Hâ€‹Mpm+1pâ€‹K12+m+1p+C~1â€‹(Mp+Mpm+1p)â€‹K1âˆ’(pâˆ’(m+1))â€‹Î²\displaystyle+\sqrt{\widetilde{L}\_{1}H}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}+\widetilde{C}\_{1}(M\_{p}+M\_{p}^{\frac{m+1}{p}})K^{1-(p-(m+1))\beta} |  |
|  |  |  | +C~1â€‹Mpm+1pâ€‹K12+(m+1)â€‹Î²+Mp1+m+1pâ€‹K1+m+1pâˆ’pâ€‹Î²+Hâ€‹Mpm+1pâ€‹K12+m+1p,\displaystyle+\widetilde{C}\_{1}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+(m+1)\beta}+M\_{p}^{1+\frac{m+1}{p}}K^{1+\frac{m+1}{p}-p\beta}+HM\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}, |  |

where the second inequality is due to ([5.41](https://arxiv.org/html/2512.14991v1#S5.E41 "In Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the fact that Nrâ€‹(Zhr,Ï)Ïdğ’®â‰¤câ€‹râˆ’zh,c\frac{N\_{r}(Z\_{h}^{r,\rho})}{\rho^{d\_{\mathcal{S}}}}\leq cr^{-z\_{h,c}}.
âˆ

We now derive the optimal order by selecting hyperparameters to balance the competing terms.

###### Theorem 5.19.

Take the same assumptions in Theorem [5.18](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem18 "Theorem 5.18. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). The optimal regret order on KK in ([5.44](https://arxiv.org/html/2512.14991v1#S5.E44 "In Theorem 5.18. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) is achieved as 1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)} if we
take

|  |  |  |
| --- | --- | --- |
|  | Î²=p+(m+1)â€‹(zmax,c+2)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4),Î³=(2â€‹dğ’®+2â€‹m+4)â€‹Î²2âˆ’1zmax,c+2.\displaystyle\beta=\frac{p+(m+1)(z\_{\max,c}+2)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)},\quad\gamma=\frac{(2d\_{\mathcal{S}}+2m+4)\beta\_{2}-1}{z\_{\max,c}+2}. |  |

Then with probability at least 1âˆ’6â€‹Î´1-6\delta, the following optimal regret bound holds that:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) |  | (5.46) |
|  |  | â‰²\displaystyle\lesssim | Cmaxâ€‹Mpm+1pâ€‹Hâ€‹K1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)â€‹(logâ¡(2â€‹Hâ€‹K2Î´))m2\displaystyle C\_{\max}M\_{p}^{\frac{m+1}{p}}HK^{1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{m}{2}}}} |  |
|  |  |  | +(Cmaxâ€‹CÂ¯max2+Cmax)â€‹âˆ‘h=1HMp2â€‹dğ’®+3â€‹m+5pâ€‹Hâ€‹K1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)â€‹(logâ¡(2â€‹Hâ€‹K2Î´))3â€‹m2+2\displaystyle+(C\_{\max}\overline{C}\_{\max}^{2}+C\_{\max})\sum\_{h=1}^{H}M\_{p}^{\frac{2d\_{\mathcal{S}}+3m+5}{p}}HK^{1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}}{{\Bigg(\log\left(\frac{2HK^{2}}{\delta}\right)\Bigg)^{\frac{3m}{2}+2}}} |  |
|  |  |  | +L~1â€‹Hâ€‹Mpm+1pâ€‹K12+m+1p+C~1â€‹(Mp+Mpm+1p)â€‹K1âˆ’(pâˆ’mâˆ’1)â€‹(p+(m+1)â€‹(zmax,c+2))pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)\displaystyle+\sqrt{\widetilde{L}\_{1}H}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}+\widetilde{C}\_{1}(M\_{p}+M\_{p}^{\frac{m+1}{p}})K^{1-\frac{(p-m-1)(p+(m+1)(z\_{\max,c}+2))}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}} |  |
|  |  |  | +C~1â€‹Mpm+1pâ€‹K12+(m+1)â€‹p+(m+1)2â€‹(zmax,c+2)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)+Mp1+m+1pâ€‹K1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)\displaystyle+\widetilde{C}\_{1}M\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{(m+1)p+(m+1)^{2}(z\_{\max,c}+2)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}}+M\_{p}^{1+\frac{m+1}{p}}K^{1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}} |  |
|  |  |  | +Hâ€‹Mpm+1pâ€‹K12+m+1p,\displaystyle+HM\_{p}^{\frac{m+1}{p}}K^{\frac{1}{2}+\frac{m+1}{p}}, |  |

###### Proof.

To find the optimal orders in ([5.44](https://arxiv.org/html/2512.14991v1#S5.E44 "In Theorem 5.18. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) with respect to KK, it is sufficient to solve the minimization problem of the following objective function Uâ€‹(Î²,Î³)U(\beta,\gamma).

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Uâ€‹(Î²,Î³)\displaystyle U(\beta,\gamma) | :=\displaystyle:= | max{1+Î³+(m+1)Î²,(2dğ’®+3m+5)Î²âˆ’Î³(zmax,c+1),\displaystyle\max\Big\{1+\gamma+(m+1)\beta,(2d\_{\mathcal{S}}+3m+5)\beta-\gamma(z\_{\max,c}+1), |  |
|  |  |  | 12+m+1p,12+(m+1)Î²,1âˆ’(pâˆ’(m+1))Î²,1+m+1pâˆ’pÎ²}.\displaystyle\qquad\quad\frac{1}{2}+\frac{m+1}{p},\frac{1}{2}+(m+1)\beta,1-(p-(m+1))\beta,1+\frac{m+1}{p}-p\beta\Big\}. |  |

We analyze the problem under two regimes: (1) Î²â‰¥1p\beta\geq\frac{1}{p} and (2) Î²<1p\beta<\frac{1}{p}.

Case (1): In this regime, we can simplify ([5.4](https://arxiv.org/html/2512.14991v1#S5.Ex46 "5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) as
Uâ€‹(Î²,Î³)=maxâ¡{1+Î³+(m+1)â€‹Î²,(2â€‹dğ’®+3â€‹m+5)â€‹Î²âˆ’Î³â€‹(zmax,c+1),12+(m+1)â€‹Î²}U(\beta,\gamma)=\max\Big\{1+\gamma+(m+1)\beta,(2d\_{\mathcal{S}}+3m+5)\beta-\gamma(z\_{\max,c}+1),\frac{1}{2}+(m+1)\beta\Big\}. Clearly, over this region, the minimizer (Î²1,Î³1)(\beta\_{1},\gamma\_{1}) satisfies the following equation:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 1+Î³1+(m+1)â€‹Î²1\displaystyle 1+\gamma\_{1}+(m+1)\beta\_{1} | =\displaystyle= | (2â€‹dğ’®+3â€‹m+5)â€‹Î²1âˆ’Î³1â€‹(zmax,c+1),\displaystyle(2d\_{\mathcal{S}}+3m+5)\beta\_{1}-\gamma\_{1}(z\_{\max,c}+1), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î²1\displaystyle\beta\_{1} | =\displaystyle= | 1p.\displaystyle\frac{1}{p}. |  |

By straightforward calculations, we get Î³1=2â€‹dğ’®+2â€‹m+4âˆ’ppâ€‹(zmax,c+2)\gamma\_{1}=\frac{2d\_{\mathcal{S}}+2m+4-p}{p(z\_{\max,c}+2)} and Uâ€‹(Î²1,Î³1)=1âˆ’(pâˆ’(m+1)â€‹(zmax,c+4)âˆ’2â€‹dğ’®âˆ’2)pâ€‹(zmax,c+2)U(\beta\_{1},\gamma\_{1})=1-\frac{(p-(m+1)(z\_{\max,c}+4)-2d\_{\mathcal{S}}-2)}{{p(z\_{\max,c}+2)}}.

Case (2):
In this regime, we can simplify ([5.4](https://arxiv.org/html/2512.14991v1#S5.Ex46 "5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) as
Uâ€‹(Î²,Î³)=maxâ¡{1+Î³+(m+1)â€‹Î²,(2â€‹dğ’®+3â€‹m+5)â€‹Î²âˆ’Î³â€‹(zmax,c+1),12+m+1p,1+m+1pâˆ’pâ€‹Î²}U(\beta,\gamma)=\max\Big\{1+\gamma+(m+1)\beta,(2d\_{\mathcal{S}}+3m+5)\beta-\gamma(z\_{\max,c}+1),\frac{1}{2}+\frac{m+1}{p},1+\frac{m+1}{p}-p\beta\Big\}. Then the minimum of Uâ€‹(â‹…,â‹…)U(\cdot,\cdot) shall be Uâ€‹(Î²2,Î³2)U(\beta\_{2},\gamma\_{2}) where (Î²2,Î³2)(\beta\_{2},\gamma\_{2}) satisfies:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 1+Î³2+(m+1)â€‹Î²2\displaystyle 1+\gamma\_{2}+(m+1)\beta\_{2} | =\displaystyle= | (2â€‹dğ’®+3â€‹m+5)â€‹Î²2âˆ’Î³2â€‹(zmax,c+1),\displaystyle(2d\_{\mathcal{S}}+3m+5)\beta\_{2}-\gamma\_{2}(z\_{\max,c}+1), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 1+m+1pâˆ’pâ€‹Î²2\displaystyle 1+\frac{m+1}{p}-p\beta\_{2} | =\displaystyle= | 1+Î³2+(m+1)â€‹Î²2.\displaystyle 1+\gamma\_{2}+(m+1)\beta\_{2}. |  |

By straightforward calculations, we get
Î²2=p+(m+1)â€‹(zmax,c+2)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)\beta\_{2}=\frac{p+(m+1)(z\_{\max,c}+2)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}, Î³2=(2â€‹dğ’®+2â€‹m+4)â€‹Î²2âˆ’1zmax,c+2\gamma\_{2}=\frac{(2d\_{\mathcal{S}}+2m+4)\beta\_{2}-1}{z\_{\max,c}+2} and Uâ€‹(Î²2,Î³2)=1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)U(\beta\_{2},\gamma\_{2})=1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}.

In addition, we can show that Uâ€‹(Î²1,Î³1)>Uâ€‹(Î²2,Î³2)U(\beta\_{1},\gamma\_{1})>U(\beta\_{2},\gamma\_{2}).

Therefore, the optimal leading order on KK is achieved at 1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)} if we
take Î²=p+(m+1)â€‹(zmax,c+2)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)\beta=\frac{p+(m+1)(z\_{\max,c}+2)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)} and Î³=(2â€‹dğ’®+2â€‹m+4)â€‹Î²2âˆ’1zmax,c+2\gamma=\frac{(2d\_{\mathcal{S}}+2m+4)\beta\_{2}-1}{z\_{\max,c}+2}. Combined with ([5.44](https://arxiv.org/html/2512.14991v1#S5.E44 "In Theorem 5.18. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we can verify that ([5.46](https://arxiv.org/html/2512.14991v1#S5.E46 "In Theorem 5.19. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds with probability at least 1âˆ’6â€‹Î´1-6\delta.
âˆ

###### Remark 5.20 (Dependence on HH).

Following the usual convention in (Domingues etÂ al., [2021](https://arxiv.org/html/2512.14991v1#bib.bib17); Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)), we suppress the dependence of the Lipschitz constants on the horizon HH, and thus the dependence of Cmax,CÂ¯max,C~max,C~1,L~1C\_{\max},\overline{C}\_{\max},\widetilde{C}\_{\max},\widetilde{C}\_{1},\widetilde{L}\_{1} on HH in Theorem [5.19](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem19 "Theorem 5.19. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). In the bounded reward and bounded state space setting, this dependence can be removed by appropriately rescaling the system (see Lemma 2.4 in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53))). Extending such an argument to our framework with unbounded state spaces and reward functions, however, might be more difficult.

###### Remark 5.21 (Comparison of our regret to the literature).

Note that

|  |  |  |
| --- | --- | --- |
|  | 1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)â†’zmax,c+1zmax,c+21-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}\rightarrow\frac{z\_{\max,c}+1}{z\_{\max,c}+2} |  |

as pp tends to infinity. This suggests that if the initial distribution has all moments bounded, we recover the regret of the AdaMB algorithm proposed in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) for bounded state space in terms of the episode number KK.

A detailed comparison between our algorithms and those proposed in (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) is presented in Table [1](https://arxiv.org/html/2512.14991v1#S5.T1 "Table 1 â€£ Remark 5.21 (Comparison of our regret to the literature). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), where zmax,câ€²z^{\prime}\_{\max,c} is defined in Definition 2.7 of (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)).

On one hand, our dependence on
HH is linear, obtained by applying Lipschitz-type properties of the value functions. In contrast, (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) incurs a higher-order dependence on
HH, since their analysis relies on the fact that cumulative rewards over
HH time steps are bounded by
HH. However, in both our work and theirs, the dependence of the Lipschitz constants on
HH is masked. Consequently, the comparison in terms of the order of
HH may not be fully accurate, and we therefore prefer to place less emphasis on it.

|  |  |  |  |
| --- | --- | --- | --- |
| AdaMB | AdaQL | APL-Diffusion | APL-Diffusion |
| (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) | (Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)) | (ours) | (ours) (pâ†¦âˆ)(p\mapsto\infty) |
| H32â€‹Kzmax,câ€²+maxâ¡{dğ’®,2}âˆ’1zmax,câ€²+maxâ¡{dğ’®,2}H^{\frac{3}{2}}K^{\frac{{z^{\prime}\_{\max,c}}+\max\{d\_{\mathcal{S}},2\}-1}{{z^{\prime}\_{\max,c}}+\max\{d\_{\mathcal{S}},2\}}} | H52â€‹Kzmax,câ€²+1zmax,câ€²+2H^{\frac{5}{2}}K^{\frac{{z^{\prime}\_{\max,c}}+1}{{z^{\prime}\_{\max,c}}+2}} | Hâ€‹K1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)HK^{1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)}} | Hâ€‹Kzmax,c+1zmax,c+2HK^{\frac{z\_{\max,c}+1}{z\_{\max,c}+2}} |

Table 1: Comparison of the regret orders.

###### Remark 5.22 (Without knowing KK a priori.).

To achieve a regret order as indicated in Theorem [5.19](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem19 "Theorem 5.19. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we need to know the total number of episodes a prior as the hyper-parameters Ï\rho and r0r\_{0} depend on KK. When KK is not known in advance, the classic doubling trick (Besson and Kaufmann, [2018](https://arxiv.org/html/2512.14991v1#bib.bib7)) can be applied to achieve the same order of regret (see Algorithm [6](https://arxiv.org/html/2512.14991v1#alg6 "Algorithm 6 â€£ Remark 5.22 (Without knowing ğ¾ a priori.). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Algorithm 6  The Doubling Trick

Initialize: K0K\_{0}

for iâˆˆ{0,1,2,â‹¯,n}i\in\{0,1,2,\cdots,n\} do

Kiâ†2iâ€‹K0K\_{i}\leftarrow 2^{i}K\_{0}

Run Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") for KiK\_{i} episodes.

end for

Denote Îº=1âˆ’p2âˆ’(m+1)2â€‹(zmax,c+2)âˆ’(m+1)â€‹(2â€‹dğ’®+2â€‹m+4)pâ€‹(p+m+1)â€‹(zmax,c+2)+pâ€‹(2â€‹dğ’®+2â€‹m+4)\kappa=1-\frac{p^{2}-(m+1)^{2}(z\_{\max,c}+2)-(m+1)(2d\_{\mathcal{S}}+2m+4)}{p(p+m+1)(z\_{\max,c}+2)+p(2d\_{\mathcal{S}}+2m+4)} and Ktotal=âˆ‘i=1nKi=K0â€‹âˆ‘i=1n2i=K0â€‹(2n+1âˆ’1)K\_{\rm total}=\sum\_{i=1}^{n}K\_{i}=K\_{0}\sum\_{i=1}^{n}2^{i}=K\_{0}(2^{n+1}-1),

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘i=1nRâ€‹(Ki)=âˆ‘i=1n(2i)Îºâ€‹âˆ‘i=1n2Îºâ€‹iâ‰ˆ2Îºâ€‹(n+1)âˆ’12Îºâˆ’1â‰ˆ(Ktotal)Îº.\displaystyle\sum\_{i=1}^{n}R(K\_{i})=\sum\_{i=1}^{n}(2^{i})^{\kappa}\sum\_{i=1}^{n}2^{\kappa i}\approx\frac{2^{\kappa(n+1)}-1}{2^{\kappa}-1}\approx(K\_{\rm total})^{\kappa}. |  | (5.48) |

## 6 Numerical experiments

We illustrate the performance of the APL-Diffusion Algorithm with two examples. The first is a toy one-dimensional problem, featuring a reward function with quadratic growth and dynamics followed by a mean-reverting process. The second example involves a mean-variance portfolio optimization problem, where the state process represents asset prices and the controls correspond to the allocation of wealth among portfolio assets.

### 6.1 A one-dimensional example

We first illustrate the performance using a tractable one-dimensional problem. Let us take the state space as ğ’®=â„\mathcal{S}=\mathbb{R} and the action space as [0,10][0,10].

##### Set-up.

The experiment set-up is specified as follows.

* â€¢

  Dynamics and reward: for hâˆˆ[Hâˆ’1]h\in[H-1], Î¼hâ€‹(x,a)=0.05âˆ’0.1â€‹x+0.01â€‹a\mu\_{h}(x,a)=0.05-0.1x+0.01a, Ïƒhâ€‹(x,a)=0.1\sigma\_{h}(x,a)=0.1, X1=4X\_{1}=4, Rhâ€‹(x,a)âˆ¼ğ’©â€‹((xâˆ’a)2,0.01)R\_{h}(x,a)\sim\mathcal{N}((x-a)^{2},0.01).
* â€¢

  Model parameters: H=10H=10, K=2000K=2000, Ï=10\rho=10, âˆ€hâˆˆ[H],C~h=5,D=10â€‹2,Î”=1\forall h\in[H],\widetilde{C}\_{h}=5,D=10\sqrt{2},\Delta=1.
* â€¢

  Initialization: For any
  hâˆˆ[H],kâˆˆ[K]h\in[H],k\in[K], and Bâˆˆğ’«h0B\in\mathcal{P}\_{h}^{0}, we set

  |  |  |  |
  | --- | --- | --- |
  |  | ğ’«h0={[0,10]Ã—[0,10],[10,0]Ã—[0,10]},QÂ¯h0â€‹(â‹…)=1837.1,QÂ¯hkâ€‹(ZÂ¯âˆ)=âˆ’505,\displaystyle\mathcal{P}\_{h}^{0}=\{[0,10]\times[0,10],[10,0]\times[0,10]\},\,\,\overline{Q}\_{h}^{0}(\cdot)=1837.1,\,\,\overline{Q}\_{h}^{k}(\bar{Z}^{\complement})=-505, |  |
  |  |  |  |
  | --- | --- | --- |
  |  | V~h0â€‹(S)=1837.1,S=Î“ğ’®â€‹(B),VÂ¯h0â€‹(x)=5+5â€‹â€–xâ€–2â€‹Â forÂ â€‹xâˆˆâ„dğ’®.\displaystyle\widetilde{V}\_{h}^{0}(S)=1837.1,\,\,S=\Gamma\_{\mathcal{S}}(B),\,\,\overline{V}\_{h}^{0}(x)=5+5\|x\|^{2}\mbox{ for }x\in\mathbb{R}^{d\_{\mathcal{S}}}. |  |

##### Adaptive partition and convergence.

In Figure [2](https://arxiv.org/html/2512.14991v1#S6.F2 "Figure 2 â€£ Regret order. â€£ 6.1 A one-dimensional example â€£ 6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), our algorithm adaptively refines the partition granularity in regions where the underlying Qhâˆ—Q\_{h}^{\*} values are high (with high confidence). Notably, the ground truth optimal action aâˆ—a^{\*} which is equal to 10 with high probability, unknown to the algorithm, falls within these finely partitioned regions, highlighting the algorithmâ€™s effectiveness and superior performance in efficient discretization.

In addition, Figure [3](https://arxiv.org/html/2512.14991v1#S6.F3 "Figure 3 â€£ Regret order. â€£ 6.1 A one-dimensional example â€£ 6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-(a) shows that the estimated VÏ€~V^{\widetilde{\pi}} rapidly converge to the optimal level, indicating a fast convergence rate of the algorithm.

##### Regret order.

In Figure [3](https://arxiv.org/html/2512.14991v1#S6.F3 "Figure 3 â€£ Regret order. â€£ 6.1 A one-dimensional example â€£ 6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-(b),we present the log-log plot of cumulative regret versus episode index, focusing on the regime where performance has stabilized. By fitting a linear regression model to the data, we estimate the regret order based on the slope of the fitted linear line. The estimated slope is 0.69 which is smaller than the worst case regret order of value 1+dğ’®+dğ’œ2+dğ’®+dğ’œ=34\frac{1+d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2+d\_{\mathcal{S}}+d\_{\mathcal{A}}}=\frac{3}{4}.

![Refer to caption](heat_map.png)


Figure 2: Demonstration of the adaptive partition from the APL-Diffusion algorithm for ğ’«92000\mathcal{P}\_{9}^{2000}.



![Refer to caption](estimated_vpi_simple_1.png)


(a) Estimated VÏ€~V^{\widetilde{\pi}} (per episode) throughout training.

![Refer to caption](linear_fit_simple_2000.png)


(b) Estimating regret order via linear regression: log(cumulative regret) with respect to log(episode).

Figure 3: Algorithm performance.

### 6.2 Mean-variance portfolio optimization

We next evaluate the performance of the APL-Diffusion Algorithm in the context of mean-variance portfolio optimization with multiple assets. In this setting, the agent learns to determine the optimal allocation of wealth across a basket of securities, balancing expected return against portfolio variance.

We consider a market with nn assets. One of the assets is a risk-free asset with interest rate r0>0r\_{0}>0. For hâˆˆ[Hâˆ’1]h\in[H-1], the price follows:

|  |  |  |
| --- | --- | --- |
|  | Yh+1âˆ’Yh=r0â€‹Yhâ€‹Î”,\displaystyle Y\_{h+1}-Y\_{h}=r\_{0}Y\_{h}\Delta, |  |

with initial condition Y1=y>0.Y\_{1}=y>0.

The other five assets are stocks whose price processes follow, for hâˆˆ[Hâˆ’1]h\in[H-1],

|  |  |  |
| --- | --- | --- |
|  | Zh+1iâˆ’Zhi=biâ€‹Zhiâ€‹Î”+Ïƒiâ€‹Zhiâ€‹Bhiâ€‹Î”,\displaystyle Z^{i}\_{h+1}-Z^{i}\_{h}=b^{i}Z\_{h}^{i}\Delta+\sigma^{i}Z\_{h}^{i}B\_{h}^{i}\sqrt{\Delta}, |  |

with initial condition Z1i=zi>0Z^{i}\_{1}=z^{i}>0. Here, bi>r0b^{i}>r\_{0} is the appreciation rate and Ïƒi>0\sigma^{i}>0 is the volatility of the stock ii (i=1,â‹¯,nâˆ’1i=1,\cdots,n-1).

Consider an investor who invests ahia\_{h}^{i} proportion of the wealth to stock ZiZ^{i} at time hh, with the remaining proportion 1âˆ’âˆ‘i=1nâˆ’1ahi1-\sum\_{i=1}^{n-1}a\_{h}^{i} to the risk-free asset,
then the wealth process follows, for hâˆˆ[Hâˆ’1]h\in[H-1],

|  |  |  |
| --- | --- | --- |
|  | Xh+1âˆ’Xh=(r0â€‹Xh+âˆ‘i=1nâˆ’1(biâˆ’r0)â€‹Xhâ€‹ahi)â€‹Î”+âˆ‘i=1nâˆ’1Ïƒiâ€‹Xhâ€‹ahiâ€‹Bhiâ€‹Î”,\displaystyle X\_{h+1}-X\_{h}=\left(r\_{0}X\_{h}+\sum\_{i=1}^{n-1}(b^{i}-r\_{0})X\_{h}a\_{h}^{i}\right)\Delta+\sum\_{i=1}^{n-1}\sigma^{i}X\_{h}a^{i}\_{h}B\_{h}^{i}\sqrt{\Delta}, |  |

with initial condition X1=x1>0.X\_{1}=x\_{1}>0.
Here we restrict that 0â‰¤ahiâ‰¤1,âˆ‘i=1nâˆ’1ahiâ‰¤10\leq a\_{h}^{i}\leq 1,\sum\_{i=1}^{n-1}a\_{h}^{i}\leq 1.

The reward function is set as

|  |  |  |
| --- | --- | --- |
|  | Rhâ€‹(x,a)=Î´0,Â forÂ â€‹hâˆˆ[Hâˆ’1],Â andÂ â€‹RHâ€‹(x,a)=Î´(Î½âˆ’x)â€‹x.\displaystyle R\_{h}(x,a)=\delta\_{0},\mbox{ for }h\in[H-1],\mbox{ and }R\_{H}(x,a)=\delta\_{(\nu-x)x}. |  |

###### Remark 6.1.

It is worth emphasizing that in this experiment setting, the volatility can become arbitrarily small, and the drift and volatility coefficients may fail to be Lipschitz continuous with respect to the action variable. These conditions fall outside the scope of Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), which are required for our theoretical regret guarantees. However, empirical results demonstrate that the APL-Diffusion Algorithm maintains strong performance despite the violation of these assumptions. This suggests that the algorithm exhibits robustness and practical effectiveness beyond the confines of the theoretical framework.

##### Set-up.

We specify the parameters governing the system dynamics and reward function, along with other model configurations and initialization settings, as follows.

* â€¢

  We take n=6n=6 in this example with 55 risky assets and 11 risk-free asset.
* â€¢

  Dynamics and reward:
  r0=0.05,bi=0.15,Ïƒi=0.2,Î½=10,X1=2,(i=1,â‹¯,5).r\_{0}=0.05,b^{i}=0.15,\sigma^{i}=0.2,\nu=10,X\_{1}=2,(i=1,\cdots,5).
* â€¢

  Model parameters: H=30H=30, K=2000K=2000, Ï=10\rho=10, âˆ€hâˆˆ[H],C~h=1\forall h\in[H],\widetilde{C}\_{h}=1, Î”=152\Delta=\frac{1}{52}.
* â€¢

  Initialization:222Note that in this application, the action domain is not a hypercube as assumed in the earlier section. Consequently, both the initialization and block-splitting procedures are modified accordingly. We define the initial partition as ğ’«h0={[0,Ï]Ã—ğ’œ,[âˆ’Ï,0]Ã—ğ’œ}\mathcal{P}\_{h}^{0}=\{[0,\rho]\times\mathcal{A},[-\rho,0]\times\mathcal{A}\} and initialize the estimators as QÂ¯h0â€‹(â‹…)=C~hâ€‹(1+Ïm+1)\overline{Q}\_{h}^{0}(\cdot)=\widetilde{C}\_{h}(1+\rho^{m+1}) and V~h0(.)=C~h(1+Ïm+1)\widetilde{V}\_{h}^{0}(.)=\widetilde{C}\_{h}(1+\rho^{m+1}). For QÂ¯hkâ€‹(ZÂ¯âˆ)\overline{Q}\_{h}^{k}(\bar{Z}^{\complement}) and VÂ¯h0\overline{V}\_{h}^{0}, we adopt the same values as in ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). When splitting a block, we divide the corresponding one-dimensional state space into two halves, and partition the five-dimensional isosceles right simplex action space into thirty-two isosceles right simplex of equal size.
  âˆ€hâˆˆ[H],âˆ€kâˆˆ[K],Bâˆˆğ’«h0\forall h\in[H],\forall k\in[K],B\in\mathcal{P}\_{h}^{0},

  |  |  |  |  |  |
  | --- | --- | --- | --- | --- |
  |  | ğ’«h0\displaystyle\mathcal{P}\_{h}^{0} | =\displaystyle= | {[0,10]Ã—ğ’œ,[âˆ’10,0]Ã—ğ’œ},whereÂ â€‹ğ’œ={a:aiâ‰¥0,âˆ‘i=15aiâ‰¤1,i=1,2,3,4,5},\displaystyle\{[0,10]\times\mathcal{A},[-10,0]\times\mathcal{A}\},\mbox{where }\mathcal{A}=\left\{a:a\_{i}\geq 0,\sum\_{i=1}^{5}a\_{i}\leq 1,i=1,2,3,4,5\right\}, |  |
  |  |  |  |  |  |
  | --- | --- | --- | --- | --- |
  |  | QÂ¯h0â€‹(â‹…)\displaystyle\overline{Q}\_{h}^{0}(\cdot) | =\displaystyle= | 101,QÂ¯hkâ€‹(ZÂ¯âˆ)=âˆ’101,V~h0â€‹(S)=101,S=Î“ğ’®â€‹(B),VÂ¯h0â€‹(x)=â€–xâ€–2+101â€‹Â forÂ â€‹xâˆˆâ„dğ’®.\displaystyle 101,\,\,\overline{Q}\_{h}^{k}(\bar{Z}^{\complement})=-101,\,\,\widetilde{V}\_{h}^{0}(S)=101,S=\Gamma\_{\mathcal{S}}(B),\overline{V}\_{h}^{0}(x)=\|x\|^{2}+101\mbox{ for }x\in\mathbb{R}^{d\_{\mathcal{S}}}. |  |

##### Reward convergence and regret order.

In Figure [3](https://arxiv.org/html/2512.14991v1#S6.F3 "Figure 3 â€£ Regret order. â€£ 6.1 A one-dimensional example â€£ 6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-(a), we see the rapid convergence of estimated VÏ€~V^{\widetilde{\pi}} towards the optimal value. In Figure [3](https://arxiv.org/html/2512.14991v1#S6.F3 "Figure 3 â€£ Regret order. â€£ 6.1 A one-dimensional example â€£ 6 Numerical experiments â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-(b), we present the log-log plot of cumulative regret versus episode index, focusing on the regime where performance has stabilized. By fitting a linear regression model to the data, we estimate the regret order based on the slope of the fitted linear line. The estimated slope is 0.78, which is lower than the worst-case theoretical regret bound with value 1+dğ’®+dğ’œ2+dğ’®+dğ’œ=78\frac{1+d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2+d\_{\mathcal{S}}+d\_{\mathcal{A}}}=\frac{7}{8}.
This indicates an improved empirical performance relative to the worst-case scenario guarantee.

![Refer to caption](estimated_vpi_initial2_2000.png)


(a) Estimated VÏ€~V^{\widetilde{\pi}} (per episode) throughout training.

![Refer to caption](linear_fit_mv_initial2_2000.png)


(b) Estimating regret order via linear regression: log(cumulative regret) with respect to log(episode).

Figure 4: Algorithm performance.

## 7 Conclusion

This work develops a model-based learning framework for episodic control in diffusion-type systems, with unbounded state space, continuous action space, and polynomially growing reward functions. This setting has broad class of applications in finance and economics but less understood in the learning literature. The proposed algorithm incorporates a novel adaptive partitioning scheme, specifically designed to address the challenges posed by the unboundedness and variability of the underlying dynamics. The analytical framework departs significantly from existing approaches in the literature, which typically rely on boundedness assumptions and compact state spaces. We derive regret bounds for the algorithm that recover classical rates in bounded settings and substantially extend their applicability to more general settings. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

## References

* Almgren and Chriss [2001]

  Robert Almgren and Neil Chriss.
  Optimal execution of portfolio transactions.
  *Journal of Risk*, 3:5â€“40, 2001.
* Auer etÂ al. [2008]

  Peter Auer, Thomas Jaksch, and Ronald Ortner.
  Near-optimal regret bounds for reinforcement learning.
  *Advances in neural information processing systems*, 21, 2008.
* Azar etÂ al. [2017]

  MohammadÂ Gheshlaghi Azar, Ian Osband, and RÃ©mi Munos.
  Minimax regret bounds for reinforcement learning.
  In *International conference on machine learning*, pages
  263â€“272. PMLR, 2017.
* Bayraktar and Kara [2023]

  Erhan Bayraktar and AliÂ Devran Kara.
  Approximate q learning for controlled diffusion processes and its
  near optimality.
  *SIAM Journal on Mathematics of Data Science*, 5(3):615â€“638, 2023.
* Bercu and Touati [2008]

  Bernard Bercu and Abderrahmen Touati.
  Exponential inequalities for self-normalized martingales with
  applications.
  *The Annals of Applied Probability*, 18:1848â€“1869,
  2008.
* Bertsekas and Tsitsiklis [1996]

  Dimitri Bertsekas and JohnÂ N Tsitsiklis.
  *Neuro-dynamic programming*.
  Athena Scientific, 1996.
* Besson and Kaufmann [2018]

  Lilian Besson and Emilie Kaufmann.
  What doubling tricks can and canâ€™t do for multi-armed bandits.
  *arXiv preprint arXiv:1803.06971*, 2018.
* Bhatia etÂ al. [2017]

  Rajendra Bhatia, Tanvi Jain, and Yongdo Lim.
  On the buresâ€“wasserstein distance between positive definite
  matrices.
  *Expositiones Mathematicae*, 2017.
  URL <https://api.semanticscholar.org/CorpusID:119151863>.
* Black and Litterman [1992]

  Fischer Black and Robert Litterman.
  Global portfolio optimization.
  *Financial analysts journal*, 48(5):28â€“43,
  1992.
* Blommestein and Turner [2012]

  HansÂ J Blommestein and Philip Turner.
  Interactions between sovereign debt management and monetary policy
  under fiscal dominance and financial instability.
  2012.
* Bubeck etÂ al. [2011]

  SÃ©bastien Bubeck, RÃ©mi Munos, Gilles Stoltz, and Csaba SzepesvÃ¡ri.
  X-armed bandits.
  *Journal of Machine Learning Research*, 12(5), 2011.
* Carr etÂ al. [2001]

  Peter Carr, Helyette Geman, and DilipÂ B Madan.
  Pricing and hedging in incomplete markets.
  *Journal of financial economics*, 62(1):131â€“167, 2001.
* Cartea etÂ al. [2015]

  Ãlvaro Cartea, Sebastian Jaimungal, and JosÃ© Penalva.
  *Algorithmic and high-frequency trading*.
  Cambridge University Press, 2015.
* Dai etÂ al. [2025]

  Min Dai, Yuchao Dong, Yanwei Jia, and XunÂ Yu Zhou.
  Data-driven mertonâ€™s strategies via policy randomization.
  *arXiv preprint arXiv*, 2312, 2025.
* Dann etÂ al. [2017]

  Christoph Dann, Tor Lattimore, and Emma Brunskill.
  Unifying pac and regret: Uniform pac bounds for episodic
  reinforcement learning.
  *Advances in Neural Information Processing Systems*, 30, 2017.
* Dayan and Watkins [1992]

  Peter Dayan and CJCH Watkins.
  Q-learning.
  *Machine learning*, 8(3):279â€“292, 1992.
* Domingues etÂ al. [2021]

  OmarÂ Darwiche Domingues, Pierre MÃ©nard, Matteo Pirotta, Emilie Kaufmann,
  and Michal Valko.
  Kernel-based reinforcement learning: A finite-time analysis.
  In *International Conference on Machine Learning*, pages
  2783â€“2792. PMLR, 2021.
* Dong etÂ al. [2019]

  Jiayu Dong, LinÂ F Wang, and Nan Jiang.
  Provably efficient exploration in policy optimization.
  In *NeurIPS*, 2019.
* Du etÂ al. [2020]

  Wenxin Du, CarolinÂ E Pflueger, and Jesse Schreger.
  Sovereign debt portfolios, bond risks, and the credibility of
  monetary policy.
  *The Journal of Finance*, 75(6):3097â€“3138,
  2020.
* Duffie etÂ al. [1997]

  Darrell Duffie, Wendell Fleming, HÂ Mete Soner, and Thaleia Zariphopoulou.
  Hedging in incomplete markets with hara utility.
  *Journal of Economic Dynamics and Control*, 21(4-5):753â€“782, 1997.
* Fan etÂ al. [2020]

  Jianqing Fan, Zhaoran Wang, Yuchen Xie, and Zhuoran Yang.
  A theoretical analysis of deep q-learning.
  In *Learning for dynamics and control*, pages 486â€“489. PMLR,
  2020.
* Fazel etÂ al. [2018]

  Maryam Fazel, Rong Ge, Sham Kakade, and Mehran Mesbahi.
  Global convergence of policy gradient methods for the linear
  quadratic regulator.
  In *International conference on machine learning*, pages
  1467â€“1476. PMLR, 2018.
* Fu etÂ al. [2020]

  Zuyue Fu, Zhuoran Yang, and Zhaoran Wang.
  Single-timescale actor-critic provably finds globally optimal policy.
  *arXiv preprint arXiv:2008.00483*, 2020.
* Givens and Shortt [1984]

  ClarkÂ R. Givens and R.Â M. Shortt.
  A class of wasserstein metrics for probability distributions.
  *Michigan Mathematical Journal*, 31:231â€“240, 1984.
  URL <https://api.semanticscholar.org/CorpusID:121338763>.
* Guo etÂ al. [2023]

  Xin Guo, Xinyu Li, and Renyuan Xu.
  Fast policy learning for linear quadratic control with entropy
  regularization.
  *arXiv preprint arXiv:2311.14168*, 2023.
* Hambly etÂ al. [2021]

  Ben Hambly, Renyuan Xu, and Huining Yang.
  Policy gradient methods for the noisy linear quadratic regulator over
  a finite horizon.
  *SIAM Journal on Control and Optimization*, 59(5):3359â€“3391, 2021.
* Hambly etÂ al. [2023]

  Ben Hambly, Renyuan Xu, and Huining Yang.
  Recent advances in reinforcement learning in finance.
  *Mathematical Finance*, 33(3):437â€“503,
  2023.
* Han etÂ al. [2023]

  Xia Han, Ruodu Wang, and XunÂ Yu Zhou.
  Choquet regularization for continuous-time reinforcement learning.
  *SIAM Journal on Control and Optimization*, 61(5):2777â€“2801, 2023.
* He etÂ al. [2015]

  XueÂ Dong He, Hanqing Jin, and XunÂ Yu Zhou.
  Dynamic portfolio choice when risk is measured by weighted var.
  *Mathematics of Operations Research*, 40(3):773â€“796, 2015.
* Hsu etÂ al. [2011]

  DanielÂ J. Hsu, ShamÂ M. Kakade, and Tong Zhang.
  A tail inequality for quadratic forms of subgaussian random vectors.
  *ArXiv*, abs/1110.2842, 2011.
  URL <https://api.semanticscholar.org/CorpusID:14207616>.
* Huang etÂ al. [2025]

  Yilie Huang, Yanwei Jia, and XunÂ Yu Zhou.
  Sublinear regret for a class of continuous-time linear-quadratic
  reinforcement learning problems.
  *SIAM Journal on Control and Optimization*, 63(5):3452â€“3474, 2025.
* Jaakkola etÂ al. [1993]

  Tommi Jaakkola, Michael Jordan, and Satinder Singh.
  Convergence of stochastic iterative dynamic programming algorithms.
  *Advances in neural information processing systems*, 6, 1993.
* Jia and Zhou [2022]

  Yanwei Jia and XunÂ Yu Zhou.
  Policy evaluation and temporal-difference learning in continuous time
  and space: A martingale approach.
  *Journal of Machine Learning Research*, 23(154):1â€“55, 2022.
* Jia and Zhou [2023]

  Yanwei Jia and XunÂ Yu Zhou.
  q-learning in continuous time.
  *Journal of Machine Learning Research*, 24(161):1â€“61, 2023.
* Jin etÂ al. [2020]

  Chi Jin, Zhuoran Yang, Zhaoran Wang, and MichaelÂ I Jordan.
  Provably efficient reinforcement learning with linear function
  approximation.
  In *Conference on learning theory*, pages 2137â€“2143. PMLR,
  2020.
* Kakade [2003]

  ShamÂ Machandranath Kakade.
  *On the sample complexity of reinforcement learning*.
  University of London, University College London (United Kingdom),
  2003.
* Kar and Singh [2024]

  Avik Kar and Rahul Singh.
  Adaptive discretization-based non-episodic reinforcement learning in
  metric spaces.
  *arXiv e-prints*, pages arXivâ€“2405, 2024.
* Kara and Yuksel [2023]

  AliÂ Devran Kara and Serdar Yuksel.
  Q-learning for continuous state and action mdps under average cost
  criteria.
  *arXiv preprint arXiv:2308.07591*, 2023.
* Kiran etÂ al. [2021]

  BÂ Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, AhmadÂ A
  AlÂ Sallab, Senthil Yogamani, and Patrick PÃ©rez.
  Deep reinforcement learning for autonomous driving: A survey.
  *IEEE transactions on intelligent transportation systems*,
  23(6):4909â€“4926, 2021.
* Kleinberg etÂ al. [2008]

  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal.
  Multi-armed bandits in metric spaces.
  In *Proceedings of the fortieth annual ACM symposium on Theory
  of computing*, pages 681â€“690, 2008.
* Kleinberg etÂ al. [2019]

  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal.
  Bandits and experts in metric spaces.
  *Journal of the ACM (JACM)*, 66(4):1â€“77,
  2019.
* Kober etÂ al. [2013]

  Jens Kober, JÂ Andrew Bagnell, and Jan Peters.
  Reinforcement learning in robotics: A survey.
  *The International Journal of Robotics Research*, 32(11):1238â€“1274, 2013.
* Lazaric etÂ al. [2012]

  Alessandro Lazaric, Mohammad Ghavamzadeh, and RÃ©mi Munos.
  Finite-sample analysis of least-squares policy iteration.
  *The Journal of Machine Learning Research*, 13(1):3041â€“3074, 2012.
* McCallum [1996]

  AndrewÂ Kachites McCallum.
  Reinforcement learning with selective perception and hidden state.
  In *Machine Learning Proceedings 1996*, pages 271â€“278. Morgan
  Kaufmann, 1996.
* Munos and Moore [2002]

  RÃ©mi Munos and Andrew Moore.
  Variable resolution discretization in optimal control.
  In *Machine Learning*, pages 291â€“323, 2002.
* Munos and SzepesvÃ¡ri [2008]

  RÃ©mi Munos and Csaba SzepesvÃ¡ri.
  Finite-time bounds for fitted value iteration.
  *Journal of Machine Learning Research*, 9:815â€“857,
  2008.
* Nguyen etÂ al. [2023]

  VietÂ Anh Nguyen, Soroosh Shafiee, Damir FilipoviÄ‡, and Daniel Kuhn.
  Mean-covariance robust risk measurement, 2023.
* Ortner etÂ al. [2014]

  Ronald Ortner, Daniil Ryabko, and Peter Auer.
  Regret bounds for reinforcement learning with model selection.
  *Machine Learning*, 96(3):217â€“261, 2014.
* Pazis and Parr [2013]

  Jason Pazis and Ronald Parr.
  Pac optimal exploration in continuous space markov decision
  processes.
  In *AAAI*, 2013.
* Puterman [2014]

  MartinÂ L Puterman.
  *Markov decision processes: discrete stochastic dynamic
  programming*.
  John Wiley & Sons, 2014.
* Schmitt [1992]

  BernhardÂ A. Schmitt.
  Perturbation bounds for matrix square roots and pythagorean sums.
  *Linear Algebra and its Applications*, 174:215â€“227,
  1992.
  ISSN 0024-3795.
  doi: https://doi.org/10.1016/0024-3795(92)90052-C.
  URL
  <https://www.sciencedirect.com/science/article/pii/002437959290052C>.
* Shalev-Shwartz etÂ al. [2016]

  Shai Shalev-Shwartz, Shaked Shammah, and Amnon Shashua.
  Safe, multi-agent, reinforcement learning for autonomous driving.
  *arXiv preprint arXiv:1610.03295*, 2016.
* Sinclair etÂ al. [2023]

  SeanÂ R Sinclair, Siddhartha Banerjee, and ChristinaÂ Lee Yu.
  Adaptive discretization in online reinforcement learning.
  *Operations Research*, 71(5):1636â€“1652,
  2023.
* Slivkins [2011]

  Aleksandrs Slivkins.
  Contextual bandits with similarity information.
  In *Proceedings of the 24th annual Conference On Learning
  Theory*, pages 679â€“702. JMLR Workshop and Conference Proceedings, 2011.
* Strehl and Littman [2006]

  AlexanderÂ L Strehl and MichaelÂ L Littman.
  Pac model-free reinforcement learning.
  In *ICML*, 2006.
* Tektas etÂ al. [2005]

  Arzu Tektas, EÂ Nur Ozkan-Gunay, and Gokhan Gunay.
  Asset and liability management in financial crisis.
  *The Journal of Risk Finance*, 6(2):135â€“149, 2005.
* Tsitsiklis and VanÂ Roy [1996]

  John Tsitsiklis and Benjamin VanÂ Roy.
  Analysis of temporal-diffference learning with function
  approximation.
  *Advances in neural information processing systems*, 9, 1996.
* Vershynin [2018]

  Roman Vershynin.
  *High-dimensional probability: An introduction with applications
  in data science*, volumeÂ 47.
  Cambridge university press, 2018.
* Wainwright [2019]

  MartinÂ J Wainwright.
  *High-dimensional statistics: A non-asymptotic viewpoint*,
  volumeÂ 48.
  Cambridge university press, 2019.
* Wang etÂ al. [2020]

  Haoran Wang, Thaleia Zariphopoulou, and XunÂ Yu Zhou.
  Reinforcement learning in continuous time and space: A stochastic
  control approach.
  *Journal of Machine Learning Research*, 21(198):1â€“34, 2020.
* Wang etÂ al. [2019]

  Lingxiao Wang, QiÂ Cai, Zhuoran Yang, and Zhaoran Wang.
  Neural policy gradient methods: Global optimality and rates of
  convergence.
  *arXiv preprint arXiv:1909.01150*, 2019.
* Winkelbauer [2012]

  Andreas Winkelbauer.
  Moments and absolute moments of the normal distribution.
  *arXiv preprint arXiv:1209.4340*, 2012.
* Yong and Zhou [1999]

  Jiongmin Yong and XunÂ Yu Zhou.
  *Stochastic controls: Hamiltonian systems and HJB equations*,
  volumeÂ 43.
  Springer Science & Business Media, 1999.
* Yu etÂ al. [2021]

  Chao Yu, Jiming Liu, Shamim Nemati, and Guosheng Yin.
  Reinforcement learning in healthcare: A survey.
  *ACM Computing Surveys (CSUR)*, 55(1):1â€“36,
  2021.
* Zhang and Suen [2025]

  Suyanpeng Zhang and Sze-chuan Suen.
  State discretization for continuous-state mdps in infectious disease
  control.
  *IISE Transactions on Healthcare Systems Engineering*,
  15(1):96â€“115, 2025.
* Zhao etÂ al. [2020]

  Wenshuai Zhao, JorgeÂ PeÃ±a Queralta, and Tomi Westerlund.
  Sim-to-real transfer in deep reinforcement learning for robotics: a
  survey.
  In *2020 IEEE symposium series on computational intelligence
  (SSCI)*, pages 737â€“744. IEEE, 2020.
* Zhou and Li [2000]

  XunÂ Yu Zhou and Duan Li.
  Continuous-time mean-variance portfolio selection: A stochastic lq
  framework.
  *Applied Mathematics and Optimization*, 42:19â€“33,
  2000.

## Appendix A Technical details in Section [2](https://arxiv.org/html/2512.14991v1#S2 "2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

### A.1 Proof of Proposition [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem2 "Proposition 2.2. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

We first prove ğ”¼â€‹[â€–X2â€–p]<cË˜1â€‹(1+ğ”¼â€‹[â€–X1â€–p])\mathbb{E}[\|X\_{2}\|^{p}]<\breve{c}\_{1}(1+\mathbb{E}[\|X\_{1}\|^{p}]) for some constant cË˜1\breve{c}\_{1}.
By the dynamics of state process, we have

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â€–X2â€–\displaystyle\|X\_{2}\| | â‰¤\displaystyle\leq | â€–X1â€–+â€–Î¼1â€‹(X1,A1)â€–â€‹Î”+â€–Ïƒ1â€‹(X1,A1)â€–â€‹â€–B1â€–â€‹Î”\displaystyle\|X\_{1}\|+\|\mu\_{1}(X\_{1},A\_{1})\|\Delta+\|\sigma\_{1}(X\_{1},A\_{1})\|\|B\_{1}\|\sqrt{\Delta} |  |
|  |  | â‰¤\displaystyle\leq | â€–X1â€–+(L0+â„“Î¼â€‹(â€–X1â€–+aÂ¯))â€‹Î”+(L0+â„“Ïƒâ€‹(â€–X1â€–+aÂ¯))â€‹â€–B1â€–â€‹Î”\displaystyle\|X\_{1}\|+(L\_{0}+\ell\_{\mu}(\|X\_{1}\|+\bar{a}))\Delta+(L\_{0}+\ell\_{\sigma}(\|X\_{1}\|+\bar{a}))\|B\_{1}\|\sqrt{\Delta} |  |
|  |  | =\displaystyle= | (1+â„“Î¼â€‹Î”+â„“Ïƒâ€‹â€–B1â€–â€‹Î”)â€‹â€–X1â€–+(â„“Î¼â€‹aÂ¯+L0)â€‹Î”+(â„“Ïƒâ€‹aÂ¯+L0)â€‹â€–B1â€–â€‹Î”.\displaystyle(1+\ell\_{\mu}\Delta+\ell\_{\sigma}\|B\_{1}\|\sqrt{\Delta})\|X\_{1}\|+(\ell\_{\mu}\bar{a}+L\_{0})\Delta+(\ell\_{\sigma}\bar{a}+L\_{0})\|B\_{1}\|\sqrt{\Delta}. |  |

So for any pâ‰¥1p\geq 1, there exists a constant cË˜3\breve{c}\_{3} depending on pp only, such that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â€–X2â€–p\displaystyle\|X\_{2}\|^{p} | â‰¤\displaystyle\leq | cË˜3â€‹((1+â„“Î¼â€‹Î”+â„“Ïƒâ€‹â€–B1â€–â€‹Î”)pâ€‹â€–X1â€–p+((â„“Î¼â€‹aÂ¯+L0)â€‹Î”+(â„“Ïƒâ€‹aÂ¯+L0)â€‹â€–B1â€–â€‹Î”)p)\displaystyle\breve{c}\_{3}\left((1+\ell\_{\mu}\Delta+\ell\_{\sigma}\|B\_{1}\|\sqrt{\Delta})^{p}\|X\_{1}\|^{p}+((\ell\_{\mu}\bar{a}+L\_{0})\Delta+(\ell\_{\sigma}\bar{a}+L\_{0})\|B\_{1}\|\sqrt{\Delta})^{p}\right) |  |
|  |  | â‰¤\displaystyle\leq | cË˜3â€‹(cË˜3â€‹(1+â„“Î¼pâ€‹Î”p+â„“Ïƒpâ€‹â€–B1â€–pâ€‹Î”p/2)â€‹â€–X1â€–p+cË˜3â€‹((â„“Î¼â€‹aÂ¯+L0)pâ€‹Î”p+(â„“Ïƒâ€‹aÂ¯+L0)pâ€‹â€–B1â€–pâ€‹Î”p2)).\displaystyle\breve{c}\_{3}\left(\breve{c}\_{3}(1+\ell\_{\mu}^{p}\Delta^{p}+\ell\_{\sigma}^{p}\|B\_{1}\|^{p}\Delta^{p/2})\|X\_{1}\|^{p}+\breve{c}\_{3}((\ell\_{\mu}\bar{a}+L\_{0})^{p}\Delta^{p}+(\ell\_{\sigma}\bar{a}+L\_{0})^{p}\|B\_{1}\|^{p}\Delta^{\frac{p}{2}})\right). |  |

Together with the fact that B1B\_{1} is independent with X1X\_{1}, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ”¼â€‹[â€–X2â€–p]\displaystyle\mathbb{E}[\|X\_{2}\|^{p}] | â‰¤\displaystyle\leq | cË˜32((1+â„“Î¼pÎ”p+â„“Ïƒpğ”¼[âˆ¥B1âˆ¥p]Î”p/2)ğ”¼[âˆ¥X1âˆ¥p]\displaystyle\breve{c}\_{3}^{2}\Big((1+\ell\_{\mu}^{p}\Delta^{p}+\ell\_{\sigma}^{p}\mathbb{E}[\|B\_{1}\|^{p}]\Delta^{p/2})\mathbb{E}[\|X\_{1}\|^{p}] |  | (A.1) |
|  |  |  | +(â„“Î¼aÂ¯+L0)pÎ”p+(â„“ÏƒaÂ¯+L0)pğ”¼[âˆ¥B1âˆ¥p]Î”p2)\displaystyle+(\ell\_{\mu}\bar{a}+L\_{0})^{p}\Delta^{p}+(\ell\_{\sigma}\bar{a}+L\_{0})^{p}\mathbb{E}[\|B\_{1}\|^{p}]\Delta^{\frac{p}{2}}\Big) |  |
|  |  | â‰¤\displaystyle\leq | cË˜4â€‹(1+ğ”¼â€‹[â€–X1â€–p]),\displaystyle\breve{c}\_{4}(1+\mathbb{E}[\|X\_{1}\|^{p}]), |  |

for some constant cË˜4\breve{c}\_{4} depending only on p,Î”,â„“Î¼,â„“Ïƒ,aÂ¯,L0p,\Delta,\ell\_{\mu},\ell\_{\sigma},\bar{a},L\_{0}.

By the same argument, we have
ğ”¼[âˆ¥X3âˆ¥p]â‰¤cË˜4(1+ğ”¼[âˆ¥X2âˆ¥p)â‰¤cË˜5(1+ğ”¼[âˆ¥X1âˆ¥p])\mathbb{E}[\|X\_{3}\|^{p}]\leq\breve{c}\_{4}(1+\mathbb{E}[\|X\_{2}\|^{p})\leq\breve{c}\_{5}(1+\mathbb{E}[\|X\_{1}\|^{p}])
for some cË˜5\breve{c}\_{5} depending only on cË˜4,\breve{c}\_{4},
as well as ğ”¼â€‹[â€–Xhâ€–p]â‰¤cË˜h+2â€‹(1+ğ”¼â€‹[â€–X1â€–p])\mathbb{E}[\|X\_{h}\|^{p}]\leq\breve{c}\_{h+2}(1+\mathbb{E}[\|X\_{1}\|^{p}]) for some cË˜h+3\breve{c}\_{h+3} depending only on p,Î”,â„“Î¼,â„“Ïƒ,aÂ¯,L0p,\Delta,\ell\_{\mu},\ell\_{\sigma},\bar{a},L\_{0}.

Finally,

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[suphâˆˆ[H]â€–Xhâ€–p]<âˆ‘hâˆˆ[H]ğ”¼â€‹[â€–Xhâ€–p]â‰¤Mâ€‹(1+ğ”¼â€‹[â€–X1â€–p]),\mathbb{E}\left[\sup\_{h\in[H]}\|X\_{h}\|^{p}\right]<\sum\_{h\in[H]}\mathbb{E}[\|X\_{h}\|^{p}]\leq M(1+\mathbb{E}[\|X\_{1}\|^{p}]), |  |

where MM only depends on p,Î”,â„“Î¼,â„“Ïƒ,aÂ¯,L0p,\Delta,\ell\_{\mu},\ell\_{\sigma},\bar{a},L\_{0} and HH.

âˆ

### A.2 Proof of Proposition [2.4](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem4 "Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

In this proof, we will often use the fact that for any functions ff and gg on the same domain, we have

|  |  |  |
| --- | --- | --- |
|  | |maxxâ¡fâ€‹(x)âˆ’maxyâ¡gâ€‹(y)|â‰¤maxxâ¡|fâ€‹(x)âˆ’gâ€‹(x)|;|\max\_{x}f(x)-\max\_{y}g(y)|\leq\max\_{x}|f(x)-g(x)|; |  |

and for any nonnegative real numbers a,b,ca,b,c, any integer m>0m>0,

|  |  |  |
| --- | --- | --- |
|  | (a+b+c)mâ‰¤k3â€‹(m)â€‹(am+bm+cm)(a+b+c)^{m}\leq k\_{3}(m)(a^{m}+b^{m}+c^{m}) |  |

for some function k3â€‹(â‹…)k\_{3}(\cdot).

We prove the statement by backward induction. For the last step h=Hh=H, we have

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |VHâˆ—â€‹(x1)âˆ’VHâˆ—â€‹(x2)|\displaystyle\left|V^{\*}\_{H}(x\_{1})-V\_{H}^{\*}(x\_{2})\right| | =\displaystyle= | |maxaâˆˆAâ¡RÂ¯Hâ€‹(x1,a)âˆ’maxbâˆˆAâ¡RÂ¯Hâ€‹(x2,b)|\displaystyle\left|\max\_{a\in A}\bar{R}\_{H}(x\_{1},a)-\max\_{b\in A}\bar{R}\_{H}(x\_{2},b)\right| |  |
|  |  | â‰¤\displaystyle\leq | maxaâˆˆAâ¡|RÂ¯Hâ€‹(x1,a)âˆ’RÂ¯Hâ€‹(x2,a)|\displaystyle\max\_{a\in A}|\bar{R}\_{H}(x\_{1},a)-\bar{R}\_{H}(x\_{2},a)| |  |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–).\displaystyle\ell\_{r}\Big(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m}\Big)\,\Big(\|x\_{1}-x\_{2}\|\Big). |  |

Let

|  |  |  |  |
| --- | --- | --- | --- |
|  | CÂ¯H:=â„“r,\displaystyle\overline{C}\_{H}:=\ell\_{r}, |  | (A.2) |

with â„“r\ell\_{r} defined in ([2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Now suppose the inequality ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for h=j>0h=j>0. We study the inequality for h=jâˆ’1h=j-1. For any state xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}} and any action aâˆˆğ’œa\in\mathcal{A}, denote by X(x,a):=x+Î¼jâˆ’1â€‹(x,a)â€‹Î”+Ïƒjâˆ’1â€‹(x,a)â€‹Bjâˆ’1â€‹Î”X^{(x,a)}:=x+\mu\_{j-1}(x,a)\Delta+\sigma\_{j-1}(x,a)B\_{j-1}\sqrt{\Delta}.

From ([2.3](https://arxiv.org/html/2512.14991v1#S2.E3 "In Bellman equation for optimal policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we know that
Vjâˆ’1âˆ—â€‹(x)=maxaâˆˆAâ¡{RÂ¯jâˆ’1â€‹(x,a)+ğ”¼â€‹[Vjâˆ—â€‹(X(x,a))]}V^{\*}\_{j-1}(x)=\max\_{a\in A}\{\bar{R}\_{j-1}(x,a)+\mathbb{E}[V\_{j}^{\*}(X^{(x,a)})]\}. Hence,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |Vjâˆ’1âˆ—â€‹(x)âˆ’Vjâˆ’1âˆ—â€‹(y)|\displaystyle|V^{\*}\_{j-1}(x)-V^{\*}\_{j-1}(y)| |  | (A.3) |
|  |  | â‰¤\displaystyle\leq | maxaâˆˆAâ¡|RÂ¯jâˆ’1â€‹(x,a)+ğ”¼â€‹[Vjâˆ—â€‹(X(x,a))]âˆ’RÂ¯jâˆ’1â€‹(y,a)âˆ’ğ”¼â€‹[Vjâˆ—â€‹(X(y,a))]|\displaystyle\max\_{a\in A}|\bar{R}\_{j-1}(x,a)+\mathbb{E}[V^{\*}\_{j}(X^{(x,a)})]-\bar{R}\_{j-1}(y,a)-\mathbb{E}[V^{\*}\_{j}(X^{(y,a)})]| |  |
|  |  | â‰¤\displaystyle\leq | maxaâˆˆAâ¡|RÂ¯jâˆ’1â€‹(x,a)âˆ’RÂ¯jâˆ’1â€‹(y,a)|+maxaâˆˆAâ¡ğ”¼â€‹[|Vjâˆ—â€‹(X(x,a))âˆ’Vjâˆ—â€‹(X(y,a))|].\displaystyle\max\_{a\in A}|\bar{R}\_{j-1}(x,a)-\bar{R}\_{j-1}(y,a)|+\max\_{a\in A}\mathbb{E}[|V^{\*}\_{j}(X^{(x,a)})-V^{\*}\_{j}(X^{(y,a)})|]. |  |

The first term in ([A.3](https://arxiv.org/html/2512.14991v1#A1.E3 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) is bounded by
â„“râ€‹(1+â€–xâ€–m+â€–yâ€–m)â€‹â€–xâˆ’yâ€–\ell\_{r}(1+\|x\|^{m}+\|y\|^{m})\|x-y\|, so it suffices to estimate the second term in ([A.3](https://arxiv.org/html/2512.14991v1#A1.E3 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

By the induction hypothesis, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Vjâˆ—â€‹(X(x,a))âˆ’Vjâˆ—â€‹(X(y,a))|â‰¤CÂ¯jâ€‹(1+â€–X(x,a)â€–m+â€–X(y,a)â€–m)â€‹â€–X(x,a)âˆ’X(y,a)â€–.\displaystyle|V^{\*}\_{j}(X^{(x,a)})-V^{\*}\_{j}(X^{(y,a)})|\leq\overline{C}\_{j}(1+\|X^{(x,a)}\|^{m}+\|X^{(y,a)}\|^{m})\|X^{(x,a)}-X^{(y,a)}\|. |  | (A.4) |

Note that

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | â€–X(x,a)â€–m\displaystyle\|X^{(x,a)}\|^{m} | â‰¤\displaystyle\leq | (â€–xâ€–+(L0+â„“Î¼â€‹(â€–xâ€–+aÂ¯))â€‹Î”+(L0+â„“Ïƒâ€‹(â€–xâ€–+aÂ¯))â€‹â€–Bjâˆ’1â€–â€‹Î”)m\displaystyle\left(\|x\|+(L\_{0}+\ell\_{\mu}(\|x\|+\bar{a}))\Delta+(L\_{0}+\ell\_{\sigma}(\|x\|+\bar{a}))\|B\_{j-1}\|\sqrt{\Delta}\right)^{m} |  | (A.5) |
|  |  | â‰¤\displaystyle\leq | k3(m)(1+â„“Î¼Î”)mâˆ¥xâˆ¥m+((L0+aÂ¯)â„“Î¼Î”)m+(L0+â„“Ïƒ(âˆ¥xâˆ¥+aÂ¯))mâˆ¥Bjâˆ’1âˆ¥m)\displaystyle k\_{3}(m)\left(1+\ell\_{\mu}\Delta)^{m}\|x\|^{m}+((L\_{0}+\bar{a})\ell\_{\mu}\Delta)^{m}+(L\_{0}+\ell\_{\sigma}(\|x\|+\bar{a}))^{m}\|B\_{j-1}\|^{m}\right) |  |
|  |  | =\displaystyle= | cË˜1+cË˜2â€‹â€–Bjâˆ’1â€–m+(cË˜3+cË˜4â€‹â€–Bjâˆ’1â€–m)â€‹â€–xâ€–m,\displaystyle\breve{c}\_{1}+\breve{c}\_{2}\|B\_{j-1}\|^{m}+(\breve{c}\_{3}+\breve{c}\_{4}\|B\_{j-1}\|^{m})\|x\|^{m}, |  |

where cË˜i\breve{c}\_{i} are all constant depending only on m,â„“Î¼,â„“Ïƒ,Î”,L0,aÂ¯m,\ell\_{\mu},\ell\_{\sigma},\Delta,L\_{0},\bar{a}. Hence, we also have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–X(x,a)âˆ’X(y,a)â€–\displaystyle\|X^{(x,a)}-X^{(y,a)}\| |  | (A.6) |
|  |  | â‰¤\displaystyle\leq | â€–xâˆ’yâ€–+â€–Î¼jâˆ’1â€‹(x,a)âˆ’Î¼jâˆ’1â€‹(y,a)â€–â€‹Î”+â€–Ïƒjâˆ’1â€‹(x,a)âˆ’Ïƒjâˆ’1â€‹(y,a)â€–â€‹Î”â€‹â€–Bjâˆ’1â€–\displaystyle\|x-y\|+\|\mu\_{j-1}(x,a)-\mu\_{j-1}(y,a)\|\Delta+\|\sigma\_{j-1}(x,a)-\sigma\_{j-1}(y,a)\|\sqrt{\Delta}\|B\_{j-1}\| |  |
|  |  | â‰¤\displaystyle\leq | (1+â„“Î¼â€‹Î”)â€‹â€–xâˆ’yâ€–+â„“Ïƒâ€‹â€–xâˆ’yâ€–â€‹Î”â€‹â€–Bjâˆ’1â€–.\displaystyle(1+\ell\_{\mu}\Delta)\|x-y\|+\ell\_{\sigma}\|x-y\|\sqrt{\Delta}\|B\_{j-1}\|. |  |

By ([A.5](https://arxiv.org/html/2512.14991v1#A1.E5 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.6](https://arxiv.org/html/2512.14991v1#A1.E6 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–X(x,a)â€–mâ€‹â€–X(x,a)âˆ’X(y,a)â€–\displaystyle\|X^{(x,a)}\|^{m}\|X^{(x,a)}-X^{(y,a)}\| |  | (A.7) |
|  |  | â‰¤\displaystyle\leq | ((cË˜1+cË˜2âˆ¥Bjâˆ’1âˆ¥m)+(cË˜3+cË˜4âˆ¥Bjâˆ’1âˆ¥m))âˆ¥xâˆ¥m)(1+â„“Î¼Î”+â„“ÏƒÎ”âˆ¥Bjâˆ’1âˆ¥)âˆ¥xâˆ’yâˆ¥\displaystyle\Big((\breve{c}\_{1}+\breve{c}\_{2}\|B\_{j-1}\|^{m})+(\breve{c}\_{3}+\breve{c}\_{4}\|B\_{j-1}\|^{m}))\|x\|^{m}\Big)(1+\ell\_{\mu}\Delta+\ell\_{\sigma}\sqrt{\Delta}\|B\_{j-1}\|)\|x-y\| |  |
|  |  | =\displaystyle= | â€–xâˆ’yâ€–â€‹(f1â€‹(â€–Bjâˆ’1â€–)+f2â€‹(â€–Bjâˆ’1â€–)â€‹â€–xâ€–m),\displaystyle\|x-y\|\Big(f\_{1}(\|B\_{j-1}\|)+f\_{2}(\|B\_{j-1}\|)\|x\|^{m}\Big), |  |

where f1â€‹(z)=cË˜5+cË˜6â€‹z+cË˜7â€‹zm+cË˜8â€‹zm+1f\_{1}(z)=\breve{c}\_{5}+\breve{c}\_{6}z+\breve{c}\_{7}z^{m}+\breve{c}\_{8}z^{m+1}
and f2â€‹(z)=cË˜9+cË˜10â€‹z+cË˜11â€‹zm+cË˜12â€‹zm+1f\_{2}(z)=\breve{c}\_{9}+\breve{c}\_{10}z+\breve{c}\_{11}z^{m}+\breve{c}\_{12}z^{m+1},
with cË˜i\breve{c}\_{i} depends only on CÂ¯j,m,aÂ¯,Î”,â„“Î¼,â„“Ïƒ,L0\overline{C}\_{j},m,\bar{a},\Delta,\ell\_{\mu},\ell\_{\sigma},L\_{0}.

By the fact that ğ”¼â€‹[â€–Bjâˆ’1â€–q]\mathbb{E}\big[\|B\_{j-1}\|^{q}\big] is a finite constant for any integer qq, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[â€–X(x,a)â€–mâ€‹â€–X(x,a)âˆ’X(y,a)â€–]â‰¤cË˜13â€‹(1+â€–xâ€–m)â€‹â€–xâˆ’yâ€–.\displaystyle\mathbb{E}\big[\|X^{(x,a)}\|^{m}\|X^{(x,a)}-X^{(y,a)}\|\big]\leq\breve{c}\_{13}(1+\|x\|^{m})\|x-y\|. |  | (A.8) |

for some cË˜13\breve{c}\_{13} only depending on CÂ¯j,m,aÂ¯,Î”,â„“Î¼,â„“Ïƒ,L0\overline{C}\_{j},m,\bar{a},\Delta,\ell\_{\mu},\ell\_{\sigma},L\_{0}.

Similarly, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[â€–X(y,a)â€–mâ€‹â€–X(x,a)âˆ’X(y,a)â€–]â‰¤cË˜13â€‹(1+â€–xâ€–m)â€‹â€–xâˆ’yâ€–.\displaystyle\mathbb{E}[\|X^{(y,a)}\|^{m}\|X^{(x,a)}-X^{(y,a)}\|]\leq\breve{c}\_{13}(1+\|x\|^{m})\|x-y\|. |  | (A.9) |

Applying ([A.6](https://arxiv.org/html/2512.14991v1#A1.E6 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([A.8](https://arxiv.org/html/2512.14991v1#A1.E8 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.9](https://arxiv.org/html/2512.14991v1#A1.E9 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) to ([A.4](https://arxiv.org/html/2512.14991v1#A1.E4 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we get

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[Vjâˆ’1âˆ—â€‹(X(x,a))âˆ’Vjâˆ’1âˆ—â€‹(X(y,a))]â‰¤cË˜14â€‹(1+â€–xâ€–m+â€–yâ€–m)â€‹â€–xâˆ’yâ€–,\displaystyle\mathbb{E}\left[V^{\*}\_{j-1}(X^{(x,a)})-V^{\*}\_{j-1}(X^{(y,a)})\right]\leq\breve{c}\_{14}(1+\|x\|^{m}+\|y\|^{m})\|x-y\|, |  | (A.10) |

with cË˜14=CÂ¯jâ€‹(2â€‹cË˜9+(1+â„“Î¼â€‹Î”+â„“Ïƒâ€‹Î”â€‹ğ”¼â€‹[â€–Bjâˆ’1â€–]))\breve{c}\_{14}=\overline{C}\_{j}\Big(2\breve{c}\_{9}+(1+\ell\_{\mu}\Delta+\ell\_{\sigma}\sqrt{\Delta}\mathbb{E}[\|B\_{j-1}\|])\Big).

Finally, let

|  |  |  |  |
| --- | --- | --- | --- |
|  | CÂ¯jâˆ’1:=â„“r+cË˜14,\displaystyle\overline{C}\_{j-1}:=\ell\_{r}+\breve{c}\_{14}, |  | (A.11) |

and we have shown that

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Vjâˆ’1âˆ—â€‹(x)âˆ’Vjâˆ’1âˆ—â€‹(y)|â‰¤CÂ¯jâˆ’1â€‹(1+â€–xâ€–m+â€–yâ€–m)â€‹â€–xâˆ’yâ€–.\displaystyle|V^{\*}\_{j-1}(x)-V^{\*}\_{j-1}(y)|\leq\overline{C}\_{j-1}(1+\|x\|^{m}+\|y\|^{m})\|x-y\|. |  | (A.12) |

âˆ

### A.3 Proof of Proposition [2.5](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem5 "Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

We prove the statement by backward induction.

For the last step h=Hh=H,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | |VHÏ€â€‹(x)|\displaystyle|V\_{H}^{\pi}(x)| | =\displaystyle= | |ğ”¼aâˆ¼Ï€Hâ€‹(x)â€‹[RÂ¯Hâ€‹(x,a)]|\displaystyle|\mathbb{E}\_{a\sim\pi\_{H}(x)}[\bar{R}\_{H}(x,a)]| |  | (A.13) |
|  |  | â‰¤\displaystyle\leq | ğ”¼aâˆ¼Ï€Hâ€‹(x)â€‹[|RÂ¯Hâ€‹(x,a)âˆ’RÂ¯Hâ€‹(0,0)|+|RÂ¯Hâ€‹(0,0)|]\displaystyle\mathbb{E}\_{a\sim\pi\_{H}(x)}[|\bar{R}\_{H}(x,a)-\bar{R}\_{H}(0,0)|+|\bar{R}\_{H}(0,0)|] |  |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹(â€–xâ€–m+1)â€‹(â€–xâ€–+aÂ¯)+L0\displaystyle\ell\_{r}(\|x\|^{m}+1)(\|x\|+\bar{a})+L\_{0} |  |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹â€–xâ€–m+1+â„“râ€‹aÂ¯â€‹(mm+1â€‹â€–xâ€–m+1+1m+1)+â„“râ€‹(1m+1â€‹â€–xâ€–m+1+mm+1)+â„“râ€‹aÂ¯+L0\displaystyle\ell\_{r}\|x\|^{m+1}+\ell\_{r}\bar{a}\left(\frac{m}{m+1}\|x\|^{m+1}+\frac{1}{m+1}\right)+\ell\_{r}\left(\frac{1}{m+1}\|x\|^{m+1}+\frac{m}{m+1}\right)+\ell\_{r}\bar{a}+L\_{0} |  |
|  |  | â‰¤\displaystyle\leq | C~Hâ€‹(â€–xâ€–m+1+1),\displaystyle\widetilde{C}\_{H}(\|x\|^{m+1}+1), |  |

where C~H:=maxâ¡{â„“râ€‹(1+aÂ¯â€‹m+1m+1),â„“râ€‹(aÂ¯+mm+1+aÂ¯)+L0}\widetilde{C}\_{H}:=\max\{\ell\_{r}(1+\frac{\bar{a}m+1}{m+1}),\ell\_{r}(\frac{\bar{a}+m}{m+1}+\bar{a})+L\_{0}\}. Here, the first equality holds by ([2.1](https://arxiv.org/html/2512.14991v1#S2.Ex5 "Bellman equation for generic policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the second inequality holds by Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), and the third inequality holds due to the fact that â€–xâ€–mâ‰¤mm+1â€‹â€–xâ€–m+1+1m+1\|x\|^{m}\leq\frac{m}{m+1}\|x\|^{m+1}+\frac{1}{m+1} and â€–xâ€–â‰¤1m+1â€‹â€–xâ€–m+1+mm+1\|x\|\leq\frac{1}{m+1}\|x\|^{m+1}+\frac{m}{m+1} . Now suppose the inequality ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for h=j>0h=j>0. We now prove the inequality for h=jâˆ’1h=j-1:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | |Vjâˆ’1Ï€â€‹(x)|\displaystyle|V\_{j-1}^{\pi}(x)| | â‰¤\displaystyle\leq | ğ”¼aâˆ¼Ï€jâˆ’1â€‹(x)â€‹[|RÂ¯jâˆ’1â€‹(x,a)|]+ğ”¼Xjâˆ¼Tjâˆ’1(â‹…|x,a),aâˆ¼Ï€jâˆ’1(x)â€‹[|VjÏ€â€‹(Xj)||Xjâˆ’1=x]\displaystyle\mathbb{E}\_{a\sim\pi\_{j-1}(x)}\Big[|\bar{R}\_{j-1}(x,a)|\Big]+\mathbb{E}\_{X\_{j}\sim T\_{j-1}(\cdot|x,a),a\sim\pi\_{j-1}(x)}\Big[\Big|V\_{j}^{\pi}(X\_{j})\Big||X\_{j-1}=x\Big] |  | (A.14) |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹(â€–xâ€–m+1)â€‹(aÂ¯+â€–xâ€–)+L0+ğ”¼Xjâˆ¼Tjâˆ’1(â‹…|x,a),aâˆ¼Ï€jâˆ’1(x)â€‹[C~jâ€‹(â€–Xjâ€–m+1+1)|Xjâˆ’1=x]\displaystyle\ell\_{r}(\|x\|^{m}+1)(\overline{a}+\|x\|)+L\_{0}+\mathbb{E}\_{X\_{j}\sim T\_{j-1}(\cdot|x,a),a\sim\pi\_{j-1}(x)}\Big[\widetilde{C}\_{j}(\|X\_{j}\|^{m+1}+1)|X\_{j-1}=x\Big] |  |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹â€–xâ€–m+1+â„“râ€‹aÂ¯â€‹(mm+1â€‹â€–xâ€–m+1+1m+1)+â„“râ€‹(1m+1â€‹â€–xâ€–m+1+mm+1)+â„“râ€‹aÂ¯+L0\displaystyle\ell\_{r}\|x\|^{m+1}+\ell\_{r}\bar{a}\left(\frac{m}{m+1}\|x\|^{m+1}+\frac{1}{m+1}\right)+\ell\_{r}\left(\frac{1}{m+1}\|x\|^{m+1}+\frac{m}{m+1}\right)+\ell\_{r}\bar{a}+L\_{0} |  |
|  |  |  | +C~j+C~jâ€‹cË˜4â€‹(1+â€–xâ€–m+1)\displaystyle+\widetilde{C}\_{j}+\widetilde{C}\_{j}\breve{c}\_{4}(1+\|x\|^{m+1}) |  |
|  |  | â‰¤\displaystyle\leq | C~jâˆ’1â€‹(â€–xâ€–m+1+1),\displaystyle\widetilde{C}\_{j-1}(\|x\|^{m+1}+1), |  |

where cË˜4\breve{c}\_{4} depends only on m,Î”,â„“Î¼,â„“Ïƒ,aÂ¯,L0m,\Delta,\ell\_{\mu},\ell\_{\sigma},\bar{a},L\_{0}, and we define C~jâˆ’1:=max{â„“r(1+aÂ¯â€‹m+1m+1)+C~jcË˜4,â„“r(aÂ¯+mm+1+aÂ¯+C~j}\widetilde{C}\_{j-1}:=\max\{\ell\_{r}(1+\frac{\bar{a}m+1}{m+1})+\widetilde{C}\_{j}\breve{c}\_{4},\ell\_{r}(\frac{\bar{a}+m}{m+1}+\bar{a}+\widetilde{C}\_{j}\}. Here, the first inequality holds due to ([2.1](https://arxiv.org/html/2512.14991v1#S2.Ex5 "Bellman equation for generic policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and triangle inequality, the second inequality holds by Assumption [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). In addition, the third inequality holds due to the fact that â€–xâ€–mâ‰¤mm+1â€‹â€–xâ€–m+1+1m+1\|x\|^{m}\leq\frac{m}{m+1}\|x\|^{m+1}+\frac{1}{m+1}, â€–xâ€–â‰¤1m+1â€‹â€–xâ€–m+1+mm+1\|x\|\leq\frac{1}{m+1}\|x\|^{m+1}+\frac{m}{m+1} and an argument simular to ([A.1](https://arxiv.org/html/2512.14991v1#A1.E1 "In A.1 Proof of Proposition 2.2 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) such that

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Xjâˆ¼Tjâˆ’1(â‹…|x,a),aâˆ¼Ï€jâˆ’1(x)â€‹[â€–Xjâ€–m+1|Xjâˆ’1=x]â‰¤cË˜4â€‹(1+â€–xâ€–m+1).\displaystyle\mathbb{E}\_{X\_{j}\sim T\_{j-1}(\cdot|x,a),a\sim\pi\_{j-1}(x)}\Big[\|X\_{j}\|^{m+1}|X\_{j-1}=x\Big]\leq\breve{c}\_{4}(1+\|x\|^{m+1}). |  |

âˆ

### A.4 Local lipschitz property for optimal Q function

In this subsection, we establish the local Lipschitz property of the optimal QQ-function. This result plays an important role in the proof of Lemma [5.17](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem17 "Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). The proof follows the same general strategy as that for the Lipschitz property of the optimal value function. For completeness, we present the full argument here.

###### Proposition A.1.

Suppose Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [2.2](https://arxiv.org/html/2512.14991v1#S2.Thmassumption2 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. Then for all hâˆˆ[H]h\in[H], it holds that

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Qhâˆ—â€‹(x1,a1)âˆ’Qhâˆ—â€‹(x2,a2)|â‰¤2â€‹CÂ¯hâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle|Q\_{h}^{\*}(x\_{1},a\_{1})-Q\_{h}^{\*}(x\_{2},a\_{2})|\leq 2\overline{C}\_{h}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|), |  | (A.15) |

where CÂ¯h\overline{C}\_{h} is defined in ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Proof.

We prove the statement by backward induction. For the last step h=Hh=H, we have

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |QHâˆ—â€‹(x1,a1)âˆ’QHâˆ—â€‹(x2,a2)|\displaystyle|Q\_{H}^{\*}(x\_{1},a\_{1})-Q\_{H}^{\*}(x\_{2},a\_{2})| | =\displaystyle= | |RÂ¯Hâ€‹(x1,a1)âˆ’RÂ¯Hâ€‹(x2,a2)|\displaystyle|\bar{R}\_{H}(x\_{1},a\_{1})-\bar{R}\_{H}(x\_{2},a\_{2})| |  |
|  |  | â‰¤\displaystyle\leq | â„“râ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–)\displaystyle\ell\_{r}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|) |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹CÂ¯Hâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle 2\overline{C}\_{H}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|), |  |

where the first inequality holds due to ([2.2](https://arxiv.org/html/2512.14991v1#S2.Ex14 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the second inequality holds due to the fact that CÂ¯H=â„“r\overline{C}\_{H}=\ell\_{r} by ([A.2](https://arxiv.org/html/2512.14991v1#A1.E2 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then suppose the inequality ([A.15](https://arxiv.org/html/2512.14991v1#A1.E15 "In Proposition A.1. â€£ A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for h=j>1h=j>1. We then study the inequality for h=jâˆ’1h=j-1.

For any state xx at time jâˆ’1j-1 and any action aâˆˆğ’œa\in\mathcal{A}, denote by X(x,a):=x+Î¼jâˆ’1â€‹(x,a)â€‹Î”+Ïƒjâˆ’1â€‹(x,a)â€‹Bjâˆ’1â€‹Î”X^{(x,a)}:=x+\mu\_{j-1}(x,a)\Delta+\sigma\_{j-1}(x,a)B\_{j-1}\sqrt{\Delta} the next state.

By ([2.4](https://arxiv.org/html/2512.14991v1#S2.E4 "In Bellman equation for optimal policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) we know
Qjâˆ’1âˆ—â€‹(x,a)=RÂ¯jâˆ’1â€‹(x,a)+ğ”¼â€‹[Vjâˆ—â€‹(X(x,a))].Q^{\*}\_{j-1}(x,a)=\bar{R}\_{j-1}(x,a)+\mathbb{E}[V\_{j}^{\*}(X^{(x,a)})].

Therefore

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |Qjâˆ’1âˆ—â€‹(x1,a1)âˆ’Qjâˆ’1âˆ—â€‹(x2,a2)|\displaystyle|Q\_{j-1}^{\*}(x\_{1},a\_{1})-Q\_{j-1}^{\*}(x\_{2},a\_{2})| |  | (A.16) |
|  |  | â‰¤\displaystyle\leq | |Qjâˆ’1âˆ—â€‹(x1,a1)âˆ’Qjâˆ’1âˆ—â€‹(x2,a1)|+|Qjâˆ’1âˆ—â€‹(x2,a1)âˆ’Qjâˆ’1âˆ—â€‹(x2,a2)|\displaystyle|Q\_{j-1}^{\*}(x\_{1},a\_{1})-Q\_{j-1}^{\*}(x\_{2},a\_{1})|+|Q\_{j-1}^{\*}(x\_{2},a\_{1})-Q\_{j-1}^{\*}(x\_{2},a\_{2})| |  |
|  |  | â‰¤\displaystyle\leq | |RÂ¯jâˆ’1â€‹(x1,a1)âˆ’RÂ¯jâˆ’1â€‹(x2,a1)|+|RÂ¯jâˆ’1â€‹(x2,a1)âˆ’RÂ¯jâˆ’1â€‹(x2,a2)|âŸ(I)\displaystyle\underbrace{|\bar{R}\_{j-1}(x\_{1},a\_{1})-\bar{R}\_{j-1}(x\_{2},a\_{1})|+|\bar{R}\_{j-1}(x\_{2},a\_{1})-\bar{R}\_{j-1}(x\_{2},a\_{2})|}\_{(I)} |  |
|  |  |  | +ğ”¼â€‹[|Vjâˆ—â€‹(X(x1,a1))âˆ’Vjâˆ—â€‹(X(x2,a1))|]âŸ(Iâ€‹I)+ğ”¼â€‹[|Vjâˆ—â€‹(X(x2,a1))âˆ’Vjâˆ—â€‹(X(x2,a2))|]âŸ(Iâ€‹Iâ€‹I).\displaystyle+\underbrace{\mathbb{E}[|V\_{j}^{\*}(X^{(x\_{1},a\_{1})})-V\_{j}^{\*}(X^{(x\_{2},a\_{1})})|]}\_{(II)}+\underbrace{\mathbb{E}[|V\_{j}^{\*}(X^{(x\_{2},a\_{1})})-V\_{j}^{\*}(X^{(x\_{2},a\_{2})})|]}\_{(III)}. |  |

For term (I), by ([2.2](https://arxiv.org/html/2512.14991v1#S2.Ex14 "Assumption 2.2 (Regularity of the reward). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (I)â‰¤â„“râ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–).\displaystyle(I)\leq\ell\_{r}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|). |  | (A.17) |

For term (II), by ([A.10](https://arxiv.org/html/2512.14991v1#A1.E10 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Iâ€‹I)â‰¤cË˜14â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle(II)\leq\breve{c}\_{14}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})\|x\_{1}-x\_{2}\|, |  | (A.18) |

where cË˜14\breve{c}\_{14} is defined in ([A.10](https://arxiv.org/html/2512.14991v1#A1.E10 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Next, we handle term (III). By Theorem [2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"),
we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Vjâˆ—â€‹(X(x2,a1))âˆ’Vjâˆ—â€‹(X(x2,a2))|â‰¤CÂ¯jâ€‹(1+â€–X(x2,a1)â€–m+â€–X(x2,a2)â€–m)â€‹â€–X(x2,a1)âˆ’X(x2,a2)â€–.\displaystyle|V^{\*}\_{j}(X^{(x\_{2},a\_{1})})-V^{\*}\_{j}(X^{(x\_{2},a\_{2})})|\leq\overline{C}\_{j}(1+\|X^{(x\_{2},a\_{1})}\|^{m}+\|X^{(x\_{2},a\_{2})}\|^{m})\|X^{(x\_{2},a\_{1})}-X^{(x\_{2},a\_{2})}\|. |  | (A.19) |

By ([A.5](https://arxiv.org/html/2512.14991v1#A1.E5 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | maxâ¡{â€–X(x2,a1)â€–m,â€–X(x2,a2)â€–m}â‰¤cË˜1+cË˜2â€‹â€–Bjâˆ’1â€–m+(cË˜3+cË˜4â€‹â€–Bjâˆ’1â€–m)â€‹â€–x2â€–m,\displaystyle\max\Big\{\|X^{(x\_{2},a\_{1})}\|^{m},\|X^{(x\_{2},a\_{2})}\|^{m}\Big\}\leq\breve{c}\_{1}+\breve{c}\_{2}\|B\_{j-1}\|^{m}+(\breve{c}\_{3}+\breve{c}\_{4}\|B\_{j-1}\|^{m})\|x\_{2}\|^{m}, |  | (A.20) |

where cË˜1,cË˜2,cË˜3,cË˜4\breve{c}\_{1},\breve{c}\_{2},\breve{c}\_{3},\breve{c}\_{4} are defined in ([A.5](https://arxiv.org/html/2512.14991v1#A1.E5 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

By Assumption ([2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–X(x2,a1)âˆ’X(x2,a2)â€–\displaystyle\|X^{(x\_{2},a\_{1})}-X^{(x\_{2},a\_{2})}\| |  | (A.21) |
|  |  | â‰¤\displaystyle\leq | â€–Î¼jâˆ’1â€‹(x2,a1)âˆ’Î¼jâˆ’1â€‹(x2,a2)â€–â€‹Î”+â€–Ïƒjâˆ’1â€‹(x2,a1)âˆ’Ïƒjâˆ’1â€‹(x2,a2)â€–â€‹Î”â€‹â€–Bjâˆ’1â€–\displaystyle\|\mu\_{j-1}(x\_{2},a\_{1})-\mu\_{j-1}(x\_{2},a\_{2})\|\Delta+\|\sigma\_{j-1}(x\_{2},a\_{1})-\sigma\_{j-1}(x\_{2},a\_{2})\|\sqrt{\Delta}\|B\_{j-1}\| |  |
|  |  | â‰¤\displaystyle\leq | (1+â„“Î¼â€‹Î”)â€‹â€–a1âˆ’a2â€–+â„“Ïƒâ€‹â€–a1âˆ’a2â€–â€‹Î”â€‹â€–Bjâˆ’1â€–.\displaystyle(1+\ell\_{\mu}\Delta)\|a\_{1}-a\_{2}\|+\ell\_{\sigma}\|a\_{1}-a\_{2}\|\sqrt{\Delta}\|B\_{j-1}\|. |  |

By ([A.20](https://arxiv.org/html/2512.14991v1#A1.E20 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.21](https://arxiv.org/html/2512.14991v1#A1.E21 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | (â€–X(x2,a1)â€–m+â€–X(x2,a2)â€–m)â€‹â€–X(x2,a1)âˆ’X(x2,a2)â€–\displaystyle(\|X^{(x\_{2},a\_{1})}\|^{m}+\|X^{(x\_{2},a\_{2})}\|^{m})\|X^{(x\_{2},a\_{1})}-X^{(x\_{2},a\_{2})}\| |  | (A.22) |
|  |  | â‰¤\displaystyle\leq | 2((cË˜1+cË˜2âˆ¥Bjâˆ’1âˆ¥m)+(cË˜3+cË˜4âˆ¥Bjâˆ’1âˆ¥m))âˆ¥x2âˆ¥m)(1+â„“Î¼Î”+â„“ÏƒÎ”âˆ¥Bjâˆ’1âˆ¥)âˆ¥a1âˆ’a2âˆ¥\displaystyle 2\Big((\breve{c}\_{1}+\breve{c}\_{2}\|B\_{j-1}\|^{m})+(\breve{c}\_{3}+\breve{c}\_{4}\|B\_{j-1}\|^{m}))\|x\_{2}\|^{m}\Big)(1+\ell\_{\mu}\Delta+\ell\_{\sigma}\sqrt{\Delta}\|B\_{j-1}\|)\|a\_{1}-a\_{2}\| |  |
|  |  | =\displaystyle= | 2â€‹â€–a1âˆ’a2â€–â€‹(f1â€‹(â€–Bjâˆ’1â€–)+f2â€‹(â€–Bjâˆ’1â€–)â€‹â€–x2â€–m),\displaystyle 2\|a\_{1}-a\_{2}\|\Big(f\_{1}(\|B\_{j-1}\|)+f\_{2}(\|B\_{j-1}\|)\|x\_{2}\|^{m}\Big), |  |

where f1â€‹(z)=cË˜5+cË˜6â€‹z+cË˜7â€‹zm+cË˜8â€‹zm+1f\_{1}(z)=\breve{c}\_{5}+\breve{c}\_{6}z+\breve{c}\_{7}z^{m}+\breve{c}\_{8}z^{m+1}
and f2â€‹(z)=cË˜9+cË˜10â€‹z+cË˜11â€‹zm+cË˜12â€‹zm+1f\_{2}(z)=\breve{c}\_{9}+\breve{c}\_{10}z+\breve{c}\_{11}z^{m}+\breve{c}\_{12}z^{m+1}
with cË˜i\breve{c}\_{i} all defined in ([A.7](https://arxiv.org/html/2512.14991v1#A1.E7 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

By the fact that ğ”¼â€‹[â€–Bjâˆ’1â€–q]\mathbb{E}\big[\|B\_{j-1}\|^{q}\big] is a finite constant for any integer qq, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[(â€–X(x2,a1)â€–m+â€–X(x2,a2)â€–m)â€‹â€–X(x2,a1)âˆ’X(x2,a2)â€–]â‰¤2â€‹cË˜13â€‹(1+â€–x2â€–m)â€‹â€–a1âˆ’a2â€–.\displaystyle\mathbb{E}[(\|X^{(x\_{2},a\_{1})}\|^{m}+\|X^{(x\_{2},a\_{2})}\|^{m})\|X^{(x\_{2},a\_{1})}-X^{(x\_{2},a\_{2})}\|]\leq 2\breve{c}\_{13}(1+\|x\_{2}\|^{m})\|a\_{1}-a\_{2}\|. |  | (A.23) |

for cË˜13\breve{c}\_{13} defined in ([A.8](https://arxiv.org/html/2512.14991v1#A1.E8 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Combine ([A.21](https://arxiv.org/html/2512.14991v1#A1.E21 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.23](https://arxiv.org/html/2512.14991v1#A1.E23 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) in ([A.19](https://arxiv.org/html/2512.14991v1#A1.E19 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we get

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Iâ€‹Iâ€‹I)â‰¤2â€‹cË˜14â€‹(1+â€–x2â€–m)â€‹â€–a1âˆ’a2â€–,\displaystyle(III)\leq 2\breve{c}\_{14}(1+\|x\_{2}\|^{m})\|a\_{1}-a\_{2}\|, |  | (A.24) |

with cË˜14\breve{c}\_{14} defined in ([A.10](https://arxiv.org/html/2512.14991v1#A1.E10 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Applying ([A.17](https://arxiv.org/html/2512.14991v1#A1.E17 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([A.18](https://arxiv.org/html/2512.14991v1#A1.E18 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.24](https://arxiv.org/html/2512.14991v1#A1.E24 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) to ([A.16](https://arxiv.org/html/2512.14991v1#A1.E16 "In A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we get:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |Qjâˆ’1âˆ—â€‹(x1,a1)âˆ’Qjâˆ’1âˆ—â€‹(x2,a2)|\displaystyle|Q\_{j-1}^{\*}(x\_{1},a\_{1})-Q\_{j-1}^{\*}(x\_{2},a\_{2})| | â‰¤\displaystyle\leq | (â„“r+2â€‹cË˜14)â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–)\displaystyle(\ell\_{r}+2\breve{c}\_{14})(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|) |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹CÂ¯jâˆ’1â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–),\displaystyle 2\overline{C}\_{j-1}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|), |  |

where the second inequality holds due to ([A.11](https://arxiv.org/html/2512.14991v1#A1.E11 "In A.2 Proof of Proposition 2.4 â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
âˆ

## Appendix B Technical details in Section [4](https://arxiv.org/html/2512.14991v1#S4 "4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

### B.1 Lemma [B.1](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem1 "Lemma B.1. â€£ B.1 Lemma B.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Lemma B.1.

For all (h,k)âˆˆ[Hâˆ’1]Ã—[K](h,k)\in{[H-1]\times[K]}, we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Xh+1kiâˆ’XhkiÎ”|(Xhki,Ahki)âˆ¼ğ’©â€‹(Î¼hâ€‹(Xhki,Ahki),Î£hâ€‹(Xhki,Ahki)Î”);\displaystyle\frac{X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}}}{\Delta}\,\Big|\,(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\sim\mathcal{N}\Bigg(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}}),\frac{\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{\Delta}\Bigg); |  | (B.1) |
|  |  |  |
| --- | --- | --- |
|  | Î¼^hkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)Î¼hâ€‹(Xhki,Ahki)nhkâ€‹(B)|(Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B))âˆ¼ğ’©â€‹(0,âˆ‘i=1nhkâ€‹(B)Î£hâ€‹(Xhki,Ahki)n2â€‹Î”).\displaystyle\widehat{\mu}\_{h}^{k}(B)-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\,\Big|\,(X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}})\sim\mathcal{N}\Bigg(0,\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n^{2}\Delta}\Bigg). |  |

###### Proof.

The first and second statements are straightforward by the definition in ([2.1](https://arxiv.org/html/2512.14991v1#S2.E1 "In 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the independence among Xh+1k1âˆ’Xhk1,â€¦,Xh+1knhkâ€‹(B)âˆ’Xhknhkâ€‹(B)X\_{h+1}^{k\_{1}}-X\_{h}^{k\_{1}},...,X\_{h+1}^{k\_{n\_{h}^{k}(B)}}-X\_{h}^{k\_{n\_{h}^{k}(B)}} given Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B)X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}}.
âˆ

### B.2 Lemma [B.2](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem2 "Lemma B.2. â€£ B.2 Lemma B.2 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Lemma B.2.

The following holds for all (h,k)âˆˆ[Hâˆ’1]Ã—[K](h,k)\in[H-1]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} such that for nâˆˆâ„•+n\in\mathbb{N}\_{+}:

|  |  |  |
| --- | --- | --- |
|  | ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]=âˆ‘i=1nhkâ€‹(B)(Î£hâ€‹(Xhki,Ahki)+(Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])â€‹(Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])âŠ¤â€‹Î”)nhkâ€‹(B).\displaystyle\overline{\mathbb{E}}\big[\widetilde{\Sigma}\_{h}^{k}(B)\big]=\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big(\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})+\big(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)\big(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)^{\top}\Delta\Big)}{n\_{h}^{k}(B)}. |  |

###### Proof.

From Lemma [B.1](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem1 "Lemma B.1. â€£ B.1 Lemma B.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") we know that

|  |  |  |
| --- | --- | --- |
|  | Xh+1kiâˆ’XhkiÎ”|(Xhki,Ahki)âˆ¼ğ’©â€‹(Î¼hâ€‹(Xhki,Ahki),Î£hâ€‹(Xhki,Ahki)Î”).\displaystyle\frac{X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}}}{\Delta}\,\Big|\,(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\sim\mathcal{N}\left(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}}),\frac{\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{\Delta}\right). |  |

Therefore

|  |  |  |
| --- | --- | --- |
|  | Xh+1kiâˆ’Xhkiâˆ’Î”â€‹ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]nhkâ€‹(B)â€‹Î”|(Xhk1,Ahk1,â€¦)âˆ¼ğ’©â€‹((Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)])â€‹Î”nhkâ€‹(B),Î£hâ€‹(Xhki,Ahki)nhkâ€‹(B)),\displaystyle\frac{X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}}-\Delta\overline{\mathbb{E}}[\widehat{\mu}^{k}\_{h}(B)]}{\sqrt{n\_{h}^{k}(B)\Delta}}\,\Big|\,(X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...)\sim\mathcal{N}\left(\frac{\big(\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)\sqrt{\Delta}}{\sqrt{n\_{h}^{k}(B)}},\frac{\Sigma\_{h}\left(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}}\right)}{n\_{h}^{k}(B)}\right), |  |

where the expression for the conditional mean follows the independence and the property of Gaussian distribution.
âˆ

### B.3 Proof of Proposition [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

For fixed h,kh,k and Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} s.t. nhkâ€‹(B)>0n\_{h}^{k}(B)>0, according to Lemma [B.1](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem1 "Lemma B.1. â€£ B.1 Lemma B.1 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we have for all zâˆˆâ„dğ’®z\in\mathbb{R}^{d\_{\mathcal{S}}},

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | ğ”¼Â¯â€‹[expâ¡(zâŠ¤â€‹(Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]))]\displaystyle\overline{\mathbb{E}}\Big[\exp\Big(z^{\top}\big(\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\big)\Big)\Big] | â‰¤\displaystyle\leq | expâ¡(12â€‹â€–zâ€–2â€‹â€–âˆ‘i=1nhkâ€‹(B)Î£hâ€‹(Xhki,Ahki)n2â€‹Î”â€–)\displaystyle\exp\Big(\frac{1}{2}\|z\|^{2}\left\|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n^{2}\Delta}\right\|\Big) |  |
|  |  | â‰¤\displaystyle\leq | expâ¡(12â€‹â€–zâ€–2â€‹âˆ‘i=1nhkâ€‹(B)â€–Ïƒhâ€‹(Xhki,Ahki)â€–2n2â€‹Î”)\displaystyle\exp\Big(\frac{1}{2}\|z\|^{2}\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\|\sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\|^{2}}{n^{2}\Delta}\Big) |  |
|  |  | â‰¤\displaystyle\leq | expâ¡(12â€‹â€–zâ€–2â€‹Î·(âˆ¥x~(oB)âˆ¥)2nhkâ€‹(B)â€‹Î”).\displaystyle\exp\Big(\frac{1}{2}\|z\|^{2}\frac{\eta(\|\tilde{x}(^{o}B)\|)^{2}}{n\_{h}^{k}(B)\Delta}\Big). |  |

Then Theorem 1 in [Hsu etÂ al., [2011](https://arxiv.org/html/2512.14991v1#bib.bib30)] guarantees that:

|  |  |  |
| --- | --- | --- |
|  | â„™Â¯â€‹(â€–Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–2â‰¥Î·(âˆ¥x~(oB)âˆ¥)2nhkâ€‹(B)â€‹Î”â€‹(dğ’®+2â€‹dğ’®â€‹logâ¡(Hâ€‹K2Î´)+2â€‹logâ¡(Hâ€‹K2Î´)))â‰¤Î´Hâ€‹K2.\displaystyle\overline{\mathbb{P}}\left(\Big\|\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big\|^{2}\geq\frac{\eta(\|\tilde{x}(^{o}B)\|)^{2}}{n\_{h}^{k}(B)\Delta}\Bigg(d\_{\mathcal{S}}+2d\_{\mathcal{S}}\sqrt{\log\Big(\frac{HK^{2}}{\delta}\Big)}+2\log\Big(\frac{HK^{2}}{\delta}\Big)\Bigg)\right)\leq\frac{\delta}{HK^{2}}. |  |

Note that dğ’®+2â€‹dğ’®â€‹logâ¡(Hâ€‹K2Î´)+2â€‹logâ¡(Hâ€‹K2Î´)â‰¤(dğ’®+2â€‹logâ¡(Hâ€‹K2Î´))2d\_{\mathcal{S}}+2d\_{\mathcal{S}}\sqrt{\log\Big(\frac{HK^{2}}{\delta}\Big)}+2\log\Big(\frac{HK^{2}}{\delta}\Big)\leq\left(\sqrt{d\_{\mathcal{S}}}+\sqrt{2\log\Big(\frac{HK^{2}}{\delta}\Big)}\right)^{2}, hence we have:

|  |  |  |
| --- | --- | --- |
|  | â„™Â¯(âˆ¥Î¼^hk(B)âˆ’ğ”¼Â¯[Î¼^hk(B)]âˆ¥â‰¥ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)))â‰¤Î´Hâ€‹K2.\displaystyle\overline{\mathbb{P}}\Big(\Big\|\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big\|\geq\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Big)\leq\frac{\delta}{HK^{2}}. |  |

Taking expectations on both side, we have:

|  |  |  |
| --- | --- | --- |
|  | â„™(âˆ¥Î¼^hk(B)âˆ’ğ”¼Â¯[Î¼^hk(B)]âˆ¥â‰¥ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)))â‰¤Î´Hâ€‹K2.\displaystyle\mathbb{P}\Big(\Big\|\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big\|\geq\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Big)\leq\frac{\delta}{HK^{2}}. |  |

Then taking a union bound, we get:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | â„™(âˆ©h=1Hâˆ’1âˆ©k=1Kâˆ©Bâˆˆğ’«hk,nhkâ€‹(B)>0{âˆ¥Î¼^hk(B)âˆ’ğ”¼Â¯[Î¼^hk(B)]âˆ¥â‰¤ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H-1}\cap\_{k=1}^{K}\cap\_{B\in\mathcal{P}\_{h}^{k},n\_{h}^{k}(B)>0}\Bigg\{\Big\|\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big\|\leq\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Bigg\}\Bigg) |  |
|  |  | =\displaystyle= | â„™(âˆ©h=1Hâˆ’1âˆ©k=1Kâˆ©nhkâ€‹(Bhk)=1,Bhkâˆˆğ’«hkâˆ’1K{âˆ¥Î¼^hk(Bhk)âˆ’ğ”¼Â¯[Î¼^hk(Bhk)]âˆ¥â‰¤ÎºÎ¼(Î´,âˆ¥x~(oBhk)âˆ¥,nhk(Bhk))})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H-1}\cap\_{k=1}^{K}\cap\_{n\_{h}^{k}(B\_{h}^{k})=1,B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1}}^{K}\Bigg\{\Big\|\widehat{\mu}\_{h}^{k}(B\_{h}^{k})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B\_{h}^{k})]\Big\|\leq\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|,n\_{h}^{k}(B\_{h}^{k}))\Bigg\}\Bigg) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’âˆ‘h=1Hâˆ’1âˆ‘k=1Kâˆ‘nhkâ€‹(Bhk)=1,Bhkâˆˆğ’«hkKâ„™(âˆ¥Î¼^hk(Bhk)âˆ’ğ”¼Â¯[Î¼^hk(Bhk)]âˆ¥â‰¥ÎºÎ¼(Î´,âˆ¥x~(oBhk)âˆ¥,nhk(Bhk)))\displaystyle 1-\sum\_{h=1}^{H-1}\sum\_{k=1}^{K}\sum\_{n\_{h}^{k}(B\_{h}^{k})=1,B\_{h}^{k}\in\mathcal{P}\_{h}^{k}}^{K}\mathbb{P}\Big(\Big\|\widehat{\mu}\_{h}^{k}(B\_{h}^{k})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B\_{h}^{k})]\Big\|\geq\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|,n\_{h}^{k}(B\_{h}^{k}))\Big) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’Î´,\displaystyle 1-\delta, |  |

where BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), and note that Î¼^hkâ€‹(Bhk)\widehat{\mu}\_{h}^{k}(B\_{h}^{k}) depends on nhkâ€‹(Bhk)n\_{h}^{k}(B\_{h}^{k}). The first equality holds since only the estimate for the selected block BhkB\_{h}^{k} is updated for each (h,k)(h,k) pair. The first inequality holds since, for a countable set of events E1,E2,â€¦,E\_{1},E\_{2},..., we have â„™â€‹(âˆ©iEi)â‰¥1âˆ’âˆ‘iâ„™â€‹(Eiâˆ)\mathbb{P}(\cap\_{i}E\_{i})\geq 1-\sum\_{i}\mathbb{P}(E\_{i}^{\complement}).

âˆ

### B.4 Proof of Proposition [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

For any h,kâˆˆ[Hâˆ’1]Ã—[K]h,k\in{[H-1]\times[K]} and Bâˆˆğ’«hk,nhkâ€‹(B)>0B\in\mathcal{P}\_{h}^{k},n\_{h}^{k}(B)>0, denote Zi:=Xh+1kiâˆ’Xhkiâˆ’Î”â€‹ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]Î”Z\_{i}:=\frac{X\_{h+1}^{k\_{i}}-X\_{h}^{k\_{i}}-\Delta\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]}{\sqrt{\Delta}}, then by Lemma [B.2](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem2 "Lemma B.2. â€£ B.2 Lemma B.2 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"):

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î£~hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]\displaystyle\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)] | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)Ziâ€‹ZiâŠ¤nhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)ğ”¼Â¯â€‹[Zi]â€‹ğ”¼Â¯â€‹[ZiâŠ¤]nhkâ€‹(B)âˆ’âˆ‘i=1nhkâ€‹(B)ğ•Â¯â€‹[Zi]nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}Z\_{i}Z\_{i}^{\top}}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\overline{\mathbb{E}}[Z\_{i}]\overline{\mathbb{E}}[Z\_{i}^{\top}]}{n\_{h}^{k}(B)}-\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\overline{\mathbb{V}}[Z\_{i}]}{n\_{h}^{k}(B)} |  |
|  |  | =\displaystyle= | âˆ‘i=1nhkâ€‹(B)(Ziâ€‹xiâŠ¤âˆ’ğ”¼Â¯â€‹[Ziâ€‹ZiâŠ¤])nhkâ€‹(B).\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\Big(Z\_{i}x\_{i}^{\top}-\overline{\mathbb{E}}[Z\_{i}Z\_{i}^{\top}]\Big)}{n\_{h}^{k}(B)}. |  |

Notice that Z1,â€¦,Znhkâ€‹(B)Z\_{1},...,Z\_{n\_{h}^{k}(B)} are conditionally independent given Xhk1,Ahk1,â€¦,Xhknhkâ€‹(B),Ahknhkâ€‹(B)X\_{h}^{k\_{1}},A\_{h}^{k\_{1}},...,X\_{h}^{k\_{n\_{h}^{k}(B)}},A\_{h}^{k\_{n\_{h}^{k}(B)}} and they share the same sub-Gaussian variance proxy Î·(âˆ¥x~(oB)âˆ¥)\eta(\|\tilde{x}(^{o}B)\|) with âˆ¥Î£h(Xhki,Ahki)âˆ¥â‰¤Î·(âˆ¥x~(oB)âˆ¥)2\|\Sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\|\leq\eta(\|\tilde{x}(^{o}B)\|)^{2}.
  
Then by Theorem 6.5 in [Wainwright, [2019](https://arxiv.org/html/2512.14991v1#bib.bib59)], there exist universal constants D1>0,D2>1D\_{1}>0,D\_{2}>1 and D3>0D\_{3}>0 such that:

|  |  |  |
| --- | --- | --- |
|  | â„™Â¯(âˆ¥Î£~hk(B)âˆ’ğ”¼Â¯[Î£~hk(B)]âˆ¥â‰¥Î·(âˆ¥x~(oB)âˆ¥)2(D1(dğ’®nhkâ€‹(B)+dğ’®nhkâ€‹(B))+Ïµ))â‰¤D2eâˆ’D3â€‹nhkâ€‹(B)â€‹minâ¡{Ïµ,Ïµ2}.\displaystyle\overline{\mathbb{P}}\left(\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\geq\eta(\|\tilde{x}(^{o}B)\|)^{2}\left(D\_{1}\left(\sqrt{\frac{d\_{\mathcal{S}}}{n\_{h}^{k}(B)}}+\frac{d\_{\mathcal{S}}}{n\_{h}^{k}(B)}\right)+\epsilon\right)\right)\leq D\_{2}e^{-D\_{3}n\_{h}^{k}(B)\min\{\epsilon,\epsilon^{2}\}}. |  |

Notice that for a,b,câˆˆâ„a,b,c\in\mathbb{R}, we have maxâ¡{a,b}â‰¤a+b\max\{a,b\}\leq a+b and 1câ‰¤1c\frac{1}{c}\leq\sqrt{\frac{1}{c}} for câ‰¥1c\geq 1.Therefore, we conclude that:

|  |  |  |
| --- | --- | --- |
|  | â„™Â¯(âˆ¥Î£~hk(B)âˆ’ğ”¼Â¯[Î£~hk(B)]âˆ¥â‰¥ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)))â‰¤Î´Hâ€‹K2.\displaystyle\overline{\mathbb{P}}\Bigg(\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\geq\kappa\_{\Sigma}\Big(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)\Big)\Bigg)\leq\frac{\delta}{HK^{2}}. |  |

Taking expectations, we have:

|  |  |  |
| --- | --- | --- |
|  | â„™(âˆ¥Î£~hk(B)âˆ’ğ”¼Â¯[Î£~hk(B)]âˆ¥â‰¥ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B)))â‰¤Î´Hâ€‹K2.\displaystyle\mathbb{P}\Bigg(\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\geq\kappa\_{\Sigma}\Big(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)\Big)\Bigg)\leq\frac{\delta}{HK^{2}}. |  |

Then taking a union bound, we get:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | â„™(âˆ©h=1Hâˆ’1âˆ©k=1Kâˆ©Bâˆˆğ’«hk,nhkâ€‹(B)>0âˆ¥Î£~hk(B)âˆ’ğ”¼Â¯[Î£~hk(B)]âˆ¥â‰¤ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H-1}\cap\_{k=1}^{K}\cap\_{B\in\mathcal{P}\_{h}^{k},n\_{h}^{k}(B)>0}\Big\|\widetilde{\Sigma}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Big\|\leq\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Bigg\}\Bigg) |  |
|  |  | =\displaystyle= | â„™(âˆ©h=1Hâˆ’1âˆ©k=1Kâˆ©nhkâ€‹(Bhk)=1Kâˆ¥Î£~hk(Bhk)âˆ’ğ”¼Â¯[Î£~hk(Bhk)]âˆ¥â‰¤ÎºÎ£(Î´,âˆ¥x~(oBhk)âˆ¥,nhk(Bhk))})\displaystyle\mathbb{P}\Bigg(\cap\_{h=1}^{H-1}\cap\_{k=1}^{K}\cap\_{n\_{h}^{k}(B\_{h}^{k})=1}^{K}\Big\|\widetilde{\Sigma}\_{h}^{k}(B\_{h}^{k})-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B\_{h}^{k})]\Big\|\leq\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|,n\_{h}^{k}(B\_{h}^{k}))\Bigg\}\Bigg) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’âˆ‘h=1Hâˆ’1âˆ‘k=1Kâˆ‘nhkâ€‹(Bhk)=1Kâ„™(âˆ¥Î£~hk(Bhk)âˆ’ğ”¼Â¯[Î£~hk(Bhk)]âˆ¥â‰¥ÎºÎ£(Î´,âˆ¥x~(oBhk)âˆ¥,nhk(Bhk)))\displaystyle 1-\sum\_{h=1}^{H-1}\sum\_{k=1}^{K}\sum\_{n\_{h}^{k}(B\_{h}^{k})=1}^{K}\mathbb{P}\Bigg(\Big\|\widetilde{\Sigma}\_{h}^{k}(B\_{h}^{k})-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B\_{h}^{k})]\Big\|\geq\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|,n\_{h}^{k}(B\_{h}^{k}))\Bigg) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’Î´,\displaystyle 1-\delta, |  |

where BhkB\_{h}^{k} is selected according to Algorithm [2](https://arxiv.org/html/2512.14991v1#alg2 "Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and note that Î£~hkâ€‹(Bhk)\widetilde{\Sigma}\_{h}^{k}(B\_{h}^{k}) depends on nhkâ€‹(Bhk)n\_{h}^{k}(B\_{h}^{k}). The first equality holds since only the estimate for the selected block BhkB\_{h}^{k} is updated for each (h,k)(h,k) pair. The first inequality holds since, for a countable set of events E1,E2,â€¦,E\_{1},E\_{2},..., we have â„™â€‹(âˆ©iEi)â‰¥1âˆ’âˆ‘iâ„™â€‹(Eiâˆ)\mathbb{P}(\cap\_{i}E\_{i})\geq 1-\sum\_{i}\mathbb{P}(E\_{i}^{\complement}).

âˆ

### B.5 Proof of Theorem [4.3](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem3 "Theorem 4.3. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

We have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ’²Â¯2â€‹(ğ’©â€‹(Î¼^hkâ€‹(B)â€‹Î”,Î£^hkâ€‹(B)â€‹Î”),ğ’©â€‹(Î¼hâ€‹(x,a)â€‹Î”,Î£hâ€‹(x,a)â€‹Î”))\displaystyle\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big) |  | (B.2) |
|  |  | =\displaystyle= | (âˆ¥Î¼^hk(B)Î”âˆ’Î¼h(x,a)Î”âˆ¥2\displaystyle\Bigg(\|\widehat{\mu}\_{h}^{k}(B)\Delta-\mu\_{h}(x,a)\Delta\|^{2} |  |
|  |  |  | +Tr(Î£^hk(B)Î”+Î£h(x,a)Î”âˆ’2((Î£^hk(B)Î”)12(Î£h(x,a)Î”)(Î£^hk(B)Î”)12)12))12\displaystyle+{\rm Tr}\Big(\widehat{\Sigma}\_{h}^{k}(B)\Delta+\Sigma\_{h}(x,a)\Delta-2((\widehat{\Sigma}\_{h}^{k}(B)\Delta)^{\frac{1}{2}}(\Sigma\_{h}(x,a)\Delta)(\widehat{\Sigma}\_{h}^{k}(B)\Delta)^{\frac{1}{2}})^{\frac{1}{2}}\Big)\Bigg)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | â€–Î¼^hkâ€‹(B)â€‹Î”âˆ’Î¼hâ€‹(x,a)â€‹Î”â€–2+â€–(Î£^hkâ€‹(B)â€‹Î”)12âˆ’(Î£hâ€‹(x,a)â€‹Î”)12â€–F2\displaystyle\sqrt{\|\widehat{\mu}\_{h}^{k}(B)\Delta-\mu\_{h}(x,a)\Delta\|^{2}+\|(\widehat{\Sigma}\_{h}^{k}(B)\Delta)^{\frac{1}{2}}-(\Sigma\_{h}(x,a)\Delta)^{\frac{1}{2}}\|\_{F}^{2}} |  |
|  |  | â‰¤\displaystyle\leq | â€–Î¼^hkâ€‹(B)â€‹Î”âˆ’Î¼hâ€‹(x,a)â€‹Î”â€–+â€–(Î£^hkâ€‹(B)â€‹Î”)12âˆ’(Î£hâ€‹(x,a)â€‹Î”)12â€–F\displaystyle\|\widehat{\mu}\_{h}^{k}(B)\Delta-\mu\_{h}(x,a)\Delta\|+\|(\widehat{\Sigma}\_{h}^{k}(B)\Delta)^{\frac{1}{2}}-(\Sigma\_{h}(x,a)\Delta)^{\frac{1}{2}}\|\_{F} |  |
|  |  | â‰¤\displaystyle\leq | â€–Î¼^hkâ€‹(B)â€‹Î”âˆ’Î¼hâ€‹(x,a)â€‹Î”â€–âŸ(I)+1Î»â€‹â€–Î£^hkâ€‹(B)â€‹Î”12âˆ’Î£hâ€‹(x,a)â€‹Î”12â€–FâŸ(Iâ€‹I).\displaystyle\underbrace{\|\widehat{\mu}\_{h}^{k}(B)\Delta-\mu\_{h}(x,a)\Delta\|}\_{(I)}+\underbrace{\frac{1}{\sqrt{\lambda}}\|\widehat{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}-\Sigma\_{h}(x,a)\Delta^{\frac{1}{2}}\|\_{F}}\_{(II)}. |  |

Here, the first equality holds by Proposition 7 in [Givens and Shortt, [1984](https://arxiv.org/html/2512.14991v1#bib.bib24)] and the first inequality holds by Theorem 1 in [Bhatia etÂ al., [2017](https://arxiv.org/html/2512.14991v1#bib.bib8)]. The second inequality holds since a2+b2â‰¤a+b\sqrt{a^{2}+b^{2}}\leq a+b for aâ‰¥0,bâ‰¥0a\geq 0,b\geq 0; and, to get the third inequality, we apply (1.1)-(1.3) in [Schmitt, [1992](https://arxiv.org/html/2512.14991v1#bib.bib51)] and ([2.5](https://arxiv.org/html/2512.14991v1#S2.E5 "In Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For term (I), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–Î¼^hkâ€‹(B)â€‹Î”âˆ’Î¼hâ€‹(x,a)â€‹Î”â€–â‰¤â€–Î¼^hkâ€‹(B)â€‹Î”âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€‹Î”â€–+â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€‹Î”âˆ’Î¼hâ€‹(x,a)â€‹Î”â€–.\displaystyle\big\|\widehat{\mu}\_{h}^{k}(B)\Delta-\mu\_{h}(x,a)\Delta\big\|\leq\big\|\widehat{\mu}\_{h}^{k}(B)\Delta-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Delta\big\|+\big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Delta-\mu\_{h}(x,a)\Delta\big\|. |  | (B.3) |

For term (II), we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | 1Î»â€‹â€–Î£^hkâ€‹(B)â€‹Î”12âˆ’Î£hâ€‹(x,a)â€‹Î”12â€–F\displaystyle\frac{1}{\sqrt{\lambda}}\|\widehat{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}-\Sigma\_{h}(x,a)\Delta^{\frac{1}{2}}\|\_{F} |  | (B.4) |
|  |  | â‰¤\displaystyle\leq | 1Î»(âˆ¥Î£^hk(B)Î”12âˆ’Î£~hk(B)Î”12âˆ¥F+âˆ¥Î£~hk(B)Î”12âˆ’ğ”¼Â¯[Î£~hk(B)]Î”12âˆ¥F\displaystyle\frac{1}{\sqrt{\lambda}}(\|\widehat{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}-\widetilde{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}\|\_{F}+\|\widetilde{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Delta^{\frac{1}{2}}\|\_{F} |  |
|  |  |  | +âˆ¥ğ”¼Â¯[Î£~hk(B)]Î”12âˆ’Î£h(x,a)Î”12âˆ¥F)\displaystyle+\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Delta^{\frac{1}{2}}-\Sigma\_{h}(x,a)\Delta^{\frac{1}{2}}\|\_{F}) |  |
|  |  | â‰¤\displaystyle\leq | 1Î»(âˆ¥(Î¼^hk(B)âˆ’ğ”¼Â¯[Î¼^hk(B)])âˆ¥2Î”32+dğ’®âˆ¥Î£~hk(B)Î”12âˆ’ğ”¼Â¯[Î£~hk(B)]Î”12âˆ¥\displaystyle\frac{1}{\sqrt{\lambda}}\Big(\Big\|\Big(\widehat{\mu}\_{h}^{k}(B)-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\Big)\Big\|^{2}\Delta^{\frac{3}{2}}+\sqrt{d\_{\mathcal{S}}}\|\widetilde{\Sigma}\_{h}^{k}(B)\Delta^{\frac{1}{2}}-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Delta^{\frac{1}{2}}\| |  |
|  |  |  | +âˆ¥ğ”¼Â¯[Î£~hk(B)]Î”12âˆ’Î£h(x,a)Î”12âˆ¥F).\displaystyle+\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]\Delta^{\frac{1}{2}}-\Sigma\_{h}(x,a)\Delta^{\frac{1}{2}}\|\_{F}\Big). |  |

Here, we apply ([4.2](https://arxiv.org/html/2512.14991v1#S4.E2 "In 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) to get the first inequality and ([4.3](https://arxiv.org/html/2512.14991v1#S4.E3 "In 2nd item â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) to get the second inequality.

Note that by Propositions [4.1](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem1 "Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we have ([4.8](https://arxiv.org/html/2512.14991v1#S4.E8 "In Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([4.9](https://arxiv.org/html/2512.14991v1#S4.E9 "In Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) hold. Combine ([4.8](https://arxiv.org/html/2512.14991v1#S4.E8 "In Proposition 4.1. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([4.9](https://arxiv.org/html/2512.14991v1#S4.E9 "In Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([B.2](https://arxiv.org/html/2512.14991v1#A2.E2 "In B.5 Proof of Theorem 4.3 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([B.3](https://arxiv.org/html/2512.14991v1#A2.E3 "In B.5 Proof of Theorem 4.3 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([B.4](https://arxiv.org/html/2512.14991v1#A2.E4 "In B.5 Proof of Theorem 4.3 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we verify that it holds with probability at least 1âˆ’2â€‹Î´1-2\delta that, for any (h,k)Ã—[Hâˆ’1]Ã—[K](h,k)\times[H-1]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B,

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | ğ’²Â¯2â€‹(ğ’©â€‹(Î¼^hkâ€‹(B)â€‹Î”,Î£^hkâ€‹(B)â€‹Î”),ğ’©â€‹(Î¼hâ€‹(x,a)â€‹Î”,Î£hâ€‹(x,a)â€‹Î”))\displaystyle\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big) |  |
|  |  | â‰¤\displaystyle\leq | Î”ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))+Î”32Î»ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))2+dğ’®â€‹Î”12Î»ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))\displaystyle\Delta\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))+\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}}\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{2}+\frac{\sqrt{d\_{\mathcal{S}}}\Delta^{\frac{1}{2}}}{\sqrt{\lambda}}\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B)) |  |
|  |  |  | +â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]âˆ’Î¼hâ€‹(x,a)â€–â€‹Î”+â€–ğ”¼Â¯â€‹[Î£~hkâ€‹(B)]âˆ’Î£hâ€‹(x,a)â€–â€‹Î”Î».\displaystyle+\Big\|\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]-\mu\_{h}(x,a)\Big\|\Delta+\Big\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}^{k}(B)]-\Sigma\_{h}(x,a)\Big\|\frac{\sqrt{\Delta}}{\sqrt{\lambda}}. |  |

âˆ

### B.6 Proof of Theorem [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

We first introduce two technical lemmas.

###### Lemma B.3.

Suppose Zâˆ¼ğ’©â€‹(Î¼,Î£)Z\sim\mathcal{N}(\mu,\Sigma) with Î¼âˆˆâ„d\mu\in\mathbb{R}^{d}, Î£âˆˆâ„dÃ—d\Sigma\in\mathbb{R}^{d\times d} and Î£âª°0\Sigma\succeq 0, then âˆ€qâˆˆâ„•+\forall q\in\mathbb{N}^{+}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (ğ”¼Zâˆ¼ğ’©â€‹(Î¼,Î£)â€‹[â€–Zâ€–2â€‹q])12â‰¤C~â€‹(q,d)â€‹(â€–Î¼â€–q+â€–Î£â€–q2),\displaystyle(\mathbb{E}\_{Z\sim\mathcal{N}(\mu,\Sigma)}[\|Z\|^{2q}])^{\frac{1}{2}}\leq\widetilde{C}(q,d)(\|\mu\|^{q}+\|\Sigma\|^{\frac{q}{2}}), |  | (B.5) |

where C~â€‹(q,d)\widetilde{C}(q,d) is defined in ([4.14](https://arxiv.org/html/2512.14991v1#S4.E14 "In 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Proof.

Denote ZjZ\_{j} as the jjth random variable of the random vector ZZ, and hence Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj}) where Î¼j\mu\_{j} is the jjth component of Î¼\mu and Î£jâ€‹j\Sigma\_{jj} is the (j,j)(j,j)th component of Î£\Sigma. Therefore,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | (ğ”¼Zâˆ¼ğ’©â€‹(Î¼,Î£)â€‹[â€–Zâ€–]2â€‹q)12\displaystyle(\mathbb{E}\_{Z\sim\mathcal{N}(\mu,\Sigma)}[\|Z\|]^{2q})^{\frac{1}{2}} | =\displaystyle= | (ğ”¼Zâˆ¼ğ’©â€‹(Î¼,Î£)â€‹[Z12+â€¦+Zd2]q)12\displaystyle\Big(\mathbb{E}\_{Z\sim\mathcal{N}(\mu,\Sigma)}[Z\_{1}^{2}+...+Z\_{d}^{2}]^{q}\Big)^{\frac{1}{2}} |  | (B.6) |
|  |  | â‰¤\displaystyle\leq | (dqâˆ’1â€‹âˆ‘j=1dğ”¼Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)â€‹[Zj]2â€‹q)12\displaystyle\Big(d^{q-1}\sum\_{j=1}^{d}\mathbb{E}\_{Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj})}[Z\_{j}]^{2q}\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | dqâˆ’12â€‹âˆ‘j=1d(ğ”¼Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)â€‹[|Zjâˆ’Î¼j|+|Î¼j|]2â€‹q)12\displaystyle d^{\frac{q-1}{2}}\sum\_{j=1}^{d}\Big(\mathbb{E}\_{Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj})}[|Z\_{j}-\mu\_{j}|+|\mu\_{j}|]^{2q}\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | dqâˆ’12â€‹âˆ‘j=1d(22â€‹qâˆ’1â€‹(ğ”¼Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)â€‹[|Zjâˆ’Î¼j|]2â€‹q+|Î¼j|2â€‹q))12,\displaystyle d^{\frac{q-1}{2}}\sum\_{j=1}^{d}\Big(2^{2q-1}(\mathbb{E}\_{Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj})}[|Z\_{j}-\mu\_{j}|]^{2q}+|\mu\_{j}|^{2q})\Big)^{\frac{1}{2}}, |  |

where the first inequality holds by the power-mean inequality.
The second inequality follows from a+bâ‰¤a+b\sqrt{a+b}\leq\sqrt{a}+\sqrt{b} when a,b>0a,b>0.

According to [Winkelbauer, [2012](https://arxiv.org/html/2512.14991v1#bib.bib62)], we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)â€‹[|Zjâˆ’Î¼j|]2â€‹q=2qâ€‹Î“â€‹(q+12)Ï€â€‹(Î£jâ€‹j)q.\displaystyle\mathbb{E}\_{Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj})}[|Z\_{j}-\mu\_{j}|]^{2q}=\frac{2^{q}\Gamma(q+\frac{1}{2})}{\sqrt{\pi}}(\Sigma\_{jj})^{q}. |  | (B.7) |

Hence, combining ([B.6](https://arxiv.org/html/2512.14991v1#A2.E6 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([B.7](https://arxiv.org/html/2512.14991v1#A2.E7 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | (ğ”¼Zâˆ¼ğ’©â€‹(Î¼,Î£)â€‹[â€–Zâ€–]2â€‹q)12\displaystyle(\mathbb{E}\_{Z\sim\mathcal{N}(\mu,\Sigma)}[\|Z\|]^{2q})^{\frac{1}{2}} | â‰¤\displaystyle\leq | dqâˆ’12â€‹Î£j=1dâ€‹(22â€‹qâˆ’1â€‹(ğ”¼Zjâˆ¼ğ’©â€‹(Î¼j,Î£jâ€‹j)â€‹[|Zjâˆ’Î¼j|]2â€‹q+|Î¼j|2â€‹q))12\displaystyle d^{\frac{q-1}{2}}\Sigma\_{j=1}^{d}\Big(2^{2q-1}(\mathbb{E}\_{Z\_{j}\sim\mathcal{N}(\mu\_{j},\Sigma\_{jj})}[|Z\_{j}-\mu\_{j}|]^{2q}+|\mu\_{j}|^{2q})\Big)^{\frac{1}{2}} |  | (B.8) |
|  |  | â‰¤\displaystyle\leq | dqâˆ’12â€‹Î£j=1dâ€‹(22â€‹qâˆ’1â€‹(2qâ€‹Î“â€‹(q+12)Ï€â€‹(Î£jâ€‹j)q+|Î¼j|2â€‹q))12\displaystyle d^{\frac{q-1}{2}}\Sigma\_{j=1}^{d}\Big(2^{2q-1}(\frac{2^{q}\Gamma(q+\frac{1}{2})}{\sqrt{\pi}}(\Sigma\_{jj})^{q}+|\mu\_{j}|^{2q})\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | dqâˆ’12Î£j=1d(22â€‹qâˆ’1(2qâ€‹Î“â€‹(q+12)Ï€(dq2âˆ¥Î£âˆ¥q+âˆ¥Î¼âˆ¥2â€‹q))12\displaystyle d^{\frac{q-1}{2}}\Sigma\_{j=1}^{d}\Big(2^{2q-1}(\frac{2^{q}\Gamma(q+\frac{1}{2})}{\sqrt{\pi}}(d^{\frac{q}{2}}\|\Sigma\|^{q}+\|\mu\|^{2q})\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | C~â€‹(q,d)â€‹(â€–Î¼â€–q+â€–Î£â€–q2),\displaystyle\widetilde{C}(q,d)(\|\mu\|^{q}+\|\Sigma\|^{\frac{q}{2}}), |  |

where third inequality holds due to Î£jâ€‹jâ‰¤dâ€‹â€–Î£â€–\Sigma\_{jj}\leq\sqrt{d}\|\Sigma\| and Î¼jâ‰¤â€–Î¼â€–\mu\_{j}\leq\|\mu\|.
âˆ

###### Lemma B.4.

Suppose a function U:â„dâ†¦â„U:\mathbb{R}^{d}\mapsto\mathbb{R} has the following property:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |Uâ€‹(x1)âˆ’Uâ€‹(x2)|â‰¤CË˜â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle|U(x\_{1})-U(x\_{2})|\leq\breve{C}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})\|x\_{1}-x\_{2}\|, |  | (B.9) |

where CË˜\breve{C} is a constant. Then it holds that

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Uâ€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Uâ€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[U(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[U(Y)]\right| |  | (B.10) |
|  |  | â‰¤\displaystyle\leq | LUâ€‹(B,x,a)â€‹ğ’²Â¯2â€‹(ğ’©â€‹(Î¼^hkâ€‹(B)â€‹Î”,Î£^hkâ€‹(B)â€‹Î”),ğ’©â€‹(Î¼hâ€‹(x,a)â€‹Î”,Î£hâ€‹(x,a)â€‹Î”)),\displaystyle L\_{U}(B,x,a)\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big), |  |

where

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | LUâ€‹(B,x,a):\displaystyle L\_{U}(B,x,a): | =\displaystyle= | 3CË˜(1+C~(m,d)(âˆ¥Î¼^hk(B)âˆ¥mÎ”m\displaystyle\sqrt{3}\breve{C}\Big(1+\widetilde{C}(m,d)(\|\widehat{\mu}\_{h}^{k}(B)\|^{m}\Delta^{m} |  |
|  |  |  | +âˆ¥Î£^hk(B)âˆ¥m2Î”m2+âˆ¥Î¼h(x,a)âˆ¥mÎ”m+âˆ¥Î£h(x,a)âˆ¥m2Î”m2)).\displaystyle+\|\widehat{\Sigma}\_{h}^{k}(B)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}}+\|\mu\_{h}(x,a)\|^{m}\Delta^{m}+\|\Sigma\_{h}(x,a)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}})\Big). |  |

###### Proof.

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Uâ€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Uâ€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[U(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[U(Y)]\right| |  | (B.11) |
|  |  | â‰¤\displaystyle\leq | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[|Uâ€‹(X)âˆ’Uâ€‹(Y)|]\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}[\left|U(X)-U(Y)\right|] |  |
|  |  | â‰¤\displaystyle\leq | CË˜â€‹ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[(1+â€–Xâ€–m+â€–Yâ€–m)â€‹(â€–Xâˆ’Yâ€–)]\displaystyle\breve{C}\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}\Big[\Big(1+\|X\|^{m}+\|Y\|^{m}\Big)\Big(\|X-Y\|\Big)\Big] |  |
|  |  | â‰¤\displaystyle\leq | CË˜â€‹(ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[1+â€–Xâ€–2â€‹m+â€–Yâ€–2â€‹m])12â€‹(ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[â€–Xâˆ’Yâ€–2])12\displaystyle\breve{C}\Big(\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}[1+\|X\|^{2m}+\|Y\|^{2m}]\Big)^{\frac{1}{2}}\Big(\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}[\|X-Y\|^{2}]\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | 3â€‹CË˜â€‹(1+(ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[â€–Xâ€–2â€‹m])12+(ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[â€–Yâ€–2â€‹m])12)â€‹(ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[â€–Xâˆ’Yâ€–2])12\displaystyle\sqrt{3}\breve{C}\Big(1+(\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\|X\|^{2m}])^{\frac{1}{2}}+(\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[\|Y\|^{2m}])^{\frac{1}{2}}\Big)\Big(\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}[\|X-Y\|^{2}]\Big)^{\frac{1}{2}} |  |
|  |  | â‰¤\displaystyle\leq | 3â€‹CË˜â€‹(1+C~â€‹(m,d)â€‹(â€–Î¼^hkâ€‹(B)â€–mâ€‹Î”m+â€–Î£^hkâ€‹(B)â€–m2â€‹Î”m2+â€–Î¼hâ€‹(x,a)â€–mâ€‹Î”m+â€–Î£hâ€‹(x,a)â€–m2â€‹Î”m2))\displaystyle\sqrt{3}\breve{C}\Big(1+\widetilde{C}(m,d)(\|\widehat{\mu}\_{h}^{k}(B)\|^{m}\Delta^{m}+\|\widehat{\Sigma}\_{h}^{k}(B)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}}+\|\mu\_{h}(x,a)\|^{m}\Delta^{m}+\|\Sigma\_{h}(x,a)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}})\Big) |  |
|  |  |  | Ã—(EXâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹â€–Xâˆ’Yâ€–2)12,\displaystyle\qquad\times\Big({E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}\|X-Y\|^{2}\Big)^{\frac{1}{2}}, |  |

where the second inequality holds due to ([B.9](https://arxiv.org/html/2512.14991v1#A2.E9 "In Lemma B.4. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the third inequality holds by HÃ¶lderâ€™s inequality and the last inequality holds due to ([B.5](https://arxiv.org/html/2512.14991v1#A2.E5 "In Lemma B.3. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Note that ([B.11](https://arxiv.org/html/2512.14991v1#A2.E11 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for any joint distribution (coupling) of TÂ¯hk(â‹…|B)\bar{T}\_{h}^{k}(\cdot|B) and Th(â‹…|x,a){T}\_{h}(\cdot|x,a), hence we may choose the one which can minimize (ğ”¼Xâˆ¼TÂ¯hk(â‹…|B),Yâˆ¼Th(â‹…|x,a)â€‹[â€–Xâˆ’Yâ€–2])12\Big(\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B),Y\sim{T}\_{h}(\cdot|x,a)}[\|X-Y\|^{2}]\Big)^{\frac{1}{2}}. Then we obtain the following:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Uâ€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Uâ€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[U(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[U(Y)]\right| |  |
|  |  | â‰¤\displaystyle\leq | LUâ€‹(B,x,a)â€‹ğ’²Â¯2â€‹(ğ’©â€‹(Î¼^hkâ€‹(B)â€‹Î”,Î£^hkâ€‹(B)â€‹Î”),ğ’©â€‹(Î¼hâ€‹(x,a)â€‹Î”,Î£hâ€‹(x,a)â€‹Î”)).\displaystyle L\_{U}(B,x,a)\,\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big). |  |

âˆ

Then with the two lemmas above, we are ready to provide the proof for Theorem [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proof.

From ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we know Vh+1âˆ—V\_{h+1}^{\*} has local lipschitz property required to apply Theorem [B.4](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem4 "Lemma B.4. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), so ([B.10](https://arxiv.org/html/2512.14991v1#A2.E10 "In Lemma B.4. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for U=Vh+1âˆ—U=V\_{h+1}^{\*} with CË˜=CÂ¯h+1\breve{C}=\overline{C}\_{h+1}.

For the drift term, with probability at least 1âˆ’Î´1-\delta, it holds that, âˆ€(h,k)âˆˆ[Hâˆ’1]Ã—[K]\forall(h,k)\in[H-1]\times[K] and âˆ€Bâˆˆğ’«hk\forall B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | â€–Î¼^hkâ€‹(B)â€–m\displaystyle\|\widehat{\mu}\_{h}^{k}(B)\|^{m} | â‰¤\displaystyle\leq | (â€–Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–+â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–)m\displaystyle\Big(\|\widehat{\mu}\_{h}^{k}(B)-\bar{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\|+\|\bar{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\|\Big)^{m} |  | (B.12) |
|  |  | â‰¤\displaystyle\leq | 2mâ€‹(â€–Î¼^hkâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–m+â€–ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–m)\displaystyle 2^{m}\Big(\|\widehat{\mu}\_{h}^{k}(B)-\bar{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\|^{m}+\|\bar{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\|^{m}\Big) |  |
|  |  | â‰¤\displaystyle\leq | 2m(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))m+Î·(âˆ¥x~(oB)âˆ¥)m),\displaystyle 2^{m}\Bigg(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{m}+\eta(\|\tilde{x}(^{o}B)\|)^{m}\Bigg), |  |

where the second inequality holds by power-mean inequality.

Let Z:=â€–ğ”¼Â¯â€‹[Î£~hâ€‹(B)]â€–Z:=\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}(B)]\|, we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Z\displaystyle Z | â‰¤\displaystyle\leq | âˆ‘i=1nâ€–Ïƒhâ€‹(Xhki,Ahki)â€–2nhkâ€‹(B)+âˆ‘i=1nhkâ€‹(B)â€–Î¼hâ€‹(Xhki,Ahki)âˆ’ğ”¼Â¯â€‹[Î¼^hkâ€‹(B)]â€–2nhkâ€‹(B)â€‹Î”\displaystyle\frac{\sum\_{i=1}^{n}\|\sigma\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})\|^{2}}{n\_{h}^{k}(B)}+\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\|\mu\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\overline{\mathbb{E}}[\widehat{\mu}\_{h}^{k}(B)]\|^{2}}{n\_{h}^{k}(B)}\Delta |  | (B.13) |
|  |  | â‰¤\displaystyle\leq | Î·(âˆ¥x~(oB)âˆ¥)2+L2D2Î”,\displaystyle\eta(\|\tilde{x}(^{o}B)\|)^{2}+L^{2}D^{2}\Delta, |  |

where the last inequality holds by ([4.7](https://arxiv.org/html/2512.14991v1#S4.E7 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then similar to ([B.12](https://arxiv.org/html/2512.14991v1#A2.E12 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), with probability at least 1âˆ’Î´1-\delta, it holds that âˆ€(h,k)âˆˆ[Hâˆ’1]Ã—[K]\forall(h,k)\in[H-1]\times[K], âˆ€Bâˆˆğ’«hk\forall B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | â€–Î£^hkâ€‹(B)â€–m2\displaystyle\|\widehat{\Sigma}\_{h}^{k}(B)\|^{\frac{m}{2}} | â‰¤\displaystyle\leq | (â€–Î£^hkâ€‹(B)âˆ’Î£~hâ€‹(B)â€–+â€–Î£~hâ€‹(B)âˆ’ğ”¼Â¯â€‹[Î£~hâ€‹(B)]â€–+â€–ğ”¼Â¯â€‹[Î£~hâ€‹(B)]â€–)m2\displaystyle(\|\widehat{\Sigma}\_{h}^{k}(B)-\widetilde{\Sigma}\_{h}(B)\|+\|\widetilde{\Sigma}\_{h}(B)-\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}(B)]\|+\|\overline{\mathbb{E}}[\widetilde{\Sigma}\_{h}(B)]\|)^{\frac{m}{2}} |  | (B.14) |
|  |  | â‰¤\displaystyle\leq | 3m2(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))mÎ”m2\displaystyle 3^{\frac{m}{2}}\Bigg(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{m}\Delta^{\frac{m}{2}} |  |
|  |  |  | +ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))m2+(Î·(âˆ¥x~(oB)âˆ¥)2+L2D2Î”)m2),\displaystyle+\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{\frac{m}{2}}+\Big(\eta(\|\tilde{x}(^{o}B)\|)^{2}+L^{2}D^{2}\Delta\Big)^{\frac{m}{2}}\Bigg), |  |

where the second inequality holds due to ([4.3](https://arxiv.org/html/2512.14991v1#S4.E3 "In 2nd item â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and Proposition [4.2](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem2 "Proposition 4.2. â€£ 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Therefore, with probability at least 1âˆ’2â€‹Î´1-2\delta , it holds that âˆ€(h,k)âˆˆ[Hâˆ’1]Ã—[K]\forall(h,k)\in[H-1]\times[K], âˆ€Bâˆˆğ’«hk\forall B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and âˆ€(x,a)âˆˆB\forall(x,a)\in B:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | |ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Vh+1âˆ—â€‹(X)]âˆ’ğ”¼Yâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(Y)]|\displaystyle\left|\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[V\_{h+1}^{\*}(X)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(Y)]\right| |  | (B.15) |
|  |  | â‰¤\displaystyle\leq | 3CÂ¯h+1(1+C~(m,dğ’®)(âˆ¥Î¼^hk(B)âˆ¥mÎ”m+âˆ¥Î£^hk(B)âˆ¥m2Î”m2+âˆ¥Î¼h(x,a)âˆ¥mÎ”m\displaystyle\sqrt{3}\,\overline{C}\_{h+1}\Big(1+{\widetilde{C}(m,d\_{\mathcal{S}})}(\|\widehat{\mu}\_{h}^{k}(B)\|^{m}\Delta^{m}+\|\widehat{\Sigma}\_{h}^{k}(B)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}}+\|\mu\_{h}(x,a)\|^{m}\Delta^{m} |  |
|  |  |  | +âˆ¥Î£h(x,a)âˆ¥m2Î”m2))Ã—ğ’²Â¯2(ğ’©(Î¼^hk(B)Î”,Î£^hk(B)Î”),ğ’©(Î¼h(x,a)Î”,Î£h(x,a)Î”))\displaystyle\quad+\|\Sigma\_{h}(x,a)\|^{\frac{m}{2}}\Delta^{\frac{m}{2}})\Big)\times\overline{\mathcal{W}}\_{2}\Big(\mathcal{N}(\widehat{\mu}\_{h}^{k}(B)\Delta,\widehat{\Sigma}\_{h}^{k}(B)\Delta),\mathcal{N}(\mu\_{h}(x,a)\Delta,\Sigma\_{h}(x,a)\Delta)\Big) |  |
|  |  | â‰¤\displaystyle\leq | 3CÂ¯max(1+C~(m,dğ’®)(2m(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))m+Î·(âˆ¥x~(oB)âˆ¥)m)Î”m\displaystyle\sqrt{3}\,\overline{C}\_{\max}\Bigg(1+{\widetilde{C}(m,d\_{\mathcal{S}})}\Bigg(2^{m}\Big(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{m}+\eta(\|\tilde{x}(^{o}B)\|)^{m}\Big)\Delta^{m} |  |
|  |  |  | +3m2(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))mÎ”m2+ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))m2\displaystyle\quad+3^{\frac{m}{2}}\Big(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{m}\Delta^{\frac{m}{2}}+\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{\frac{m}{2}} |  |
|  |  |  | +(Î·(âˆ¥x~(oB)âˆ¥)2+L2D2Î”)m2)Î”m2\displaystyle\quad+\Big(\eta(\|\tilde{x}(^{o}B)\|)^{2}+L^{2}D^{2}\Delta\Big)^{\frac{m}{2}}\Big)\Delta^{\frac{m}{2}} |  |
|  |  |  | +Î·(âˆ¥x~(oB)âˆ¥)mÎ”m+Î·(âˆ¥x~(oB)âˆ¥)mÎ”m2))\displaystyle\quad+\eta(\|\tilde{x}(^{o}B)\|)^{m}\Delta^{m}+\eta(\|\tilde{x}(^{o}B)\|)^{m}\Delta^{\frac{m}{2}}\Bigg)\Bigg) |  |
|  |  |  | Ã—(ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))Î”+ÎºÎ¼(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))2Î”32Î»\displaystyle\quad\times\Big(\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\Delta+\kappa\_{\mu}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))^{2}\frac{\Delta^{\frac{3}{2}}}{\sqrt{\lambda}} |  |
|  |  |  | +ÎºÎ£(Î´,âˆ¥x~(oB)âˆ¥,nhk(B))dğ’®â€‹Î”12Î»+T-BIAS(B))\displaystyle\quad+\kappa\_{\Sigma}(\delta,\|\tilde{x}(^{o}B)\|,n\_{h}^{k}(B))\frac{\sqrt{d\_{\mathcal{S}}}\Delta^{\frac{1}{2}}}{\sqrt{\lambda}}+\mbox{\rm T-BIAS}(B)\Big) |  |
|  |  | â‰¤\displaystyle\leq | T-UCBhk(B)+LV(Î´,âˆ¥x~(oB)âˆ¥)T-BIAS(B),\displaystyle\mbox{\rm T-UCB}\_{h}^{k}(B)+L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\,\,\mbox{\rm T-BIAS}(B), |  |

where the first inequality holds due to Lemma [B.4](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem4 "Lemma B.4. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). In addition, the second inequality holds due to ([B.12](https://arxiv.org/html/2512.14991v1#A2.E12 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([B.14](https://arxiv.org/html/2512.14991v1#A2.E14 "In B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the power-mean inequality and ([4.10](https://arxiv.org/html/2512.14991v1#S4.E10 "In Theorem 4.3. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). Finally, the third inequality holds since nhkâ€‹(B)â‰¥1\sqrt{n\_{h}^{k}(B)}\geq 1.

âˆ

### B.7 Proof of Lemma [4.6](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem6 "Lemma 4.6. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

For Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k}, hâˆˆ[H]h\in[H] and kâˆˆJÏKk\in J\_{\rho}^{K}:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | CONFhkâ€‹(B)\displaystyle{\rm CONF}\_{h}^{k}(B) | =\displaystyle= | g1(Î´,âˆ¥x~(oB)âˆ¥)nhkâ€‹(B)\displaystyle\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{\sqrt{n\_{h}^{k}(B)}} |  | (B.16) |
|  |  | â‰¤\displaystyle\leq | g1(Î´,âˆ¥x~(opar(B))âˆ¥)nhkâ€‹(parâ€‹(B))=CONFhkâ€‹(parâ€‹(B))\displaystyle\frac{g\_{1}(\delta,\|\tilde{x}(^{o}{\rm par}(B))\|)}{\sqrt{n\_{h}^{k}({\rm par}(B))}}={\rm CONF}\_{h}^{k}({\rm par}(B)) |  |
|  |  | â‰¤\displaystyle\leq | diamâ€‹(parâ€‹(B))=2â€‹diamâ€‹(B),\displaystyle{\rm diam}({\rm par}(B))=2\,\,{\rm diam}(B), |  |

where parâ€‹(B){\rm par}(B) is the parent block of BB and we use the fact that Bo=oparâ€‹(B){}^{o}B=\,^{o}{\rm par}(B).

Rearranging ([B.16](https://arxiv.org/html/2512.14991v1#A2.E16 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we get:

|  |  |  |  |
| --- | --- | --- | --- |
|  | nhkâ€‹(B)â‰¥(g1(Î´,âˆ¥x~(oB)âˆ¥)2â€‹diamâ€‹(B))2.\displaystyle n\_{h}^{k}(B)\geq\Big(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{2\,\,{\rm diam}(B)}\Big)^{2}. |  | (B.17) |

In addition, nhkâ€‹(B)n\_{h}^{k}(B) must satisfy CONFhkâ€‹(B)>diamâ€‹(B){\rm CONF}\_{h}^{k}(B)>{\rm diam}(B), hence

|  |  |  |  |
| --- | --- | --- | --- |
|  | nhkâ€‹(B)<(g1(Î´,âˆ¥x~(oB)âˆ¥)diamâ€‹(B))2.\displaystyle n\_{h}^{k}(B)<\Big(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{{\rm diam}(B)}\Big)^{2}. |  | (B.18) |

Let lâ€‹(B)l(B) be the total number of ancestors of BB in the adaptive partition and denote them as B0,B1,â€¦,Blâ€‹(B)âˆ’1B\_{0},B\_{1},...,B\_{l(B)-1} arranged in descending order of size. Also denote BB as Blâ€‹(B)B\_{l(B)} for consistency. Then we have

|  |  |  |
| --- | --- | --- |
|  | âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)â‰¤âˆ‘l=0lâ€‹(B)âˆ’1|{kâ€²:Bhkâ€²=Bl}|â€‹diamâ€‹(Bl)âˆ‘l=0lâ€‹(B)âˆ’1|{kâ€²:Bhkâ€²=Bl}|.\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}\leq\frac{\sum\_{l=0}^{l(B)-1}|\{k^{\prime}:B\_{h}^{k^{\prime}}=B\_{l}\}|{\rm diam}(B\_{l})}{\sum\_{l=0}^{l(B)-1}|\{k^{\prime}:B\_{h}^{k^{\prime}}=B\_{l}\}|}. |  |

By ([B.17](https://arxiv.org/html/2512.14991v1#A2.E17 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([B.18](https://arxiv.org/html/2512.14991v1#A2.E18 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")):

|  |  |  |
| --- | --- | --- |
|  | |{kâ€²:Bhkâ€²=Bl}|â‰¤(g1(Î´,âˆ¥x~(oB)âˆ¥)diamâ€‹(B))2âˆ’(g1(Î´,âˆ¥x~(oB)âˆ¥)2â€‹diamâ€‹(B))2=34â€‹g1(Î´,âˆ¥x~(oB)âˆ¥)2diamâ€‹(Bl)2.\displaystyle|\{k^{\prime}:B\_{h}^{k^{\prime}}=B\_{l}\}|\leq\left(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{{\rm diam}(B)}\right)^{2}-\left(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)}{2\,\,{\rm diam}(B)}\right)^{2}=\frac{3}{4}\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|)^{2}}{{\rm diam}(B\_{l})^{2}}. |  |

Note that diamâ€‹(Bl)=2âˆ’lâ€‹D{\rm diam}(B\_{l})=2^{-l}D, we have:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)} | â‰¤\displaystyle\leq | âˆ‘l=0lâ€‹(B)âˆ’1|{kâ€²:Bhkâ€²=Bl}|â€‹diamâ€‹(Bl)âˆ‘l=0lâ€‹(B)âˆ’1|{kâ€²:Bhkâ€²=Bl}|\displaystyle\frac{\sum\_{l=0}^{l(B)-1}|\{k^{\prime}:B\_{h}^{k^{\prime}}=B\_{l}\}|{\rm diam}(B\_{l})}{\sum\_{l=0}^{l(B)-1}|\{k^{\prime}:B\_{h}^{k^{\prime}}=B\_{l}\}|} |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘l=0lâ€‹(B)âˆ’12âˆ’lâ€‹22â€‹lâˆ‘l=0lâ€‹(B)âˆ’122â€‹lâ€‹Dâ‰¤4Ã—2âˆ’lâ€‹(B)â€‹D=4â€‹diamâ€‹(B).\displaystyle\frac{\sum\_{l=0}^{l(B)-1}2^{-l}2^{2l}}{\sum\_{l=0}^{l(B)-1}2^{2l}}D\leq 4\times 2^{-l(B)}D=4\,\,{\rm diam}(B). |  |

Then since diamâ€‹(Bhki)â‰¤D{\rm diam}(B\_{h}^{k\_{i}})\leq D, we have:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)2nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})^{2}}{n\_{h}^{k}(B)} | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)â€‹D\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}D |  |
|  |  | â‰¤\displaystyle\leq | 4â€‹Dâ€‹diamâ€‹(B),\displaystyle 4D\,\ {\rm diam}(B), |  |

where the second inequality holds due to ([4.22](https://arxiv.org/html/2512.14991v1#S4.E22 "In Lemma 4.6. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
âˆ

## Appendix C Technical details in Section [5](https://arxiv.org/html/2512.14991v1#S5 "5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

### C.1 Proof of Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

We first state a proposition before proving the main theorem.

###### Proposition C.1.

With the same assumptions as in Theorem [4.5](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem5 "Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), the following inequality holds for all (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K], Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and any (x,a)âˆˆB(x,a)\in B:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|â‰¤R-BIASâ€‹(B).\displaystyle\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right|\leq\mbox{\rm R-BIAS}(B). |  | (C.1) |

###### Proof of Proposition [C.1](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem1 "Proposition C.1. â€£ C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |âˆ‘i=1nhkâ€‹(B)RÂ¯hâ€‹(Xhki,Ahki)nhkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)|\displaystyle\left|\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})}{n\_{h}^{k}(B)}-\bar{R}\_{h}(x,a)\right| | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)|RÂ¯hâ€‹(Xhki,Ahki)âˆ’RÂ¯hâ€‹(x,a)|nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}|\bar{R}\_{h}(X\_{h}^{k\_{i}},A\_{h}^{k\_{i}})-\bar{R}\_{h}(x,a)|}{n\_{h}^{k}(B)} |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘i=1nhkâ€‹(B)Lâ€‹(1+â€–Xhkiâ€–m+â€–xâ€–m)â€‹(â€–Xhkiâˆ’xâ€–+â€–Ahkiâˆ’aâ€–)nhkâ€‹(B)\displaystyle\frac{\sum\_{i=1}^{n\_{h}^{k}(B)}L(1+\|X\_{h}^{k\_{i}}\|^{m}+\|x\|^{m})(\|X\_{h}^{k\_{i}}-x\|+\|A\_{h}^{k\_{i}}-a\|)}{n\_{h}^{k}(B)} |  |
|  |  | â‰¤\displaystyle\leq | 2L(1+2(âˆ¥x~(oB)âˆ¥+D)m)âˆ‘i=1nhkâ€‹(B)diamâ€‹(Bhki)nhkâ€‹(B)\displaystyle 2L\Big(1+2(\|\tilde{x}(^{o}B)\|+D)^{m}\Big)\sum\_{i=1}^{n\_{h}^{k}(B)}\frac{{\rm diam}(B\_{h}^{k\_{i}})}{n\_{h}^{k}(B)} |  |
|  |  | â‰¤\displaystyle\leq | R-BIASâ€‹(B).\displaystyle\mbox{\rm R-BIAS}(B). |  |

Here, we apply ([4.22](https://arxiv.org/html/2512.14991v1#S4.E22 "In Lemma 4.6. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) to get the last inequality.
âˆ

Then we proceed to the proof of Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proof.

Recall from Theorems [4.4](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem4 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [4.5](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem5 "Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we know that with probability at least 1âˆ’3â€‹Î´1-3\delta,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ([4.4](https://arxiv.org/html/2512.14991v1#S4.Ex20 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))Â andÂ ([4.18](https://arxiv.org/html/2512.14991v1#S4.E18 "In Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"))Â hold simultaneously,\displaystyle\eqref{eq:transition kernel wasserstein local lipschitz all together}\mbox{ and }\eqref{eq:reward high prob bound}\mbox{ hold simultaneously}, |  | (C.2) |

This fact serves as a building block of the proof.

For k=0k=0, with the initialization of (QÂ¯h0(\overline{Q}\_{h}^{0}, V~h0)hâˆˆ[H]\widetilde{V}\_{h}^{0})\_{h\in[H]} in ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we know ([5.2](https://arxiv.org/html/2512.14991v1#S5.Ex10 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds.
Now assume that ([5.2](https://arxiv.org/html/2512.14991v1#S5.Ex10 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for kâˆ’1k-1 and we prove it holds for kk.

For the case of h=Hh=H:
For Bâˆˆğ’«HkB\in\mathcal{P}\_{H}^{k} with nHkâ€‹(B)>0n\_{H}^{k}(B)>0 and for any (x,a)âˆˆB(x,a)\in B, note that by ([4.18](https://arxiv.org/html/2512.14991v1#S4.E18 "In Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.1](https://arxiv.org/html/2512.14991v1#A3.E1 "In Proposition C.1. â€£ C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) :

|  |  |  |  |
| --- | --- | --- | --- |
|  | R^Hkâ€‹(B)âˆ’RÂ¯Hâ€‹(x,a)â‰¥âˆ’R-UCBHkâ€‹(B)âˆ’R-BIASâ€‹(B).\displaystyle\widehat{R}\_{H}^{k}(B)-\bar{R}\_{H}(x,a)\geq-\mbox{\rm R-UCB}\_{H}^{k}(B)-\mbox{\rm R-BIAS}(B). |  | (C.3) |

Therefore
QÂ¯Hkâ€‹(B)=R^Hkâ€‹(B)+R-UCBHkâ€‹(B)+R-BIASâ€‹(B)â‰¥QHâˆ—â€‹(x,a).\overline{Q}\_{H}^{k}(B)=\widehat{R}\_{H}^{k}(B)+\mbox{\rm R-UCB}\_{H}^{k}(B)+\mbox{\rm R-BIAS}(B)\geq Q\_{H}^{\*}(x,a). For Bâˆˆğ’«HkB\in\mathcal{P}\_{H}^{k} with nHkâ€‹(B)=0n\_{H}^{k}(B)=0, by ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")),
we have QÂ¯Hkâ€‹(B)=QÂ¯H0â€‹(B)â‰¥QHâˆ—â€‹(x,a).\overline{Q}\_{H}^{k}(B)=\overline{Q}\_{H}^{0}(B)\geq Q\_{H}^{\*}(x,a). So we proved the first inequality in ([5.2](https://arxiv.org/html/2512.14991v1#S5.Ex10 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For any SâˆˆÎ“ğ’®â€‹(ğ’«Hk)S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{H}^{k}) and any xâˆˆSx\in S,
we have V~Hkâˆ’1â€‹(S)â‰¥VHâˆ—â€‹(x)\widetilde{V}\_{H}^{k-1}(S)\geq V^{\*}\_{H}(x) by induction.
Furthermore,

|  |  |  |
| --- | --- | --- |
|  | V~Hkâ€‹(S)=maxBâˆˆğ’«Hk,Î“ğ’®â€‹(B)âŠƒSâ¡QÂ¯Hkâ€‹(B)â‰¥QÂ¯Hkâ€‹(Bâˆ—)â‰¥QHâˆ—â€‹(x,aHâˆ—â€‹(x))=VHâˆ—â€‹(x),\displaystyle\widetilde{V}\_{H}^{k}(S)=\max\_{B\in\mathcal{P}\_{H}^{k},\Gamma\_{\mathcal{S}}(B)\supset S}\overline{Q}\_{H}^{k}(B)\geq\overline{Q}\_{H}^{k}(B^{\*})\geq Q\_{H}^{\*}(x,a\_{H}^{\*}(x))=V\_{H}^{\*}(x), |  |

where Bâˆ—âˆˆğ’«HkB^{\*}\in\mathcal{P}\_{H}^{k} is defined such that (x,aHâˆ—â€‹(x))âˆˆBâˆ—(x,a\_{H}^{\*}(x))\in B^{\*}. Hence
we have V~Hkâ€‹(S)â‰¥VHâˆ—â€‹(x)\widetilde{V}\_{H}^{k}(S)\geq V^{\*}\_{H}(x).

Finally, we check VÂ¯Hkâ€‹(x)â‰¥VHâˆ—â€‹(x)\bar{V}^{k}\_{H}(x)\geq V\_{H}^{\*}(x). For any xâˆˆğ’®1x\in\mathcal{S}\_{1}, there exits some Sâ€²âˆˆÎ“ğ’®â€‹(ğ’«Hk)S^{\prime}\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{H}^{k}) such that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VÂ¯Hkâ€‹(x)\displaystyle\overline{V}\_{H}^{k}(x) | =\displaystyle= | V~hkâ€‹(Sâ€²)+CHâ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–\displaystyle\widetilde{V}\_{h}^{k}(S^{\prime})+C\_{H}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| |  |
|  |  | â‰¥\displaystyle\geq | VHâˆ—â€‹(x~â€‹(Sâ€²))+CHâ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–\displaystyle V\_{H}^{\*}(\tilde{x}(S^{\prime}))+C\_{H}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| |  |
|  |  | â‰¥\displaystyle\geq | VHâˆ—â€‹(x),\displaystyle V\_{H}^{\*}(x), |  |

where the last inequality holds since |VHâˆ—â€‹(x~â€‹(Sâ€²))âˆ’VHâˆ—â€‹(x)|â‰¤CHâ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–|V\_{H}^{\*}(\tilde{x}(S^{\prime}))-V\_{H}^{\*}(x)|\leq C\_{H}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| by ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For xâˆˆâ„dğ’®âˆ–ğ’®1x\in\mathbb{R}^{d\_{\mathcal{S}}}\setminus\mathcal{S}\_{1}, by ([5.10](https://arxiv.org/html/2512.14991v1#S5.E10 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we know that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VÂ¯Hkâ€‹(x)\displaystyle\overline{V}\_{H}^{k}(x) | =\displaystyle= | VÂ¯Hkâ€‹(Ïâ€–xâ€–â€‹x)+CHâ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–\displaystyle\overline{V}\_{H}^{k}\left(\frac{\rho}{\|x\|}x\right)+C\_{H}(1+\|x\|^{m}+\rho^{m})\left\|\left(1-\frac{\rho}{\|x\|}\right)x\right\| |  |
|  |  | â‰¥\displaystyle\geq | VHâˆ—â€‹(Ïâ€–xâ€–â€‹x)+CHâ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–\displaystyle V\_{H}^{\*}(\frac{\rho}{\|x\|}x)+C\_{H}(1+\|x\|^{m}+\rho^{m})\left\|(1-\frac{\rho}{\|x\|})x\right\| |  |
|  |  | â‰¥\displaystyle\geq | VHâˆ—â€‹(x),\displaystyle V\_{H}^{\*}(x), |  |

where the first inequality holds since Ïâ€–xâ€–â€‹xâˆˆğ’®1\frac{\rho}{\|x\|}x\in\mathcal{S}\_{1}.

Induction (h+1â†¦hh+1\mapsto h):
Assume ([5.2](https://arxiv.org/html/2512.14991v1#S5.Ex10 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds for h+1h+1 and we now show it also holds for hh.

For Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, by ([4.18](https://arxiv.org/html/2512.14991v1#S4.E18 "In Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.1](https://arxiv.org/html/2512.14991v1#A3.E1 "In Proposition C.1. â€£ C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | R^hkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)â‰¥âˆ’R-UCBhkâ€‹(B)âˆ’R-BIASâ€‹(B).\displaystyle\widehat{R}\_{h}^{k}(B)-\bar{R}\_{h}(x,a)\geq-\mbox{\rm R-UCB}\_{h}^{k}(B)-\mbox{\rm R-BIAS}(B). |  | (C.4) |

We also have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)]\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(X)] |  | (C.5) |
|  |  | â‰¥\displaystyle\geq | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[Vh+1âˆ—â€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)]\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[V\_{h+1}^{\*}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(X)] |  |
|  |  | â‰¥\displaystyle\geq | âˆ’T-UCBhk(B)âˆ’LV(Î´,âˆ¥x~(oB)âˆ¥)T-BIAS(B).\displaystyle-\mbox{\rm T-UCB}\_{h}^{k}(B)-L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\mbox{\rm T-BIAS}(B). |  |

The first inequality holds by induction hypothesis on h+1h+1 and the second inequality holds due to ([4.4](https://arxiv.org/html/2512.14991v1#S4.Ex20 "Theorem 4.4. â€£ 4.2 Concentration inequalities for transition kernel estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([4.23](https://arxiv.org/html/2512.14991v1#S4.E23 "In Theorem 4.7. â€£ 4.4 Bias of the estimators â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Combining ([C.4](https://arxiv.org/html/2512.14991v1#A3.E4 "In C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.5](https://arxiv.org/html/2512.14991v1#A3.E5 "In C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |
| --- | --- | --- |
|  | QÂ¯hkâ€‹(B)=R^hkâ€‹(B)+R-UCBhkâ€‹(B)+ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]+T-UCBhkâ€‹(B)+BIASâ€‹(B)â‰¥Qhâˆ—â€‹(x,a).\overline{Q}\_{h}^{k}(B)=\widehat{R}\_{h}^{k}(B)+\mbox{\rm R-UCB}\_{h}^{k}(B)+\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]+\mbox{\rm T-UCB}\_{h}^{k}(B)+{\rm BIAS}(B)\geq Q\_{h}^{\*}(x,a). |  |

For Bâˆˆğ’«hkB\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)=0n\_{h}^{k}(B)=0, by ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we also have

|  |  |  |  |
| --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(B)=QÂ¯h0â€‹(B)â‰¥Qhâˆ—â€‹(x,a).\displaystyle\overline{Q}\_{h}^{k}(B)=\overline{Q}\_{h}^{0}(B)\geq Q\_{h}^{\*}(x,a). |  | (C.6) |

For any SâˆˆÎ“ğ’®â€‹(ğ’«hk)S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}) and any xâˆˆSx\in S,
V~hkâˆ’1â€‹(S)â‰¥Vhâˆ—â€‹(x)\widetilde{V}\_{h}^{k-1}(S)\geq V^{\*}\_{h}(x) holds by induction, and

|  |  |  |
| --- | --- | --- |
|  | maxBâˆˆğ’«hk,Î“ğ’®â€‹(B)âŠƒSâ¡QÂ¯hkâ€‹(B)â‰¥QÂ¯hkâ€‹(Bâˆ—)â‰¥Qhâˆ—â€‹(x,ahâˆ—â€‹(x))=Vhâˆ—â€‹(x),\max\_{B\in\mathcal{P}\_{h}^{k},\Gamma\_{\mathcal{S}}(B)\supset S}\overline{Q}\_{h}^{k}(B)\geq\overline{Q}\_{h}^{k}(B^{\*})\geq Q\_{h}^{\*}(x,a\_{h}^{\*}(x))=V\_{h}^{\*}(x), |  |

where Bâˆ—âˆˆğ’«hkB^{\*}\in\mathcal{P}\_{h}^{k} is the block containing (x,ahâˆ—â€‹(x))(x,a\_{h}^{\*}(x)).
Hence V~hkâ€‹(S)â‰¥Vhâˆ—â€‹(x).\widetilde{V}\_{h}^{k}(S)\geq V^{\*}\_{h}(x).

Finally, for any xâˆˆğ’®1x\in\mathcal{S}\_{1}, there exists a Sâ€²âˆˆÎ“ğ’®â€‹(ğ’«hk)S^{\prime}\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}) such that,

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(x)\displaystyle\overline{V}\_{h}^{k}(x) | =\displaystyle= | V~hkâ€‹(Sâ€²)+Châ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–\displaystyle\widetilde{V}\_{h}^{k}(S^{\prime})+C\_{h}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| |  |
|  |  | â‰¥\displaystyle\geq | Vhâˆ—â€‹(x~â€‹(Sâ€²))+Châ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–\displaystyle V\_{h}^{\*}(\tilde{x}(S^{\prime}))+C\_{h}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| |  |
|  |  | â‰¥\displaystyle\geq | Vhâˆ—â€‹(x),\displaystyle V\_{h}^{\*}(x), |  |

where the last inequality holds since |Vhâˆ—â€‹(x~â€‹(Sâ€²))âˆ’Vhâˆ—â€‹(x)|â‰¤Châ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹â€–xâˆ’x~â€‹(Sâ€²)â€–|V\_{h}^{\*}(\tilde{x}(S^{\prime}))-V\_{h}^{\*}(x)|\leq C\_{h}(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m})\|x-\tilde{x}(S^{\prime})\| by ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For xâˆˆâ„dğ’®âˆ–ğ’®1x\in\mathbb{R}^{d\_{\mathcal{S}}}\setminus\mathcal{S}\_{1}, we know that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(x)\displaystyle\overline{V}\_{h}^{k}(x) | =\displaystyle= | VÂ¯hkâ€‹(Ïâ€–xâ€–â€‹x)+Châ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–\displaystyle\overline{V}\_{h}^{k}\left(\frac{\rho}{\|x\|}x\right)+C\_{h}(1+\|x\|^{m}+\rho^{m})\left\|\left(1-\frac{\rho}{\|x\|}\right)x\right\| |  |
|  |  | â‰¥\displaystyle\geq | Vhâˆ—â€‹(Ïâ€–xâ€–â€‹x)+Châ€‹(1+â€–xâ€–m+Ïm)â€‹â€–(1âˆ’Ïâ€–xâ€–)â€‹xâ€–\displaystyle V\_{h}^{\*}(\frac{\rho}{\|x\|}x)+C\_{h}(1+\|x\|^{m}+\rho^{m})\left\|(1-\frac{\rho}{\|x\|})x\right\| |  |
|  |  | â‰¥\displaystyle\geq | Vhâˆ—â€‹(x),\displaystyle V\_{h}^{\*}(x), |  |

where the first inequality holds since Ïâ€–xâ€–â€‹xâˆˆğ’®1\frac{\rho}{\|x\|}x\in\mathcal{S}\_{1}.
âˆ

### C.2 Proof of Theorem [5.3](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem3 "Theorem 5.3. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

We divide the proof subject into three cases.

Case (1) â€–x1â€–â‰¤Ï,â€–x2â€–â‰¤Ï\|x\_{1}\|\leq\rho,\|x\_{2}\|\leq\rho. Without lose of generality, let us assume â€–x1â€–â‰¥â€–x2â€–\|x\_{1}\|\geq\|x\_{2}\|.

For i=1,2i=1,2, define SÂ¯i:=argâ¡minSâˆˆÎ“Sâ€‹(ğ’«hk)â¡Vh,klocalâ€‹(xi,S)\overline{S}\_{i}:=\arg\min\_{S\in\Gamma\_{S}(\mathcal{P}\_{h}^{k})}V\_{h,k}^{\rm local}(x\_{i},S), and denote S~i\widetilde{S}\_{i} as the state block such that xiâˆˆS~ix\_{i}\in\widetilde{S}\_{i} and S~iâˆˆÎ“ğ’®â€‹(ğ’«hk)\widetilde{S}\_{i}\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h}^{k}).
Then we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | VÂ¯hkâ€‹(xi)=Vh,klocalâ€‹(xi,SÂ¯i)â‰¤Vh,klocalâ€‹(xi,S~i).\displaystyle\overline{V}\_{h}^{k}(x\_{i})=V\_{h,k}^{\rm local}(x\_{i},\overline{S}\_{i})\leq V\_{h,k}^{\rm local}(x\_{i},\tilde{S}\_{i}). |  | (C.7) |

By the last inequality, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â€–xiâˆ’x~â€‹(SÂ¯i)â€–\displaystyle\|x\_{i}-\tilde{x}(\overline{S}\_{i})\| |  | (C.8) |
|  |  | â‰¤\displaystyle\leq | V~hkâ€‹(S~i)+Châ€‹(1+â€–xiâ€–m+â€–x~â€‹(S~i)â€–m)â€‹â€–xiâˆ’x~â€‹(S~i)â€–âˆ’V~hkâ€‹(SÂ¯i)Châ€‹(1+â€–xiâ€–m+â€–x~â€‹(SÂ¯i)â€–m)\displaystyle\frac{\widetilde{V}\_{h}^{k}(\widetilde{S}\_{i})+C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\widetilde{S}\_{i})\|^{m}\Big)\|x\_{i}-\tilde{x}(\widetilde{S}\_{i})\|-\widetilde{V}\_{h}^{k}(\overline{S}\_{i})}{C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\overline{S}\_{i})\|^{m}\Big)} |  |
|  |  | â‰¤\displaystyle\leq | |V~hkâ€‹(S~i)|+|V~hkâ€‹(SÂ¯i)|+Châ€‹(1+â€–xiâ€–m+â€–x~â€‹(S~i)â€–m)â€‹DChâ€‹(1+â€–xiâ€–m+â€–x~â€‹(SÂ¯i)â€–m)\displaystyle\frac{\Big|\widetilde{V}\_{h}^{k}(\widetilde{S}\_{i})\Big|+\Big|\widetilde{V}\_{h}^{k}(\overline{S}\_{i})\Big|+C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\widetilde{S}\_{i})\|^{m}\Big)D}{C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\overline{S}\_{i})\|^{m}\Big)} |  |
|  |  | â‰¤\displaystyle\leq | C~hâ€‹(2+(â€–xiâ€–+2â€‹D)m+1+(â€–x~â€‹(SÂ¯i)â€–+2â€‹D)m+1)+Châ€‹(1+â€–xiâ€–m+(â€–xiâ€–+D)m)â€‹DChâ€‹(1+â€–xiâ€–m+â€–x~â€‹(SÂ¯i)â€–m)\displaystyle\frac{\widetilde{C}\_{h}\Big(2+(\|x\_{i}\|+2D)^{m+1}+(\|\tilde{x}(\overline{S}\_{i})\|+2D)^{m+1}\Big)+C\_{h}\Big(1+\|x\_{i}\|^{m}+(\|x\_{i}\|+D)^{m}\Big)D}{C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\overline{S}\_{i})\|^{m}\Big)} |  |
|  |  | â‰¤\displaystyle\leq | C~hâ€‹(2+2mâ€‹â€–xiâ€–m+1+2mâ€‹â€–x~â€‹(SÂ¯i)â€–m+1+22â€‹m+1â€‹Dm+1)Châ€‹(1+â€–xiâ€–m+â€–x~â€‹(SÂ¯i)â€–m)\displaystyle\frac{\widetilde{C}\_{h}\Big(2+2^{m}\|x\_{i}\|^{m+1}+2^{m}\|\tilde{x}(\overline{S}\_{i})\|^{m+1}+2^{2m+1}D^{m+1}\Big)}{C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\overline{S}\_{i})\|^{m}\Big)} |  |
|  |  |  | +Châ€‹(1+(2mâˆ’1+1)â€‹â€–xiâ€–m+2mâˆ’1â€‹Dm)â€‹DChâ€‹(1+â€–xiâ€–m+â€–x~â€‹(SÂ¯i)â€–m)\displaystyle\,\,+\frac{C\_{h}\Big(1+(2^{m-1}+1)\|x\_{i}\|^{m}+2^{m-1}D^{m}\Big)D}{C\_{h}\Big(1+\|x\_{i}\|^{m}+\|\tilde{x}(\overline{S}\_{i})\|^{m}\Big)} |  |
|  |  | â‰¤\displaystyle\leq | 12â€‹(â€–xiâ€–+â€–x~â€‹(SÂ¯i)â€–)+cË˜0,\displaystyle\frac{1}{2}(\|x\_{i}\|+\|\tilde{x}(\overline{S}\_{i})\|)+\breve{c}\_{0}, |  |

where cË˜0\breve{c}\_{0} a positive constant depending on D,m,Ch,C~hD,m,C\_{h},\widetilde{C}\_{h}.
The first inequality holds due to ([C.7](https://arxiv.org/html/2512.14991v1#A3.E7 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the definition of Vh,klocal(.,.)V\_{h,k}^{\rm local}(.,.) in ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). The third inequality holds with probability at least 1âˆ’3â€‹Î´1-3\delta due to ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), and the fact that â€–xâˆ’x~â€‹(S~i)â€–â‰¤D\|x-\tilde{x}(\widetilde{S}\_{i})\|\leq D. The fourth inequality holds due to the power-mean inequality. The last inequality holds by the fact that Châ‰¥2m+1â€‹C~hC\_{h}\geq 2^{m+1}\widetilde{C}\_{h}.

By the triangle inequalty â€–x~â€‹(SÂ¯i)â€–âˆ’â€–xiâ€–â‰¤â€–xiâˆ’x~â€‹(SÂ¯i)â€–\|\tilde{x}(\overline{S}\_{i})\|-\|x\_{i}\|\leq\|x\_{i}-\tilde{x}(\overline{S}\_{i})\| and ([C.8](https://arxiv.org/html/2512.14991v1#A3.E8 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–x~â€‹(SÂ¯i)â€–â‰¤3â€‹â€–xiâ€–+2â€‹cË˜0.\displaystyle\|\tilde{x}(\overline{S}\_{i})\|\leq 3\|x\_{i}\|+2\breve{c}\_{0}. |  | (C.9) |

Now we are ready to bound |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)||\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})| by two terms.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|\displaystyle|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})| |  |
|  |  | =\displaystyle= | (VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2))â€‹ğ•€{VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)â‰¥0}+(VÂ¯hkâ€‹(x2)âˆ’VÂ¯hkâ€‹(x1))â€‹ğ•€{VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)<0}\displaystyle(\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2}))\mathbb{I}\_{\{\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})\geq 0\}}+(\overline{V}\_{h}^{k}(x\_{2})-\overline{V}\_{h}^{k}(x\_{1}))\mathbb{I}\_{\{\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})<0\}} |  |
|  |  | â‰¤\displaystyle\leq | |Vh,klocalâ€‹(x1,SÂ¯2)âˆ’Vh,klocalâ€‹(x2,SÂ¯2)|âŸ(I)+|Vh,klocalâ€‹(x2,SÂ¯1)âˆ’VH,klocalâ€‹(x1,SÂ¯1)|âŸ(Iâ€‹I),\displaystyle\underbrace{\Big|V\_{h,k}^{\rm local}(x\_{1},\overline{S}\_{2})-V\_{h,k}^{\rm local}(x\_{2},\overline{S}\_{2})\Big|}\_{(I)}+\underbrace{\Big|V\_{h,k}^{\rm local}(x\_{2},\overline{S}\_{1})-V\_{H,k}^{\rm local}(x\_{1},\overline{S}\_{1})\Big|}\_{(II)}, |  |

where the inequality holds due to ([C.7](https://arxiv.org/html/2512.14991v1#A3.E7 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For term (I),

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |Vh,klocalâ€‹(x1,SÂ¯2)âˆ’Vh,klocalâ€‹(x2,SÂ¯2)|\displaystyle\Big|V\_{h,k}^{\rm local}(x\_{1},\overline{S}\_{2})-V\_{h,k}^{\rm local}(x\_{2},\overline{S}\_{2})\Big| |  |
|  |  | â‰¤\displaystyle\leq | Châ€‹(1+â€–x~â€‹(SÂ¯2)â€–m)â€‹â€–x1âˆ’x2â€‹â€–+Ch|â€‹â€–x1â€–mâ€‹â€–x1âˆ’x~â€‹(SÂ¯2)â€–âˆ’â€–x2â€–mâ€‹â€–x2âˆ’x~â€‹(SÂ¯2)â€–|\displaystyle C\_{h}\Bigg(1+\|\tilde{x}(\overline{S}\_{2})\|^{m}\Bigg)\|x\_{1}-x\_{2}\|+C\_{h}\Bigg|\|x\_{1}\|^{m}\|x\_{1}-\tilde{x}(\overline{S}\_{2})\|-\|x\_{2}\|^{m}\|x\_{2}-\tilde{x}(\overline{S}\_{2})\|\Bigg| |  |
|  |  | â‰¤\displaystyle\leq | Châ€‹(1+(3â€‹â€–x2â€–+2â€‹cË˜0)m)â€‹â€–x1âˆ’x2â€–+â€–x1â€–mâ€‹â€–x1âˆ’x2â€–+(4â€‹â€–x2â€–+2â€‹cË˜0)â€‹|â€–x1â€–mâˆ’â€–x2â€–m|,\displaystyle C\_{h}\Bigg(1+(3\|x\_{2}\|+2\breve{c}\_{0})^{m}\Bigg)\|x\_{1}-x\_{2}\|+\|x\_{1}\|^{m}\|x\_{1}-x\_{2}\|+(4\|x\_{2}\|+2\breve{c}\_{0})\Big|\|x\_{1}\|^{m}-\|x\_{2}\|^{m}\Big|, |  |

where the first inequality holds by triangle inequality and the second inequality holds due to ([C.9](https://arxiv.org/html/2512.14991v1#A3.E9 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Similarly, for term (II):

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | |Vh,klocalâ€‹(x2,SÂ¯1)âˆ’VH,klocalâ€‹(x1,SÂ¯1)|\displaystyle\Big|V\_{h,k}^{\rm local}(x\_{2},\overline{S}\_{1})-V\_{H,k}^{\rm local}(x\_{1},\overline{S}\_{1})\Big| |  |
|  |  | â‰¤\displaystyle\leq | Châ€‹(1+(3â€‹â€–x1â€–+2â€‹cË˜0)m)â€‹â€–x1âˆ’x2â€–+â€–x2â€–mâ€‹â€–x1âˆ’x2â€–+(4â€‹â€–x1â€–+2â€‹cË˜0)â€‹|â€–x1â€–mâˆ’â€–x2â€–m|.\displaystyle C\_{h}\Bigg(1+(3\|x\_{1}\|+2\breve{c}\_{0})^{m}\Bigg)\|x\_{1}-x\_{2}\|+\|x\_{2}\|^{m}\|x\_{1}-x\_{2}\|+(4\|x\_{1}\|+2\breve{c}\_{0})\Big|\|x\_{1}\|^{m}-\|x\_{2}\|^{m}\Big|. |  |

It is clear that m=0m=0 is a trivial case, so we only consider mâ‰¥1m\geq 1, with which we have

|  |  |  |
| --- | --- | --- |
|  | |â€–x1â€–mâˆ’â€–x2â€–m|â‰¤(mâˆ’1)â€‹â€–x1â€–mâˆ’1â€‹â€–x1âˆ’x2â€–,Â andÂ â€‹â€–x1â€–mâˆ’1â‰¤mâˆ’1mâ€‹â€–x1â€–m+1m.\Big|\|x\_{1}\|^{m}-\|x\_{2}\|^{m}\Big|\leq(m-1)\|x\_{1}\|^{m-1}\|x\_{1}-x\_{2}\|,\mbox{ and }\|x\_{1}\|^{m-1}\leq\frac{m-1}{m}\|x\_{1}\|^{m}+\frac{1}{m}. |  |

Combine ([C.2](https://arxiv.org/html/2512.14991v1#A3.Ex29 "C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.2](https://arxiv.org/html/2512.14991v1#A3.Ex31 "C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.2](https://arxiv.org/html/2512.14991v1#A3.Ex32 "C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the facts above, we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|â‰¤cË˜h1â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})|\leq\breve{c}^{1}\_{h}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})\|x\_{1}-x\_{2}\|, |  | (C.13) |

where cË˜h1\breve{c}^{1}\_{h} depends only on Ch,C~h,m,DC\_{h},\widetilde{C}\_{h},m,D.

Case (2) â€–x1â€–>Ï,â€–x2â€–â‰¤Ï\|x\_{1}\|>\rho,\|x\_{2}\|\leq\rho. In this case,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|\displaystyle\Big|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})\Big| | =\displaystyle= | |VÂ¯hkâ€‹(Ïâ€–x1â€–â€‹x1)âˆ’VÂ¯hkâ€‹(x2)+Châ€‹(1+â€–x1â€–m+Ïm)â€‹(â€–x1â€–âˆ’Ï)|\displaystyle\Big|\overline{V}\_{h}^{k}\Big(\frac{\rho}{\|x\_{1}\|}x\_{1}\Big)-\overline{V}\_{h}^{k}(x\_{2})+C\_{h}(1+\|x\_{1}\|^{m}+\rho^{m})(\|x\_{1}\|-\rho)\Big| |  | (C.14) |
|  |  | â‰¤\displaystyle\leq | cË˜h3â€‹(1+2â€‹Ïm)â€‹â€–Ïâ€–x1â€–â€‹x1âˆ’x2â€–+Châ€‹(1+â€–x1â€–m+Ïm)â€‹(â€–x1â€–âˆ’Ï)\displaystyle\breve{c}^{3}\_{h}(1+2\rho^{m})\Big\|\frac{\rho}{\|x\_{1}\|}x\_{1}-x\_{2}\Big\|+C\_{h}(1+\|x\_{1}\|^{m}+\rho^{m})(\|x\_{1}\|-\rho) |  |
|  |  | â‰¤\displaystyle\leq | cË˜h4â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle\breve{c}^{4}\_{h}\Big(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m}\Big)\|x\_{1}-x\_{2}\|, |  |

where the first inequality holds due to ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) , ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.13](https://arxiv.org/html/2512.14991v1#A3.E13 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")); the second inequality holds due to â€–Ïâ€–x1â€–â€‹x1âˆ’x2â€–â‰¤â€–x1âˆ’x2â€–\|\frac{\rho}{\|x\_{1}\|}x\_{1}-x\_{2}\|\leq\|x\_{1}-x\_{2}\| and â€–x1â€–âˆ’Ïâ‰¤â€–x1âˆ’x2â€–\|x\_{1}\|-\rho\leq\|x\_{1}-x\_{2}\| ; and finally, the third inequality holds since Ïmâ‰¤â€–x1â€–m\rho^{m}\leq\|x\_{1}\|^{m}. Note that cË˜h4\breve{c}^{4}\_{h} depends only on Ch,C~h,m,DC\_{h},\widetilde{C}\_{h},m,D.

Case (3) â€–x1â€–>Ï,â€–x2â€–>Ï\|x\_{1}\|>\rho,\|x\_{2}\|>\rho. In this case,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|\displaystyle\Big|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})\Big| | =\displaystyle= | |VÂ¯hk(Ïâ€–x1â€–x1)âˆ’VÂ¯hk(Ïâ€–x2â€–x2)+Ch(1+Ïm)(âˆ¥x1âˆ¥âˆ’âˆ¥x2âˆ¥)\displaystyle\Big|\overline{V}\_{h}^{k}\Big(\frac{\rho}{\|x\_{1}\|}x\_{1}\Big)-\overline{V}\_{h}^{k}\Big(\frac{\rho}{\|x\_{2}\|}x\_{2}\Big)+C\_{h}(1+\rho^{m})(\|x\_{1}\|-\|x\_{2}\|) |  | (C.15) |
|  |  |  | +Châˆ¥x1âˆ¥m(âˆ¥x1âˆ¥âˆ’Ï)âˆ’Châˆ¥x2âˆ¥m(âˆ¥x2âˆ¥âˆ’Ï)|\displaystyle+C\_{h}\|x\_{1}\|^{m}(\|x\_{1}\|-\rho)-C\_{h}\|x\_{2}\|^{m}(\|x\_{2}\|-\rho)\Big| |  |
|  |  | â‰¤\displaystyle\leq | |VÂ¯hkâ€‹(Ïâ€–x1â€–â€‹x1)âˆ’VÂ¯hkâ€‹(Ïâ€–x2â€–â€‹x2)|+|Châ€‹(1+Ïm)â€‹(â€–x1â€–âˆ’â€–x2â€–)|\displaystyle\Big|\overline{V}\_{h}^{k}\Big(\frac{\rho}{\|x\_{1}\|}x\_{1}\Big)-\overline{V}\_{h}^{k}\Big(\frac{\rho}{\|x\_{2}\|}x\_{2}\Big)\Big|+\Big|C\_{h}(1+\rho^{m})(\|x\_{1}\|-\|x\_{2}\|)\Big| |  |
|  |  |  | +|Châ€‹â€–x1â€–mâ€‹(â€–x1â€–âˆ’Ï)âˆ’Châ€‹â€–x2â€–mâ€‹(â€–x2â€–âˆ’Ï)â€–\displaystyle+\Big|C\_{h}\|x\_{1}\|^{m}(\|x\_{1}\|-\rho)-C\_{h}\|x\_{2}\|^{m}(\|x\_{2}\|-\rho)\Big\| |  |
|  |  | â‰¤\displaystyle\leq | cË˜h3â€‹(1+2â€‹Ïm)â€‹â€–Ïâ€–x1â€–â€‹x1âˆ’Ïâ€–x2â€–â€‹x2â€‹â€–+Châ€‹(1+Ïm)|â€‹â€–x1â€–âˆ’â€–x2â€–|\displaystyle\breve{c}^{3}\_{h}(1+2\rho^{m})\Big\|\frac{\rho}{\|x\_{1}\|}x\_{1}-\frac{\rho}{\|x\_{2}\|}x\_{2}\Big\|+C\_{h}(1+\rho^{m})\Big|\|x\_{1}\|-\|x\_{2}\|\Big| |  |
|  |  |  | +Châ€‹|â€–x1â€–m+1âˆ’â€–x2â€–m+1â€‹|+Ïâ€‹Ch|â€‹â€–x1â€–mâˆ’â€–x2â€–m|\displaystyle+C\_{h}\Big|\|x\_{1}\|^{m+1}-\|x\_{2}\|^{m+1}\Big|+\rho C\_{h}\Big|\|x\_{1}\|^{m}-\|x\_{2}\|^{m}\Big| |  |
|  |  | â‰¤\displaystyle\leq | cË˜h5â€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–,\displaystyle\breve{c}^{5}\_{h}\Big(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m}\Big)\|x\_{1}-x\_{2}\|, |  |

where the second inequality holds due to ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.13](https://arxiv.org/html/2512.14991v1#A3.E13 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In addition, the third inequality holds due to the facts that |amâˆ’bm|â‰¤|aâˆ’b|â€‹(a+b)mâˆ’1|a^{m}-b^{m}|\leq|a-b|(a+b)^{m-1} for a,bâ‰¥0a,b\geq 0 and â€–Ïâ€–x1â€–â€‹x1âˆ’Ïâ€–x2â€–â€‹x2â€–â‰¤â€–x1âˆ’x2â€–\|\frac{\rho}{\|x\_{1}\|}x\_{1}-\frac{\rho}{\|x\_{2}\|}x\_{2}\|\leq\|x\_{1}-x\_{2}\|. Also, the fourth inequality holds since Ïmâ‰¤â€–x1â€–m+â€–x2â€–m\rho^{m}\leq\|x\_{1}\|^{m}+\|x\_{2}\|^{m}. cË˜h5\breve{c}^{5}\_{h} depends only on Ch,C~h,m,DC\_{h},\widetilde{C}\_{h},m,D.

Finally, let C^h=maxâ¡{cË˜h3,cË˜h4,cË˜h5}\widehat{C}\_{h}=\max\{\breve{c}^{3}\_{h},\breve{c}^{4}\_{h},\breve{c}^{5}\_{h}\}, combine ([C.13](https://arxiv.org/html/2512.14991v1#A3.E13 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.14](https://arxiv.org/html/2512.14991v1#A3.E14 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.15](https://arxiv.org/html/2512.14991v1#A3.E15 "In C.2 Proof of Theorem 5.3 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we conclude that:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |VÂ¯hkâ€‹(x1)âˆ’VÂ¯hkâ€‹(x2)|â‰¤C^hâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹â€–x1âˆ’x2â€–.\displaystyle|\overline{V}\_{h}^{k}(x\_{1})-\overline{V}\_{h}^{k}(x\_{2})|\leq\widehat{C}\_{h}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})\|x\_{1}-x\_{2}\|. |  | (C.16) |

âˆ

### C.3 Proof of Theorem [5.5](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem5 "Theorem 5.5. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

Combine Theorem [4.5](https://arxiv.org/html/2512.14991v1#S4.Thmtheorem5 "Theorem 4.5. â€£ 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), Proposition [C.1](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem1 "Proposition C.1. â€£ C.1 Proof of Theorem 5.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), Corollary [5.4](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem4 "Corollary 5.4. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), and the fact that
C^maxCÂ¯max>1\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}>1, we have the following result. With probability at least 1âˆ’3â€‹Î´1-3\delta, it holds that âˆ€(h,k)âˆˆ[H]Ã—[K]\forall(h,k)\in[H]\times[K], âˆ€Bâˆˆğ’«hk\forall B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and âˆ€(x,a)âˆˆB\forall(x,a)\in B:

|  |  |  |  |
| --- | --- | --- | --- |
|  | R^hkâ€‹(B)âˆ’RÂ¯hâ€‹(x,a)â‰¤C^maxCÂ¯maxâ€‹(R-UCBhkâ€‹(B)+R-BIASâ€‹(B));\displaystyle\widehat{R}\_{h}^{k}(B)-\bar{R}\_{h}(x,a)\leq\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k}(B)+\mbox{\rm R-BIAS}(B)\Big); |  | (C.17) |

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(X)]\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[\overline{V}\_{h+1}^{k}(X)] |  | (C.18) |
|  |  | â‰¤\displaystyle\leq | C^maxCÂ¯max(T-UCBhk(B)+LV(Î´,âˆ¥x~(oB)âˆ¥)T-BIAS(B)).\displaystyle\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm T-UCB}\_{h}^{k}(B)+L\_{V}(\delta,\|\tilde{x}(^{o}B)\|)\mbox{\rm T-BIAS}(B)\Big). |  |

Also, we have the following decomposition:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)]\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(X)] |  |
|  |  | =\displaystyle= | ğ”¼Xâˆ¼TÂ¯hk(â‹…|B)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(X)]+ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)].\displaystyle\mathbb{E}\_{X\sim\bar{T}\_{h}^{k}(\cdot|B)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[\overline{V}\_{h+1}^{k}(X)]+\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h}(\cdot|x,a)}[V\_{h+1}^{\*}(X)]. |  |

Combining the results in ([C.17](https://arxiv.org/html/2512.14991v1#A3.E17 "In C.3 Proof of Theorem 5.5 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.18](https://arxiv.org/html/2512.14991v1#A3.E18 "In C.3 Proof of Theorem 5.5 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.3](https://arxiv.org/html/2512.14991v1#A3.Ex43 "C.3 Proof of Theorem 5.5 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), it holds with probability at least 1âˆ’3â€‹Î´1-3\delta that, âˆ€(h,k)âˆˆ[H]Ã—[K]\forall(h,k)\in[H]\times[K], âˆ€Bâˆˆğ’«hk\forall B\in\mathcal{P}\_{h}^{k} with nhkâ€‹(B)>0n\_{h}^{k}(B)>0, and âˆ€(x,a)âˆˆB\forall(x,a)\in B:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QÂ¯hkâ€‹(B)âˆ’Qhâˆ—â€‹(x,a)\displaystyle\overline{Q}\_{h}^{k}(B)-Q\_{h}^{\*}(x,a) | â‰¤\displaystyle\leq | 2â€‹C^maxCÂ¯maxâ€‹(R-UCBhkâ€‹(B)+T-UCBhkâ€‹(B)+BIASâ€‹(B))\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k}(B)+\mbox{\rm T-UCB}\_{h}^{k}(B)+{\rm BIAS}(B)\Big) |  |
|  |  |  | +ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[VÂ¯h+1kâ€‹(X)]âˆ’ğ”¼Xâˆ¼Th(â‹…|x,a)â€‹[Vh+1âˆ—â€‹(X)],h<H,\displaystyle+\mathbb{E}\_{X\sim{T}\_{h(\cdot|x,a)}}[\overline{V}\_{h+1}^{k}(X)]-\mathbb{E}\_{X\sim{T}\_{h(\cdot|x,a)}}[V\_{h+1}^{\*}(X)],\,\,h<H, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | QÂ¯Hkâ€‹(B)âˆ’QHâˆ—â€‹(x,a)\displaystyle\overline{Q}\_{H}^{k}(B)-Q\_{H}^{\*}(x,a) | â‰¤\displaystyle\leq | 2â€‹C^maxCÂ¯maxâ€‹(R-UCBHkâ€‹(B)+R-BIASâ€‹(B)).\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{H}^{k}(B)+\mbox{\rm R-BIAS}(B)\Big). |  |

âˆ

### C.4 Proof of Proposition [5.6](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem6 "Proposition 5.6. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

Since nhkâ€‹(B)=0n\_{h}^{k}(B)=0, we must have Bâˆˆğ’«h0B\in\mathcal{P}\_{h}^{0}, diamâ€‹(B)=D{\rm diam}(B)=D, QÂ¯hkâ€‹(B)=QÂ¯h0â€‹(B)\overline{Q}\_{h}^{k}(B)=\overline{Q}\_{h}^{0}(B) and Bo=B{}^{o}B=B. Hence

|  |  |  |
| --- | --- | --- |
|  | QÂ¯hk(B)âˆ’Qhâˆ—(x,a)â‰¤QÂ¯h0(B)+|Vhâˆ—(x)|â‰¤2C~hD(1+(âˆ¥x~(oB)âˆ¥+D)m+1)diam(B),\overline{Q}\_{h}^{k}(B)-Q\_{h}^{\*}(x,a)\leq\overline{Q}\_{h}^{0}(B)+|V\_{h}^{\*}(x)|\leq 2\frac{\widetilde{C}\_{h}}{D}(1+(\|\tilde{x}(^{o}B)\|+D)^{m+1}){\rm diam}(B), |  |

where the last inequality holds by ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

âˆ

### C.5 Proof of Proposition [5.7](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem7 "Proposition 5.7. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

Note that conditioned on Xhkâˆˆğ’®1X\_{h}^{k}\in\mathcal{S}\_{1}, we have Bhkâˆˆğ’«hkâˆ’1B\_{h}^{k}\in\mathcal{P}\_{h}^{k-1}. We then divide the proof into two cases: (1) k>1k>1 and (2) k=1k=1.

Case (1). For k>1k>1, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | VÂ¯hkâˆ’1â€‹(Xhk)\displaystyle\overline{V}\_{h}^{k-1}(X\_{h}^{k}) | â‰¤\displaystyle\leq | V~hkâˆ’1(Î“ğ’®(Bhk))+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle\widetilde{V}\_{h}^{k-1}(\Gamma\_{\mathcal{S}}(B\_{h}^{k}))+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}) |  | (C.20) |
|  |  | =\displaystyle= | maxBâˆˆPhkâˆ’1:Î“ğ’®â€‹(Bhk)âŠ‚Î“ğ’®â€‹(B)QÂ¯hkâˆ’1(B)+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle\max\_{B\in P\_{h}^{k-1}:\Gamma\_{\mathcal{S}}(B\_{h}^{k})\subset\Gamma\_{\mathcal{S}}(B)}\overline{Q}\_{h}^{k-1}(B)+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}) |  |
|  |  | =\displaystyle= | QÂ¯hkâˆ’1(Bhk)+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk).\displaystyle\overline{Q}\_{h}^{k-1}(B\_{h}^{k})+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}). |  |

The first inequality holds by the definition of VÂ¯hkâˆ’1â€‹(Xhk)\overline{V}\_{h}^{k-1}(X\_{h}^{k}) in ([5.8](https://arxiv.org/html/2512.14991v1#S5.E8 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and the first equality holds due to the greedy selection rule (line [2](https://arxiv.org/html/2512.14991v1#alg2.l2 "In Algorithm 2 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) in Algorithm [1](https://arxiv.org/html/2512.14991v1#alg1 "Algorithm 1 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Case (2).
For k=1k=1, we have

|  |  |  |
| --- | --- | --- |
|  | VÂ¯h0(Xh1)â‰¤QÂ¯h0(Bh1)+Ch(1+2(âˆ¥x~(oBh1)âˆ¥+D)m)diam(Bh1).\displaystyle\overline{V}\_{h}^{0}(X\_{h}^{1})\leq\overline{Q}\_{h}^{0}(B\_{h}^{1})+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{1})\|+D)^{m}){\rm diam}(B\_{h}^{1}). |  |

This inequality holds due to the initial estimators we set in ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the fact that Bh1o=Bh1{}^{o}B\_{h}^{1}=B\_{h}^{1} since Bh1âˆˆğ’«h0B\_{h}^{1}\in\mathcal{P}\_{h}^{0}.
âˆ

### C.6 Proof of Theorem [5.9](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem9 "Theorem 5.9. â€£ 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

By the definition in ([5.23](https://arxiv.org/html/2512.14991v1#S5.E23 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")),

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Gaphâ€‹(Bhk)\displaystyle{\rm Gap}\_{h}(B\_{h}^{k}) | â‰¤\displaystyle\leq | G~â€‹aphâ€‹(Xhk,Ahk)\displaystyle{\rm\widetilde{G}ap}\_{h}(X\_{h}^{k},A\_{h}^{k}) |  | (C.21) |
|  |  | â‰¤\displaystyle\leq | VÂ¯hkâˆ’1â€‹(Xhk)âˆ’Qhâˆ—â€‹(Xhk,Ahk)\displaystyle\overline{V}\_{h}^{k-1}(X\_{h}^{k})-Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k}) |  |
|  |  | â‰¤\displaystyle\leq | QÂ¯hkâˆ’1(Bhk)âˆ’Qhâˆ—(Xhk,Ahk)+Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle\overline{Q}\_{h}^{k-1}(B\_{h}^{k})-Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}) |  |
|  |  | â‰¤\displaystyle\leq | Ghkâ€‹(Bhk)+fh+1kâˆ’1â€‹(Xhk,Ahk):=Ï•1+Ï•2,\displaystyle G\_{h}^{k}(B\_{h}^{k})+f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k}):=\phi\_{1}+\phi\_{2}, |  |

in which the second inequality holds due to Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") , the third inequality holds by ([5.20](https://arxiv.org/html/2512.14991v1#S5.E20 "In Proposition 5.7. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). and the fourth inequality holds due to ([5.5](https://arxiv.org/html/2512.14991v1#S5.Ex14 "Theorem 5.5. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([5.19](https://arxiv.org/html/2512.14991v1#S5.E19 "In Proposition 5.6. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In the last line, we use the simplified notations Ï•1:=Ghkâ€‹(Bhk)\phi\_{1}:=G\_{h}^{k}(B\_{h}^{k}) and Ï•2:=fh+1kâˆ’1â€‹(Xhk,Ahk)\phi\_{2}:=f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k}).

Let Ï•:=VÂ¯hkâˆ’1â€‹(Xhk)âˆ’Qhâˆ—â€‹(Xhk,Ahk)\phi:=\overline{V}\_{h}^{k-1}(X\_{h}^{k})-Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k}). We claim that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ï•â‰¤CLIPâ€‹(Ï•1|Gaphâ€‹(Bhk)H+1)+(1+1H)â€‹Ï•2.\displaystyle\phi\leq{\rm CLIP}\Bigg(\phi\_{1}\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+\Big(1+\frac{1}{H}\Big)\phi\_{2}. |  | (C.22) |

When Ï•1â‰¥Gaphâ€‹(Bhk)H+1\phi\_{1}\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}, ([C.22](https://arxiv.org/html/2512.14991v1#A3.E22 "In C.6 Proof of Theorem 5.9 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) is trivial.
So we only need to prove the claim when
Ï•1<Gaphâ€‹(Bhk)H+1\phi\_{1}<\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}. In this case,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Gaphâ€‹(Bhk)â‰¤Ï•1+Ï•2â‰¤Gaphâ€‹(Bhk)H+1+Ï•2.\displaystyle{\rm Gap}\_{h}(B\_{h}^{k})\leq\phi\_{1}+\phi\_{2}\leq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}+\phi\_{2}. |  | (C.23) |

Rearranging terms in ([C.23](https://arxiv.org/html/2512.14991v1#A3.E23 "In C.6 Proof of Theorem 5.9 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have
Gaphâ€‹(Bhk)â‰¤H+1Hâ€‹Ï•2{\rm Gap}\_{h}(B\_{h}^{k})\leq\frac{H+1}{H}\phi\_{2}, and hence
Ï•1+Ï•2â‰¤1H+1â€‹H+1Hâ€‹Ï•2+Ï•2=(1+1H)â€‹Ï•2.\phi\_{1}+\phi\_{2}\leq\frac{1}{H+1}\frac{H+1}{H}\phi\_{2}+\phi\_{2}=(1+\frac{1}{H})\phi\_{2}.
This implies that

|  |  |  |
| --- | --- | --- |
|  | Ï•â‰¤Ï•1+Ï•2â‰¤CLIPâ€‹(Ï•1|Gaphâ€‹(Bhk)H+1)+(1+1H)â€‹Ï•2.\phi\leq\phi\_{1}+\phi\_{2}\leq{\rm CLIP}\Bigg(\phi\_{1}\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+\Big(1+\frac{1}{H}\Big)\phi\_{2}. |  |

With the inequality ([C.22](https://arxiv.org/html/2512.14991v1#A3.E22 "In C.6 Proof of Theorem 5.9 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Î”h(k)\displaystyle\Delta\_{h}^{(k)} | =\displaystyle= | VÂ¯hkâˆ’1â€‹(Xhk)âˆ’Qhâˆ—â€‹(Xhk,Ahk)+Qhâˆ—â€‹(Xhk,Ahk)âˆ’VhÏ€~kâ€‹(Xhk)\displaystyle\overline{V}\_{h}^{k-1}(X\_{h}^{k})-Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})+Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k}) |  | (C.24) |
|  |  | â‰¤\displaystyle\leq | CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+(1+1H)â€‹fh+1kâˆ’1â€‹(Xhk,Ahk)+Qhâˆ—â€‹(Xhk,Ahk)âˆ’VhÏ€~kâ€‹(Xhk),\displaystyle{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+\Big(1+\frac{1}{H}\Big)f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k})+Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k}), |  |

âˆ

### C.7 Proof of Proposition [5.10](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem10 "Proposition 5.10. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

Let ğ’¢k=Ïƒâ€‹((Xhkâ€²,Ahkâ€²,rhkâ€²)hâˆˆ[H],kâ€²â‰¤k)\mathcal{G}\_{k}=\sigma((X\_{h}^{k^{\prime}},A\_{h}^{k^{\prime}},r\_{h}^{k^{\prime}})\_{h\in[H]},k^{\prime}\leq k) be the information generated up to episode kk with ğ’¢0\mathcal{G}\_{0} being the null information. Then we have ğ”¼â€‹[Ik|ğ’¢kâˆ’1]â‰¥1âˆ’MpÏp\mathbb{E}[I\_{k}|\mathcal{G}\_{k-1}]\geq 1-\frac{M\_{p}}{\rho^{p}} given ([5.33](https://arxiv.org/html/2512.14991v1#S5.E33 "In 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Let Y0=0Y\_{0}=0 and Yk=âˆ‘i=1k(Ikâˆ’ğ”¼â€‹[Ik|ğ’¢kâˆ’1])Y\_{k}=\sum\_{i=1}^{k}(I\_{k}-\mathbb{E}[I\_{k}|\mathcal{G}\_{k-1}]) for k>1k>1.
Then it is clear that {Yk}k=0,1,â€¦,K\{Y\_{k}\}\_{k=0,1,...,K} is a martingale and we have |Ykâˆ’Ykâˆ’1|â‰¤1|Y\_{k}-Y\_{k-1}|\leq 1. By Azuma-Hoeffding inequality, for any Ïµ>0\epsilon>0 we have

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(YKâˆ’Y0â‰¤âˆ’Ïµ)â‰¤expâ¡(âˆ’Ïµ22â€‹K).\displaystyle\mathbb{P}(Y\_{K}-Y\_{0}\leq-\epsilon)\leq\exp\left(-\frac{\epsilon^{2}}{2K}\right). |  |

By the fact that YK=K0âˆ’Kâ€‹ğ”¼â€‹[Ik|ğ’¢kâˆ’1]â‰¤K0âˆ’Kâ€‹(1âˆ’MpÏp)Y\_{K}=K\_{0}-K\mathbb{E}[I\_{k}|\mathcal{G}\_{k-1}]\leq K\_{0}-K\left(1-\frac{M\_{p}}{\rho^{p}}\right), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(K0âˆ’Kâ€‹(1âˆ’MpÏp)â‰¥âˆ’Ïµ)â‰¥â„™â€‹(YKâˆ’Y0â‰¥âˆ’Ïµ)â‰¥1âˆ’expâ¡(âˆ’Ïµ22â€‹K).\mathbb{P}\left(K\_{0}-K\left(1-\frac{M\_{p}}{\rho^{p}}\right)\geq-\epsilon\right)\geq\mathbb{P}(Y\_{K}-Y\_{0}\geq-\epsilon)\geq 1-\exp\left(-\frac{\epsilon^{2}}{2K}\right). |  | (C.25) |

Let Î´=expâ¡(âˆ’Ïµ22â€‹K)\delta=\exp(-\frac{\epsilon^{2}}{2K}), then we have ([5.10](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem10 "Proposition 5.10. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) hold with probability at least 1âˆ’Î´1-\delta.
âˆ

### C.8 Proof of Theorem [5.11](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem11 "Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

Denote sets J1J\_{1} and J2J\_{2} as the following:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | J1\displaystyle J\_{1} | :=\displaystyle:= | {kâˆˆ[K]:â€–X1kâ€–>Ï},\displaystyle\left\{k\in[K]:\|X\_{1}^{k}\|>\rho\right\}, |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | J2\displaystyle J\_{2} | :=\displaystyle:= | {kâˆˆ[K]:â€–X1kâ€–â‰¤Ï,suph=2,â€¦,Hâ€–Xhkâ€–>Ï}.\displaystyle\left\{k\in[K]:\|X\_{1}^{k}\|\leq\rho,\sup\_{h=2,...,H}\|X\_{h}^{k}\|>\rho\right\}. |  |

Then it is clear that J1âˆªJ2=[K]\JÏKJ\_{1}\cup J\_{2}=[K]\backslash J\_{\rho}^{K} and J1âˆ©J2=âˆ…J\_{1}\cap J\_{2}=\emptyset. Further denote Ki=|Ji|K\_{i}=|J\_{i}| for i=1,2i=1,2, then Kâˆ’K0=K1+K2K-K\_{0}=K\_{1}+K\_{2}. With these notation, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | âˆ‘kâˆˆJ\JÏK|V1Ï€â€‹(X1k)|\displaystyle\sum\_{k\in J\backslash J\_{\rho}^{K}}|V\_{1}^{\pi}(X\_{1}^{k})| | =\displaystyle= | âˆ‘kâˆˆJ1|V1Ï€â€‹(X1k)|+âˆ‘kâˆˆJ2|V1Ï€â€‹(X1k)|\displaystyle\sum\_{k\in J\_{1}}|V\_{1}^{\pi}(X\_{1}^{k})|+\sum\_{k\in J\_{2}}|V\_{1}^{\pi}(X\_{1}^{k})| |  | (C.26) |
|  |  | =\displaystyle= | âˆ‘k=1K|V1Ï€â€‹(X1k)|â€‹ğ•€{â€–X1kâ€–>Ï}+âˆ‘kâˆˆJ2|V1Ï€â€‹(X1k)|\displaystyle\sum\_{k=1}^{K}|V\_{1}^{\pi}(X\_{1}^{k})|\mathbb{I}\_{\{\|X\_{1}^{k}\|>\rho\}}+\sum\_{k\in J\_{2}}|V\_{1}^{\pi}(X\_{1}^{k})| |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘k=1KC~1â€‹(â€–X1kâ€–m+1+1)â€‹ğ•€{â€–X1kâ€–>Ï}+C~1â€‹(Kâˆ’K0)â€‹(Ïm+1+1),\displaystyle\sum\_{k=1}^{K}\widetilde{C}\_{1}\Big(\|X\_{1}^{k}\|^{m+1}+1\Big)\mathbb{I}\_{\{\|X\_{1}^{k}\|>\rho\}}+\widetilde{C}\_{1}(K-K\_{0})\Big(\rho^{m+1}+1\Big), |  |

where the inequality holds due to Proposition [2.5](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem5 "Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

Let Y:=âˆ‘k=1KC~1â€‹(â€–X1kâ€–m+1+1)â€‹ğ•€{â€–X1kâ€–>Ï}Y:=\sum\_{k=1}^{K}\widetilde{C}\_{1}\Big(\|X\_{1}^{k}\|^{m+1}+1\Big)\mathbb{I}\_{\{\|X\_{1}^{k}\|>\rho\}}, then

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ”¼â€‹[Y]\displaystyle\mathbb{E}[Y] | â‰¤\displaystyle\leq | Kâ€‹C~1â€‹(â„™â€‹(â€–Î¾â€–>Ï)+ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–m+1â€‹ğ•€{â€–Î¾â€–>Ï}])\displaystyle K\widetilde{C}\_{1}\Big(\mathbb{P}(\|\xi\|>\rho)+\mathbb{E}\_{\xi\sim\Xi}\big[\|\xi\|^{m+1}\mathbb{I}\_{\{\|\xi\|>\rho\}}\big]\Big) |  | (C.27) |
|  |  | â‰¤\displaystyle\leq | Kâ€‹C~1â€‹(ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]Ïp+(ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p])m+1pâ€‹(â„™â€‹(â€–Î¾â€–>Ï))1âˆ’m+1p)\displaystyle K\widetilde{C}\_{1}\Big(\frac{\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]}{\rho^{p}}+\big(\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]\big)^{\frac{m+1}{p}}(\mathbb{P}(\|\xi\|>\rho))^{1-\frac{m+1}{p}}\Big) |  |
|  |  | â‰¤\displaystyle\leq | Kâ€‹C~1â€‹(ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]Ïp+ğ”¼Î¾âˆ¼Îâ€‹[â€–Î¾â€–p]Ïpâˆ’(m+1))=Î´â€‹Kâ€‹Îºm+1â€‹(Î´,Ï),\displaystyle K\widetilde{C}\_{1}\Big(\frac{\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]}{\rho^{p}}+\frac{\mathbb{E}\_{\xi\sim\Xi}[\|\xi\|^{p}]}{\rho^{p-(m+1)}}\Big)=\delta K\kappa\_{m+1}(\delta,\rho), |  |

where the second inequality holds by applying HÃ¶lderâ€™s inequality. By this inequality,
we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(Yâ‰¥Kâ€‹Îºm+1â€‹(Î´,Ï))â‰¤â„™â€‹(Yâ‰¥ğ”¼â€‹[Y]Î´)â‰¤Î´,\displaystyle\mathbb{P}\Big(Y\geq K\kappa\_{m+1}(\delta,\rho)\Big)\leq\mathbb{P}\left(Y\geq\frac{\mathbb{E}[Y]}{\delta}\right)\leq\delta, |  | (C.28) |

where the last inequality holds by Markov inequality.
Putting ([C.26](https://arxiv.org/html/2512.14991v1#A3.E26 "In C.8 Proof of Theorem 5.11 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.28](https://arxiv.org/html/2512.14991v1#A3.E28 "In C.8 Proof of Theorem 5.11 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) together,
we have ([5.34](https://arxiv.org/html/2512.14991v1#S5.E34 "In Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) holds with probability at least 1âˆ’Î´1-\delta.
âˆ

### C.9 Lemma [C.2](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem2 "Lemma C.2 (Theorem F.1 in [Sinclair et al., 2023]). â€£ C.9 Lemma C.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

We adapt Theorem F.1 from [Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)], stated below with minor modifications to suit our setting.

###### Lemma C.2 (Theorem F.1 in [Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)]).

It holds that

|  |  |  |
| --- | --- | --- |
|  | (1+1H)â€‹fh+1kâˆ’1â€‹(Xhk,Ahk)+Qhâˆ—â€‹(Xhk,Ahk)âˆ’VhÏ€~kâ€‹(Xhk)â‰¤(1+1H)â€‹(Î”h+1(k)+Î¾h+1k),\Big(1+\frac{1}{H}\Big)f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k})+Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k})\leq\Big(1+\frac{1}{H}\Big)(\Delta\_{h+1}^{(k)}+\xi\_{h+1}^{k}), |  |

in which for h<Hh<H

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î¾h+1k\displaystyle\xi\_{h+1}^{k} | :=\displaystyle:= | ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[VÂ¯h+1kâˆ’1â€‹(Y)]âˆ’ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1Ï€~kâ€‹(Y)]âˆ’(VÂ¯h+1kâˆ’1â€‹(Xh+1k)âˆ’Vh+1Ï€~kâ€‹(Xh+1k))\displaystyle\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\overline{V}\_{h+1}^{k-1}(Y)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\tilde{\pi}^{k}}(Y)]-(\overline{V}\_{h+1}^{k-1}(X\_{h+1}^{k})-V\_{h+1}^{\tilde{\pi}^{k}}(X\_{h+1}^{k})) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Î¶h+1k\displaystyle\zeta\_{h+1}^{k} | :=\displaystyle:= | RÂ¯hâ€‹(Xhk,Ahk)âˆ’ğ”¼aâˆ¼Ï€hkâ€‹(Xhk)â€‹[RÂ¯hâ€‹(Xhk,a)]\displaystyle\bar{R}\_{h}(X\_{h}^{k},A\_{h}^{k})-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k})}[\bar{R}\_{h}(X\_{h}^{k},a)] |  |
|  |  |  | +ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1Ï€~kâ€‹(Y)]âˆ’ğ”¼aâˆ¼Ï€hk(Xhk),Yâ€²âˆ¼Th(â‹…|Xhk,a)â€‹[Vh+1Ï€~kâ€‹(Yâ€²)],\displaystyle+\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\tilde{\pi}^{k}}(Y)]-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k}),Y^{{}^{\prime}}\sim{T}\_{h}(\cdot|X\_{h}^{k},a)}[V\_{h+1}^{\tilde{\pi}^{k}}(Y^{{}^{\prime}})], |  |

Î¾H+1k:=0\xi\_{H+1}^{k}:=0 and Î¶H+1k:=RÂ¯Hâ€‹(XHk,AHk)âˆ’ğ”¼aâˆ¼Ï€Hkâ€‹(XHk)â€‹[RÂ¯Hâ€‹(XHk,a)]\zeta\_{H+1}^{k}:=\bar{R}\_{H}(X\_{H}^{k},A\_{H}^{k})-\mathbb{E}\_{a\sim\pi\_{H}^{k}(X\_{H}^{k})}[\bar{R}\_{H}(X\_{H}^{k},a)]. In addition, Î”h+1(k)\Delta\_{h+1}^{(k)} is defined in ([5.21](https://arxiv.org/html/2512.14991v1#S5.E21 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) for h<Hh<H, Î”H+1(k):=0\Delta\_{H+1}^{(k)}:=0, and fh+1kâˆ’1â€‹(Xhk,Ahk)f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k}) is defined in ([5.25](https://arxiv.org/html/2512.14991v1#S5.E25 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Proof.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | (1+1H)â€‹fh+1kâˆ’1â€‹(Xhk,Ahk)+Qhâˆ—â€‹(Xhk,Ahk)âˆ’VhÏ€~kâ€‹(Xhk)\displaystyle\Big(1+\frac{1}{H}\Big)f\_{h+1}^{k-1}(X\_{h}^{k},A\_{h}^{k})+Q\_{h}^{\*}(X\_{h}^{k},A\_{h}^{k})-V\_{h}^{\tilde{\pi}^{k}}(X\_{h}^{k}) |  |
|  |  | =\displaystyle= | (1+1H)â€‹(ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[VÂ¯h+1kâˆ’1â€‹(Y)]âˆ’ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1âˆ—â€‹(Y)])+RÂ¯hâ€‹(Xhk,Ahk)\displaystyle\Big(1+\frac{1}{H}\Big)\Big(\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\overline{V}\_{h+1}^{k-1}(Y)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\*}(Y)]\Big)+\bar{R}\_{h}(X\_{h}^{k},A\_{h}^{k}) |  |
|  |  |  | +ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1âˆ—â€‹(Y)]âˆ’ğ”¼aâˆ¼Ï€hkâ€‹(Xhk)â€‹[RÂ¯hâ€‹(Xhk,a)]âˆ’ğ”¼aâˆ¼Ï€hk(Xhk),Yâ€²âˆ¼Th(â‹…|Xhk,a)â€‹[Vh+1Ï€~kâ€‹(Yâ€²)]\displaystyle+\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\*}(Y)]-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k})}[\bar{R}\_{h}(X\_{h}^{k},a)]-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k}),Y^{{}^{\prime}}\sim{T}\_{h}(\cdot|X\_{h}^{k},a)}[V\_{h+1}^{\tilde{\pi}^{k}}(Y^{{}^{\prime}})] |  |
|  |  | â‰¤\displaystyle\leq | (1+1H)â€‹(ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[VÂ¯h+1kâˆ’1â€‹(Y)]âˆ’ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1âˆ—â€‹(Y)])\displaystyle\Big(1+\frac{1}{H}\Big)\Big(\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\overline{V}\_{h+1}^{k-1}(Y)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\*}(Y)]\Big) |  |
|  |  |  | +(1+1H)â€‹(ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1âˆ—â€‹(Y)]âˆ’ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1Ï€~kâ€‹(Y)])\displaystyle+\Big(1+\frac{1}{H}\Big)\Big(\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\*}(Y)]-\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\tilde{\pi}^{k}}(Y)]\Big) |  |
|  |  |  | +RÂ¯hâ€‹(Xhk,Ahk)âˆ’ğ”¼aâˆ¼Ï€hkâ€‹(Xhk)â€‹[RÂ¯hâ€‹(Xhk,a)]\displaystyle+\bar{R}\_{h}(X\_{h}^{k},A\_{h}^{k})-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k})}[\bar{R}\_{h}(X\_{h}^{k},a)] |  |
|  |  |  | +ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)â€‹[Vh+1Ï€~kâ€‹(Y)]âˆ’ğ”¼aâˆ¼Ï€hk(Xhk),Yâ€²âˆ¼Th(â‹…|Xhk,a)â€‹[Vh+1Ï€~kâ€‹(Yâ€²)]\displaystyle+\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[V\_{h+1}^{\tilde{\pi}^{k}}(Y)]-\mathbb{E}\_{a\sim\pi\_{h}^{k}(X\_{h}^{k}),Y^{{}^{\prime}}\sim{T}\_{h}(\cdot|X\_{h}^{k},a)}[V\_{h+1}^{\tilde{\pi}^{k}}(Y^{{}^{\prime}})] |  |
|  |  | =\displaystyle= | (1+1H)â€‹(Î”h+1(k)+Î¾h+1k)+Î¶h+1k,\displaystyle\Big(1+\frac{1}{H}\Big)(\Delta\_{h+1}^{(k)}+\xi\_{h+1}^{k})+\zeta\_{h+1}^{k}, |  |

where the first inequality holds due to ([2.1](https://arxiv.org/html/2512.14991v1#S2.Ex5 "Bellman equation for generic policy. â€£ 2.1 Value function, Bellman equations and evaluation criterion â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
âˆ

### C.10 Proof of Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

Before the proof of Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we introduce several technical lemmas.

We first provide a high probability bound for the state process that holds simultaneously across all episodes. For convenience, we denote

|  |  |  |  |
| --- | --- | --- | --- |
|  | Z:=suphâˆˆ[H],kâˆˆ[K]â€–Xhkâ€–.\displaystyle Z:=\sup\_{h\in[H],k\in[K]}\|X\_{h}^{k}\|. |  | (C.29) |

###### Lemma C.3.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. We have:

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(Zâ‰¤(Kâ€‹MpÎ´)1p)â‰¥1âˆ’Î´.\displaystyle\mathbb{P}\Big(Z\leq\Big(\frac{KM\_{p}}{\delta}\Big)^{\frac{1}{p}}\Big)\geq 1-\delta. |  |

###### Proof.

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â„™â€‹(Zâ‰¤(Kâ€‹MpK)1p)\displaystyle\mathbb{P}\Big(Z\leq\Big(\frac{KM\_{p}}{K}\Big)^{\frac{1}{p}}\Big) | â‰¥\displaystyle\geq | 1âˆ’âˆ‘k=1Kâ„™â€‹(suphâˆˆ[H]â€–Xhkâ€–â‰¥(Kâ€‹MpÎ´)1p)\displaystyle 1-\sum\_{k=1}^{K}\mathbb{P}\Big(\sup\_{h\in[H]}\|X\_{h}^{k}\|\geq\Big(\frac{KM\_{p}}{\delta}\Big)^{\frac{1}{p}}\Big) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’Kâ€‹MpKâ€‹MpÎ´\displaystyle 1-K\frac{M\_{p}}{\frac{KM\_{p}}{\delta}} |  |
|  |  | =\displaystyle= | 1âˆ’Î´,\displaystyle 1-\delta, |  |

where the first inequality holds by the union bound (namely, for a countable set of events E1,E2,â€¦E\_{1},E\_{2},..., we have â„™â€‹(âˆ©iEi)â‰¥1âˆ’âˆ‘iâ„™â€‹(Eiâˆ)\mathbb{P}(\cap\_{i}E\_{i})\geq 1-\sum\_{i}\mathbb{P}(E\_{i}^{\complement})) and the second inequality holds due to Corollary [2.3](https://arxiv.org/html/2512.14991v1#S2.Thmtheorem3 "Corollary 2.3. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
âˆ

Unlike the bounded state space setting in [Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)], the martingale difference term Î¾h+1k\xi\_{h+1}^{k} in our setting is unbounded. Therefore, we need a more general version of the martingale concentration inequality instead of the usual Azuma-Hoeffding inequality.

###### Lemma C.4.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. We have:

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(âˆ‘h=1Hâˆ‘k=1KÎ¾h+1kâ‰¤2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´))â‰¥1âˆ’5â€‹Î´,\displaystyle\mathbb{P}\Bigg(\sum\_{h=1}^{H}\sum\_{k=1}^{K}\xi\_{h+1}^{k}\leq 2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)}\Bigg)\geq 1-5\delta, |  |

where L~1\widetilde{L}\_{1} is defined in ([5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Proof.

With probability at least 1âˆ’3â€‹Î´1-3\delta, it holds that, for xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}}, hâˆˆ[Hâˆ’1]h\in[H-1] and k>1k>1, we have:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | |VÂ¯h+1kâˆ’1â€‹(x)|\displaystyle|\overline{V}\_{h+1}^{k-1}(x)| | â‰¤\displaystyle\leq | maxâ¡{|Vh+1,kâˆ’1localâ€‹(x,Sâ€²)|,|Vh+1âˆ—â€‹(x)|}\displaystyle\max\{|V\_{h+1,k-1}^{\rm local}(x,S^{\prime})|,|V\_{h+1}^{\*}(x)|\} |  |
|  |  | â‰¤\displaystyle\leq | V~h+10â€‹(Sâ€²)+Châ€‹(1+â€–xâ€–m+â€–x~â€‹(Sâ€²)â€–m)â€‹(â€–xâ€–+â€–x~â€‹(Sâ€²)â€–)\displaystyle\widetilde{V}\_{h+1}^{0}(S^{\prime})+C\_{h}\Big(1+\|x\|^{m}+\|\tilde{x}(S^{\prime})\|^{m}\Big)(\|x\|+\|\tilde{x}(S^{\prime})\|) |  |
|  |  | â‰¤\displaystyle\leq | cË˜1â€‹â€–xâ€–m+1+cË˜2,\displaystyle\breve{c}\_{1}\|x\|^{m+1}+\breve{c}\_{2}, |  |

where Sâ€²=argâ¡minSâˆˆÎ“ğ’®â€‹(ğ’«h+1kâˆ’1)â¡Vh+1,kâˆ’1localâ€‹(x,S)S^{\prime}=\operatorname\*{\arg\min}\_{S\in\Gamma\_{\mathcal{S}}(\mathcal{P}\_{h+1}^{k-1})}V\_{h+1,k-1}^{\rm local}(x,S), and cË˜1,cË˜2\breve{c}\_{1},\breve{c}\_{2} depend only on m,D,Cmax,C~maxm,D,C\_{\max},\widetilde{C}\_{\max}. The first inequality holds due to Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and the third line of ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). In addition, the second inequality holds due to ([5.1](https://arxiv.org/html/2512.14991v1#S5.Ex2 "Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the fact that V~h+1kâˆ’1â€‹(Sâ€²)â‰¤V~h+10â€‹(Sâ€²)\widetilde{V}\_{h+1}^{k-1}(S^{\prime})\leq\widetilde{V}\_{h+1}^{0}(S^{\prime}) according to the second line of ([5.12](https://arxiv.org/html/2512.14991v1#S5.E12 "In Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and the fact that â€–xâˆ’x~â€‹(Sâ€²)â€–â‰¤â€–xâ€–+â€–x~â€‹(Sâ€²)â€–\|x-\tilde{x}(S^{\prime})\|\leq\|x\|+\|\tilde{x}(S^{\prime})\|. Finally, the third inequality holds due to the fact that â€–x~â€‹(Sâ€²)â€–â‰¤â€–xâ€–+D\|\tilde{x}(S^{\prime})\|\leq\|x\|+D.

In addition, note that ([C.10](https://arxiv.org/html/2512.14991v1#A3.Ex82 "C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) also holds for k=1k=1, xâˆˆâ„dğ’®x\in\mathbb{R}^{d\_{\mathcal{S}}}, and hâˆˆ[Hâˆ’1]h\in[H-1].

Let â„±h,k=Ïƒ((Xhkâ€²,Ahkâ€²,rhkâ€²),hâ€²â‰¤h,kâ€²â‰¤k)\mathcal{F}\_{h,k}=\sigma((X\_{h}^{k^{\prime}},A\_{h}^{k^{\prime}},r\_{h}^{k^{\prime}}),h^{\prime}\leq h,k^{\prime}\leq k). We next show that we can bound (Î¾h+1k)2(\xi\_{h+1}^{k})^{2} and ğ”¼â€‹[(Î¾h+1k)2|â„±h,k]\mathbb{E}[(\xi\_{h+1}^{k})^{2}|\mathcal{F}\_{h,k}] by polynomials of ZZ.

To proceed, we will often use the fact that for n,qâˆˆâ„•+n,q\in\mathbb{N}\_{+}:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (âˆ‘i=1nai)qâ‰¤nqâˆ’1â€‹âˆ‘i=1naiq\displaystyle(\sum\_{i=1}^{n}a\_{i})^{q}\leq n^{q-1}\sum\_{i=1}^{n}a\_{i}^{q} |  | (C.30) |

and

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)â€‹[â€–Xâ€–q]\displaystyle\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\|X\|^{q}] | â‰¤\displaystyle\leq | (ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)â€‹[â€–Xâ€–2â€‹q])12\displaystyle(\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[\|X\|^{2q}])^{\frac{1}{2}} |  | (C.31) |
|  |  | â‰¤\displaystyle\leq | C~â€‹(q,dğ’®)â€‹(â€–Î¼hâ€‹(Xhk,Ahk)â€–q+â€–Î£hâ€‹(Xhk,Ahk)â€–q2)\displaystyle\widetilde{C}(q,d\_{\mathcal{S}})(\|\mu\_{h}(X\_{h}^{k},A\_{h}^{k})\|^{q}+\|\Sigma\_{h}(X\_{h}^{k},A\_{h}^{k})\|^{\frac{q}{2}}) |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹C~â€‹(q,dğ’®)â€‹Î·â€‹(Xhk)q,\displaystyle 2\widetilde{C}(q,d\_{\mathcal{S}})\eta(X\_{h}^{k})^{q}, |  |

where the second inequality holds due to Lemma [B.3](https://arxiv.org/html/2512.14991v1#A2.Thmtheorem3 "Lemma B.3. â€£ B.6 Proof of Theorem 4.4 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and the third inequality holds due to ([4.7](https://arxiv.org/html/2512.14991v1#S4.E7 "In 4.1 Concentration of the estimators for drift and volatility â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then with probability at least 1âˆ’3â€‹Î´1-3\delta, the following inequality holds for hâˆˆ[H]h\in[H] and kâˆˆ[K]k\in[K]:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | (Î¾h+1k)2\displaystyle(\xi\_{h+1}^{k})^{2} | â‰¤\displaystyle\leq | (ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|VÂ¯h+1kâˆ’1(X)|]+ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|Vh+1Ï€~k(X)|]\displaystyle\Big(\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|\overline{V}\_{h+1}^{k-1}(X)|]+\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|V\_{h+1}^{\tilde{\pi}^{k}}(X)|] |  | (C.32) |
|  |  |  | +|VÂ¯h+1kâˆ’1(Xh+1k)|+|Vh+1Ï€~k(Xh+1k)|)2\displaystyle+|\overline{V}\_{h+1}^{k-1}(X\_{h+1}^{k})|+|V\_{h+1}^{\tilde{\pi}^{k}}(X\_{h+1}^{k})|\Big)^{2} |  |
|  |  | â‰¤\displaystyle\leq | 4((ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|VÂ¯h+1kâˆ’1(X)|])2+(ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|Vh+1Ï€~k(X)|])2\displaystyle 4\Big((\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|\overline{V}\_{h+1}^{k-1}(X)|])^{2}+(\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|V\_{h+1}^{\tilde{\pi}^{k}}(X)|])^{2} |  |
|  |  |  | +(VÂ¯h+1kâˆ’1(Xh+1k))2+(Vh+1Ï€~k(Xh+1k))2)\displaystyle+(\overline{V}\_{h+1}^{k-1}(X\_{h+1}^{k}))^{2}+(V\_{h+1}^{\tilde{\pi}^{k}}(X\_{h+1}^{k}))^{2}\Big) |  |
|  |  | â‰¤\displaystyle\leq | cË˜3â€‹Z2â€‹m+2+cË˜4,\displaystyle\breve{c}\_{3}Z^{2m+2}+\breve{c}\_{4}, |  |

where cË˜3,cË˜4\breve{c}\_{3},\breve{c}\_{4} depends only on C~max,Cmax,m,D,dğ’®\widetilde{C}\_{\max},C\_{\max},m,D,d\_{\mathcal{S}}. The last inequality holds due to ([C.10](https://arxiv.org/html/2512.14991v1#A3.Ex82 "C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([2.8](https://arxiv.org/html/2512.14991v1#S2.E8 "In Proposition 2.5. â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.30](https://arxiv.org/html/2512.14991v1#A3.E30 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.31](https://arxiv.org/html/2512.14991v1#A3.E31 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the fact that â€–Xhkâ€–â‰¤Z\|X\_{h}^{k}\|\leq Z for (h,k)âˆˆ[H]Ã—[K](h,k)\in[H]\times[K].

Similarly, with probability at least 1âˆ’3â€‹Î´1-3\delta, the following inequality holds for hâˆˆ[H]h\in[H] and kâˆˆ[K]k\in[K]:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ”¼â€‹[(Î¾h+1k)2|â„±h,k]\displaystyle\mathbb{E}[(\xi\_{h+1}^{k})^{2}|\mathcal{F}\_{h,k}] |  | (C.33) |
|  |  | â‰¤\displaystyle\leq | ğ”¼Yâˆ¼Th(â‹…|Xhk,Ahk)[(ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|VÂ¯h+1kâˆ’1(X)|]+ğ”¼Xâˆ¼Th(â‹…|Xhk,Ahk)[|Vh+1Ï€~k(X)|]\displaystyle\mathbb{E}\_{Y\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}\Bigg[\Big(\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|\overline{V}\_{h+1}^{k-1}(X)|]+\mathbb{E}\_{X\sim{T}\_{h}(\cdot|X\_{h}^{k},A\_{h}^{k})}[|V\_{h+1}^{\tilde{\pi}^{k}}(X)|] |  |
|  |  |  | +|VÂ¯h+1kâˆ’1(Y)|+|Vh+1Ï€~k(Y)|)2]\displaystyle\qquad\qquad\qquad\qquad+|\overline{V}\_{h+1}^{k-1}(Y)|+|V\_{h+1}^{\tilde{\pi}^{k}}(Y)|\Big)^{2}\Bigg] |  |
|  |  | â‰¤\displaystyle\leq | cË˜5â€‹Z2â€‹m+2+cË˜6,\displaystyle\breve{c}\_{5}Z^{2m+2}+\breve{c}\_{6}, |  |

where cË˜5,cË˜6\breve{c}\_{5},\breve{c}\_{6} depends only on C~max,Cmax,m,D,dğ’®\widetilde{C}\_{\max},C\_{\max},m,D,d\_{\mathcal{S}}.

Define Mh+1,k:=âˆ‘hâ€²â‰¤h,kâ€²â‰¤kÎ¾h+1kM\_{h+1,k}:=\sum\_{h^{\prime}\leq h,k^{\prime}\leq k}\xi\_{h+1}^{k}. It is clear that Mh+1,kM\_{h+1,k} is a square integrable martingale. Then by Theorem 2.1 in [Bercu and Touati, [2008](https://arxiv.org/html/2512.14991v1#bib.bib5)], for any a,b>0a,b>0 we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(|MH+1,K|â‰¥a,âŸ¨MâŸ©H+1,K+[M]H+1,Kâ‰¤b)â‰¤2â€‹expâ¡(âˆ’a22â€‹b),\displaystyle\mathbb{P}\Big(|M\_{H+1,K}|\geq a,\langle M\rangle\_{H+1,K}+[M]\_{H+1,K}\leq b\Big)\leq 2\exp{(-\frac{a^{2}}{2b})}, |  | (C.34) |

where [M]H+1,K=âˆ‘hâˆˆ[H],kâˆˆ[K](Î¾h+1k)2,âŸ¨MâŸ©H+1,K=âˆ‘hâˆˆ[H],kâˆˆ[K]ğ”¼â€‹[(Î¾h+1k)2|â„±h,k][M]\_{H+1,K}=\sum\_{h\in[H],k\in[K]}(\xi\_{h+1}^{k})^{2},\langle M\rangle\_{H+1,K}=\sum\_{h\in[H],k\in[K]}\mathbb{E}[(\xi\_{h+1}^{k})^{2}|\mathcal{F}\_{h,k}].

Therefore, we have for any a,b,c>0a,b,c>0:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â„™â€‹(|MH+1,K|â‰¥a)\displaystyle\mathbb{P}(|M\_{H+1,K}|\geq a) |  | (C.35) |
|  |  | â‰¤\displaystyle\leq | â„™â€‹(|MH+1,K|â‰¥a,âŸ¨MâŸ©H+1,K+[M]H+1,Kâ‰¤b)+â„™â€‹(âŸ¨MâŸ©H+1,K+[M]H+1,Kâ‰¥b)\displaystyle\mathbb{P}(|M\_{H+1,K}|\geq a,\langle M\rangle\_{H+1,K}+[M]\_{H+1,K}\leq b)+\mathbb{P}(\langle M\rangle\_{H+1,K}+[M]\_{H+1,K}\geq b) |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹expâ¡(âˆ’a22â€‹b)+â„™â€‹(âŸ¨MâŸ©H+1,K+[M]H+1,Kâ‰¥b,Zâ‰¤c)+â„™â€‹(Zâ‰¥c).\displaystyle 2\exp{(-\frac{a^{2}}{2b})}+\mathbb{P}(\langle M\rangle\_{H+1,K}+[M]\_{H+1,K}\geq b,Z\leq c)+\mathbb{P}(Z\geq c). |  |

Let a=2â€‹bâ€‹logâ¡(2Î´)a=\sqrt{2b\log(\frac{2}{\delta})}, b=2â€‹Hâ€‹Kâ€‹(cË˜3+cË˜4+cË˜5+cË˜6)â€‹(c2â€‹m+2+1)b=2HK(\breve{c}\_{3}+\breve{c}\_{4}+\breve{c}\_{5}+\breve{c}\_{6})(c^{2m+2}+1), and c=(Mpâ€‹KÎ´)1pc=\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{1}{p}}, we get that:

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(âŸ¨MâŸ©H+1,K+[M]H+1,Kâ‰¥b,Zâ‰¤c)â‰¤3â€‹Î´,Â andÂ â€‹â„™â€‹(Zâ‰¥c)â‰¤Î´,\displaystyle\mathbb{P}\Big(\langle M\rangle\_{H+1,K}+[M]\_{H+1,K}\geq b,Z\leq c\Big)\leq 3\delta,\textit{ and }\mathbb{P}\Big(Z\geq c\Big)\leq\delta, |  |

where the first inequality holds since with probability at least 1âˆ’3â€‹Î´1-3\delta, for any hâˆˆ[H]h\in[H] and kâˆˆ[K]k\in[K], it holds that ([C.32](https://arxiv.org/html/2512.14991v1#A3.E32 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.33](https://arxiv.org/html/2512.14991v1#A3.E33 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Hence, we conclude that

|  |  |  |  |
| --- | --- | --- | --- |
|  | â„™â€‹(|MH+1,K|â‰¤2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´))â‰¥1âˆ’5â€‹Î´,\displaystyle\mathbb{P}\Bigg(|M\_{H+1,K}|\leq 2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)}\,\,\Bigg)\geq 1-5\delta, |  | (C.36) |

where L~1=cË˜3+cË˜4+cË˜5+cË˜6\widetilde{L}\_{1}=\breve{c}\_{3}+\breve{c}\_{4}+\breve{c}\_{5}+\breve{c}\_{6}.
âˆ

###### Lemma C.5.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. We have:

|  |  |  |
| --- | --- | --- |
|  | â„™(|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKKÎ¾h+1k|â‰¤e2L~2H(Kâ€‹MpÏp+2Klog(1Î´))((Mpâ€‹KÎ´)m+1p+1))â‰¥1âˆ’2Î´,\displaystyle\mathbb{P}\Big(\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}^{K}\xi\_{h+1}^{k}\Big|\leq e^{2}\widetilde{L}\_{2}H\Big(\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log(\frac{1}{\delta}})\Big)\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}+1\Big)\Big)\geq 1-2\delta, |  |

where L~2\widetilde{L}\_{2} is defined in ([5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Proof.

By similar methods to show ([C.32](https://arxiv.org/html/2512.14991v1#A3.E32 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) in the proof of Lemma [C.4](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem4 "Lemma C.4. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we can show that

|  |  |  |
| --- | --- | --- |
|  | |Î¾h+1k|â‰¤cË˜1â€‹Zm+1+cË˜2,\displaystyle|\xi\_{h+1}^{k}|\leq\breve{c}\_{1}Z^{m+1}+\breve{c}\_{2}, |  |

where cË˜1,cË˜2\breve{c}\_{1},\breve{c}\_{2} depends only on C~max,Cmax,m,D,dğ’®\widetilde{C}\_{\max},C\_{\max},m,D,d\_{\mathcal{S}}.

Therefore, let L~2=cË˜1+cË˜2\widetilde{L}\_{2}=\breve{c}\_{1}+\breve{c}\_{2}, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | â„™(|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKKÎ¾h+1k|â‰¤e2L~2H(Kâ€‹MpÏp+2Klog(1Î´))((Mpâ€‹KÎ´)m+1p+1))\displaystyle\mathbb{P}\Big(\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}^{K}\xi\_{h+1}^{k}\Big|\leq e^{2}\widetilde{L}\_{2}H\Big(\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log(\frac{1}{\delta}})\Big)\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}+1\Big)\Big) |  | (C.37) |
|  |  | â‰¥\displaystyle\geq | â„™(âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKK|Î¾h+1k|â‰¤e2L~2H(Kâ€‹MpÏp+2Klog(1Î´))((Mpâ€‹KÎ´)m+1p+1))\displaystyle\mathbb{P}\Big(\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}^{K}\Big|\xi\_{h+1}^{k}\Big|\leq e^{2}\widetilde{L}\_{2}H\Big(\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log(\frac{1}{\delta}})\Big)\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}+1\Big)\Big) |  |
|  |  | â‰¥\displaystyle\geq | â„™(H(Kâˆ’K0)(cË˜1Zm+1+cË˜2)â‰¤e2L~2H(Kâ€‹MpÏp+2Klog(1Î´))((Mpâ€‹KÎ´)m+1p+1))\displaystyle\mathbb{P}\Big(H(K-K\_{0})(\breve{c}\_{1}Z^{m+1}+\breve{c}\_{2})\leq e^{2}\widetilde{L}\_{2}H\Big(\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log(\frac{1}{\delta}})\Big)\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}+1\Big)\Big) |  |
|  |  | â‰¥\displaystyle\geq | 1âˆ’2â€‹Î´,\displaystyle 1-2\delta, |  |

where the last inequality holds due to Proposition [5.10](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem10 "Proposition 5.10. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Lemma [C.3](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem3 "Lemma C.3. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
âˆ

Similarly, we can prove the following lemmas for {Î¶h+1k}(h,k)âˆˆ[H]Ã—[K]\{\zeta\_{h+1}^{k}\}\_{(h,k)\in[H]\times[K]} in the same fashion as the proof of Lemma [C.4](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem4 "Lemma C.4. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [C.5](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem5 "Lemma C.5. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Lemma C.6.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. We have:

|  |  |  |
| --- | --- | --- |
|  | â„™â€‹(âˆ‘h=1Hâˆ‘k=1KÎ¶h+1kâ‰¤2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´))â‰¥1âˆ’2â€‹Î´,\displaystyle\mathbb{P}\Bigg(\sum\_{h=1}^{H}\sum\_{k=1}^{K}\zeta\_{h+1}^{k}\leq 2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)}\Bigg)\geq 1-2\delta, |  |

where L~1\widetilde{L}\_{1} is defined in ([5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

###### Lemma C.7.

Assume Assumptions [2.1](https://arxiv.org/html/2512.14991v1#S2.Thmassumption1 "Assumption 2.1 (Regularity of the dynamics). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")-[2.3](https://arxiv.org/html/2512.14991v1#S2.Thmassumption3 "Assumption 2.3 (Regularity of the initial distribution). â€£ 2.2 Outstanding assumptions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") hold. We have:

|  |  |  |
| --- | --- | --- |
|  | â„™(|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKKÎ¶h+1k|â‰¤e2L~2H(Kâ€‹MpÏp+2Klog(1Î´))((Mpâ€‹KÎ´)m+1p+1))â‰¥1âˆ’2Î´,\displaystyle\mathbb{P}\Big(\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}^{K}\zeta\_{h+1}^{k}\Big|\leq e^{2}\widetilde{L}\_{2}H\Big(\frac{KM\_{p}}{\rho^{p}}+\sqrt{2K\log(\frac{1}{\delta}})\Big)\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}+1\Big)\Big)\geq 1-2\delta, |  |

where L~2\widetilde{L}\_{2} is defined in ([5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then with the five lemmas above, we are ready to provide the proof for Theorem [5.12](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem12 "Theorem 5.12. â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

###### Proof.

Combine Theorem [5.9](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem9 "Theorem 5.9. â€£ 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), Lemma [C.2](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem2 "Lemma C.2 (Theorem F.1 in [Sinclair et al., 2023]). â€£ C.9 Lemma C.2 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), and the fact that (1+1H)Hâ‰¤e\Big(1+\frac{1}{H}\Big)^{H}\leq e, with probability at least 1âˆ’3â€‹Î´1-3\delta, we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | âˆ‘kâˆˆJÏKÎ”1(k)\displaystyle\sum\_{k\in J\_{\rho}^{K}}\Delta\_{1}^{(k)} | â‰¤\displaystyle\leq | âˆ‘kâˆˆJÏKCLIPâ€‹(G1kâ€‹(B1k)|Gap1â€‹(B1k)H+1)+(1+1H)â€‹(âˆ‘kâˆˆJÏKÎ”2(k)+âˆ‘kâˆˆJÏKÎ¾2k)+âˆ‘kâˆˆJÏKÎ¶2k\displaystyle\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Bigg(G\_{1}^{k}(B\_{1}^{k})\Bigg|\frac{{\rm Gap}\_{1}(B\_{1}^{k})}{H+1}\Bigg)+\Big(1+\frac{1}{H}\Big)\Big(\sum\_{k\in J\_{\rho}^{K}}\Delta\_{2}^{(k)}+\sum\_{k\in J\_{\rho}^{K}}\xi\_{2}^{k}\Big)+\sum\_{k\in J\_{\rho}^{K}}\zeta\_{2}^{k} |  | (C.39) |
|  |  | â‰¤\displaystyle\leq | âˆ‘h=1Hâˆ‘kâˆˆJÏK(1+1H)2â€‹(hâˆ’1)â€‹CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}\Big(1+\frac{1}{H}\Big)^{2(h-1)}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg) |  |
|  |  |  | +âˆ‘h=1Hâˆ‘kâˆˆJÏK(1+1H)2â€‹hâ€‹Î¾h+1k+âˆ‘h=1Hâˆ‘kâˆˆJÏKÎ¶h+1k\displaystyle+\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}\Big(1+\frac{1}{H}\Big)^{2h}\xi\_{h+1}^{k}+\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}\zeta\_{h+1}^{k} |  |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJÏKCLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJÏKÎ¾h+1k+âˆ‘h=1Hâˆ‘kâˆˆJÏKÎ¶h+1k\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}\xi\_{h+1}^{k}+\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}\zeta\_{h+1}^{k} |  |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJÏKCLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹âˆ‘h=1Hâˆ‘kâˆˆ[K]Î¾h+1k+2â€‹e2â€‹|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKÎ¾h+1k|\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sum\_{h=1}^{H}\sum\_{k\in[K]}\xi\_{h+1}^{k}+2e^{2}\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}\xi\_{h+1}^{k}\Big| |  |
|  |  |  | +âˆ‘h=1Hâˆ‘kâˆˆ[K]Î¶h+1k+|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKÎ¶h+1k|.\displaystyle+\sum\_{h=1}^{H}\sum\_{k\in[K]}\zeta\_{h+1}^{k}+\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}\zeta\_{h+1}^{k}\Big|. |  |

By combining Theorems [5.9](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem9 "Theorem 5.9. â€£ 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), [5.10](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem10 "Proposition 5.10. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and [5.11](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem11 "Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"), we get that with probability at least 1âˆ’6â€‹Î´1-6\delta, it holds that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | Regretâ€‹(K)\displaystyle{\rm Regret}(K) | â‰¤\displaystyle\leq | âˆ‘kâˆˆJÏK(VÂ¯1kâˆ’1â€‹(X1k)âˆ’V1Ï€~kâ€‹(X1k))+âˆ‘kâˆˆJ\JÏK(|V1âˆ—â€‹(X1k)|+|V1Ï€~kâ€‹(X1k)|)\displaystyle\sum\_{k\in J\_{\rho}^{K}}(\overline{V}\_{1}^{k-1}(X\_{1}^{k})-V\_{1}^{\tilde{\pi}^{k}}(X\_{1}^{k}))+\sum\_{k\in J\backslash J\_{\rho}^{K}}(|V\_{1}^{\*}(X\_{1}^{k})|+|V\_{1}^{\tilde{\pi}^{k}}(X\_{1}^{k})|) |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘kâˆˆJÏKÎ”1(k)+2â€‹(Kâ€‹Îºm+1â€‹(Î´,Ï)+C~1â€‹(1+Ïm+1)â€‹(Kâˆ’K0))\displaystyle\sum\_{k\in J\_{\rho}^{K}}\Delta\_{1}^{(k)}+2\Big(K\kappa\_{m+1}(\delta,\rho)+\widetilde{C}\_{1}\Big(1+\rho^{m+1}\Big)(K-K\_{0})\Big) |  |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJ1CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹âˆ‘h=1Hâˆ‘kâˆˆ[K]Î¾h+1k+2â€‹e2â€‹|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKÎ¾h+1k|\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{1}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sum\_{h=1}^{H}\sum\_{k\in[K]}\xi\_{h+1}^{k}+2e^{2}\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}\xi\_{h+1}^{k}\Big| |  |
|  |  |  | +âˆ‘h=1Hâˆ‘kâˆˆ[K]Î¶h+1k+|âˆ‘h=1Hâˆ‘kâˆˆ[K]\JÏKÎ¶h+1k|\displaystyle+\sum\_{h=1}^{H}\sum\_{k\in[K]}\zeta\_{h+1}^{k}+\Big|\sum\_{h=1}^{H}\sum\_{k\in[K]\backslash J\_{\rho}^{K}}\zeta\_{h+1}^{k}\Big| |  |
|  |  |  | +2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)+4â€‹C~1â€‹(1+Ïm+1)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´))\displaystyle+2K\kappa\_{m+1}(\delta,\rho)+4\widetilde{C}\_{1}\Big(1+\rho^{m+1}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right) |  |
|  |  | â‰¤\displaystyle\leq | e2â€‹âˆ‘h=1Hâˆ‘kâˆˆJ1CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)+2â€‹e2â€‹L~1â€‹Hâ€‹Kâ€‹((Mpâ€‹KÎ´)2â€‹m+2p+1)â€‹logâ¡(2Î´)\displaystyle e^{2}\sum\_{h=1}^{H}\sum\_{k\in J\_{1}}{\rm CLIP}\Bigg(G\_{h}^{k}(B\_{h}^{k})\Bigg|\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Bigg)+2e^{2}\sqrt{\widetilde{L}\_{1}HK\Big(\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{2m+2}{p}}+1\Big)\log\Big(\frac{2}{\delta}\Big)} |  |
|  |  |  | +2â€‹Kâ€‹Îºm+1â€‹(Î´,Ï)+4â€‹C~1â€‹(L~3+Ïm+1+e2â€‹L~2â€‹Hâ€‹(Mpâ€‹KÎ´)m+1p)â€‹(MpÏpâ€‹K+2â€‹Kâ€‹logâ¡(1Î´)),\displaystyle+2K\kappa\_{m+1}(\delta,\rho)+4\widetilde{C}\_{1}\Big(\widetilde{L}\_{3}+\rho^{m+1}+e^{2}\widetilde{L}\_{2}H\Big(\frac{M\_{p}K}{\delta}\Big)^{\frac{m+1}{p}}\Big)\left(\frac{M\_{p}}{\rho^{p}}K+\sqrt{2K\log\Big(\frac{1}{\delta}\Big)}\right), |  |

where J=[K]J=[K] and JÏKJ\_{\rho}^{K} is defined in ([5.32](https://arxiv.org/html/2512.14991v1#S5.E32 "In 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
The first inequality holds due to Theorem [5.2](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem2 "Theorem 5.2. â€£ Design of value estimators. â€£ 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). The second inequality holds due to Theorem [5.11](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem11 "Theorem 5.11. â€£ 5.3 Concentrations on the size of ğ½_ğœŒ^ğ¾ and initial value function â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes"). The third inequality holds due to ([C.39](https://arxiv.org/html/2512.14991v1#A3.E39 "In C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). Finally, the last inequality holds due to Lemma [C.4](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem4 "Lemma C.4. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") and Lemma [C.5](https://arxiv.org/html/2512.14991v1#A3.Thmtheorem5 "Lemma C.5. â€£ C.10 Proof of Theorem 5.12 â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").
âˆ

### C.11 Technical results modified from [Sinclair etÂ al., [2023](https://arxiv.org/html/2512.14991v1#bib.bib53)]

#### C.11.1 Proof of Lemma [5.17](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem17 "Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")

###### Proof.

We firstly split âˆ‘hâˆ‘kâˆˆJÏKCLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) into two terms.

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | âˆ‘hâˆ‘kâˆˆJÏKCLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) |  | (C.40) |
|  |  | =\displaystyle= | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)>0CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)âŸ(I)\displaystyle\underbrace{\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})>0}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big)}\_{(I)} |  |
|  |  |  | +âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)=0CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)âŸ(Iâ€‹I).\displaystyle+\underbrace{\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})=0}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big)}\_{(II)}. |  |

Then we handle these two terms separately.

Bound for Term (I):

For fixed (h,k)(h,k), if nhkâˆ’1â€‹(Bhk)>0n\_{h}^{k-1}(B\_{h}^{k})>0, then:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | Ghkâ€‹(Bhk)\displaystyle G\_{h}^{k}(B\_{h}^{k}) | =\displaystyle= | 2â€‹C^maxCÂ¯maxâ€‹(R-UCBhkâˆ’1â€‹(Bhk)+T-UCBhkâˆ’1â€‹(Bhk)+BIASâ€‹(Bhk))\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big(\mbox{\rm R-UCB}\_{h}^{k-1}(B\_{h}^{k})+\mbox{\rm T-UCB}\_{h}^{k-1}(B\_{h}^{k})+{\rm BIAS}(B\_{h}^{k})\Big) |  | (C.41) |
|  |  |  | +Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm diam}(B\_{h}^{k}) |  |
|  |  | â‰¤\displaystyle\leq | 2C^maxCÂ¯max(CONFhkâˆ’1(Bhk)+g2(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk))\displaystyle 2\frac{\widehat{C}\_{\max}}{\overline{C}\_{\max}}\Big({\rm CONF}\_{h}^{k-1}(B\_{h}^{k})+g\_{2}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\Big) |  |
|  |  |  | +Ch(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)CONFhkâˆ’1(Bhk)\displaystyle+C\_{h}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}){\rm CONF}\_{h}^{k-1}(B\_{h}^{k}) |  |
|  |  | =\displaystyle= | g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk),\displaystyle g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)\,\,{\rm CONF}\_{h}^{k-1}(B\_{h}^{k}), |  |

where g2g\_{2} is defined in ([5.2](https://arxiv.org/html/2512.14991v1#S5.E2 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and g3g\_{3} is defined in ([5.39](https://arxiv.org/html/2512.14991v1#S5.E39 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). The first equality holds by the definition of Ghkâ€‹(Bhk)G\_{h}^{k}(B\_{h}^{k}) in ([5.31](https://arxiv.org/html/2512.14991v1#S5.E31 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). The inequality holds because

* (a)

  R-UCBhkâˆ’1â€‹(Bhk)+T-UCBhkâˆ’1â€‹(Bhk)â‰¤CONFhkâˆ’1â€‹(Bhk)\mbox{\rm R-UCB}\_{h}^{k-1}(B\_{h}^{k})+\mbox{\rm T-UCB}\_{h}^{k-1}(B\_{h}^{k})\leq{\rm CONF}\_{h}^{k-1}(B\_{h}^{k}) by ([4.20](https://arxiv.org/html/2512.14991v1#S4.E20 "In 4.3 Concentration on reward estimators and properties of adaptive partition â€£ 4 Concentration inequalities of the estimators â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")),
* (b)

  BIAS(Bhk)=g2(Î´,âˆ¥x~(oBhk)âˆ¥)diam(Bhk){\rm BIAS}(B\_{h}^{k})=g\_{2}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)\,\,{\rm diam}(B\_{h}^{k}) by ([5.2](https://arxiv.org/html/2512.14991v1#S5.E2 "In 5.1 Construction of value estimators â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and
* (c)

  diamâ€‹(Bhk)â‰¤CONFhkâˆ’1â€‹(Bhk){\rm diam}(B\_{h}^{k})\leq{\rm CONF}\_{h}^{k-1}(B\_{h}^{k}) by the Splitting Rule in line [1](https://arxiv.org/html/2512.14991v1#alg4.l1 "In Algorithm 4 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes") of Algorithm [4](https://arxiv.org/html/2512.14991v1#alg4 "Algorithm 4 â€£ Initial state partition. â€£ 3 Algorithm design â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes").

The last equality holds by ([5.39](https://arxiv.org/html/2512.14991v1#S5.E39 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

By definition of the CLIP(â‹…|.){\rm CLIP}(\cdot|.) function in ([5.22](https://arxiv.org/html/2512.14991v1#S5.E22 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.41](https://arxiv.org/html/2512.14991v1#A3.E41 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) implies that

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) | â‰¤\displaystyle\leq | CLIP(g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle{\rm CLIP}\Big(g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)\,\,{\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) |  |
|  |  | =\displaystyle= | g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)ğ•€{g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}.\displaystyle g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)\,\,{\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\mathbb{I}\_{\left\{g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\right\}}. |  |

Next, we find an upper bound for ğ•€{g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}\mathbb{I}\_{\left\{g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\right\}}.

Note that for (x1,a1),(x2,a2)âˆˆâ„dğ’®Ã—ğ’œ(x\_{1},a\_{1}),(x\_{2},a\_{2})\in\mathbb{R}^{d\_{\mathcal{S}}}\times\mathcal{A}, by ([2.7](https://arxiv.org/html/2512.14991v1#S2.E7 "In Proposition 2.4 (Local Lipschitz property of the value function). â€£ 2.3 Properties of the dynamics and value functions â€£ 2 Mathematical set-up â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([A.15](https://arxiv.org/html/2512.14991v1#A1.E15 "In Proposition A.1. â€£ A.4 Local lipschitz property for optimal Q function â€£ Appendix A Technical details in Section 2 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | |G~â€‹aphâ€‹(x1,a1)âˆ’G~â€‹aphâ€‹(x2,a2)|â‰¤3â€‹CÂ¯maxâ€‹(1+â€–x1â€–m+â€–x2â€–m)â€‹(â€–x1âˆ’x2â€–+â€–a1âˆ’a2â€–).\displaystyle|{\rm\widetilde{G}ap}\_{h}(x\_{1},a\_{1})-{\rm\widetilde{G}ap}\_{h}(x\_{2},a\_{2})|\leq 3{\overline{C}\_{\max}(1+\|x\_{1}\|^{m}+\|x\_{2}\|^{m})}(\|x\_{1}-x\_{2}\|+\|a\_{1}-a\_{2}\|). |  | (C.43) |

Then by definition in ([5.23](https://arxiv.org/html/2512.14991v1#S5.E23 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.43](https://arxiv.org/html/2512.14991v1#A3.E43 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we have:

|  |  |  |  |
| --- | --- | --- | --- |
|  | G~aph(center(Bhk))â‰¤Gaph(Bhk)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m))diam(Bhk).\displaystyle{\rm\widetilde{G}ap}\_{h}({\rm center}(B\_{h}^{k}))\leq{\rm Gap}\_{h}(B\_{h}^{k})+3{\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m}))}{\rm diam}(B\_{h}^{k}). |  | (C.44) |

In addition, we have

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | (H+1)g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle(H+1)g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)\,\,{\rm CONF}\_{h}^{k-1}(B\_{h}^{k})+3{\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m})}{\rm diam}(B\_{h}^{k}) |  | (C.45) |
|  |  | â‰¤\displaystyle\leq | 2((H+1)g3(Î´,âˆ¥x~(oBhk)âˆ¥)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m))diam(Bhk)\displaystyle 2\Big((H+1)g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|)+3\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m})\Big){\rm diam}(B\_{h}^{k}) |  |
|  |  | â‰¤\displaystyle\leq | gÂ¯â€‹(Î´,x~â€‹(Bhk))â€‹(H+1)â€‹diamâ€‹(Bhk),\displaystyle\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k}), |  |

where the first inequality holds due to ([B.16](https://arxiv.org/html/2512.14991v1#A2.E16 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the second inequality holds due to ([5.38](https://arxiv.org/html/2512.14991v1#S5.E38 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Therefore,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | ğ•€{g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}\displaystyle\mathbb{I}\_{\left\{g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\right\}} |  | (C.46) |
|  |  | =\displaystyle= | ğ•€{(H+1)g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)â‰¥Gaph(Bhk)}\displaystyle\mathbb{I}\_{\left\{(H+1)g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\geq{\rm Gap}\_{h}(B\_{h}^{k})\right\}} |  |
|  |  | â‰¤\displaystyle\leq | ğ•€{gÂ¯(Î´,x~(Bhk))(H+1)diam(Bhk)â‰¥Gaph(Bhk)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)}\displaystyle\mathbb{I}\_{\left\{\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k})\geq{\rm Gap}\_{h}(B\_{h}^{k})+3{\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m})}{\rm diam}(B\_{h}^{k})\right\}} |  |
|  |  | â‰¤\displaystyle\leq | ğ•€{gÂ¯â€‹(Î´,x~â€‹(Bhk))â€‹(H+1)â€‹diamâ€‹(Bhk)â‰¥G~â€‹aphâ€‹(centerâ€‹(Bhk))}\displaystyle\mathbb{I}\_{\left\{\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k})\geq{\rm\widetilde{G}ap}\_{h}({\rm center}(B\_{h}^{k}))\right\}} |  |
|  |  | â‰¤\displaystyle\leq | ğ•€{centerâ€‹(Bhk)âˆˆZhdiamâ€‹(Bhk),Ï},\displaystyle\mathbb{I}\_{\left\{{\rm center}(B\_{h}^{k})\in Z\_{h}^{{\rm diam}(B\_{h}^{k}),\rho}\right\}}, |  |

where the first inequality holds by ([C.45](https://arxiv.org/html/2512.14991v1#A3.E45 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the second inequality holds by ([C.44](https://arxiv.org/html/2512.14991v1#A3.E44 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the last inequality holds by ([5.37](https://arxiv.org/html/2512.14991v1#S5.E37 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)>0CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})>0}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) |  | (C.47) |
|  |  | â‰¤\displaystyle\leq | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)>0CLIP(g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})>0}{\rm CLIP}\Big(g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) |  |
|  |  | =\displaystyle= | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)>0g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)ğ•€{g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})>0}g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\mathbb{I}\_{\{g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\}} |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)>0g3(Î´,âˆ¥x~(oBhk)âˆ¥)CONFhkâˆ’1(Bhk)ğ•€{centerâ€‹(Bhk)âˆˆZhdiamâ€‹(Bhk),Ï,l}\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})>0}g\_{3}(\delta,\|\tilde{x}(^{o}B\_{h}^{k})\|){\rm CONF}\_{h}^{k-1}(B\_{h}^{k})\mathbb{I}\_{\{{\rm center}(B\_{h}^{k})\in Z\_{h}^{{\rm diam}(B\_{h}^{k}),\rho,l}\}} |  |
|  |  | =\displaystyle= | âˆ‘hâˆ‘râˆˆâ„›âˆ‘B:diamâ€‹(B)=râˆ‘k:Bhk=B,nhkâˆ’1â€‹(Bhk)>0g3(Î´,âˆ¥x~(oB)âˆ¥)CONFhkâˆ’1(B)ğ•€{centerâ€‹(B)âˆˆZhr,Ï}\displaystyle\sum\_{h}\sum\_{r\in\mathcal{R}}\sum\_{B:{\rm diam}(B)=r}\sum\_{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})>0}g\_{3}(\delta,\|\tilde{x}(^{o}B)\|){\rm CONF}\_{h}^{k-1}(B)\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}} |  |
|  |  | =\displaystyle= | âˆ‘hâˆ‘râˆˆâ„›,r<r0âˆ‘B:diamâ€‹(B)=râˆ‘k:Bhk=B,nhkâˆ’1â€‹(Bhk)>0g3(Î´,âˆ¥x~(oB)âˆ¥)CONFhkâˆ’1(B)ğ•€{centerâ€‹(B)âˆˆZhr,Ï}\displaystyle\sum\_{h}\sum\_{r\in\mathcal{R},r<r\_{0}}\sum\_{B:{\rm diam}(B)=r}\sum\_{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})>0}g\_{3}(\delta,\|\tilde{x}(^{o}B)\|){\rm CONF}\_{h}^{k-1}(B)\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}} |  |
|  |  |  | +âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=râˆ‘k:Bhk=B,nhkâˆ’1â€‹(Bhk)>0g3(Î´,âˆ¥x~(oB)âˆ¥)CONFhkâˆ’1(B)ğ•€{centerâ€‹(B)âˆˆZhr,Ï}\displaystyle+\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\sum\_{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})>0}g\_{3}(\delta,\|\tilde{x}(^{o}B)\|){\rm CONF}\_{h}^{k-1}(B)\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}} |  |
|  |  | â‰¤\displaystyle\leq | 2g3(Î´,Ï+D)Kr0+g3(Î´,Ï+D)g1(Î´,Ï+D)Ã—\displaystyle 2g\_{3}(\delta,\rho+D)Kr\_{0}+g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)\times |  |
|  |  |  | âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹âˆ‘k:Bhk=B1nhkâˆ’1â€‹(B),\displaystyle\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\sum\_{k:B\_{h}^{k}=B}\frac{1}{\sqrt{n\_{h}^{k-1}(B)}}, |  |

where the first inequality holds by ([C.11.1](https://arxiv.org/html/2512.14991v1#A3.Ex119 "C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the second inequality holds by ([C.46](https://arxiv.org/html/2512.14991v1#A3.E46 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and the last inequality holds due to ([B.16](https://arxiv.org/html/2512.14991v1#A2.E16 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

To bound the second term above,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | g3â€‹(Î´,Ï+D)â€‹g1â€‹(Î´,Ï+D)â€‹âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹âˆ‘k:Bhk=B1nhkâˆ’1â€‹(B)\displaystyle g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\sum\_{k:B\_{h}^{k}=B}\frac{1}{\sqrt{n\_{h}^{k-1}(B)}} |  | (C.48) |
|  |  | â‰¤\displaystyle\leq | g3(Î´,Ï+D)g1(Î´,Ï+D)Ã—\displaystyle g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)\times |  |
|  |  |  | âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹âˆ«x=0nmaxâ€‹(B)âˆ’nminâ€‹(B)1x+nminâ€‹(B)â€‹ğ‘‘x\displaystyle\qquad\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\int\_{x=0}^{n\_{\max}(B)-n\_{\min}(B)}\frac{1}{\sqrt{x+n\_{\min}(B)}}\,dx |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹g3â€‹(Î´,Ï+D)â€‹g1â€‹(Î´,Ï+D)â€‹âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹nmaxâ€‹(B)\displaystyle 2g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\sqrt{n\_{\max}(B)} |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹g3â€‹(Î´,Ï+D)â€‹g1â€‹(Î´,Ï+D)â€‹âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹g1â€‹(Î´,Ï+D)r\displaystyle 2g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\frac{g\_{1}(\delta,\rho+D)}{r} |  |
|  |  | â‰¤\displaystyle\leq | 2â€‹g3â€‹(Î´,Ï+D)â€‹g1â€‹(Î´,Ï+D)2â€‹âˆ‘hâˆ‘râˆˆâ„›,râ‰¥r0Nrâ€‹(Zhr,Ï)â€‹1r,\displaystyle 2g\_{3}(\delta,\rho+D)g\_{1}(\delta,\rho+D)^{2}\sum\_{h}\sum\_{r\in\mathcal{R},r\geq r\_{0}}N\_{r}(Z\_{h}^{r,\rho})\frac{1}{r}, |  |

where nmaxâ€‹(B)=(g1(Î´,âˆ¥x~(oB)âˆ¥diamâ€‹(B))2,nminâ€‹(B)=(g1(Î´,âˆ¥x~(oB)âˆ¥2â€‹dâ€‹iâ€‹aâ€‹mâ€‹(B))2n\_{\max}(B)=(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|}{{\rm diam}(B)})^{2},n\_{\min}(B)=(\frac{g\_{1}(\delta,\|\tilde{x}(^{o}B)\|}{2{\rm diam}(B)})^{2}. The first inequality holds due to the fact that nminâ€‹(B)â‰¤nhkâˆ’1â€‹(B)<nmaxâ€‹(B)n\_{\min}(B)\leq n\_{h}^{k-1}(B)<n\_{\max}(B) by ([B.17](https://arxiv.org/html/2512.14991v1#A2.E17 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([B.18](https://arxiv.org/html/2512.14991v1#A2.E18 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). The second inequality holds by the fact that âˆ«ab1yâ€‹ğ‘‘yâ‰¤2â€‹b\int\_{a}^{b}\frac{1}{\sqrt{y}}\,dy\leq 2\sqrt{b} for b>a>0b>a>0. The fourth inequality holds due to ([B.18](https://arxiv.org/html/2512.14991v1#A2.E18 "In B.7 Proof of Lemma 4.6 â€£ Appendix B Technical details in Section 4 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the last inequality holds due to the fact that âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â‰¤Nrâ€‹(Zhr,Ï)\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\leq N\_{r}(Z\_{h}^{r,\rho}). This fact holds since the distance between the centers of two blocks B1B\_{1} and B2B\_{2} with same diameter rr is at least rr.

Bound for Term (II): Next we bound Term (II) in ([C.40](https://arxiv.org/html/2512.14991v1#A3.E40 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

For fixed (h,k)(h,k), if nhkâˆ’1â€‹(Bhk)=0n\_{h}^{k-1}(B\_{h}^{k})=0, then diamâ€‹(Bhk)=D{\rm diam}(B\_{h}^{k})=D.

We now find an upper bound for ğ•€{Ghkâ€‹(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}\mathbb{I}\_{\left\{G\_{h}^{k}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\right\}}. Note that by ([5.31](https://arxiv.org/html/2512.14991v1#S5.E31 "In 5.2 Upper bound via clipping â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([5.38](https://arxiv.org/html/2512.14991v1#S5.E38 "In Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) we have:

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  |  |  | (H+1)Ghk(Bhk)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)\displaystyle(H+1)G\_{h}^{k}(B\_{h}^{k})+3{\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m})}{\rm diam}(B\_{h}^{k}) |  | (C.49) |
|  |  | â‰¤\displaystyle\leq | gÂ¯â€‹(Î´,x~â€‹(Bhk))â€‹(H+1)â€‹diamâ€‹(Bhk).\displaystyle\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k}). |  |

Therefore,

|  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- |
|  | ğ•€{Ghkâ€‹(Bhk)â‰¥Gaphâ€‹(Bhk)H+1}\displaystyle\mathbb{I}\_{\left\{G\_{h}^{k}(B\_{h}^{k})\geq\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\right\}} | =\displaystyle= | ğ•€{gÂ¯(Î´,x~(Bhk))(H+1)diam(Bhk)â‰¥Gaph(Bhk)+3CÂ¯max(1+2(âˆ¥x~(oBhk)âˆ¥+D)m)diam(Bhk)}\displaystyle\mathbb{I}\_{\left\{\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k})\geq{\rm Gap}\_{h}(B\_{h}^{k})+3{\overline{C}\_{\max}(1+2(\|\tilde{x}(^{o}B\_{h}^{k})\|+D)^{m})}{\rm diam}(B\_{h}^{k})\right\}} |  | (C.50) |
|  |  | â‰¤\displaystyle\leq | ğ•€{gÂ¯â€‹(Î´,x~â€‹(Bhk))â€‹(H+1)â€‹diamâ€‹(Bhk)â‰¥G~â€‹aphâ€‹(centerâ€‹(Bhk))}\displaystyle\mathbb{I}\_{\left\{\bar{g}(\delta,\tilde{x}(B\_{h}^{k}))(H+1){\rm diam}(B\_{h}^{k})\geq{\rm\widetilde{G}ap}\_{h}({\rm center}(B\_{h}^{k}))\right\}} |  |
|  |  | â‰¤\displaystyle\leq | ğ•€{centerâ€‹(Bhk)âˆˆZhdiamâ€‹(Bhk),Ï},\displaystyle\mathbb{I}\_{\left\{{\rm center}(B\_{h}^{k})\in Z\_{h}^{{\rm diam}(B\_{h}^{k}),\rho}\right\}}, |  |

where the first inequality holds by ([C.49](https://arxiv.org/html/2512.14991v1#A3.E49 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), the second inequality holds by ([C.44](https://arxiv.org/html/2512.14991v1#A3.E44 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and the third inequality holds by ([5.13](https://arxiv.org/html/2512.14991v1#S5.Thmtheorem13 "Definition 5.13 (Near optimal set). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).

Then

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  |  | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)=0CLIPâ€‹(Ghkâ€‹(Bhk)|Gaphâ€‹(Bhk)H+1)\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})=0}{\rm CLIP}\Big(G\_{h}^{k}(B\_{h}^{k})\,\Big|\,\frac{{\rm Gap}\_{h}(B\_{h}^{k})}{H+1}\Big) |  |
|  |  | â‰¤\displaystyle\leq | âˆ‘hâˆ‘kâˆˆJÏKâˆ‘Bhk:nhkâˆ’1â€‹(Bhk)=0gÂ¯(Î´,x~(oBhk))diam(Bhk)ğ•€{centerâ€‹(Bhk)âˆˆZhdiamâ€‹(Bhk),Ï}\displaystyle\sum\_{h}\sum\_{k\in J\_{\rho}^{K}}\sum\_{B\_{h}^{k}:n\_{h}^{k-1}(B\_{h}^{k})=0}\bar{g}(\delta,\tilde{x}(^{o}B\_{h}^{k})){\rm diam}(B\_{h}^{k})\mathbb{I}\_{\left\{{\rm center}(B\_{h}^{k})\in Z\_{h}^{{\rm diam}(B\_{h}^{k}),\rho}\right\}} |  |
|  |  | =\displaystyle= | âˆ‘hâˆ‘r=Dâˆ‘B:diamâ€‹(B)=râˆ‘k:Bhk=B,nhkâˆ’1â€‹(Bhk)=0gÂ¯(Î´,x~(oB))diam(B)ğ•€{centerâ€‹(B)âˆˆZhr,Ï}\displaystyle\sum\_{h}\sum\_{r=D}\sum\_{B:{\rm diam}(B)=r}\sum\_{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})=0}\bar{g}(\delta,\tilde{x}(^{o}B)){\rm diam}(B)\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}} |  |
|  |  | â‰¤\displaystyle\leq | gÂ¯â€‹(Î´,Ï+D)â€‹Dâ€‹âˆ‘hâˆ‘r=Dâˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â€‹|{k:Bhk=B,nhkâˆ’1â€‹(Bhk)=0}|,\displaystyle\bar{g}(\delta,\rho+D)D\sum\_{h}\sum\_{r=D}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}|\{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})=0\}|, |  |
|  |  | â‰¤\displaystyle\leq | (dğ’®+dğ’œ)dğ’®+dğ’œ2â€‹(Ï+D)dğ’®â€‹(2â€‹aÂ¯)dğ’œDdğ’®+dğ’œâˆ’1â€‹gÂ¯â€‹(Î´,Ï+D)â€‹âˆ‘hâˆ‘r=Dâˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï},\displaystyle(d\_{\mathcal{S}}+d\_{\mathcal{A}})^{\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}}\frac{(\rho+D)^{d\_{\mathcal{S}}}(2\bar{a})^{d\_{\mathcal{A}}}}{D^{d\_{\mathcal{S}}+d\_{\mathcal{A}}-1}}\bar{g}(\delta,\rho+D)\sum\_{h}\sum\_{r=D}\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}, |  |
|  |  | â‰¤\displaystyle\leq | (dğ’®+dğ’œ)dğ’®+dğ’œ2â€‹(Ï+D)dğ’®â€‹(2â€‹aÂ¯)dğ’œDdğ’®+dğ’œâˆ’2â€‹gÂ¯â€‹(Î´,Ï+D)â€‹âˆ‘hâˆ‘r=DNrâ€‹(Zhr,Ï)â€‹1r.\displaystyle(d\_{\mathcal{S}}+d\_{\mathcal{A}})^{\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}}\frac{(\rho+D)^{d\_{\mathcal{S}}}(2\bar{a})^{d\_{\mathcal{A}}}}{D^{d\_{\mathcal{S}}+d\_{\mathcal{A}}-2}}\bar{g}(\delta,\rho+D)\sum\_{h}\sum\_{r=D}N\_{r}(Z\_{h}^{r,\rho})\frac{1}{r}. |  |

The first inequality holds due to ([C.49](https://arxiv.org/html/2512.14991v1#A3.E49 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")) and ([C.50](https://arxiv.org/html/2512.14991v1#A3.E50 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")). The third inequality holds since |{k:Bhk=B,nhkâˆ’1â€‹(Bhk)=0}|â‰¤|ğ’«h0|â‰¤(dğ’®+dğ’œ)dğ’®+dğ’œ2â€‹(Ï+D)dğ’®â€‹(2â€‹aÂ¯)dğ’œDdğ’®+dğ’œ|\{k:B\_{h}^{k}=B,n\_{h}^{k-1}(B\_{h}^{k})=0\}|\leq|\mathcal{P}\_{h}^{0}|\leq(d\_{\mathcal{S}}+d\_{\mathcal{A}})^{\frac{d\_{\mathcal{S}}+d\_{\mathcal{A}}}{2}}\frac{(\rho+D)^{d\_{\mathcal{S}}}(2\bar{a})^{d\_{\mathcal{A}}}}{D^{d\_{\mathcal{S}}+d\_{\mathcal{A}}}}, and the last inequality holds due to the fact that âˆ‘B:diamâ€‹(B)=rğ•€{centerâ€‹(B)âˆˆZhr,Ï}â‰¤Nrâ€‹(Zhr,Ï)\sum\_{B:{\rm diam}(B)=r}\mathbb{I}\_{\{{\rm center}(B)\in Z\_{h}^{r,\rho}\}}\leq N\_{r}(Z\_{h}^{r,\rho}). This fact holds since the distance between the centers of two blocks B1B\_{1} and B2B\_{2} with the same diameter rr is at least rr.

Finally, combining ([C.47](https://arxiv.org/html/2512.14991v1#A3.E47 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.48](https://arxiv.org/html/2512.14991v1#A3.E48 "In C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), ([C.11.1](https://arxiv.org/html/2512.14991v1#A3.Ex147 "C.11.1 Proof of Lemma 5.17 â€£ C.11 Technical results modified from [Sinclair et al., 2023] â€£ Appendix C Technical details in Section 5 â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), and noting the definition of g4(.,.)g\_{4}(.,.) in ([5.42](https://arxiv.org/html/2512.14991v1#S5.E42 "In Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")), we verify ([5.41](https://arxiv.org/html/2512.14991v1#S5.E41 "In Lemma 5.17 (Theorem F.3 in (Sinclair et al., 2023)). â€£ 5.4 Regret composition â€£ 5 Regret analysis â€£ Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes")).
âˆ