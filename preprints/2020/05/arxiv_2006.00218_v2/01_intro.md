---
authors:
- Imanol Perez Arribas
- Cristopher Salvi
- Lukasz Szpruch
doc_id: arxiv:2006.00218v2
family_id: arxiv:2006.00218
is_current: true
taxonomy:
  alpha_families: []
  asset_classes: []
  horizons: []
  themes: []
title: '[2006.00218] Sig-SDEs model for quantitative finance.'
url_abs: http://arxiv.org/abs/2006.00218v2
url_html: https://ar5iv.org/html/2006.00218v2
venue: arXiv q-fin
version: 2
year: 2020
---


Imanol Perez Arribas
[imanol.perez@maths.ox.ac.uk](mailto:imanol.perez@maths.ox.ac.uk)
University of OxfordAlan Turing InstituteUnited Kingdom
,Â 
Cristopher Salvi
[cristopher.salvi@maths.ox.ac.uk](mailto:cristopher.salvi@maths.ox.ac.uk)
University of OxfordAlan Turing InstituteUnited Kingdom
Â andÂ 
Lukasz Szpruch
[l.szpruch@ed.ac.uk](mailto:l.szpruch@ed.ac.uk)
University of EdinburghAlan Turing InstituteUnited Kingdom

(2018)

###### Abstract.

Mathematical models, calibrated to data, have become ubiquitous to make key decision processes in modern quantitative finance. In this work, we propose a novel framework for data-driven model selection by integrating a classical quantitative setup with a generative modelling approach. Leveraging the properties of the signature, a well-known path-transform from stochastic analysis that recently emerged as leading machine learning technology for learning time-series data, we develop the Sig-SDE model. Sig-SDE provides a new perspective on neural SDEs and can be calibrated to exotic financial products that depend, in a non-linear way, on the whole trajectory of asset prices. Furthermore, we our approach enables to consistently calibrate under the pricing measure â„šâ„š\mathbb{Q} and real-world measure â„™â„™\mathbb{P}. Finally, we demonstrate the ability of Sig-SDE to simulate future possible market scenarios needed for computing risk profiles or hedging strategies. Importantly, this new model is underpinned by rigorous mathematical analysis, that under appropriate conditions provides theoretical guarantees for convergence of the presented algorithms.

market simulation, pricing, signatures, rough path theory

â€ â€ copyright: acmcopyrightâ€ â€ journalyear: 2018â€ â€ doi: 10.1145/1122445.1122456â€ â€ conference: 2020 ACM International Conference on AI in Finance; October 15â€“16, 2020; NYâ€ â€ booktitle: 2020 ACM International Conference on AI in Finance,
October 15â€“16, 2020, NYâ€ â€ price: 15.00â€ â€ isbn: 978-1-4503-XXXX-X/18/06â€ â€ ccs: Mathematics of computingÂ Probability and statisticsâ€ â€ ccs: Applied computingâ€ â€ ccs: Computing methodologiesÂ Machine learning

## 1. Introduction

The question of finding a parsimonious model that well represents empirical data has been of paramount importance in quantitative finance. The modelling choice is dictated by the desire to fit and explain the available data, but is also subject to computational considerations. Inevitably, all models can only provide an approximation to reality, and the risk of using inadequate ones is hard to detect.
A classical approach consists in fixing a class of parametric models, with a number of parameters that is significantly smaller than the number of available data points. Next, in the process called calibration, the goal is to solve a data-dependent optimization problem yielding an optimal choice of model parameters. The main challenge, of course, is to decide what class of models one should choose from. The theory of statistical learning (Vapnik, [2013](#bib.bib29)) tell us that to simple models cannot fit the data, and to complex one are not expected to generalise to unseen observations. In modern machine learning approaches, one usually starts by defining a highly oveparametrised model from some universality class, exhibiting a number of parameters often exceeding the number of data points, and let (stochastic) gradient algorithms find the best configuration of parameters yielding a calibrated model. In this work, we find a middle ground between the two approaches. We develop a new framework for systematic model selection that exhibits universal approximation properties, and we provide a explicit solution to the optimization used in its calibration, that completely removes the need to deploy expensive gradient descent algorithms. Importantly the class of models that we consider builds upon classical risk models that are well underpinned by research on quantitative finance.

The mathematical object at the core of this work is the expected signature of a path, whose properties are well-understood in the field of stochastic analysis. It allows to identify a linear structure underpinning the high non-linearity of the sequential data we work with. This linear structure leads to a massive speed-up of calibration, pricing, and generation of future scenarios. Our approach provides a new systematic model selection mechanism, that can also be deployed to calibrate classical non-Markovian models in a computationally efficient way. Signatures have been deployed to solve various tasks in mathematical finance, such as options pricing and hedging (Lyons
etÂ al., [2019](#bib.bib23), [2020](#bib.bib24)), high frequency optimal execution (Kalsi
etÂ al., [2020](#bib.bib15); Cartea etÂ al., [2020](#bib.bib5)) and others (Lyons
etÂ al., [2014](#bib.bib25); GyurkÃ³ etÂ al., [2013](#bib.bib13)). They have also been applied in several areas of machine learning (Kidger etÂ al., [2019](#bib.bib17); Yang
etÂ al., [2015](#bib.bib31), [2016a](#bib.bib32), [2016c](#bib.bib34), [2016b](#bib.bib33), [2017](#bib.bib35); Xie
etÂ al., [2017](#bib.bib30); Li etÂ al., [2017](#bib.bib22); Chevyrev and
Oberhauser, [2018](#bib.bib7); KirÃ¡ly and
Oberhauser, [2016](#bib.bib20)).

### 1.1. Sig-SDE Model

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} denote the price process of an arbitrary financial asset under the pricing measure â„šâ„š\mathbb{Q}. To ensure the no-arbitrage assumption is not violated, Xğ‘‹X typically is given by the solution of the following Stochastic Differential Equation (SDE)

|  |  |  |  |
| --- | --- | --- | --- |
| (1) |  | dâ€‹Xt=Î£tâ€‹dâ€‹Wt,X0=x,formulae-sequenceğ‘‘subscriptğ‘‹ğ‘¡subscriptÎ£ğ‘¡ğ‘‘subscriptğ‘Šğ‘¡subscriptğ‘‹0ğ‘¥dX\_{t}=\Sigma\_{t}dW\_{t},\quad X\_{0}=x\,, |  |

where Wğ‘ŠW is a one-dimensional Brownian motion and Î£tsubscriptÎ£ğ‘¡\Sigma\_{t} is an adapted process (the volatility process). Model ([1](#S1.E1 "In 1.1. Sig-SDE Model â€£ 1. Introduction â€£ Sig-SDEs model for quantitative finance.")) accommodates many standard risk models used e.g: the classical Blackâ€“Scholes model assumes that volatility is proportional to the spot price, i.e. Î£t:=Ïƒâ€‹XtassignsubscriptÎ£ğ‘¡ğœsubscriptğ‘‹ğ‘¡\Sigma\_{t}:=\sigma X\_{t} with Ïƒâˆˆâ„ğœâ„\sigma\in\mathbb{R} constant; the local volatility model assumes that Î£t:=Ïƒâ€‹(t,Xt)â€‹XtassignsubscriptÎ£ğ‘¡ğœğ‘¡subscriptğ‘‹ğ‘¡subscriptğ‘‹ğ‘¡\Sigma\_{t}:=\sigma(t,X\_{t})X\_{t}, where Ïƒâ€‹(â‹…,â‹…)ğœâ‹…â‹…\sigma(\cdot,\cdot) (called local volatility surface) depends on both time and spot. Hence, it is a generalisation of the Blackâ€“Scholes model;
various stochastic volatility model assume that Î£t:=Ïƒtâ€‹XtassignsubscriptÎ£ğ‘¡subscriptğœğ‘¡subscriptğ‘‹ğ‘¡\Sigma\_{t}:=\sigma\_{t}X\_{t} with Ïƒt2superscriptsubscriptğœğ‘¡2\sigma\_{t}^{2} following some diffusion process;
the SABR model chooses Î£t:=Ïƒtâ€‹XtÎ²assignsubscriptÎ£ğ‘¡subscriptğœğ‘¡superscriptsubscriptğ‘‹ğ‘¡ğ›½\Sigma\_{t}:=\sigma\_{t}X\_{t}^{\beta}, with Î²âˆˆ[0,1]ğ›½01\beta\in[0,1] and where Ïƒtsubscriptğœğ‘¡\sigma\_{t} follows a diffusion process.

A natural question would be whether one can find a model for the volatility process Î£tsubscriptÎ£ğ‘¡\Sigma\_{t} that is large enough to include all the classical models such as the ones mentioned above and that would allow for systematic a data driven model selection. We will require such a model to satisfy the following requirements:

1. (1)

   Universality. The model should be able to approximate arbitrarily well the dynamics of classical models.
2. (2)

   Efficient calibration. Given market prices for a family of options, it should be possible to efficiently calibrate the model so that it correctly prices the family of options.
3. (3)

   Fast pricing. Ideally, it should be possible to quickly price (potentially exotic) options under the model without using Monte Carlo techniques.
4. (4)

   Efficient simulation. Sampling trajectories from the model should be computationally cheap and efficient.

An example of a model that satisfies point 1. above is a neural network model, where the volatility process Î£tsubscriptÎ£ğ‘¡\Sigma\_{t} is approximated by a neural network ğ’©â€‹ğ’©Î¸â€‹(t,(Ws)sâˆˆ[0,t])ğ’©superscriptğ’©ğœƒğ‘¡subscriptsubscriptğ‘Šğ‘ ğ‘ 0ğ‘¡\mathcal{NN}^{\theta}(t,(W\_{s})\_{s\in[0,t]}) with parameters Î¸ğœƒ\theta. Such a model would be able to approximate a rich class of classical models. However, the calibration and pricing of such models would involve performing multiple Monte Carlo simulations on each epoch, which might be expensive if done naively. See however, (Cuchiero
etÂ al., [2020](#bib.bib8); GierjatowiczÂ P., [2020](#bib.bib11)).

The aim of this paper is to propose a model for asset price dynamics that, we believe, satisfies all four points above. Our technique models the volatility process Î£tsubscriptÎ£ğ‘¡\Sigma\_{t} as

|  |  |  |  |
| --- | --- | --- | --- |
| (2) |  | Î£t=âŸ¨â„“N,ğ•^0,tâŸ©subscriptÎ£ğ‘¡  superscriptâ„“ğ‘subscript^ğ•  0ğ‘¡\Sigma\_{t}=\langle\ell^{N},\widehat{\mathbb{W}}\_{0,t}\rangle |  |

where â„“Nsuperscriptâ„“ğ‘\ell^{N} is the model parameters and ğ•^0,tsubscript^ğ•

0ğ‘¡\widehat{\mathbb{W}}\_{0,t} is the signature (c.f definition [2.6](#S2.Thmtheorem6 "Definition 2.6 (Signature). â€£ 2.3. Signatures â€£ 2. Notation and preliminaries â€£ Sig-SDEs model for quantitative finance.")) of the stochastic process W^t:=(t,Wt)assignsubscript^ğ‘Šğ‘¡ğ‘¡subscriptğ‘Šğ‘¡\widehat{W}\_{t}:=(t,W\_{t}). The motivation for choosing the signature as the main building block of this paper is anchored in a very powerful result for universal approximation of functions based on the celebrated Stone-Weierstrass Theorem that we present next in an informal manner (for more technical details see (Fermanian, [2019](#bib.bib9), Proposition 3))

###### Theorem 1.1.

Consider a compact set Kğ¾K of continuous â„dsuperscriptâ„ğ‘‘\mathbb{R}^{d}-valued paths. Denote by Sğ‘†S the function that maps a path Xğ‘‹X from Kğ¾K to its signature ğ•ğ•\mathbb{X}. Let f:Kâ†’â„:ğ‘“â†’ğ¾â„f:K\to\mathbb{R} be any any continuous functions. Then, for any Ïµ>0italic-Ïµ0\epsilon>0 and any path XâˆˆKğ‘‹ğ¾X\in K, there exists a linear function lâˆsuperscriptğ‘™l^{\infty} acting on the signature such that

|  |  |  |  |
| --- | --- | --- | --- |
| (3) |  | â€–fâ€‹(X)âˆ’âŸ¨lâˆ,ğ•âŸ©â€–âˆ<Ïµsubscriptnormğ‘“ğ‘‹  superscriptğ‘™ğ•italic-Ïµ||f(X)-\langle l^{\infty},\mathbb{X}\rangle||\_{\infty}<\epsilon |  |

In other words, any continuous function on a compact set of paths can be uniformly well approximated by a linear combination of terms of the signature. This universal approximation property is similar to the one provided by Neural Networks (NN). However, as we will discuss below, NN models depend on a very large collection of parameters that need to be optimized via expensive back-propagation-based techniques, whilst the optimization needed in our Sig-SDE model consists of a simple linear regression on the terms of the signature. In this way, the signature can be thought of as a feature map for paths that provides a linear basis for the space of continuous functions on paths. In the setting of SDEs, sample paths are Brownian and solutions are images of these sample trajectories by a continuous functions that one wishes to approximate from a set of observations. Our Sig-SDE model will rely upon the universality of the signature to approximate such functions acting on Brownian trajectories. Importantly, the signature of a realisation of a semimartingale provides a unique representation of the sample trajectory (Hambly and Lyons, [2010](#bib.bib14); Boedihardjo etÂ al., [2016](#bib.bib3)). Similarly, the expected signature â€“ i.e. the collection of the expectations of the iterated integrals â€“ provides a unique representation of the law of the semimartingale (Chevyrev
etÂ al., [2016](#bib.bib6)).

Note that model calibration is an example of generative modelling (Goodfellow etÂ al., [2014](#bib.bib12); Kingma and
Welling, [2013](#bib.bib19)).
Indeed, recall that if one knew prices of traded liquid derivatives, then one can approximate the pricing measure from market data (Breeden and
Litzenberger, [1978](#bib.bib4); Lyons
etÂ al., [2019](#bib.bib23)). We denote this measure by â„šrâ€‹eâ€‹aâ€‹lsuperscriptâ„šğ‘Ÿğ‘’ğ‘ğ‘™\mathbb{Q}^{real}.

We know that when equation ([1](#S1.E1 "In 1.1. Sig-SDE Model â€£ 1. Introduction â€£ Sig-SDEs model for quantitative finance.")) admits a strong solution then there exists a measurable map G:â„Ã—Câ€‹([0,T])â†’Câ€‹([0,T]):ğºâ†’â„ğ¶0ğ‘‡ğ¶0ğ‘‡G:\mathbb{R}\times C([0,T])\rightarrow C([0,T]) such that

|  |  |  |  |
| --- | --- | --- | --- |
| (4) |  | X=Gâ€‹(x,(Ws)sâˆˆ[0,T])ğ‘‹ğºğ‘¥subscriptsubscriptğ‘Šğ‘ ğ‘ 0ğ‘‡X=G(x,(W\_{s})\_{s\in[0,T]}) |  |

as shown in (Karatzas and
Shreve, [2012](#bib.bib16), Corollary 3.23). If Gtsubscriptğºğ‘¡G\_{t} denotes the projection of GğºG given by Xt:=Gtâ€‹(Î¾,(Ws)sâˆˆ[0,t])assignsubscriptğ‘‹ğ‘¡subscriptğºğ‘¡ğœ‰subscriptsubscriptğ‘Šğ‘ ğ‘ 0ğ‘¡X\_{t}:=G\_{t}(\xi,(W\_{s})\_{s\in[0,t]}), then one can view ([1](#S1.E1 "In 1.1. Sig-SDE Model â€£ 1. Introduction â€£ Sig-SDEs model for quantitative finance.")) as a generative model that maps Î¼0subscriptğœ‡0\mu\_{0} supported on â„dsuperscriptâ„ğ‘‘\mathbb{R}^{d} into (Gt)#â€‹Î¼0=QtÎ¸subscriptsubscriptğºğ‘¡#subscriptğœ‡0superscriptsubscriptğ‘„ğ‘¡ğœƒ(G\_{t})\_{\#}\mu\_{0}=Q\_{t}^{\theta}. Note that by construction GğºG is a casual transport map i.e a transport map that is adapted to the filtration â„±tsubscriptâ„±ğ‘¡\mathcal{F}\_{t} (Acciaio etÂ al., [2019](#bib.bib2)). In practice, one is interested in finding such a transport map from a family of parametrised functions GÎ¸superscriptğºğœƒG^{\theta}. One then looks for a Î¸ğœƒ\theta such that G#Î¸â€‹Î¼0subscriptsuperscriptğºğœƒ#subscriptğœ‡0G^{\theta}\_{\#}\mu\_{0} is a good approximation of Qrâ€‹eâ€‹aâ€‹lsuperscriptğ‘„ğ‘Ÿğ‘’ğ‘ğ‘™Q^{real} with respect to a metric specified by the user. In this paper the family of transport maps GÎ¸superscriptğºğœƒG^{\theta} is given by linear functions on signatures (or linear functionals below).

## 2. Notation and preliminaries

We begin by introducing some notation and preliminary results that are used in this paper.

### 2.1. Multi-indices

###### Definition 2.1.

Let dâˆˆâ„•ğ‘‘â„•d\in\mathbb{N}. For any nâ‰¥0ğ‘›0n\geq 0, we call an nğ‘›n-dimensional dğ‘‘d-multi-index any nğ‘›n-tuple of non-negative integers of the form K=(k1,â€¦,kn)ğ¾subscriptğ‘˜1â€¦subscriptğ‘˜ğ‘›K=(k\_{1},\ldots,k\_{n}) such that kiâˆˆ{1,â€¦,d}subscriptğ‘˜ğ‘–1â€¦ğ‘‘k\_{i}\in\{1,\ldots,d\} for all iâˆˆ{1,â€¦,n}ğ‘–1â€¦ğ‘›i\in\{1,\ldots,n\}. We denote its length by |K|=nğ¾ğ‘›|K|=n. The empty multi-index is denoted by Ã¸italic-Ã¸\o. We denote by â„dsubscriptâ„ğ‘‘\mathcal{I}\_{d} the set of all dğ‘‘d-multi-indices, and by â„dnâŠ‚â„dsubscriptsuperscriptâ„ğ‘›ğ‘‘subscriptâ„ğ‘‘\mathcal{I}^{n}\_{d}\subset\mathcal{I}\_{d} the set of all dğ‘‘d-multi-indices of length at most nâˆˆâ„•ğ‘›â„•n\in\mathbb{N}.

###### Definition 2.2 (Concatenation of multi-indices).

Let I=(i1,â€¦,ip)ğ¼subscriptğ‘–1â€¦subscriptğ‘–ğ‘I=(i\_{1},\ldots,i\_{p}) and J=(j1,â€¦,jq)ğ½subscriptğ‘—1â€¦subscriptğ‘—ğ‘J=(j\_{1},\ldots,j\_{q}) be any two multi-indices in â„dsubscriptâ„ğ‘‘\mathcal{I}\_{d}. Their concatenation product âŠ—tensor-product\otimes as the multi-index IâŠ—J=(i1,â€¦,im,j1,â€¦,jn)âˆˆâ„dtensor-productğ¼ğ½subscriptğ‘–1â€¦subscriptğ‘–ğ‘šsubscriptğ‘—1â€¦subscriptğ‘—ğ‘›subscriptâ„ğ‘‘I\otimes J=(i\_{1},\ldots,i\_{m},j\_{1},\ldots,j\_{n})\in\mathcal{I}\_{d}.

###### Example 2.3.

1. (1)

   (1,3)âŠ—(2,2)=(1,3,2,2)tensor-product13221322(1,3)\otimes(2,2)=(1,3,2,2).
2. (2)

   (2,1,3)âŠ—(1)=(2,1,3,1)tensor-product21312131(2,1,3)\otimes(1)=(2,1,3,1).
3. (3)

   (2,2)âŠ—Ã¸=(2,2)tensor-product22italic-Ã¸22(2,2)\otimes\o=(2,2).

### 2.2. Linear functionals

###### Definition 2.4 (Linear functional).

For a given dâ‰¥1ğ‘‘1d\geq 1, a linear functional is a (possibly infinite) sequence of real numbers indexed by multi-indices in â„dsubscriptâ„ğ‘‘\mathcal{I}\_{d} of the following form

|  |  |  |  |
| --- | --- | --- | --- |
| (5) |  | F={F(K)âˆˆâ„:Kâˆˆâ„d}.ğ¹conditional-setsuperscriptğ¹ğ¾â„ğ¾subscriptâ„ğ‘‘F=\{F^{(K)}\in\mathbb{R}:K\in\mathcal{I}\_{d}\}. |  |

We note that a multi-index Kâˆˆâ„dğ¾subscriptâ„ğ‘‘K\in\mathcal{I}\_{d} is always a linear functional. Both concatenation âŠ—tensor-product\otimes and can be extended by linearity to operations on linear functionals. We will now define two basic operations on linear functionals that will be used throughout the paper.

###### Definition 2.5.

For any two linear functionals F,G

ğ¹ğºF,G and any real numbers Î±,Î²âˆˆâ„

ğ›¼ğ›½
â„\alpha,\beta\in\mathbb{R} define

|  |  |  |  |
| --- | --- | --- | --- |
| (6) |  | Î±â€‹F+Î²â€‹G={Î±â€‹F(K)+Î²â€‹G(K)âˆˆâ„:Kâˆˆâ„d}ğ›¼ğ¹ğ›½ğºconditional-setğ›¼superscriptğ¹ğ¾ğ›½superscriptğºğ¾â„ğ¾subscriptâ„ğ‘‘\alpha F+\beta G=\{\alpha F^{(K)}+\beta G^{(K)}\in\mathbb{R}:K\in\mathcal{I}\_{d}\} |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
| (7) |  | âŸ¨F,GâŸ©=âˆ‘Kâˆˆâ„dF(K)â€‹G(K)âˆˆâ„  ğ¹ğº subscriptğ¾subscriptâ„ğ‘‘superscriptğ¹ğ¾superscriptğºğ¾â„\langle F,G\rangle=\sum\_{K\in\mathcal{I}\_{d}}F^{(K)}G^{(K)}\in\mathbb{R} |  |

### 2.3. Signatures

Rough paths theory can be briefly described as a non-linear extension of the classical theory of controlled differential equations which is robust enough to allow a deterministic treatment of stochastic differential equations controlled by much rougher signals than semi-martingales (Lyons
etÂ al., [2007](#bib.bib27)).

###### Definition 2.6 (Signature).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} be a continuous semimartingale. The Signature of Xğ‘‹X over a time interval [s,t]âŠ‚[0,T]ğ‘ ğ‘¡0ğ‘‡[s,t]\subset[0,T] is the linear functional ğ•s,t:={ğ•s,t(K)âˆˆâ„:Kâˆˆâ„d}assignsubscriptğ•

ğ‘ ğ‘¡conditional-setsuperscriptsubscriptğ•

ğ‘ ğ‘¡ğ¾â„ğ¾subscriptâ„ğ‘‘\mathbb{X}\_{s,t}:=\{\mathbb{X}\_{s,t}^{(K)}\in\mathbb{R}:K\in\mathcal{I}\_{d}\}, such that ğ•s,t(Ã¸)=1superscriptsubscriptğ•

ğ‘ ğ‘¡italic-Ã¸1\mathbb{X}\_{s,t}^{(\o)}=1 and so that for any nâ‰¥1ğ‘›1n\geq 1 and K=K^âŠ—aâˆˆâ„dnğ¾tensor-product^ğ¾ğ‘subscriptsuperscriptâ„ğ‘›ğ‘‘K=\widehat{K}\otimes a\in\mathcal{I}^{n}\_{d}, with aâˆˆ{1,â€¦,d}ğ‘1â€¦ğ‘‘a\in\{1,\ldots,d\} and K^âˆˆâ„dnâˆ’1^ğ¾subscriptsuperscriptâ„ğ‘›1ğ‘‘\widehat{K}\in\mathcal{I}^{n-1}\_{d} we have

|  |  |  |  |
| --- | --- | --- | --- |
| (8) |  | ğ•s,t(K)=âˆ«stğ•s,u(K^)âˆ˜ğ‘‘ğ•u(a)superscriptsubscriptğ•  ğ‘ ğ‘¡ğ¾superscriptsubscriptğ‘ ğ‘¡subscriptsuperscriptğ•^ğ¾  ğ‘ ğ‘¢differential-dsubscriptsuperscriptğ•ğ‘ğ‘¢\mathbb{X}\_{s,t}^{(K)}=\int\_{s}^{t}\mathbb{X}^{(\widehat{K})}\_{s,u}\circ d\mathbb{X}^{(a)}\_{u} |  |

where the integral is to be interpreted in the Stratonovich sense.

###### Example 2.7.

Let X:[0,T]â†’â„2:ğ‘‹â†’0ğ‘‡superscriptâ„2X:[0,T]\to\mathbb{R}^{2} be a semimartingale.

1. (1)

   ğ•s,t(1)=Xt(1)âˆ’Xs(1)superscriptsubscriptğ•
   ğ‘ ğ‘¡1superscriptsubscriptğ‘‹ğ‘¡1superscriptsubscriptğ‘‹ğ‘ 1\mathbb{X}\_{s,t}^{(1)}=X\_{t}^{(1)}-X\_{s}^{(1)}.
2. (2)

   ğ•s,t(1,2)=âˆ«stXs,u(1)âˆ˜ğ‘‘Xu(2)superscriptsubscriptğ•
   ğ‘ ğ‘¡12superscriptsubscriptğ‘ ğ‘¡superscriptsubscriptğ‘‹
   ğ‘ ğ‘¢1differential-dsuperscriptsubscriptğ‘‹ğ‘¢2\mathbb{X}\_{s,t}^{(1,2)}=\int\_{s}^{t}X\_{s,u}^{(1)}\circ dX\_{u}^{(2)}.
3. (3)

   ğ•s,t(2,2)=12â€‹(Xs(2)âˆ’Xt(2))2superscriptsubscriptğ•
   ğ‘ ğ‘¡2212superscriptsuperscriptsubscriptğ‘‹ğ‘ 2superscriptsubscriptğ‘‹ğ‘¡22\mathbb{X}\_{s,t}^{(2,2)}=\frac{1}{2}(X\_{s}^{(2)}-X\_{t}^{(2)})^{2}.

A more detailed overview of signatures is included in Appendix [A](#A1 "Appendix A Overview of signatures â€£ Sig-SDEs model for quantitative finance.").

## 3. Signature Model

In this section we define the Signature Model for asset price dynamics that we propose in this paper. The goal is to approximate the volatility process Î£tsubscriptÎ£ğ‘¡\Sigma\_{t} (that is a continuous function on the driving Brownian path) by a linear functional on the signature of the Brownian path.

###### Definition 3.1 (Signature Model).

Let Wğ‘ŠW be a one-dimensional Brownian motion. Let Nâˆˆâ„•ğ‘â„•N\in\mathbb{N} be the order of the Signature Model. The Signature Model of parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾subscriptsuperscriptâ„ğ‘2\ell=\{\ell^{(K)}:K\in\mathcal{I}^{N}\_{2}\} is given by Î£t:=âŸ¨â„“,ğ•^0,tâŸ©assignsubscriptÎ£ğ‘¡

â„“subscript^ğ•

0ğ‘¡\Sigma\_{t}:=\langle\ell,\widehat{\mathbb{W}}\_{0,t}\rangle, where ğ•^^ğ•\widehat{\mathbb{W}} denotes the signature of Wadd-timesuperscriptğ‘Šadd-timeW^{\text{add-time}}. In other words, the asset price dynamics are given by

|  |  |  |  |
| --- | --- | --- | --- |
| (9) |  | dâ€‹Xt=âŸ¨â„“,ğ•^0,tâŸ©â€‹dâ€‹Wt,X0=xâˆˆâ„.formulae-sequenceğ‘‘subscriptğ‘‹ğ‘¡  â„“subscript^ğ•  0ğ‘¡ ğ‘‘subscriptğ‘Šğ‘¡subscriptğ‘‹0ğ‘¥â„dX\_{t}=\langle\ell,\widehat{\mathbb{W}}\_{0,t}\rangle dW\_{t},\quad X\_{0}=x\in\mathbb{R}. |  |

We note that the Signature Model has two components: the hyperparameter Nâˆˆâ„•ğ‘â„•N\in\mathbb{N}, and the model parameter â„“â„“\ell. Intuitively, the hyperparameter Nğ‘N plays a similar role to the width of a layer in a neural network. The larger this value is, the richer the range of market dynamics the Signature Models can generate. Once the value of Nğ‘N is fixed, the challenge is to find a suitable model parameter â„“â„“\ell. Again, in analogy with neural networks, â„“â„“\ell plays the role of the weights of the network.

The Signature Model possesses the universality property, in the sense that given a classical model, there exists a Signature Model that can approximate its dynamics to a given accuracy (Levin
etÂ al., [2013](#bib.bib21)).

We show in the upcoming Sections [5](#S5 "5. Simulation â€£ Sig-SDEs model for quantitative finance.")-[7](#S7 "7. Calibration â€£ Sig-SDEs model for quantitative finance.") that (a) the Signature Model is efficient to simulate, (b) it is efficient to calibrate, and (c) exotic options can be priced fast under the Signature Model.

###### Remark 1.

The Signature Model introduced in Definition [3.1](#S3.Thmtheorem1 "Definition 3.1 (Signature Model). â€£ 3. Signature Model â€£ Sig-SDEs model for quantitative finance.") assumes that the source of noise (i.e. the Brownian motion Wğ‘ŠW) is one-dimensional. This was done for simplicity, but the authors would like to emphasise that the model generalises in a straightforward way to multi-dimensional Brownian motion.

## 4. Numerical experiments

We now demonstrate the feasibility of our methodology as outlined in Sections [5](#S5 "5. Simulation â€£ Sig-SDEs model for quantitative finance.")-[7](#S7 "7. Calibration â€£ Sig-SDEs model for quantitative finance."). Throughout this section, we work with the Signature Model

|  |  |  |
| --- | --- | --- |
|  | dâ€‹Xt=âŸ¨â„“,ğ•^0,tâŸ©â€‹dâ€‹Wt,X0=1formulae-sequenceğ‘‘subscriptğ‘‹ğ‘¡  â„“subscript^ğ•  0ğ‘¡ ğ‘‘subscriptğ‘Šğ‘¡subscriptğ‘‹01dX\_{t}=\langle\ell,\widehat{\mathbb{W}}\_{0,t}\rangle dW\_{t},\quad X\_{0}=1 |  |

with â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾superscriptsubscriptâ„2ğ‘\ell=\{\ell^{(K)}:K\in\mathcal{I}\_{2}^{N}\}. We fix N=4ğ‘4N=4. Therefore, the model has 1+2+22+23+24=3112superscript22superscript23superscript24311+2+2^{2}+2^{3}+2^{4}=31 parameters that need to be calibrated. We also fix the terminal maturity T=1ğ‘‡1T=1.

In this section we will show experiments for the calibration of the model, pricing of options under the signature model and simulation. Sections [5](#S5 "5. Simulation â€£ Sig-SDEs model for quantitative finance.")-[7](#S7 "7. Calibration â€£ Sig-SDEs model for quantitative finance.") will then include the technical details of how calibration, pricing and simulation of signatures model are done.

### 4.1. Calibration

![Refer to caption](/html/2006.00218/assets/signature_model.png)

Figure 1. Error analysis between the option prices of the real model and the calibrated Signature Model.

\Description

Error analysis.

We assume that the family of options available on the market are a mixture of vanilla and exotic options, given as follows:

* â€¢

  Vanilla call options with strikes K=0.5,0.6,â€¦,1,1.ğ¾
  0.50.6â€¦11K=0.5,0.6,\ldots,1,1. and maturities t=0.4,0.45,0.5,â€¦,0.9,0.95,1ğ‘¡
  0.40.450.5â€¦0.90.951t=0.4,0.45,0.5,\ldots,0.9,0.95,1:

  |  |  |  |
  | --- | --- | --- |
  |  | Î¦:=maxâ¡(Xtâˆ’K,0).assignÎ¦subscriptğ‘‹ğ‘¡ğ¾0\Phi:=\max(X\_{t}-K,0). |  |
* â€¢

  Variance options with strikes K=0.01,0.015,â€¦,0.035,0.04ğ¾
  0.010.015â€¦0.0350.04K=0.01,0.015,\ldots,0.035,0.04 and maturities t=0.4,0.45,0.5,â€¦,0.9,0.95,1ğ‘¡
  0.40.450.5â€¦0.90.951t=0.4,0.45,0.5,\ldots,0.9,0.95,1:

  |  |  |  |
  | --- | --- | --- |
  |  | Î¦:=maxâ¡(âŸ¨XâŸ©tâˆ’K,0).assignÎ¦subscriptdelimited-âŸ¨âŸ©ğ‘‹ğ‘¡ğ¾0\Phi:=\max(\langle X\rangle\_{t}-K,0). |  |

  where âŸ¨XâŸ©delimited-âŸ¨âŸ©ğ‘‹\langle X\rangle is the quadratic variation of Xğ‘‹X.
* â€¢

  Down-and-Out barrier call options with maturity 1, strikes K=0.9,0.92,0.94,â€¦,1.01,1.03ğ¾
  0.90.920.94â€¦1.011.03K=0.9,0.92,0.94,\ldots,1.01,1.03 and barrier levels L=0.6,0.62,0.64,â€¦,0.88,0.9ğ¿
  0.60.620.64â€¦0.880.9L=0.6,0.62,0.64,\ldots,0.88,0.9:

  |  |  |  |
  | --- | --- | --- |
  |  | Î¦:={maxâ¡(Xtâˆ’K,0)ifÂ â€‹minsâˆˆ[0,t]â¡Xs>L0else.assignÎ¦casessubscriptğ‘‹ğ‘¡ğ¾0ifÂ subscriptğ‘ 0ğ‘¡subscriptğ‘‹ğ‘ ğ¿0else\Phi:=\begin{cases}\max(X\_{t}-K,0)&\mbox{if }\min\_{s\in[0,t]}X\_{s}>L\\ 0&\mbox{else}.\end{cases} |  |

The option prices are generated from a Black-Scholes model with volatility Ïƒ=0.2ğœ0.2\sigma=0.2:

|  |  |  |
| --- | --- | --- |
|  | dâ€‹Xt=Ïƒâ€‹Xtâ€‹dâ€‹Wt.ğ‘‘subscriptğ‘‹ğ‘¡ğœsubscriptğ‘‹ğ‘¡ğ‘‘subscriptğ‘Šğ‘¡dX\_{t}=\sigma X\_{t}dW\_{t}. |  |

The optimisation ([14](#S7.E14 "In 7. Calibration â€£ Sig-SDEs model for quantitative finance.")) was then solved to calibrate the model parameters â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾superscriptsubscriptâ„2ğ‘\ell=\{\ell^{(K)}:K\in\mathcal{I}\_{2}^{N}\}.

Figure [1](#S4.F1 "Figure 1 â€£ 4.1. Calibration â€£ 4. Numerical experiments â€£ Sig-SDEs model for quantitative finance.") shows the absolute error between the real option prices and the option prices of the calibrated model, for the different option types.

### 4.2. Simulation

![Refer to caption](/html/2006.00218/assets/simulation.png)

Figure 2. 1,000 realisations of the calibrated Signature Model.

\Description

Simulation.

Once the Signature Model has been calibrated to the available option prices, we can use Algorithm [1](#algorithm1 "In 5. Simulation â€£ Sig-SDEs model for quantitative finance.") to simulate realisations of the calibrated Signature Model. Figure [2](#S4.F2 "Figure 2 â€£ 4.2. Simulation â€£ 4. Numerical experiments â€£ Sig-SDEs model for quantitative finance.") shows 1,000 realisations of the Signature Model.

### 4.3. Pricing

![Refer to caption](/html/2006.00218/assets/pricing.png)

Figure 3. Error analysis between the option prices of the real model and the calibrated Signature Model.

\Description

Error analysis.

We will now use the calibrated Signature Model to price a new set of options that was not used in the calibration step. This set of option consists of Down-and-In barrier put options with barriers levels L=0.7,0.71,â€¦,0.81,0.82ğ¿

0.70.71â€¦0.810.82L=0.7,0.71,\ldots,0.81,0.82 and strikes K=0.9,0.92,â€¦,1.01,1.03ğ¾

0.90.92â€¦1.011.03K=0.9,0.92,\ldots,1.01,1.03:

|  |  |  |
| --- | --- | --- |
|  | Î¦:={maxâ¡(Kâˆ’Xt,0)ifÂ â€‹minsâˆˆ[0,t]â¡Xs<L0else.assignÎ¦casesğ¾subscriptğ‘‹ğ‘¡0ifÂ subscriptğ‘ 0ğ‘¡subscriptğ‘‹ğ‘ ğ¿0else\Phi:=\begin{cases}\max(K-X\_{t},0)&\mbox{if }\min\_{s\in[0,t]}X\_{s}<L\\ 0&\mbox{else}.\end{cases} |  |

Figure [3](#S4.F3 "Figure 3 â€£ 4.3. Pricing â€£ 4. Numerical experiments â€£ Sig-SDEs model for quantitative finance.") shows the absolute error of the prices under the Signature Model, compared to the real prices.

As we see, the calibrated model is able to generate accurate prices for these new exotic options. The error is highest when the barrier is close to the strike price, as expected.

## 5. Simulation

This section will address the question of simulation efficiency of Signature Models. We begin by stating the following two results. The first result rewrites the differential equation ([9](#S3.E9 "In Definition 3.1 (Signature Model). â€£ 3. Signature Model â€£ Sig-SDEs model for quantitative finance.")) solely in terms of the lead-lag signature of the Brownian motion, ğ•^0,tLâ€‹Lsuperscriptsubscript^ğ•

0ğ‘¡ğ¿ğ¿\mathbb{\widehat{W}}\_{0,t}^{LL}. Here ğ•^Lâ€‹Lsuperscript^ğ•ğ¿ğ¿\widehat{\mathbb{W}}^{LL} denotes the lead-lag transformation of W^^ğ‘Š\widehat{W}, see Appendix [B](#A2 "Appendix B Time and Lead-lag transformation â€£ Sig-SDEs model for quantitative finance."). We use the lead-lag transformation because it allows us to rewrite ItÃ´ integrals as certain Stratonovich integrals, which in turn can be written as linear functions on signatures. The second result guarantees that the computational cost of computing ğ•^0,tLâ€‹Lsuperscriptsubscript^ğ•

0ğ‘¡ğ¿ğ¿\mathbb{\widehat{W}}\_{0,t}^{LL} is the same as the cost of computing {ğ•^0,sLâ€‹L;â€„0â‰¤sâ‰¤t}

superscriptsubscript^ğ•

0ğ‘ ğ¿ğ¿â€„0
ğ‘ ğ‘¡\{\mathbb{\widehat{W}}\_{0,s}^{LL}\;;\;0\leq s\leq t\}. These two results lead to Algorithm [1](#algorithm1 "In 5. Simulation â€£ Sig-SDEs model for quantitative finance."), which provides an efficient algorithm to sample from a Signature Model.

###### Proposition 5.1 ((Lyons etÂ al., [2019](#bib.bib23), Lemma 3.11)).

Let Xğ‘‹X follow a Signature Model with parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾subscriptsuperscriptâ„ğ‘2\ell=\{\ell^{(K)}:K\in\mathcal{I}^{N}\_{2}\}. Then, Xğ‘‹X is given by

|  |  |  |  |
| --- | --- | --- | --- |
| (10) |  | Xt=âŸ¨xâ€‹(Ã¸)+â„“âŠ—(4),ğ•^0,tLâ€‹LâŸ©subscriptğ‘‹ğ‘¡  ğ‘¥italic-Ã¸tensor-productâ„“4superscriptsubscript^ğ•  0ğ‘¡ğ¿ğ¿X\_{t}=\langle x(\o)+\ell\otimes(4),\widehat{\mathbb{W}}\_{0,t}^{LL}\rangle |  |

where â„“âŠ—(4)={KâŠ—(4):Kâˆˆâ„“}tensor-productâ„“4conditional-settensor-productğ¾4ğ¾â„“\ell\otimes(4)=\{K\otimes(4):K\in\ell\}, x=X0âˆˆâ„ğ‘¥subscriptğ‘‹0â„x=X\_{0}\in\mathbb{R}, and ğ•^Lâ€‹Lsuperscript^ğ•ğ¿ğ¿\widehat{\mathbb{W}}^{LL} denotes the lead-lag transformation, introduced in Definition [B.1](#A2.Thmtheorem1 "Definition B.1 (Lead-lag transformation). â€£ Appendix B Time and Lead-lag transformation â€£ Sig-SDEs model for quantitative finance."), of the 2-dimensional process W^=(t,Wt)^ğ‘Šğ‘¡subscriptğ‘Šğ‘¡\widehat{W}=(t,W\_{t}).

###### Theorem 5.2 (Chenâ€™s identity, (Lyons, [1998](#bib.bib26), Theorem 2.12)).

Let 0â‰¤sâ‰¤t0ğ‘ ğ‘¡0\leq s\leq t. Then, for each multi-index Kâˆˆâ„dğ¾subscriptâ„ğ‘‘K\in\mathcal{I}\_{d} we have

|  |  |  |  |
| --- | --- | --- | --- |
| (11) |  | ğ•^0,tLâ€‹L,(K)=âˆ‘I,Jâˆˆâ„dIâŠ—J=Kğ•^0,tLâ€‹L,(I)â‹…ğ•^0,tLâ€‹L,(J)superscriptsubscript^ğ•  0ğ‘¡  ğ¿ğ¿ğ¾subscript    ğ¼ğ½ subscriptâ„ğ‘‘tensor-productğ¼ğ½ğ¾â‹…superscriptsubscript^ğ•  0ğ‘¡  ğ¿ğ¿ğ¼superscriptsubscript^ğ•  0ğ‘¡  ğ¿ğ¿ğ½\widehat{\mathbb{W}}\_{0,t}^{LL,(K)}=\sum\_{\begin{subarray}{c}I,J\in\mathcal{I}\_{d}\\ I\otimes J=K\end{subarray}}\widehat{\mathbb{W}}\_{0,t}^{LL,(I)}\cdot\widehat{\mathbb{W}}\_{0,t}^{LL,(J)} |  |

where for any multi-index Kâˆˆâ„dğ¾subscriptâ„ğ‘‘K\in\mathcal{I}\_{d} we used the notation ğ•^0,tLâ€‹L,(K)=âŸ¨K,ğ•^0,tLâ€‹LâŸ©superscriptsubscript^ğ•

0ğ‘¡

ğ¿ğ¿ğ¾

ğ¾superscriptsubscript^ğ•

0ğ‘¡ğ¿ğ¿\widehat{\mathbb{W}}\_{0,t}^{LL,(K)}=\langle K,\widehat{\mathbb{W}}\_{0,t}^{LL}\rangle.

These two results lead to Algorithm [1](#algorithm1 "In 5. Simulation â€£ Sig-SDEs model for quantitative finance."). We note there are a number of publicly available software packages to compute signatures, such as esig 111<https://pypi.org/project/esig/>, iisignature 222<https://github.com/bottler/iisignature>, (Reizenstein and
Graham, [2020](#bib.bib28)) and signatory 333<https://github.com/patrick-kidger/signatory>, (Kidger and Lyons, [2020](#bib.bib18)).

Parameters :Â 
D={ti}i=1nğ·superscriptsubscriptsubscriptğ‘¡ğ‘–ğ‘–1ğ‘›D=\{t\_{i}\}\_{i=1}^{n} with 0=t0<t1<â€¦<tnâˆ’1<tn=T0subscriptğ‘¡0subscriptğ‘¡1â€¦subscriptğ‘¡ğ‘›1subscriptğ‘¡ğ‘›ğ‘‡0=t\_{0}<t\_{1}<\ldots<t\_{n-1}<t\_{n}=T: sampling times.

â„“={â„“(K):Kâˆˆâ„4N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾subscriptsuperscriptâ„ğ‘4\ell=\{\ell^{(K)}:K\in\mathcal{I}^{N}\_{4}\}: Signature Model parameter.

xâˆˆâ„ğ‘¥â„x\in\mathbb{R}: initial spot price.

Output: A sample path {Xtk}k=0nsuperscriptsubscriptsubscriptğ‘‹subscriptğ‘¡ğ‘˜ğ‘˜0ğ‘›\{X\_{t\_{k}}\}\_{k=0}^{n} from the Signature Model.

1
Simulate a one-dimensional Brownian motion at the sampling times {Wti}i=0nsuperscriptsubscriptsubscriptğ‘Šsubscriptğ‘¡ğ‘–ğ‘–0ğ‘›\{W\_{t\_{i}}\}\_{i=0}^{n}.

2
Apply the lead-lag transformation ([25](#A2.E25 "In Definition B.1 (Lead-lag transformation). â€£ Appendix B Time and Lead-lag transformation â€£ Sig-SDEs model for quantitative finance.")) to W^^ğ‘Š\widehat{W} to obtain W^Lâ€‹Lsuperscript^ğ‘Šğ¿ğ¿\widehat{W}^{LL}.

3
ğ•^0,0Lâ€‹Lâ†{F(K):Kâˆˆâ„4N+1}â†subscriptsuperscript^ğ•ğ¿ğ¿

00conditional-setsuperscriptğ¹ğ¾ğ¾superscriptsubscriptâ„4ğ‘1\widehat{\mathbb{W}}^{LL}\_{0,0}\leftarrow\{F^{(K)}:K\in\mathcal{I}\_{4}^{N+1}\} with F(Ã¸)=1superscriptğ¹italic-Ã¸1F^{(\o)}=1 and F(K)=0superscriptğ¹ğ¾0F^{(K)}=0 for Kâ‰ Ã¸ğ¾italic-Ã¸K\neq\o.

4
X0â†xâ†subscriptğ‘‹0ğ‘¥X\_{0}\leftarrow x.

5
forÂ *k=1,â€¦,nğ‘˜

1â€¦ğ‘›k=1,\ldots,n*Â do

6Â Â Â Â Â Â 
Compute the signature ğ•^tkâˆ’1,tkLâ€‹L={ğ•^tkâˆ’1,tkLâ€‹L,(K):Kâˆˆâ„4N+1}subscriptsuperscript^ğ•ğ¿ğ¿

subscriptğ‘¡ğ‘˜1subscriptğ‘¡ğ‘˜conditional-setsuperscriptsubscript^ğ•

subscriptğ‘¡ğ‘˜1subscriptğ‘¡ğ‘˜

ğ¿ğ¿ğ¾ğ¾superscriptsubscriptâ„4ğ‘1\widehat{\mathbb{W}}^{LL}\_{t\_{k-1},t\_{k}}=\{\widehat{\mathbb{W}}\_{t\_{k-1},t\_{k}}^{LL,(K)}:K\in\mathcal{I}\_{4}^{N+1}\}.

7Â Â Â Â Â Â 
Use Chenâ€™s identity (Theorem [5.2](#S5.Thmtheorem2 "Theorem 5.2 (Chenâ€™s identity, (Lyons, 1998, Theorem 2.12)). â€£ 5. Simulation â€£ Sig-SDEs model for quantitative finance.")) to compute the signature ğ•^0,tkLâ€‹Lâ†{ğ•^0,tkLâ€‹L,K:Kâˆˆâ„4N+1}â†subscriptsuperscript^ğ•ğ¿ğ¿

0subscriptğ‘¡ğ‘˜conditional-setsuperscriptsubscript^ğ•

0subscriptğ‘¡ğ‘˜

ğ¿ğ¿ğ¾ğ¾superscriptsubscriptâ„4ğ‘1\widehat{\mathbb{W}}^{LL}\_{0,t\_{k}}\leftarrow\{\widehat{\mathbb{W}}\_{0,t\_{k}}^{LL,K}:K\in\mathcal{I}\_{4}^{N+1}\}

8Â Â Â Â Â Â 
Use proposition [5.1](#S5.Thmtheorem1 "Proposition 5.1 ((Lyons et al., 2019, Lemma 3.11)). â€£ 5. Simulation â€£ Sig-SDEs model for quantitative finance.") to get Xtkâ†âŸ¨xâ€‹(Ã¸)+â„“âŠ—(4),ğ•^0,tkLâ€‹LâŸ©â†subscriptğ‘‹subscriptğ‘¡ğ‘˜

ğ‘¥italic-Ã¸tensor-productâ„“4superscriptsubscript^ğ•

0subscriptğ‘¡ğ‘˜ğ¿ğ¿X\_{t\_{k}}\leftarrow\langle x(\o)+\ell\otimes(4),\widehat{\mathbb{W}}\_{0,t\_{k}}^{LL}\rangle.

9 end for

return *{Xtk}k=0nsuperscriptsubscriptsubscriptğ‘‹subscriptğ‘¡ğ‘˜ğ‘˜0ğ‘›\{X\_{t\_{k}}\}\_{k=0}^{n}.*

AlgorithmÂ 1 Sampling from a Signature Model.

## 6. Pricing

This section will show that exotic options can be priced fast under a Signature Model. This will be done via a two step procedure. First, it was shown in (Lyons
etÂ al., [2019](#bib.bib23), [2020](#bib.bib24)) that prices of exotic options can be approximated with arbitrary precision by a special class of payoffs called signature payoffs, defined below. Hence, we will assume that the exotic option to be priced is a signature payoff, defined as follows.

###### Definition 6.1 (Signature payoffs).

A signature payoff of maturity T>0ğ‘‡0T>0 and parameter f={f(K):Kâˆˆâ„3N}ğ‘“conditional-setsuperscriptğ‘“ğ¾ğ¾subscriptsuperscriptâ„ğ‘3f=\{f^{(K)}:K\in\mathcal{I}^{N}\_{3}\} is a payoff that pays at time Tğ‘‡T an amount given by âŸ¨f,ğ•^0,TâŸ©

ğ‘“subscript^ğ•

0ğ‘‡\langle f,\mathbb{\widehat{X}}\_{0,T}\rangle.

Second, the price of a signature payoff is âŸ¨f,ğ”¼â€‹[ğ•^0,T]âŸ©

ğ‘“ğ”¼delimited-[]subscript^ğ•

0ğ‘‡\langle f,\mathbb{E}[\mathbb{\widehat{X}}\_{0,T}]\rangle. To price a signature payoff, all we need is ğ”¼â€‹[[]â€‹ğ•^0,T]ğ”¼delimited-[]


subscript^ğ•

0ğ‘‡\mathbb{E}\left[[\right]\mathbb{\widehat{X}}\_{0,T}], which doesnâ€™t depend on the signature payoff itself. In particular, it may be reused to price other signature payoffs.

We now explicitly derive the expected signature ğ”¼â€‹[[]â€‹ğ•^0,T]ğ”¼delimited-[]


subscript^ğ•

0ğ‘‡\mathbb{E}\left[[\right]\mathbb{\widehat{X}}\_{0,T}] in terms of the model parameters and the expected signature of the lead-lag Brownian motion ğ”¼â€‹[[]â€‹ğ•^0,TLâ€‹L]ğ”¼delimited-[]


subscriptsuperscript^ğ•ğ¿ğ¿

0ğ‘‡\mathbb{E}\left[[\right]\mathbb{\widehat{W}}^{LL}\_{0,T}].

###### Proposition 6.2.

Let Xğ‘‹X be a Signature Model of order Nâˆˆâ„•ğ‘â„•N\in\mathbb{N} with parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾subscriptsuperscriptâ„ğ‘2\ell=\{\ell^{(K)}:K\in\mathcal{I}^{N}\_{2}\}. Consider the following linear functionals P1=(1)subscriptğ‘ƒ11P\_{1}=(1) and P2=â„“âŠ—(4)subscriptğ‘ƒ2tensor-productâ„“4P\_{2}=\ell\otimes(4). Consider any multi-index I=(i1,â€¦,in)âˆˆâ„2nğ¼subscriptğ‘–1â€¦subscriptğ‘–ğ‘›superscriptsubscriptâ„2ğ‘›I=(i\_{1},\ldots,i\_{n})\in\mathcal{I}\_{2}^{n} such that nâ‰¤Nğ‘›ğ‘n\leq N. Then

|  |  |  |  |
| --- | --- | --- | --- |
| (12) |  | ğ•s,t(I)=âŸ¨CIâ€‹(â„“),ğ•^s,tLâ€‹LâŸ©superscriptsubscriptğ•  ğ‘ ğ‘¡ğ¼  subscriptğ¶ğ¼â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\mathbb{X}\_{s,t}^{(I)}=\langle C\_{I}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |

where CIâ€‹(â„“)subscriptğ¶ğ¼â„“C\_{I}(\ell) is given explicitly in closed-form by

|  |  |  |  |
| --- | --- | --- | --- |
| (13) |  | CIâ€‹(â„“)=(â€¦â€‹((Pi1â‰»Pi2)â‰»Pi3)â‰»â€¦â‰»Pin)subscriptğ¶ğ¼â„“succeedsâ€¦succeedssucceedssubscriptğ‘ƒsubscriptğ‘–1subscriptğ‘ƒsubscriptğ‘–2subscriptğ‘ƒsubscriptğ‘–3â€¦succeedssubscriptğ‘ƒsubscriptğ‘–ğ‘›C\_{I}(\ell)=(\ldots((P\_{i\_{1}}\succ P\_{i\_{2}})\succ P\_{i\_{3}})\succ\ldots\succ P\_{i\_{n}}) |  |

###### Proof.

By Proposition [5.1](#S5.Thmtheorem1 "Proposition 5.1 ((Lyons et al., 2019, Lemma 3.11)). â€£ 5. Simulation â€£ Sig-SDEs model for quantitative finance.") we know that if Xğ‘‹X follows a Signature Model with parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾subscriptsuperscriptâ„ğ‘2\ell=\{\ell^{(K)}:K\in\mathcal{I}^{N}\_{2}\} then

|  |  |  |
| --- | --- | --- |
|  | Xt=âŸ¨xâ€‹(Ã¸)+â„“âŠ—(4),ğ•^0,tLâ€‹LâŸ©subscriptğ‘‹ğ‘¡  ğ‘¥italic-Ã¸tensor-productâ„“4superscriptsubscript^ğ•  0ğ‘¡ğ¿ğ¿X\_{t}=\langle x(\o)+\ell\otimes(4),\widehat{\mathbb{W}}\_{0,t}^{LL}\rangle |  |

Let I=(i1,â€¦,in)ğ¼subscriptğ‘–1â€¦subscriptğ‘–ğ‘›I=(i\_{1},\ldots,i\_{n}) be any multi-index in â„2nsuperscriptsubscriptâ„2ğ‘›\mathcal{I}\_{2}^{n} such that nâ‰¤Nğ‘›ğ‘n\leq N. If n=1ğ‘›1n=1 then I=(i1)ğ¼subscriptğ‘–1I=(i\_{1}) and we necessarily one of the following two options must hold

* â€¢

  If i1=1subscriptğ‘–11i\_{1}=1 then ğ•s,t(i1)=tâˆ’s=ğ•^s,tLâ€‹L,(1)=âŸ¨P1,ğ•^s,tLâ€‹LâŸ©superscriptsubscriptğ•
  ğ‘ ğ‘¡subscriptğ‘–1ğ‘¡ğ‘ superscriptsubscript^ğ•
  ğ‘ ğ‘¡
  ğ¿ğ¿1
  subscriptğ‘ƒ1superscriptsubscript^ğ•
  ğ‘ ğ‘¡ğ¿ğ¿\mathbb{X}\_{s,t}^{(i\_{1})}=t-s=\widehat{\mathbb{W}}\_{s,t}^{LL,(1)}=\langle P\_{1},\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle
* â€¢

  If i1=2subscriptğ‘–12i\_{1}=2 then ğ•s,t(i1)=Xtâˆ’Xs=âŸ¨â„“âŠ—(4),ğ•^s,tLâ€‹LâŸ©=âŸ¨P2,ğ•^s,tLâ€‹LâŸ©superscriptsubscriptğ•
  ğ‘ ğ‘¡subscriptğ‘–1subscriptğ‘‹ğ‘¡subscriptğ‘‹ğ‘ 
  tensor-productâ„“4superscriptsubscript^ğ•
  ğ‘ ğ‘¡ğ¿ğ¿
  subscriptğ‘ƒ2superscriptsubscript^ğ•
  ğ‘ ğ‘¡ğ¿ğ¿\mathbb{X}\_{s,t}^{(i\_{1})}=X\_{t}-X\_{s}=\langle\ell\otimes(4),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle=\langle P\_{2},\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle.

Hence the statement holds for n=1ğ‘›1n=1. Letâ€™s assume by induction that the statement holds for any 1â‰¤nâ‰¤N1ğ‘›ğ‘1\leq n\leq N. We write I=JâŠ—(in)ğ¼tensor-productğ½subscriptğ‘–ğ‘›I=J\otimes(i\_{n}) with inâˆˆ{1,2}subscriptğ‘–ğ‘›12i\_{n}\in\{1,2\} and J=(i1,â€¦,inâˆ’1)âˆˆâ„2nâˆ’1ğ½subscriptğ‘–1â€¦subscriptğ‘–ğ‘›1superscriptsubscriptâ„2ğ‘›1J=(i\_{1},\ldots,i\_{n-1})\in\mathcal{I}\_{2}^{n-1}. Clearly |(in)|,|J|<n

subscriptğ‘–ğ‘›ğ½
ğ‘›|(i\_{n})|,|J|<n, therefore by induction hypothesis

|  |  |  |
| --- | --- | --- |
|  | ğ•s,t(in)=âŸ¨C(in)â€‹(â„“),ğ•^s,tLâ€‹LâŸ©=âŸ¨Pin,ğ•^s,tLâ€‹LâŸ©superscriptsubscriptğ•  ğ‘ ğ‘¡subscriptğ‘–ğ‘›  subscriptğ¶subscriptğ‘–ğ‘›â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿  subscriptğ‘ƒsubscriptğ‘–ğ‘›superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\mathbb{X}\_{s,t}^{(i\_{n})}=\langle C\_{(i\_{n})}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle=\langle P\_{i\_{n}},\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |

and

|  |  |  |
| --- | --- | --- |
|  | ğ•s,t(J)=âŸ¨CJâ€‹(â„“),ğ•^s,tLâ€‹LâŸ©=âŸ¨(â€¦â€‹(Pi1â‰»Pi2)â‰»â€¦â‰»Pinâˆ’1),ğ•^s,tLâ€‹LâŸ©superscriptsubscriptğ•  ğ‘ ğ‘¡ğ½  subscriptğ¶ğ½â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿  succeedsâ€¦succeedssubscriptğ‘ƒsubscriptğ‘–1subscriptğ‘ƒsubscriptğ‘–2â€¦succeedssubscriptğ‘ƒsubscriptğ‘–ğ‘›1superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\displaystyle\mathbb{X}\_{s,t}^{(J)}=\langle C\_{J}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle=\langle(\ldots(P\_{i\_{1}}\succ P\_{i\_{2}})\succ\ldots\succ P\_{i\_{n-1}}),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |

By definition of the signature (see [2.6](#S2.Thmtheorem6 "Definition 2.6 (Signature). â€£ 2.3. Signatures â€£ 2. Notation and preliminaries â€£ Sig-SDEs model for quantitative finance.")) we know that

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ•s,t(I)superscriptsubscriptğ•  ğ‘ ğ‘¡ğ¼\displaystyle\mathbb{X}\_{s,t}^{(I)} | =âˆ«stğ•s,u(J)âˆ˜ğ‘‘ğ•u(in)absentsuperscriptsubscriptğ‘ ğ‘¡superscriptsubscriptğ•  ğ‘ ğ‘¢ğ½differential-dsuperscriptsubscriptğ•ğ‘¢subscriptğ‘–ğ‘›\displaystyle=\int\_{s}^{t}\mathbb{X}\_{s,u}^{(J)}\circ d\mathbb{X}\_{u}^{(i\_{n})} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ«stâŸ¨CJâ€‹(â„“),ğ•^s,tLâ€‹LâŸ©âˆ˜dâ€‹âŸ¨C(in)â€‹(â„“),ğ•^s,tLâ€‹LâŸ©absentsuperscriptsubscriptğ‘ ğ‘¡  subscriptğ¶ğ½â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿ ğ‘‘  subscriptğ¶subscriptğ‘–ğ‘›â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\displaystyle=\int\_{s}^{t}\langle C\_{J}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle\circ d\langle C\_{(i\_{n})}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âŸ¨CJâ€‹(â„“)â‰»C(in)â€‹(â„“),ğ•^s,tLâ€‹LâŸ©absentdelimited-âŸ¨âŸ©succeedssubscriptğ¶ğ½â„“  subscriptğ¶subscriptğ‘–ğ‘›â„“superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\displaystyle=\langle C\_{J}(\ell)\succ C\_{(i\_{n})}(\ell),\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âŸ¨(â€¦â€‹(Pi1â‰»Pi2)â‰»â€¦â‰»Pinâˆ’1)â‰»Pin,ğ•^s,tLâ€‹LâŸ©absentdelimited-âŸ¨âŸ©succeedssucceedsâ€¦succeedssubscriptğ‘ƒsubscriptğ‘–1subscriptğ‘ƒsubscriptğ‘–2â€¦succeedssubscriptğ‘ƒsubscriptğ‘–ğ‘›1  subscriptğ‘ƒsubscriptğ‘–ğ‘›superscriptsubscript^ğ•  ğ‘ ğ‘¡ğ¿ğ¿\displaystyle=\langle(\ldots(P\_{i\_{1}}\succ P\_{i\_{2}})\succ\ldots\succ P\_{i\_{n-1}})\succ P\_{i\_{n}},\widehat{\mathbb{W}}\_{s,t}^{LL}\rangle |  |

which concludes the induction.
âˆ

## 7. Calibration

We will now address the task of calibrating a Signature Model. We assume that the market has a family of options {Î¦i}i=1nsuperscriptsubscriptsubscriptÎ¦ğ‘–ğ‘–1ğ‘›\{\Phi\_{i}\}\_{i=1}^{n} whose market prices {pi}i=1nsuperscriptsubscriptsubscriptğ‘ğ‘–ğ‘–1ğ‘›\{p\_{i}\}\_{i=1}^{n} are observable. Typically {Î¦i}i=1nsuperscriptsubscriptsubscriptÎ¦ğ‘–ğ‘–1ğ‘›\{\Phi\_{i}\}\_{i=1}^{n} will contain vanilla options, together with some exotic options such as various variance or barrier products. Fix Nâˆˆâ„•ğ‘â„•N\in\mathbb{N} be the order of the Signature Model. The challenge here is to find the model parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾superscriptsubscriptâ„2ğ‘\ell=\{\ell^{(K)}:K\in\mathcal{I}\_{2}^{N}\} that best fits the data, in the sense that the prices of Î¦isubscriptÎ¦ğ‘–\Phi\_{i}, under the Signature Model with parameter â„“â„“\ell, are approximately given by the observed market prices pisubscriptğ‘ğ‘–p\_{i}.

Following Section [6](#S6 "6. Pricing â€£ Sig-SDEs model for quantitative finance."), we assume that the options Î¦isubscriptÎ¦ğ‘–\Phi\_{i} are given by signature options. Therefore, we assume that we can write Î¦isubscriptÎ¦ğ‘–\Phi\_{i} by

|  |  |  |
| --- | --- | --- |
|  | Î¦i=âŸ¨Ï†i,ğ•^0,TâŸ©,Ï†i={Ï†i(K):Kâˆˆâ„2N}.formulae-sequencesubscriptÎ¦ğ‘–  subscriptğœ‘ğ‘–subscript^ğ•  0ğ‘‡subscriptğœ‘ğ‘–conditional-setsuperscriptsubscriptğœ‘ğ‘–ğ¾ğ¾superscriptsubscriptâ„2ğ‘\Phi\_{i}=\langle\varphi\_{i},\widehat{\mathbb{X}}\_{0,T}\rangle,\quad\varphi\_{i}=\{\varphi\_{i}^{(K)}:K\in\mathcal{I}\_{2}^{N}\}. |  |

The minimisation problem we aim to solve now is the following:

|  |  |  |  |
| --- | --- | --- | --- |
| (14) |  | minâ„“={â„“(K):Kâˆˆâ„2N}â€‹âˆ‘i=1n(âŸ¨Ï†i,ğ”¼â€‹[ğ•^0,T]âŸ©âˆ’pi)2.subscriptâ„“conditional-setsuperscriptâ„“ğ¾ğ¾superscriptsubscriptâ„2ğ‘superscriptsubscriptğ‘–1ğ‘›superscript  subscriptğœ‘ğ‘–ğ”¼delimited-[]subscript^ğ•  0ğ‘‡ subscriptğ‘ğ‘–2\min\_{\ell=\{\ell^{(K)}:K\in\mathcal{I}\_{2}^{N}\}}\sum\_{i=1}^{n}\left(\langle\varphi\_{i},\mathbb{E}[\widehat{\mathbb{X}}\_{0,T}]\rangle-p\_{i}\right)^{2}. |  |

where ğ”¼â€‹[ğ•^0,T]ğ”¼delimited-[]subscript^ğ•

0ğ‘‡\mathbb{E}[\widehat{\mathbb{X}}\_{0,T}] is the expected signature of the Signature Model with parameter â„“={â„“(K):Kâˆˆâ„2N}â„“conditional-setsuperscriptâ„“ğ¾ğ¾superscriptsubscriptâ„2ğ‘\ell=\{\ell^{(K)}:K\in\mathcal{I}\_{2}^{N}\}.

By Proposition [6.2](#S6.Thmtheorem2 "Proposition 6.2. â€£ 6. Pricing â€£ Sig-SDEs model for quantitative finance."), the price of Î¦isubscriptÎ¦ğ‘–\Phi\_{i}, which is given by âŸ¨Ï†i,ğ”¼â€‹[ğ•^0,T]âŸ©

subscriptğœ‘ğ‘–ğ”¼delimited-[]subscript^ğ•

0ğ‘‡\langle\varphi\_{i},\mathbb{E}[\widehat{\mathbb{X}}\_{0,T}]\rangle, can be written as a polynomial on â„“(K)superscriptâ„“ğ¾\ell^{(K)}. Hence, the optimisation ([14](#S7.E14 "In 7. Calibration â€£ Sig-SDEs model for quantitative finance.")) is rewritten as a minimisation of a polynomial of variables â„“(K)superscriptâ„“ğ¾\ell^{(K)}, for Kâˆˆâ„2Nğ¾superscriptsubscriptâ„2ğ‘K\in\mathcal{I}\_{2}^{N}.

If the number of parameters â„“(K)superscriptâ„“ğ¾\ell^{(K)} is large compared to the number of available option prices, the optimisation problem might be overparametrised and there will be multiple solutions to ([14](#S7.E14 "In 7. Calibration â€£ Sig-SDEs model for quantitative finance.")). In this case, we are in the robust finance setting where there are multiple equivalent martingale measures that fit to the data. If the number of parameters â„“(K)superscriptâ„“ğ¾\ell^{(K)} is small, however, we are in the setting of classical mathematical finance modeling and there will in general be a unique solution to ([14](#S7.E14 "In 7. Calibration â€£ Sig-SDEs model for quantitative finance.")).

## 8. Conclusion

In this paper we have proposed a new model for asset price dynamics called the signature model. This model was develop with the objective of satisfying the following properties:

1. (1)

   Universality.
2. (2)

   Efficiency of calibration to vanilla and exotic options.
3. (3)

   Fast pricing of vanilla and exotic options.
4. (4)

   Efficiency of simulation.

Due to the rich properties of signatures, the signature model satisfies all four properties and is, therefore, capable of generating realistic paths without sacrificing the computational feasibility of calibration, pricing and simulation.

Although this paper has focused on the risk-neutral measure â„šâ„š\mathbb{Q}, it can also be used to learn the real-world measure â„™â„™\mathbb{P}. One would first calibrate to the risk-neutral measure â„šâ„š\mathbb{Q} and then learn the drift.

###### Acknowledgements.

This work was supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1.

## References

* (1)
* Acciaio etÂ al. (2019)

  Beatrice Acciaio, Julio
  Backhoff-Veraguas, and Anastasiia Zalashko.
  2019.
  Causal optimal transport and its links to
  enlargement of filtrations and continuous-time stochastic optimization.
  *Stochastic Processes and their Applications*
  (2019).
* Boedihardjo etÂ al. (2016)

  Horatio Boedihardjo, Xi
  Geng, Terry Lyons, and Danyu Yang.
  2016.
  The signature of a rough path: uniqueness.
  *Advances in Mathematics*
  293 (2016), 720â€“737.
* Breeden and
  Litzenberger (1978)

  DouglasÂ T Breeden and
  RobertÂ H Litzenberger. 1978.
  Prices of state-contingent claims implicit in
  option prices.
  *Journal of business* (1978),
  621â€“651.
* Cartea etÂ al. (2020)

  Ãlvaro Cartea, Imanol
  PerezÂ Arribas, and Leandro SÃ¡nchez-Betancourt.
  2020.
  Optimal Execution of Foreign Securities: A
  Double-Execution Problem with Signatures and Machine Learning.
  *Available at SSRN* (2020).
* Chevyrev
  etÂ al. (2016)

  Ilya Chevyrev, Terry
  Lyons, etÂ al. 2016.
  Characteristic functions of measures on geometric
  rough paths.
  *The Annals of Probability*
  44, 6 (2016),
  4049â€“4082.
* Chevyrev and
  Oberhauser (2018)

  Ilya Chevyrev and Harald
  Oberhauser. 2018.
  Signature moments to characterize laws of
  stochastic processes.
  *arXiv preprint arXiv:1810.10971*
  (2018).
* Cuchiero
  etÂ al. (2020)

  Christa Cuchiero, Wahid
  Khosrawi, and Josef Teichmann.
  2020.
  A generative adversarial network approach to
  calibration of local stochastic volatility models.
  *arXiv preprint arXiv:2005.02505*
  (2020).
* Fermanian (2019)

  Adeline Fermanian.
  2019.
  Embedding and learning with signatures.
  *arXiv preprint arXiv:1911.13211*
  (2019).
* Flint
  etÂ al. (2016)

  Guy Flint, Ben Hambly,
  and Terry Lyons. 2016.
  Discretely sampled signals and the rough Hoff
  process.
  *Stochastic Processes and their Applications*
  126, 9 (2016),
  2593â€“2614.
* GierjatowiczÂ P. (2020)

  M.Â Siska D. SzpruchÂ L. GierjatowiczÂ P.,
  Sabate-Vidales. 2020.
  Robust Pricing and Hedging with neural SDEs.
  *to appear* (2020).
* Goodfellow etÂ al. (2014)

  Ian Goodfellow, Jean
  Pouget-Abadie, Mehdi Mirza, Bing Xu,
  David Warde-Farley, Sherjil Ozair,
  Aaron Courville, and Yoshua Bengio.
  2014.
  Generative adversarial nets. In
  *Advances in neural information processing
  systems*. 2672â€“2680.
* GyurkÃ³ etÂ al. (2013)

  LajosÂ Gergely GyurkÃ³,
  Terry Lyons, Mark Kontkowski, and
  Jonathan Field. 2013.
  Extracting information from the signature of a
  financial data stream.
  *arXiv preprint arXiv:1307.7244*
  (2013).
* Hambly and Lyons (2010)

  Ben Hambly and Terry
  Lyons. 2010.
  Uniqueness for the signature of a path of bounded
  variation and the reduced path group.
  *Annals of Mathematics*
  (2010), 109â€“167.
* Kalsi
  etÂ al. (2020)

  Jasdeep Kalsi, Terry
  Lyons, and ImanolÂ Perez Arribas.
  2020.
  Optimal execution with rough path signatures.
  *SIAM Journal on Financial Mathematics*
  11, 2 (2020),
  470â€“493.
* Karatzas and
  Shreve (2012)

  Ioannis Karatzas and
  Steven Shreve. 2012.
  *Brownian motion and stochastic calculus.
  Vol. Vol. 113*.
  Springer Science & Business Media.
* Kidger etÂ al. (2019)

  Patrick Kidger, Patric
  Bonnier, ImanolÂ Perez Arribas, Cristopher
  Salvi, and Terry Lyons.
  2019.
  Deep Signature Transforms. In
  *Advances in Neural Information Processing
  Systems*. 3099â€“3109.
* Kidger and Lyons (2020)

  Patrick Kidger and Terry
  Lyons. 2020.
  Signatory: differentiable computations of the
  signature and logsignature transforms, on both CPU and GPU.
  *arXiv preprint arXiv:2001.00706*
  (2020).
* Kingma and
  Welling (2013)

  DiederikÂ P Kingma and
  Max Welling. 2013.
  Auto-encoding variational bayes.
  *arXiv preprint arXiv:1312.6114*
  (2013).
* KirÃ¡ly and
  Oberhauser (2016)

  FranzÂ J KirÃ¡ly and
  Harald Oberhauser. 2016.
  Kernels for sequentially ordered data.
  *arXiv preprint arXiv:1601.08169*
  (2016).
* Levin
  etÂ al. (2013)

  Daniel Levin, Terry
  Lyons, and Hao Ni. 2013.
  Learning from the past, predicting the statistics
  for the future, learning an evolving system.
  *arXiv preprint arXiv:1309.0260*
  (2013).
* Li etÂ al. (2017)

  Chenyang Li, Xin Zhang,
  and Lianwen Jin. 2017.
  Lpsnet: A novel log path signature feature based
  hand gesture recognition framework. In *Proceedings
  of the IEEE International Conference on Computer Vision Workshops*.
  631â€“639.
* Lyons
  etÂ al. (2019)

  Terry Lyons, Sina Nejad,
  and ImanolÂ Perez Arribas.
  2019.
  Nonparametric pricing and hedging of exotic
  derivatives.
  *arXiv preprint arXiv:1905.00711*
  (2019).
* Lyons
  etÂ al. (2020)

  Terry Lyons, Sina Nejad,
  and Imanol PerezÂ Arribas.
  2020.
  Numerical Method for Model-free Pricing of Exotic
  Derivatives in Discrete Time Using Rough Path Signatures.
  *Applied Mathematical Finance*
  (2020), 1â€“15.
* Lyons
  etÂ al. (2014)

  Terry Lyons, Hao Ni,
  and Harald Oberhauser. 2014.
  A feature set for streams and an application to
  high-frequency financial tick data. In *Proceedings
  of the 2014 International Conference on Big Data Science and Computing*.
  1â€“8.
* Lyons (1998)

  TerryÂ J Lyons.
  1998.
  Differential equations driven by rough signals.
  *Revista MatemÃ¡tica Iberoamericana*
  14, 2 (1998),
  215â€“310.
* Lyons
  etÂ al. (2007)

  TerryÂ J Lyons, Michael
  Caruana, and Thierry LÃ©vy.
  2007.
  *Differential equations driven by rough
  paths*.
  Springer.
* Reizenstein and
  Graham (2020)

  JeremyÂ F Reizenstein and
  Benjamin Graham. 2020.
  Algorithm 1004: The iisignature library: Efficient
  calculation of iterated-integral signatures and log signatures.
  *ACM Transactions on Mathematical Software
  (TOMS)* 46, 1 (2020),
  1â€“21.
* Vapnik (2013)

  Vladimir Vapnik.
  2013.
  *The nature of statistical learning
  theory*.
  Springer science & business media.
* Xie
  etÂ al. (2017)

  Zecheng Xie, Zenghui Sun,
  Lianwen Jin, Hao Ni, and
  Terry Lyons. 2017.
  Learning spatial-semantic context with fully
  convolutional recurrent network for online handwritten chinese text
  recognition.
  *IEEE transactions on pattern analysis and
  machine intelligence* 40, 8
  (2017), 1903â€“1917.
* Yang
  etÂ al. (2015)

  Weixin Yang, Lianwen Jin,
  and Manfei Liu. 2015.
  Chinese character-level writer identification using
  path signature feature, DropStroke and deep CNN. In
  *2015 13th International Conference on Document
  Analysis and Recognition (ICDAR)*. IEEE, 546â€“550.
* Yang
  etÂ al. (2016a)

  Weixin Yang, Lianwen Jin,
  and Manfei Liu. 2016a.
  Deepwriterid: An end-to-end online text-independent
  writer identification system.
  *IEEE Intelligent Systems*
  31, 2 (2016),
  45â€“53.
* Yang
  etÂ al. (2016b)

  Weixin Yang, Lianwen Jin,
  Hao Ni, and Terry Lyons.
  2016b.
  Rotation-free online handwritten character
  recognition using dyadic path signature features, hanging normalization, and
  deep neural network. In *2016 23rd International
  Conference on Pattern Recognition (ICPR)*. IEEE,
  4083â€“4088.
* Yang
  etÂ al. (2016c)

  Weixin Yang, Lianwen Jin,
  Dacheng Tao, Zecheng Xie, and
  Ziyong Feng. 2016c.
  DropSample: A new training method to enhance deep
  convolutional neural networks for large-scale unconstrained handwritten
  Chinese character recognition.
  *Pattern Recognition* 58
  (2016), 190â€“203.
* Yang
  etÂ al. (2017)

  Weixin Yang, Terry Lyons,
  Hao Ni, Cordelia Schmid,
  Lianwen Jin, and Jiawei Chang.
  2017.
  Leveraging the path signature for skeleton-based
  human action recognition.
  *arXiv preprint arXiv:1707.03993*
  (2017).

## Appendix A Overview of signatures

In this section we state some of the main properties of signatures that are used in this paper.

###### Definition A.1 (Shuffle of multi-indices).

For any two multi-indices I,Jâˆˆâ„d

ğ¼ğ½
subscriptâ„ğ‘‘I,J\in\mathcal{I}\_{d} and 111-dimensional multi-indices a,bâˆˆâ„d1={1,â€¦,d}

ğ‘ğ‘
superscriptsubscriptâ„ğ‘‘11â€¦ğ‘‘a,b\in\mathcal{I}\_{d}^{1}=\{1,\ldots,d\} we define the shuffle product recursively as follows:

|  |  |  |  |
| --- | --- | --- | --- |
| (15) |  | Ã¸â€‹I=Iâ€‹Ã¸=Iitalic-Ã¸ğ¼ğ¼italic-Ã¸ğ¼\o\shuffle I=I\shuffle\o=I |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
| (16) |  | (IâŠ—a)â€‹(JâŠ—b)=((IâŠ—a)â€‹J)âŠ—b+(Iâ€‹(JâŠ—b))âŠ—atensor-productğ¼ğ‘tensor-productğ½ğ‘tensor-producttensor-productğ¼ğ‘ğ½ğ‘tensor-productğ¼tensor-productğ½ğ‘ğ‘(I\otimes a)\shuffle(J\otimes b)=((I\otimes a)\shuffle J)\otimes b+(I\shuffle(J\otimes b))\otimes a |  |

###### Example A.2.

We have the following examples for â„4subscriptâ„4\mathcal{I}\_{4}:

1. (1)

   (1,2)â€‹(3)=(1,2,3)+(1,3,2)+(3,1,2)123123132312(1,2)\shuffle(3)=(1,2,3)+(1,3,2)+(3,1,2).
2. (2)

   (1,2)â€‹(3,4)=2â‹…(1,2,2,4)+(1,2,4,2)+(2,1,2,4)+(2,1,4,2)+(2,4,1,2)1234â‹…212241242212421422412(1,2)\shuffle(3,4)=2\cdot(1,2,2,4)+(1,2,4,2)+(2,1,2,4)+(2,1,4,2)+(2,4,1,2).
3. (3)

   (2,1)â€‹Ã¸=(2,1)21italic-Ã¸21(2,1)\shuffle\o=(2,1).
4. (4)

   Ã¸â€‹(2,1)=(2,1)italic-Ã¸2121\o\shuffle(2,1)=(2,1).

###### Proposition A.3 (Shuffle identity).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} be a continuous semimartingale. For any two multi-indices I,Jâˆˆâ„d

ğ¼ğ½
subscriptâ„ğ‘‘I,J\in\mathcal{I}\_{d} the following identity on the Signature of Xğ‘‹X holds

|  |  |  |  |
| --- | --- | --- | --- |
| (17) |  | âŸ¨Iâ€‹J,ğ•s,tâŸ©=âŸ¨I,ğ•s,tâŸ©â‹…âŸ¨J,ğ•s,tâŸ©:=ğ•s,t(I)â‹…ğ•s,t(J)  ğ¼ğ½subscriptğ•  ğ‘ ğ‘¡ â‹…  ğ¼subscriptğ•  ğ‘ ğ‘¡  ğ½subscriptğ•  ğ‘ ğ‘¡assignâ‹…superscriptsubscriptğ•  ğ‘ ğ‘¡ğ¼superscriptsubscriptğ•  ğ‘ ğ‘¡ğ½\langle I\shuffle J,\mathbb{X}\_{s,t}\rangle=\langle I,\mathbb{X}\_{s,t}\rangle\cdot\langle J,\mathbb{X}\_{s,t}\rangle:=\mathbb{X}\_{s,t}^{(I)}\cdot\mathbb{X}\_{s,t}^{(J)} |  |

###### Proof.

Theorem 2.15 in (Lyons
etÂ al., [2007](#bib.bib27)).
âˆ

###### Proposition A.4 (Uniqueness of the Signature).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d}, Y:[0,T]â†’â„d:ğ‘Œâ†’0ğ‘‡superscriptâ„ğ‘‘Y:[0,T]\to\mathbb{R}^{d} be two continuous semimartingales. Then

|  |  |  |  |
| --- | --- | --- | --- |
| (18) |  | âˆ€tâˆˆ[0,T],Xt=Ytâ‡”âˆ€Kâˆˆâ„d,ğ•s,t(K)=ğ•s,t(K)iffformulae-sequencefor-allğ‘¡0ğ‘‡subscriptğ‘‹ğ‘¡subscriptğ‘Œğ‘¡formulae-sequencefor-allğ¾subscriptâ„ğ‘‘subscriptsuperscriptğ•ğ¾  ğ‘ ğ‘¡subscriptsuperscriptğ•ğ¾  ğ‘ ğ‘¡\forall t\in[0,T],X\_{t}=Y\_{t}\iff\forall K\in\mathcal{I}\_{d},\mathbb{X}^{(K)}\_{s,t}=\mathbb{Y}^{(K)}\_{s,t} |  |

###### Proof.

See main result in (Hambly and Lyons, [2010](#bib.bib14)).
âˆ

###### Proposition A.5 (Factorial decay).

Given a semimartingale X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d}, for any time interval [s,t]âŠ‚[0,T]ğ‘ ğ‘¡0ğ‘‡[s,t]\subset[0,T] and any multi-index Kâˆˆâ„dğ¾subscriptâ„ğ‘‘K\in\mathcal{I}\_{d} such that |K|=nğ¾ğ‘›|K|=n

|  |  |  |  |
| --- | --- | --- | --- |
| (19) |  | |ğ•s,t(K)|=Oâ€‹(1n!)subscriptsuperscriptğ•ğ¾  ğ‘ ğ‘¡ğ‘‚1ğ‘›\big{|}\mathbb{X}^{(K)}\_{s,t}\big{|}=O\left(\frac{1}{n!}\right) |  |

###### Proof.

Proposition 2.2 in (Lyons
etÂ al., [2007](#bib.bib27)).
âˆ

###### Definition A.6.

For a given time interval [0,T]0ğ‘‡[0,T] we call a continuous, surjective, increasing function Ïˆ:[0,T]â†’[0,T]:ğœ“â†’0ğ‘‡0ğ‘‡\psi:[0,T]\to[0,T] a time-reparametrization.

###### Proposition A.7 (Invariance to time-reparametrizations).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} be a semimartingale and Ïˆ:[0,T]â†’[0,T]:ğœ“â†’0ğ‘‡0ğ‘‡\psi:[0,T]\to[0,T] be a time-reparametrization. Then the Signature of Xğ‘‹X has the following invariance property

|  |  |  |  |
| --- | --- | --- | --- |
| (20) |  | ğ•s,t=ğ•Ïˆâ€‹(s),Ïˆâ€‹(t)â€‹âˆ€s,tâˆˆ[0,T]â€‹Â such thatÂ â€‹s<tformulae-sequencesubscriptğ•  ğ‘ ğ‘¡subscriptğ•  ğœ“ğ‘ ğœ“ğ‘¡for-allğ‘ ğ‘¡0ğ‘‡Â such thatÂ ğ‘ ğ‘¡\mathbb{X}\_{s,t}=\mathbb{X}\_{\psi(s),\psi(t)}\hskip 5.69046pt\forall s,t\in[0,T]\text{ such that }s<t |  |

###### Definition A.8 (Half-Shuffle).

Let Fğ¹F and GğºG be any two linear functionals. We define their half-shuffle product â‰»succeeds\succ on ğ•s,tsubscriptğ•

ğ‘ ğ‘¡\mathbb{X}\_{s,t} as the following (Stratonovich) iterated integral on the real line

|  |  |  |  |
| --- | --- | --- | --- |
| (21) |  | âŸ¨Fâ‰»G,ğ•s,tâŸ©=âˆ«stâŸ¨F,ğ•s,uâŸ©âˆ˜dâ€‹âŸ¨G,ğ•s,uâŸ©delimited-âŸ¨âŸ©succeedsğ¹  ğºsubscriptğ•  ğ‘ ğ‘¡superscriptsubscriptğ‘ ğ‘¡  ğ¹subscriptğ•  ğ‘ ğ‘¢ ğ‘‘  ğºsubscriptğ•  ğ‘ ğ‘¢\langle F\succ G,\mathbb{X}\_{s,t}\rangle=\int\_{s}^{t}\langle F,\mathbb{X}\_{s,u}\rangle\circ d\,\langle G,\mathbb{X}\_{s,u}\rangle |  |

Let ğ”¹ğ”¹\mathbb{B} be a 222-dimensional Brownian motion, defined for example on the interval [0,1]01[0,1]. Consider two linear functionals F={F(K):Kâˆˆâ„d}ğ¹conditional-setsuperscriptğ¹ğ¾ğ¾subscriptâ„ğ‘‘F=\{F^{(K)}:K\in\mathcal{I}\_{d}\} and G={G(K):Kâˆˆâ„d}ğºconditional-setsuperscriptğºğ¾ğ¾subscriptâ„ğ‘‘G=\{G^{(K)}:K\in\mathcal{I}\_{d}\} defined as

|  |  |  |  |
| --- | --- | --- | --- |
| (22) |  | F(K)={1ifÂ â€‹K=(1,2)0otherwisesuperscriptğ¹ğ¾cases1ifÂ ğ¾120otherwiseF^{(K)}=\left\{\begin{array}[]{ll}1&\mbox{if }K=(1,2)\\ 0&\mbox{otherwise}\end{array}\right. |  |

and

|  |  |  |  |
| --- | --- | --- | --- |
| (23) |  | G(K)={1ifÂ â€‹K=(2,1)0otherwisesuperscriptğºğ¾cases1ifÂ ğ¾210otherwiseG^{(K)}=\left\{\begin{array}[]{ll}1&\mbox{if }K=(2,1)\\ 0&\mbox{otherwise}\end{array}\right. |  |

Then the following quantity

|  |  |  |  |
| --- | --- | --- | --- |
| (24) |  | ğ’œs,t=12âŸ¨Fâ‰»Gâˆ’Gâ‰»F,ğ”¹s,tâŸ©\mathcal{A}\_{s,t}=\frac{1}{2}\big{\langle}F\succ G-G\succ F,\mathbb{B}\_{s,t}\big{\rangle} |  |

is the Levy area of the Brownian motion ğ”¹ğ”¹\mathbb{B} on [s,t]âŠ‚[0,1]ğ‘ ğ‘¡01[s,t]\subset[0,1].

#### A.0.1. Expected signature

We will now define the expected signature of a semimartingale.

###### Definition A.9 (Expected signature).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} be a continuous semimartingale, and let ğ•s,t={ğ•s,t(K)âˆˆâ„:Kâˆˆâ„d}subscriptğ•

ğ‘ ğ‘¡conditional-setsuperscriptsubscriptğ•

ğ‘ ğ‘¡ğ¾â„ğ¾subscriptâ„ğ‘‘\mathbb{X}\_{s,t}=\{\mathbb{X}\_{s,t}^{(K)}\in\mathbb{R}:K\in\mathcal{I}\_{d}\} be its signature. The expected signature of Xğ‘‹X is defined by

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[ğ•s,t]:={ğ”¼â€‹[ğ•s,t(K)]âˆˆâ„:Kâˆˆâ„d}.assignğ”¼delimited-[]subscriptğ•  ğ‘ ğ‘¡conditional-setğ”¼delimited-[]superscriptsubscriptğ•  ğ‘ ğ‘¡ğ¾â„ğ¾subscriptâ„ğ‘‘\mathbb{E}[\mathbb{X}\_{s,t}]:=\{\mathbb{E}[\mathbb{X}\_{s,t}^{(K)}]\in\mathbb{R}:K\in\mathcal{I}\_{d}\}. |  |

The expected signature â€“ i.e. the expectation of the iterated integrals ([8](#S2.E8 "In Definition 2.6 (Signature). â€£ 2.3. Signatures â€£ 2. Notation and preliminaries â€£ Sig-SDEs model for quantitative finance.")) â€“ behaves analogously to the moments of random variables, in the sense that under certain assumptions it characterises the law of the stochastic process:

###### Theorem A.10 ((Chevyrev etÂ al., [2016](#bib.bib6))).

Let X:[0,T]â†’â„d:ğ‘‹â†’0ğ‘‡superscriptâ„ğ‘‘X:[0,T]\to\mathbb{R}^{d} be a semimartingale. Then, under certain assumptions (see (Chevyrev
etÂ al., [2016](#bib.bib6))) the expected signature ğ”¼â€‹[ğ•0,T]ğ”¼delimited-[]subscriptğ•

0ğ‘‡\mathbb{E}[\mathbb{X}\_{0,T}] characterises the law of Xğ‘‹X.

## Appendix B Time and Lead-lag transformation

![Refer to caption](/html/2006.00218/assets/leadlag.png)

Figure 4. Lead-lag transformation of a Brownian motion.

\Description

Lead-lag path.

The invariance of the signature of a semimartingale to time reparametrizations allows to handle irregularly sampled sample paths (prices etc.) by completely eliminating the need to retain information about the original time-parametrization. Nonetheless, for the pricing of many options, especially ones resulting from payoffs calculated pathwise (such as integrals for American options), the time represents an important information that we are required to retain. To do so it suffices to augment the state space of the input semimartingale Xğ‘‹X by adding time tğ‘¡t as an extra dimension to get Xtadd-time=(t,Xt)subscriptsuperscriptğ‘‹add-timeğ‘¡ğ‘¡subscriptğ‘‹ğ‘¡X^{\text{add-time}}\_{t}=(t,X\_{t}).

We report another basic transformation that can be applied to semimartingales and that will be useful in the sequel of the paper: the lead-lag transformation. This transformation allows us to write ItÃ´ integrals as linear functions on the signature of the lead-lag transformed path.

###### Definition B.1 (Lead-lag transformation).

Let Z:[0,T]â†’â„d:ğ‘â†’0ğ‘‡superscriptâ„ğ‘‘Z:[0,T]\to\mathbb{R}^{d} be a semimartingale. For each partition D={ti}iâŠ‚[0,T]ğ·subscriptsubscriptğ‘¡ğ‘–ğ‘–0ğ‘‡D=\{t\_{i}\}\_{i}\subset[0,T] of mesh size |D|ğ·|D|, define the piecewise linear path ZD:[0,T]â†’â„2â€‹d:superscriptğ‘ğ·â†’0ğ‘‡superscriptâ„2ğ‘‘Z^{D}:[0,T]\to\mathbb{R}^{2d} given by

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| (25) |  |  | Z2â€‹kâ€‹T/2â€‹nD:=(Ztk,Ztk),assignsuperscriptsubscriptğ‘2ğ‘˜ğ‘‡2ğ‘›ğ·subscriptğ‘subscriptğ‘¡ğ‘˜subscriptğ‘subscriptğ‘¡ğ‘˜\displaystyle Z\_{2kT/2n}^{D}:=(Z\_{t\_{k}},Z\_{t\_{k}}), |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| (26) |  |  | Z(2â€‹k+1)â€‹T/2â€‹nD:=(Ztk,Ztk+1)assignsuperscriptsubscriptğ‘2ğ‘˜1ğ‘‡2ğ‘›ğ·subscriptğ‘subscriptğ‘¡ğ‘˜subscriptğ‘subscriptğ‘¡ğ‘˜1\displaystyle Z\_{(2k+1)T/2n}^{D}:=(Z\_{t\_{k}},Z\_{t\_{k+1}}) |  |

and linear interpolation in between. Figure [4](#A2.F4 "Figure 4 â€£ Appendix B Time and Lead-lag transformation â€£ Sig-SDEs model for quantitative finance.") shows the lead-lag transformation of a Brownian motion. As we see, the lead component leads the lag component, hence the name. The lead component can be seen as the future of the path, and the lag component as the past.

Denote by â„¤Dsuperscriptâ„¤ğ·\mathbb{Z}^{D} the signature of ZDsuperscriptğ‘ğ·Z^{D}. Then, we define the lead-lag transformation of Zğ‘Z, denoted by â„¤Lâ€‹Lsuperscriptâ„¤ğ¿ğ¿\mathbb{Z}^{LL}, as the limit of signatures of â„¤Dsuperscriptâ„¤ğ·\mathbb{Z}^{D}:

|  |  |  |
| --- | --- | --- |
|  | â„¤Lâ€‹L:=lim|D|â†’0â„¤D.assignsuperscriptâ„¤ğ¿ğ¿subscriptâ†’ğ·0superscriptâ„¤ğ·\mathbb{Z}^{LL}:=\lim\_{|D|\rightarrow 0}\mathbb{Z}^{D}. |  |

The work in (Flint
etÂ al., [2016](#bib.bib10)) showed the convergence of this limit and studied some of its properties.

### B.1. Expected signature of the lead-lag Brownian motion

###### Definition B.2.

Let I=(i1,â€¦,in)âˆˆmissingâ€‹I3nğ¼subscriptğ‘–1â€¦subscriptğ‘–ğ‘›missingsubscriptsuperscriptğ¼ğ‘›3I=(i\_{1},\ldots,i\_{n})\in\mathcal{\mathcal{missing}}{I}^{n}\_{3} be a multi-index. We denote by ğ’«â€‹(I)ğ’«ğ¼\mathcal{P}(I) the set of all possible tuples of non-empty multi-indices from â„3nâˆ’1subscriptsuperscriptâ„ğ‘›13\mathcal{I}^{n-1}\_{3} such that their concatenation is equal to Iğ¼I and their length doesnâ€™t exceed 222, i.e.

|  |  |  |
| --- | --- | --- |
|  | ğ’«â€‹(I)={(I1,â€¦,Ik)âˆˆ(â„3nâˆ’1)k:I1âŠ—â€¦âŠ—Ik=Iâ€‹Â andÂ â€‹|Ij|âˆˆ{1,2}}ğ’«ğ¼conditional-setsubscriptğ¼1â€¦subscriptğ¼ğ‘˜superscriptsubscriptsuperscriptâ„ğ‘›13ğ‘˜tensor-productsubscriptğ¼1â€¦subscriptğ¼ğ‘˜ğ¼Â andÂ subscriptğ¼ğ‘—12\mathcal{P}(I)=\{(I\_{1},\ldots,I\_{k})\in(\mathcal{I}^{n-1}\_{3})^{k}:I\_{1}\otimes\ldots\otimes I\_{k}=I\text{ and }|I\_{j}|\in\{1,2\}\} |  |

###### Example B.3.

1. (1)

   ğ’«â€‹((1,2,3))={(1,2,3),(1,(2,3)),((1,2),3)}ğ’«123123123123\mathcal{P}((1,2,3))=\{(1,2,3),(1,(2,3)),((1,2),3)\}.
2. (2)

   ğ’«â€‹((1,3,2,2))={(1,3,2,2),(1,(3,2),2),(1,3,(2,2)),((1,3),2,2),((1,3),(2,2))}\begin{aligned} \mathcal{P}((1,3,2,2))=&\{(1,3,2,2),(1,(3,2),2),(1,3,(2,2)),\\
   &((1,3),2,2),((1,3),(2,2))\}\end{aligned}
3. (3)

   ğ’«â€‹((3,2))={(3,2),((3,2))}ğ’«323232\mathcal{P}((3,2))=\{(3,2),((3,2))\}.

###### Definition B.4 (Exponential of a linear functional).

Let F={F(K)âˆˆâ„:Kâˆˆâ„d}ğ¹conditional-setsuperscriptğ¹ğ¾â„ğ¾subscriptâ„ğ‘‘F=\{F^{(K)}\in\mathbb{R}:K\in\mathcal{I}\_{d}\} be a linear functional. We define the exponential of Fğ¹F as the following linear functional

|  |  |  |  |
| --- | --- | --- | --- |
| (27) |  | expâ¡(F)=(Ã¸)+âˆ‘k=1âˆ1k!â€‹FâŠ—kğ¹italic-Ã¸superscriptsubscriptğ‘˜11ğ‘˜superscriptğ¹tensor-productabsentğ‘˜\exp(F)=(\o)+\sum\_{k=1}^{\infty}\frac{1}{k!}F^{\otimes k} |  |

where for any kâ‰¥1,FâŠ—k=FâŠ—â€¦âŠ—Fformulae-sequenceğ‘˜1superscriptğ¹tensor-productabsentğ‘˜tensor-productğ¹â€¦ğ¹k\geq 1,F^{\otimes k}=F\otimes\ldots\otimes F for kğ‘˜k times.

###### Proposition B.5.

Define the function Î±:â„3â†’â„3:ğ›¼â†’subscriptâ„3subscriptâ„3\alpha:\mathcal{I}\_{3}\to\mathcal{I}\_{3} that maps a multi-index to another multi-index in the following way: âˆ€Iâˆˆâ„3for-allğ¼subscriptâ„3\forall I\in\mathcal{I}\_{3}

|  |  |  |  |
| --- | --- | --- | --- |
| (28) |  | Î±â€‹(I)={(1)ifÂ â€‹I=(1)(2)ifÂ â€‹Iâˆˆ{(2),(3)}âˆ’12â€‹(1)ifÂ â€‹I=(2,3)12â€‹(1)ifÂ â€‹I=(3,2)0â‹…(Ã¸)otherwiseğ›¼ğ¼cases1ifÂ ğ¼12ifÂ ğ¼23121ifÂ ğ¼23121ifÂ ğ¼32â‹…0italic-Ã¸otherwise\alpha(I)=\left\{\begin{array}[]{ll}(1)&\mbox{if }I=(1)\\ (2)&\mbox{if }I\in\{(2),(3)\}\\ -\frac{1}{2}(1)&\mbox{if }I=(2,3)\\ \frac{1}{2}(1)&\mbox{if }I=(3,2)\\ 0\cdot(\o)&\mbox{otherwise}\end{array}\right. |  |

Given a final time Tğ‘‡T define the linear functional ğ„T:=expâ¡(T+T2â€‹(2,2))assignsubscriptğ„ğ‘‡ğ‘‡ğ‘‡222\mathbf{E}\_{T}:=\exp(T+\frac{T}{2}(2,2)). Then we have the explicit closed-form expression for the Expected Signature of the lead-lag Brownian motion: given any multi-index Iâˆˆâ„3ğ¼subscriptâ„3I\in\mathcal{I}\_{3}

|  |  |  |  |
| --- | --- | --- | --- |
| (29) |  | ğ”¼â€‹[ğ•^0,TLâ€‹L,(I)]=âˆ‘(I1,â€¦,Ik)âˆˆğ’«â€‹(I)âŸ¨Î±â€‹(I1)âŠ—â€¦âŠ—Î±â€‹(Ik),ğ„TâŸ©ğ”¼delimited-[]superscriptsubscript^ğ•  0ğ‘‡  ğ¿ğ¿ğ¼subscriptsubscriptğ¼1â€¦subscriptğ¼ğ‘˜ğ’«ğ¼  tensor-productğ›¼subscriptğ¼1â€¦ğ›¼subscriptğ¼ğ‘˜subscriptğ„ğ‘‡\mathbb{E}\left[\mathbb{\widehat{W}}\_{0,T}^{LL,(I)}\right]=\sum\_{(I\_{1},\ldots,I\_{k})\in\mathcal{P}(I)}\mathbf{\langle}\alpha(I\_{1})\otimes\ldots\otimes\alpha(I\_{k}),\mathbf{E}\_{T}\rangle |  |

###### Proof.

Follows from (Lyons
etÂ al., [2019](#bib.bib23), Lemma B.1) and the fact that ğ”¼â€‹[ğ•^0,T]=ğ„Tğ”¼delimited-[]subscript^ğ•

0ğ‘‡subscriptğ„ğ‘‡\mathbb{E}[\widehat{\mathbb{W}}\_{0,T}]=\mathbf{E}\_{T}.
âˆ

###### Example B.6.

If I=(3,2,3)ğ¼323I=(3,2,3), ğ’«â€‹(I)={(3,2,3),((3,2),3),(3,(2,3))}ğ’«ğ¼323323323\mathcal{P}(I)=\{(3,2,3),((3,2),3),(3,(2,3))\}. Hence,

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[ğ•^0,TLâ€‹L,(I)]ğ”¼delimited-[]superscriptsubscript^ğ•  0ğ‘‡  ğ¿ğ¿ğ¼\displaystyle\mathbb{E}\left[\mathbb{\widehat{W}}\_{0,T}^{LL,(I)}\right] | =âŸ¨Î±â€‹(3)âŠ—Î±â€‹(2)âŠ—Î±â€‹(3),ğ„TâŸ©absent  tensor-producttensor-productğ›¼3ğ›¼2ğ›¼3subscriptğ„ğ‘‡\displaystyle=\langle\alpha(3)\otimes\alpha(2)\otimes\alpha(3),\mathbf{E}\_{T}\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +Î±((3,2))âŠ—Î±(3),ğ„TâŸ©\displaystyle\ \ \ +\alpha((3,2))\otimes\alpha(3),\mathbf{E}\_{T}\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +Î±(3)âŠ—Î±((2,3)),ğ„TâŸ©\displaystyle\ \ \ +\alpha(3)\otimes\alpha((2,3)),\mathbf{E}\_{T}\rangle |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =ğ„T(2,2,2)+12â€‹ğ„T(1,2)âˆ’12â€‹ğ„T(2,1).absentsuperscriptsubscriptğ„ğ‘‡22212superscriptsubscriptğ„ğ‘‡1212superscriptsubscriptğ„ğ‘‡21\displaystyle=\mathbf{E}\_{T}^{(2,2,2)}+\frac{1}{2}\mathbf{E}\_{T}^{(1,2)}-\frac{1}{2}\mathbf{E}\_{T}^{(2,1)}. |  |

[â—„](javascript: void(0))
[![ar5iv homepage](/assets/ar5iv.png)](/)
[Feeling  
lucky?](/feeling_lucky)

[Conversion  
report](/log/2006.00218)
[Report  
an issue](https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2006.00218)
[ViewÂ original  
onÂ arXiv](https://arxiv.org/abs/2006.00218)[â–º](javascript: void(0))